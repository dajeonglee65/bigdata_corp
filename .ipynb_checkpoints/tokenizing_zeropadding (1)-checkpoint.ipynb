{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-piaOvGHwGA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#!pip install pytorch_pretrained_bert==0.4.0\n",
    "os.chdir(\"/content/gdrive/My Drive/KorBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "t5I5kR8rFXjT",
    "outputId": "b289641b-ac0a-49a4-c14a-7df57eb1816c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-15613e69-9c39-431f-b0fd-88b7196fcfd6\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-15613e69-9c39-431f-b0fd-88b7196fcfd6\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving labeled_new_0829_1003.xlsx to labeled_new_0829_1003 (5).xlsx\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "makt8MeZSQcm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"labeled_new_0829_1003.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q3kuNtCmon4U"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iRiPf6HF2OZ"
   },
   "outputs": [],
   "source": [
    "# 텍스트 특수부호 제거\n",
    "\n",
    "def cleaned_text(text):\n",
    "  import re\n",
    "  #text = re.sub('\\W+',' ',text)\n",
    "  text = text.replace(' \\\\r','.')\n",
    "  text = text.replace('\\\\r','.')\n",
    "  text = text.replace('\\\\n','.')\n",
    "  \n",
    "  return text\n",
    "\n",
    "\n",
    "def cleaned(text):\n",
    "  text = cleaned_text(text)\n",
    "  for i in range(2,20):\n",
    "    text = text.replace('.'*i,'.')\n",
    "    \n",
    "  return text\n",
    "\n",
    "def preprocess(text):\n",
    "  _filter = re.compile('[^가-힣 0-9 a-z A-Z \\@ \\( \\) \\. \\, \\' \\\" \\! \\?]+')\n",
    "  text = _filter.sub('', text)\n",
    "  return text\n",
    "\n",
    "df['content1'] = df['content'].apply(lambda x : cleaned(x))\n",
    "df['content1'] = df['content1'].apply(lambda x : preprocess(x))\n",
    "df['content1'] = df.content1.apply(lambda x : x.replace('.','. '))\n",
    "\n",
    "\n",
    "a_ls = []\n",
    "for content in df['content1']:\n",
    "  clean = preprocess(content)\n",
    "  a_ls.append(clean)\n",
    "\n",
    "df['content1'] = a_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnkWzC5mEAtv"
   },
   "outputs": [],
   "source": [
    "import collections       # OrderedDict를 위해 호출\n",
    "import re                # 정규표현식\n",
    "import unicodedata       # 한국어 정준분해 및 문자열 확인\n",
    "import six               # Python version 체크\n",
    "import tensorflow as tf  # Tensorflow 파일 불러오기 및 logging\n",
    "import urllib3\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ORwIgHJGlH8r"
   },
   "source": [
    "### 명사, 동사 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "Ly2MwRe-lqRK",
    "outputId": "70e5a3ac-cb04-4ac3-f003-7878bfd7c17c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/8b/3a9e7a8d8cb14ad6afffc3983b7a7322a3a24d94ebc978a70746fcffc085/stanza-1.1.1-py3-none-any.whl (227kB)\n",
      "\r",
      "\u001b[K     |█▍                              | 10kB 20.0MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 20kB 3.0MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 30kB 4.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 40kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 51kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 61kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 71kB 3.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 81kB 4.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 92kB 3.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 102kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 112kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 122kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 133kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 143kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 153kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 163kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 174kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 184kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 194kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 204kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 215kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 225kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 235kB 4.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.6.0+cu101)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.12.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (49.6.0)\n",
      "Installing collected packages: stanza\n",
      "Successfully installed stanza-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t6e_Ad7uloel"
   },
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "4ZG1dDrNluO9",
    "outputId": "124c1bd2-fda8-499b-c064-13220c00cda2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 15.7MB/s]                    \n",
      "2020-08-30 18:20:48 INFO: Downloading these customized packages for language: ko (Korean)...\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | kaist   |\n",
      "| pos       | kaist   |\n",
      "| lemma     | kaist   |\n",
      "| depparse  | kaist   |\n",
      "| pretrain  | kaist   |\n",
      "=======================\n",
      "\n",
      "2020-08-30 18:20:48 INFO: File exists: /root/stanza_resources/ko/tokenize/kaist.pt.\n",
      "2020-08-30 18:20:48 INFO: File exists: /root/stanza_resources/ko/pos/kaist.pt.\n",
      "2020-08-30 18:20:48 INFO: File exists: /root/stanza_resources/ko/lemma/kaist.pt.\n",
      "2020-08-30 18:20:48 INFO: File exists: /root/stanza_resources/ko/depparse/kaist.pt.\n",
      "2020-08-30 18:20:48 INFO: File exists: /root/stanza_resources/ko/pretrain/kaist.pt.\n",
      "2020-08-30 18:20:48 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download('ko', package = 'kaist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "_6HuFunKluM3",
    "outputId": "3947b6c8-e04a-48d1-efae-fcbdb16dfe72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-30 18:20:49 INFO: Loading these models for language: ko (Korean):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "| depparse  | gsd     |\n",
      "=======================\n",
      "\n",
      "2020-08-30 18:20:50 INFO: Use device: gpu\n",
      "2020-08-30 18:20:50 INFO: Loading: tokenize\n",
      "2020-08-30 18:20:50 ERROR: Cannot load model from /root/stanza_resources/ko/tokenize/gsd.pt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-be02dbbff1ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ko'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang, dir, package, processors, logging_level, verbose, use_gpu, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 self.processors[processor_name] = NAME_TO_PROCESSOR_CLASS[processor_name](config=curr_processor_config,\n\u001b[1;32m    112\u001b[0m                                                                                           \u001b[0mpipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                                                                                           use_gpu=self.use_gpu)\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mProcessorRequirementsException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# if there was a requirements issue, add it to list which will be printed at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stanza/pipeline/processor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, pipeline, use_gpu)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_variant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_up_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m# build the final config for the processor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stanza/pipeline/tokenize_processor.py\u001b[0m in \u001b[0;36m_set_up_model\u001b[0;34m(self, config, use_gpu)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_pre_tokenized_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_src\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stanza/models/tokenize/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, vocab, model_file, use_cuda)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# load everything from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# build model from scratch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stanza/models/tokenize/trainer.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot load model from {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/stanza_resources/ko/tokenize/gsd.pt'"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gm_za4-4luKw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "weYgF_VClOGx"
   },
   "outputs": [],
   "source": [
    "def extract_noun(text):\n",
    "    doc = nlp(text)\n",
    "    nouns = []\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            lemma = word.lemma.split('+')\n",
    "            xpos = word.xpos.split('+')\n",
    "            \n",
    "            for tok, pos in zip(lemma, xpos):\n",
    "                if pos.startswith('n') | pos.startswith('v'): # pos[0] == 'n'과 같음\n",
    "                    nouns.append(tok)\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chFD3DVCF14r"
   },
   "outputs": [],
   "source": [
    "vocab_file = 'vocab.korean_morp.list'\n",
    "api_key = 'c149fccd-6639-4026-9fb8-cec175ff934c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uxTT-pX4RaqP"
   },
   "outputs": [],
   "source": [
    "def do_lang ( openapi_key, text ) :\n",
    "    openApiURL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "\t \n",
    "    requestJson = { \"access_key\": openapi_key, \"argument\": { \"text\": text, \"analysis_code\": \"morp\" } }\n",
    "\t \n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request( \"POST\", openApiURL, headers={\"Content-Type\": \"application/json; charset=UTF-8\"}, body=json.dumps(requestJson))\n",
    "    \n",
    "    json_data = json.loads(response.data.decode('utf-8'))\n",
    "    json_result = json_data[\"result\"]\n",
    "    \n",
    "    if json_result == -1:\n",
    "        json_reason = json_data[\"reason\"]\n",
    "        if \"Invalid Access Key\" in json_reason:\n",
    "            logger.info(json_reason)\n",
    "            logger.info(\"Please check the openapi access key.\")\n",
    "            sys.exit()\n",
    "        return \"openapi error - \" + json_reason      \n",
    "    else:\n",
    "        json_data = json.loads(response.data.decode('utf-8'))\n",
    "    \n",
    "        json_return_obj = json_data[\"return_object\"]\n",
    "        \n",
    "        return_result = \"\"\n",
    "        json_sentence = json_return_obj[\"sentence\"]\n",
    "        for json_morp in json_sentence:                        \n",
    "            for morp in json_morp[\"morp\"]:\n",
    "                return_result = return_result+str(morp[\"lemma\"])+\"/\"+str(morp[\"type\"])+\" \"\n",
    "\n",
    "        return return_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TOQhMgoop1Qd"
   },
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "tS-0_ecqJ5LH",
    "outputId": "35e094e3-5d32-4f49-ddbf-b16efa62c1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1003 entries, 0 to 1002\n",
      "Data columns (total 17 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  1003 non-null   int64  \n",
      " 1   media       1003 non-null   object \n",
      " 2   a_num       1003 non-null   int64  \n",
      " 3   title       1003 non-null   object \n",
      " 4   content     1003 non-null   object \n",
      " 5   w_num       1003 non-null   int64  \n",
      " 6   c_source    1003 non-null   int64  \n",
      " 7   a_source    1002 non-null   float64\n",
      " 8   s_num       1003 non-null   int64  \n",
      " 9   v_num       1003 non-null   int64  \n",
      " 10  nf_verb     1003 non-null   int64  \n",
      " 11  s_verb      1003 non-null   int64  \n",
      " 12  reporter    1003 non-null   int64  \n",
      " 13  non_text    1003 non-null   int64  \n",
      " 14  s_rate      999 non-null    float64\n",
      " 15  quality     1003 non-null   int64  \n",
      " 16  content1    1003 non-null   object \n",
      "dtypes: float64(2), int64(11), object(4)\n",
      "memory usage: 133.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5t5bYfNJ3n2"
   },
   "outputs": [],
   "source": [
    "a = df[df['a_num'] == 300627691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "y8bXLV5WKKcs",
    "outputId": "96744269-1d4c-4550-8418-4ae988b74be5"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a42f6267f21f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'text'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "12Sg6jsNRkCS"
   },
   "outputs": [],
   "source": [
    "text = do_lang(api_key,'검찰에 따르면 A씨는 2017년 11월 13일 술에 취한 B씨를 대신해 운전을 해주다가 대리비 다툼으로 하차했다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "a9t2BqQQRpo9",
    "outputId": "ad7d18e9-1c6c-4548-f913-692d02be5ab8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'검찰/NNG 에/JKB 따르/VV 면/EC A/SL 씨/NNB 는/JX 2017/SN 년/NNB 11/SN 월/NNB 13/SN 일/NNB 술/NNG 에/JKB 취하/VV ㄴ/ETM B/SL 씨/NNB 를/JKO 대신/NNG 하/XSV 어/EC 운전/NNG 을/JKO 하/VV 어/EC 주/VX 다가/EC 대리비/NNG 다툼/NNG 으로/JKB 하차/NNG 하/XSV 었/EP 다/EF ./SF '"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lY9sqU5AZG60"
   },
   "outputs": [],
   "source": [
    "from tokenization_morp import FullTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "56nsre4EuTPn"
   },
   "outputs": [],
   "source": [
    "# FullTokenizer\n",
    "ftk = FullTokenizer(vocab_file, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "UQbmsoXdvhmm",
    "outputId": "34e3629f-796c-494d-d8dc-44813d3d6f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['송', '주', '현/NNP_', '기자/NNG_', '왼쪽/NNG_', '위/NNG_', '부터/JX_', ')/SS_', '김', '운', '용/NNP_', ',/SP_', '이현', '옥/NNP_', ',/SP_', '이', '흥', '민/NNP_', ',/SP_', '노', '양', '호/NNP_', ',/SP_', '정', '종', '현/NNP_', ',/SP_', '신', '승', '일/NNP_', './SF_', '특례/NNG_', '시/NNB_', '지정/NNG_', '을/JKO_', '앞두/VV_', 'ㄴ/ETM_', '105/SN_', '만/NR_', '고양', '시/NNP_', '의/JKG_', '발전/NNG_', '을/JKO_', '위하/VV_', '어/EC_', '땀/NNG_', '과/JC_', '열정/NNG_', '을/JKO_', '쏟/VV_', '아/EC_', '오/VX_', 'ㄴ/ETM_', '6/SN_', '명/NNB_', '의/JKG_', '공직/NNG_', '자/XSN_', '(/SS_', '서기/NNG_', '관/XSN_', ')/SS_', '들/XSN_', '이/JKS_', '아름/NNG_', '답/XSA_', 'ㄴ/ETM_', '퇴장/NNG_', '을/JKO_', '앞두/VV_', '고/EC_', '있/VX_', '다/EF_', './SF_', '경기/NNP_', '북부/NNG_', '의/JKG_', '중심/NNG_', '도시/NNG_', '이/VCP_', 'ㄴ/ETM_', '고양', '시/NNP_', '가/JKC_', '되/VV_', '기/ETN_', '까지/JX_', '쉼', '/VV_', '없이/MAG_', '달려오/VV_', '았/EP_', '던/ETM_', '이/NP_', '들/XSN_', '은/JX_', '이제/MAG_', '후배/NNG_', '들/XSN_', '에게/JKB_', '자리/NNG_', '를/JKO_', '물', '려주/VV_', '고/EC_', '인생/NNG_', '2/SN_', '막', '/NNB_', '을/JKO_', '준비/NNG_', '중/NNB_', '이/VCP_', '다/EF_', './SF_', '김', '운', '용/NNP_', '고양', '시/NNP_', '푸', '른/NNP_', '도시/NNG_', '사업/NNG_', '소장/NNG_', '은/JX_', '1983/SN_', '년/NNB_', '공직/NNG_', '에/JKB_', '입', '문/NNG_', '하/XSV_', '어/EC_', '고양', '시/NNP_', '가/JKS_', '자연/NNG_', '을/JKO_', '품/VV_', '은/ETM_', '도시/NNG_', '가/JKC_', '되/VV_', 'ㄹ/ETM_', '수/NNB_', '있/VA_', '도록/EC_', '많/VA_', '은/ETM_', '연구/NNG_', '와/JC_', '노력/NNG_', '을/JKO_', '기울이/VV_', '어/EC_', '오/VX_', '았/EP_', '다/EF_', './SF_', '지나/VV_', 'ㄴ/ETM_', '28/SN_', '일/NNB_', '명예/NNG_', '퇴직/NNG_', '하/XSV_', 'ㄴ/ETM_', '그/NP_', '는/JX_', '산', '림/NNG_', '보호/NNG_', '유', '공/NNG_', '을/JKO_', '인정/NNG_', '받/XSV_', '아/EC_', '받/VV_', '은/ETM_', '산', '림', '청장/NNG_', '표', '창/NNG_', '을/JKO_', '비롯하/VV_', '어/EC_', ',/SP_', '국무/NNG_', '총리/NNG_', '와/JC_', '국방/NNG_', '부/NNG_', '장관/NNG_', ',/SP_', '도/NNG_', '지사/NNG_', '표', '창/NNG_', '들/XSN_', '이/JKS_', '묵', '묵', '히/MAG_', '업무/NNG_', '에/JKB_', '충실/NNG_', '하/XSA_', '어/EC_', '오/VX_', 'ㄴ/ETM_', '그/NP_', '의/JKG_', '공직/NNG_', '생활/NNG_', '을/JKO_', '보이/VV_', '어/EC_', '주/VX_', 'ㄴ다/EF_', './SF_', '40/SN_', '년/NNB_', '세월/NNG_', '동안/NNG_', '고양', '시/NNP_', '를/JKO_', '지키/VV_', '어/EC_', '오/VX_', 'ㄴ/ETM_', '이현', '옥/NNP_', '교육/NNG_', '문화/NNG_', '국장/NNG_', '도/JX_', '공직/NNG_', '을/JKO_', '마무리/NNG_', '하/XSV_', '기/ETN_', '위하/VV_', '어/EC_', '공로/NNG_', '연수/NNG_', '에/JKB_', '들어가/VV_', 'ㄴ다/EF_', './SF_', '부드럽/VA_', '고/EC_', '섬', '세/NNG_', '하/XSA_', 'ㄴ/ETM_', '그/NP_', '의/JKG_', '업무/NNG_', '스타일/NNG_', '은/JX_', '후배/NNG_', '들/XSN_', '에게/JKB_', '도/JX_', '많/VA_', '은/ETM_', '신뢰/NNG_', '와/JC_', '박수/NNG_', '를/JKO_', '받/VV_', '아/EC_', '오/VX_', '았/EP_', '다/EF_', './SF_', '정부/NNG_', '부처/NNG_', '등/NNB_', '으로부터/JKB_', '표', '창/NNG_', '을/JKO_', '13/SN_', '회/NNB_', '나/JX_', '받/VV_', '은/ETM_', '이', '흥', '민/NNP_', '민생/NNG_', '경제/NNG_', '국장/NNG_', '역시/MAG_', '고양', '시/NNP_', '에게/JKB_', '는/JX_', '아', '깝/VA_', 'ㄴ/ETM_', '인재/NNG_', '이/VCP_', '다/EF_', './SF_', '그/NP_', '는/JX_', '고양/NNP_', '지역/NNG_', '주민/NNG_', '들/XSN_', '이/JKS_', '원활/NNG_', '하/XSA_', 'ㄴ/ETM_', '생활/NNG_', '지원/NNG_', '을/JKO_', '받/VV_', '을/ETM_', '수/NNB_', '있/VA_', '도록/EC_', '늘/MAG_', '주민/NNG_', '들/XSN_', '과/JKB_', '함께/MAG_', '하/XSV_', '며/EC_', '고양', '시/NNP_', '행정/NNG_', '에/JKB_', '현장/NNG_', '의/JKG_', '목/NNG_', '소리/NNG_', '를/JKO_', '담', '아오/VV_', '았/EP_', '다/EF_', './SF_', '노', '양', '호/NNP_', '여성/NNG_', '가족/NNG_', '국장/NNG_', '도/JX_', '고양/NNP_', '지역/NNG_', '발전/NNG_', '을/JKO_', '위하/VV_', '어/EC_', '40/SN_', '년/NNB_', '넘/VV_', '게/EC_', '예산/NNG_', '법무/NNG_', '과/XSN_', '등/NNB_', '주요/NNG_', '부서/NNG_', '에서/JKB_', '활약/NNG_', '하/XSV_', '어/EC_', '오/VX_', '았/EP_', '다/EF_', './SF_', '특히/MAG_', '교육/NNG_', '지원/NNG_', '과장/NNG_', '시절/NNG_', '에/JKB_', '는/JX_', '고양/NNP_', '지역/NNG_', '학생/NNG_', '들/XSN_', '의/JKG_', '교육/NNG_', '환경/NNG_', '개선/NNG_', '을/JKO_', '위하/VV_', '어/EC_', '노력/NNG_', '을/JKO_', '아끼/VV_', '지/EC_', '않/VX_', '았/EP_', '다/EF_', './SF_', '농업/NNG_', '분야/NNG_', '전문/NNG_', '가/XSN_', '이/VCP_', 'ㄴ/ETM_', '정', '종', '현/NNP_', '농업/NNG_', '기술/NNG_', '센터/NNG_', '소장/NNG_', '도/JX_', '고양/NNP_', '지역/NNG_', '의/JKG_', '농업/NNG_', '이/JKS_', '활성/NNG_', '화/XSN_', '되/XSV_', '기/ETN_', '까지/JX_', '많/VA_', '은/ETM_', '자', '취/NNG_', '를/JKO_', '남기/VV_', '었/EP_', '다/EF_', './SF_', '2016/SN_', '년/NNB_', '에/JKB_', '는/JX_', '녹', '조', '근', '정/NNP_', '훈장/NNG_', '영', '예/NNG_', '를/JKO_', '받/VV_', '기/ETN_', '도/JX_', '하/VX_', '었/EP_', '다/EF_', './SF_', '신', '승', '일/NNP_', '시민/NNG_', '안전/NNG_', '주택/NNG_', '국장/NNG_', '도/JX_', '이/NP_', '들/XSN_', '과/JKB_', '함께/MAG_', '공로/NNG_', '연수/NNG_', '에/JKB_', '들어가/VV_', 'ㄴ다/EF_', './SF_', '신/NNP_', '국장/NNG_', '은/JX_', '경기/NNP_', '북부/NNG_', '중심/NNG_', '도시/NNG_', '가/JKC_', '되/VV_', 'ㄴ/ETM_', '고양', '시/NNP_', '의/JKG_', '미래/NNG_', '설계/NNG_', '를/JKO_', '담당/NNG_', '하/XSV_', '어/EC_', '오/VX_', 'ㄴ/ETM_', '일', '등/NNG_', '공신/NNG_', '인물/NNG_', '이/VCP_', '다/EF_', './SF_', '그/MM_', '동안/NNG_', '고양', '시/NNP_', '발전/NNG_', '을/JKO_', '위하/VV_', '어서/EC_', '는/JX_', '해당/NNG_', '업무/NNG_', '를/JKO_', '담당/NNG_', '하/XSV_', '는/ETM_', '공직/NNG_', '자/XSN_', '역시/MAG_', '계속/NNG_', '적/XSN_', '이/VCP_', 'ㄴ/ETM_', '발전/NNG_', '이/JKS_', '필요/NNG_', '하/XSA_', '다고/EC_', '강조/NNG_', '하/XSV_', '어/EC_', '오/VX_', 'ㄴ/ETM_', '그/NP_', '는/JX_', '2011/SN_', '년/NNB_', '에/JKB_', '는/JX_', '경', '희', '대/NNP_', '에서/JKB_', '경영/NNG_', '학/XSN_', '을/JKO_', '전공/NNG_', '하/XSV_', '고/EC_', '2014/SN_', '년/NNB_', '에/JKB_', '는/JX_', '고려대/NNP_', '에서/JKB_', '건축/NNG_', '공학/NNG_', '과/NNG_', '석사/NNG_', '과정/NNG_', '을/JKO_', '마치/VV_', '었/EP_', '다/EF_', './SF_', '풍부하/VA_', 'ㄴ/ETM_', '학', '식/NNG_', '과/JC_', '오랜/MM_', '행정/NNG_', '경험/NNG_', '을/JKO_', '통하/VV_', '어/EC_', '쌓/VV_', '은/ETM_', '노/NNG_', '하우/NNG_', ',/SP_', '업무/NNG_', '를/JKO_', '추진/NNG_', '하/XSV_', '는/ETM_', '뜨겁/VA_', 'ㄴ/ETM_', '열정/NNG_', ',/SP_', '뛰어나/VA_', 'ㄴ/ETM_', '리', '더', '쉽', '/NNG_', ',/SP_', '신/NNP_', '국장/NNG_', '이/JKS_', '공직/NNG_', '사회/NNG_', '후배/NNG_', '들/XSN_', '에게/JKB_', '받/VV_', '는/ETM_', '평가/NNG_', '이/VCP_', '다/EF_', './SF_', '고양', '시/NNP_', '관계/NNG_', '자/XSN_', '는/JX_', '1959/SN_', '년/NNB_', '생/XSN_', '선배/NNG_', '들/XSN_', '이/VCP_', 'ㄴ/ETM_', '여섯/NR_', '분/NNB_', '에게/JKB_', '많/VA_', '은/ETM_', '감사/NNG_', '와/JC_', '응원/NNG_', '을/JKO_', '드리/VV_', 'ㄴ다며/EC_', '이제/MAG_', '고양', '시/NNP_', '의/JKG_', '다음/NNG_', '일/NNG_', '은/JX_', '후배/NNG_', '들/XSN_', '에게/JKB_', '맡기/VV_', '고/EC_', '새롭/VA_', 'ㄴ/ETM_', '인생/NNG_', '에서/JKB_', '또/MAG_', '다른/MM_', '성공/NNG_', '이/JKS_', '있/VA_', '기/ETN_', 'ㄹ/JKO_', '기원/NNG_', '하/XSV_', 'ㄴ다고/EC_', '말/NNG_', '하/XSV_', '었/EP_', '다/EF_', './SF_', '고양', '유', '제', '원/NNP_', '송', '주', '현/NNP_', '기자/NNG_', './SF_']\n"
     ]
    }
   ],
   "source": [
    "print(ftk.tokenize(do_lang(api_key,df.content1[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H7I3T_tSrR3R"
   },
   "outputs": [],
   "source": [
    "def convert_to_unicode(text):\n",
    "    # Python version이 3.x일 때,\n",
    "    # type(text)이 `bytes`일 경우, utf-8로 변환\n",
    "    if six.PY3:\n",
    "        if isinstance(text, str):\n",
    "            return text\n",
    "        elif isinstance(text, bytes):\n",
    "            return text.decode(\"utf-8\", \"ignore\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    # Python version이 2.x일 때,\n",
    "    # type(text)이 `str`일 경우, utf-8로 변환\n",
    "    elif six.PY2:\n",
    "        if isinstance(text, str):\n",
    "            return text.decode(\"utf-8\", \"ignore\")\n",
    "        elif isinstance(text, unicode):\n",
    "            return text\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "    # Python 3.x, 2.x만 허용!\n",
    "    else:\n",
    "        raise ValueError(\"Not running on Python2 or Python 3?\")\n",
    "        \n",
    "        \n",
    "def _load_vocab(vocab_file):\n",
    "    # 단어 사전을 저장할 OrderedDict 객체 생성\n",
    "    vocab = collections.OrderedDict()\n",
    "    index = 0\n",
    "    with tf.io.gfile.GFile(vocab_file, 'r') as reader:\n",
    "        while True:\n",
    "            # Binary Text를 unicode(utf-8)로 decode.\n",
    "            token = convert_to_unicode(reader.readline())\n",
    "            if not token: break\n",
    "            if ((token.find('n_iters=') == 0) or\n",
    "                (token.find('max_length=') == 0)):\n",
    "                continue\n",
    "            token = token.split('\\t')[0]\n",
    "            token = token.strip()\n",
    "            # 토큰과 해당 index를 기록\n",
    "            vocab[token] = index\n",
    "            index += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tdrtzNADfDRA",
    "outputId": "4fc67e50-7b64-4ae9-deaf-46d78d2d7790"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(FullTokenizer(vocab_file,do_lower_case=False).tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5DbtDZcQcHf"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "12UgUMAA_Emd",
    "outputId": "1ffe2bde-151f-44e7-abae-f18a9573ec84"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media</th>\n",
       "      <th>a_num</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>w_num</th>\n",
       "      <th>c_source</th>\n",
       "      <th>a_source</th>\n",
       "      <th>s_num</th>\n",
       "      <th>v_num</th>\n",
       "      <th>nf_verb</th>\n",
       "      <th>s_verb</th>\n",
       "      <th>reporter</th>\n",
       "      <th>non_text</th>\n",
       "      <th>s_rate</th>\n",
       "      <th>quality</th>\n",
       "      <th>content1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>경기일보</td>\n",
       "      <td>329412764</td>\n",
       "      <td>105만 고양시 발전 이끌어온 서기관 6명, 아름다운 퇴장</td>\n",
       "      <td>송주현 기자 왼쪽 위부터)김운용, 이현옥, 이흥민, 노양호, 정종현, 신승일 \\r\\...</td>\n",
       "      <td>1176</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>송주현 기자 왼쪽 위부터)김운용, 이현옥, 이흥민, 노양호, 정종현, 신승일. 특례...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경기일보</td>\n",
       "      <td>329412768</td>\n",
       "      <td>고양시 새해에는 교통난 해결될까 관심</td>\n",
       "      <td>송주현 기자 \\r\\n고양시민들이 출·퇴근길 겪고 있는 교통 불편이 새해에는 개선될 ...</td>\n",
       "      <td>1197</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>1</td>\n",
       "      <td>송주현 기자. 고양시민들이 출퇴근길 겪고 있는 교통 불편이 새해에는 개선될 수 있을...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>경기일보</td>\n",
       "      <td>329412771</td>\n",
       "      <td>안양시, 오는 2022년까지 일자리 10만6천개 창출 목표</td>\n",
       "      <td>박준상 기자 \\r\\n기해년을 맞은 안양시가 향후 4년간 일자리 10만6천여개 창출을...</td>\n",
       "      <td>884</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>박준상 기자. 기해년을 맞은 안양시가 향후 4년간 일자리 10만6천여개 창출을 목표...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경기일보</td>\n",
       "      <td>329412773</td>\n",
       "      <td>오명근 의원, 평택 고평지구 학군조정을 위한 의견수렴 간담회 개최</td>\n",
       "      <td>최현호 기자 \\r\\n경기도의회 건설교통위원회 소속 오명근 의원(더불어민주당ㆍ평택4)...</td>\n",
       "      <td>759</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>최현호 기자. 경기도의회 건설교통위원회 소속 오명근 의원(더불어민주당평택4)은 지난...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>경기일보</td>\n",
       "      <td>329412774</td>\n",
       "      <td>화성시, 2020년까지 신규 일자리 13만개 창출...일자리 대책 청사진 공개</td>\n",
       "      <td>홍완식 기자 \\r\\n화성시가 새해를 맞아 민선7기 지역맞춤형 일자리 대책의 청사진을...</td>\n",
       "      <td>937</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>홍완식 기자. 화성시가 새해를 맞아 민선7기 지역맞춤형 일자리 대책의 청사진을 공개...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   media      a_num  ... quality                                           content1\n",
       "0  경기일보   329412764  ...       1  송주현 기자 왼쪽 위부터)김운용, 이현옥, 이흥민, 노양호, 정종현, 신승일. 특례...\n",
       "1  경기일보   329412768  ...       1  송주현 기자. 고양시민들이 출퇴근길 겪고 있는 교통 불편이 새해에는 개선될 수 있을...\n",
       "2  경기일보   329412771  ...       1  박준상 기자. 기해년을 맞은 안양시가 향후 4년간 일자리 10만6천여개 창출을 목표...\n",
       "3  경기일보   329412773  ...       1  최현호 기자. 경기도의회 건설교통위원회 소속 오명근 의원(더불어민주당평택4)은 지난...\n",
       "4  경기일보   329412774  ...       1  홍완식 기자. 화성시가 새해를 맞아 민선7기 지역맞춤형 일자리 대책의 청사진을 공개...\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:,1:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QzLg6mSY_0jX"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1QFgcNn_8S0"
   },
   "outputs": [],
   "source": [
    "morph_vocab = _load_vocab(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQvafPyCDVmn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def toktok1(df):\n",
    "\n",
    "\n",
    "  maxlen = 512\n",
    "\n",
    "  ipt_ids1 = []\n",
    "  ipt_ids2 = []\n",
    "  ipt_ids3 = []\n",
    "  ipt_ids4 = []\n",
    "  ipt_ids5 = []\n",
    "\n",
    "  ipt_mask1 = []\n",
    "  ipt_mask2 = []\n",
    "  ipt_mask3 = []\n",
    "  ipt_mask4 = []\n",
    "  ipt_mask5 = []\n",
    "   \n",
    "  sgm_ids1 = []\n",
    "  sgm_ids2 = []\n",
    "  sgm_ids3 = []\n",
    "  sgm_ids4 = []\n",
    "  sgm_ids5 = []\n",
    "\n",
    "\n",
    "  \n",
    "  for content in tqdm(range(len(df['content1']))):\n",
    "    text = do_lang(api_key, content)\n",
    "    split_tokens = ftk.tokenize(text)\n",
    "    k = round(len(split_tokens)/5)\n",
    "    spt1 = split_tokens[:k]\n",
    "    spt2 = split_tokens[k:(2*k)]\n",
    "    spt3 = split_tokens[(2*k):(3*k)]\n",
    "    spt4 = split_tokens[(3*k):]\n",
    "    spt5 = split_tokens[(4*k):]\n",
    "\n",
    "    tokens1 = [\"[CLS]\"] + spt1 + [\"[SEP]\"]\n",
    "    tokens2 = [\"[CLS]\"] + spt2 + [\"[SEP]\"]\n",
    "    tokens3 = [\"[CLS]\"] + spt3 + [\"[SEP]\"]\n",
    "    tokens4 = [\"[CLS]\"] + spt4 + [\"[SEP]\"]\n",
    "    tokens5 = [\"[CLS]\"] + spt5 + [\"[SEP]\"]\n",
    "\n",
    "    input_ids1 = [morph_vocab[token] for token in tokens1]\n",
    "    input_ids2 = [morph_vocab[token] for token in tokens2]\n",
    "    input_ids3 = [morph_vocab[token] for token in tokens3]\n",
    "    input_ids4 = [morph_vocab[token] for token in tokens4]\n",
    "    input_ids5 = [morph_vocab[token] for token in tokens5]\n",
    "\n",
    "    input_mask1 = [1] * len(input_ids1)\n",
    "    input_mask2 = [1] * len(input_ids2)\n",
    "    input_mask3 = [1] * len(input_ids3)\n",
    "    input_mask4 = [1] * len(input_ids4)\n",
    "    input_mask5 = [1] * len(input_ids5)\n",
    "\n",
    "    segment_ids1 = [0] * len(tokens1)\n",
    "    segment_ids2 = [0] * len(tokens2)\n",
    "    segment_ids3 = [0] * len(tokens3)\n",
    "    segment_ids4 = [0] * len(tokens4)\n",
    "    segment_ids5 = [0] * len(tokens5)\n",
    "    \n",
    "    padding1 = [0] * (maxlen - len(input_ids1))\n",
    "    padding2 = [0] * (maxlen - len(input_ids2))\n",
    "    padding3 = [0] * (maxlen - len(input_ids3))\n",
    "    padding4 = [0] * (maxlen - len(input_ids4))\n",
    "    padding5 = [0] * (maxlen - len(input_ids5))\n",
    "  \n",
    "    input_ids1 += padding1\n",
    "    input_ids2 += padding2\n",
    "    input_ids3 += padding3\n",
    "    input_ids4 += padding4\n",
    "    input_ids5 += padding5\n",
    "    \n",
    "    input_mask1 += padding1\n",
    "    input_mask2 += padding2\n",
    "    input_mask3 += padding3\n",
    "    input_mask4 += padding4\n",
    "    input_mask5 += padding5\n",
    "\n",
    "    segment_ids1 += padding1\n",
    "    segment_ids2 += padding2\n",
    "    segment_ids3 += padding3\n",
    "    segment_ids4 += padding4\n",
    "    segment_ids5 += padding5\n",
    "\n",
    "    ipt_ids1.append(input_ids1) # 토큰\n",
    "    ipt_ids2.append(input_ids2)\n",
    "    ipt_ids3.append(input_ids3)\n",
    "    ipt_ids4.append(input_ids4)\n",
    "    ipt_ids5.append(input_ids5)\n",
    "\n",
    "    ipt_mask1.append(input_mask1)\n",
    "    ipt_mask2.append(input_mask2)\n",
    "    ipt_mask3.append(input_mask3)\n",
    "    ipt_mask4.append(input_mask4)\n",
    "    ipt_mask5.append(input_mask5)\n",
    "\n",
    "\n",
    "    sgm_ids1.append(segment_ids1) # 문장 분류\n",
    "    sgm_ids2.append(segment_ids2)\n",
    "    sgm_ids3.append(segment_ids3)\n",
    "    sgm_ids4.append(segment_ids4)\n",
    "    sgm_ids5.append(segment_ids5)\n",
    "\n",
    "\n",
    "  ar_tok1 = np.array(ipt_ids1)\n",
    "  ar_tok2 = np.array(ipt_ids2)\n",
    "  ar_tok3 = np.array(ipt_ids3)\n",
    "  ar_tok4 = np.array(ipt_ids4)\n",
    "  ar_tok5 = np.array(ipt_ids5)\n",
    "\n",
    "\n",
    "  ar_seg1 = np.array(sgm_ids1)\n",
    "  ar_seg2 = np.array(sgm_ids2)\n",
    "  ar_seg3 = np.array(sgm_ids3)\n",
    "  ar_seg4 = np.array(sgm_ids4)\n",
    "  ar_seg5 = np.array(sgm_ids5)\n",
    "    \n",
    "    \n",
    "  train_x = [[ar_tok1[:900], ar_tok2[:900], ar_tok3[:900], ar_tok4[:900], ar_tok5[:900]], [ar_seg1[:900], ar_seg2[:900], ar_seg3[:900], ar_seg4[:900], ar_seg5[:900]]]\n",
    "\n",
    "  test_x = [[ar_tok1[900:], ar_tok2[900:], ar_tok3[900:], ar_tok4[900:], ar_tok5[900:]], [ar_seg1[900:], ar_seg2[900:], ar_seg3[900:], ar_seg4[900:], ar_seg5[900:]]]\n",
    "\n",
    "  y = df['quality']\n",
    "  train_y = np.array(y[:900])\n",
    "  test_y = np.array(y[900:])\n",
    "\n",
    "  return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "51yjut70HuXr",
    "outputId": "1002893e-51a8-4e0b-e659-ae0af15d1339"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [04:22<00:00,  3.82it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = toktok1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fLgPrL9GJ053",
    "outputId": "2af31781-4258-48e9-c19d-3896fbee454b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "Pzf1xPdSGCHk",
    "outputId": "3adb195f-b160-4025-9f4e-4f03ccdbc0cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-bert\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/7f/95fabd29f4502924fa3f09ff6538c5a7d290dfef2c2fe076d3d1a16e08f0/keras-bert-0.86.0.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-bert) (1.18.5)\n",
      "Requirement already satisfied: Keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from keras-bert) (2.4.3)\n",
      "Collecting keras-transformer>=0.38.0\n",
      "  Downloading https://files.pythonhosted.org/packages/89/6c/d6f0c164f4cc16fbc0d0fea85f5526e87a7d2df7b077809e422a7e626150/keras-transformer-0.38.0.tar.gz\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras-bert) (3.13)\n",
      "Collecting keras-pos-embd>=0.11.0\n",
      "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
      "Collecting keras-multi-head>=0.27.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n",
      "Collecting keras-layer-normalization>=0.14.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
      "Collecting keras-position-wise-feed-forward>=0.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
      "Collecting keras-embed-sim>=0.8.0\n",
      "  Downloading https://files.pythonhosted.org/packages/57/ef/61a1e39082c9e1834a2d09261d4a0b69f7c818b359216d4e1912b20b1c86/keras-embed-sim-0.8.0.tar.gz\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras>=2.4.3->keras-bert) (1.15.0)\n",
      "Collecting keras-self-attention==0.46.0\n",
      "  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n",
      "Building wheels for collected packages: keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
      "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-bert: filename=keras_bert-0.86.0-cp36-none-any.whl size=34145 sha256=dd2459bb35b2fcdd679f9b4cbd67db30596ad7fb810e361a29db92877f1f60ad\n",
      "  Stored in directory: /root/.cache/pip/wheels/66/f0/b1/748128b58562fc9e31b907bb5e2ab6a35eb37695e83911236b\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-cp36-none-any.whl size=12942 sha256=2a3e34f5783e6ba512436abde0347169bdd97e73550fd079c98ae45e1264a551\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/fb/3a/37b2b9326c799aa010ae46a04ddb04f320d8c77c0b7e837f4e\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=d3d838096e84b33a1963ca39cfaed18f808bd95b328ded999d0722e95090da12\n",
      "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp36-none-any.whl size=15612 sha256=f087aad627f901da6ffd3538010f28ba34b371e144894a91e954d3195f08a47b\n",
      "  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=e593fec44eb5d46e65ddb00325c6edf332982dafb0305b2acddd93e22de89d1f\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5626 sha256=5e9f17cd76038fc50feae64472f899aa5ff2d90929b1c8e0b252201838a5e2e1\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-cp36-none-any.whl size=4559 sha256=9754f0105efbeb0430e32f4924cea1a78671c3e56fad90165a5bb3d2c539e1d5\n",
      "  Stored in directory: /root/.cache/pip/wheels/49/45/8b/c111f6cc8bec253e984677de73a6f4f5d2f1649f42aac191c8\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=81d631c7170d4bdb3bf2e76ec405806aabd10e3690d815aca0d3bcd440b4220a\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n",
      "Successfully built keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
      "Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert\n",
      "Successfully installed keras-bert-0.86.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tW6emqVlGGD2"
   },
   "outputs": [],
   "source": [
    "import keras_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mR4alLBF0No"
   },
   "outputs": [],
   "source": [
    "#!pip install keras-bert\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras_bert import load_trained_model_from_checkpoint, load_vocabulary\n",
    "#from keras_bert import Tokenizer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "#from transformers import *\n",
    "\n",
    "#from keras_radam import RAdam\n",
    "\n",
    "\n",
    "config_path = '/content/gdrive/My Drive/KorBERT/bert_config.json'\n",
    "checkpoint_path = '/content/gdrive/My Drive/KorBERT/model.ckpt'\n",
    "SEQ_LEN = 512\n",
    "\n",
    "layer_num = 12\n",
    "\n",
    "model = load_trained_model_from_checkpoint(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    "    training=True,\n",
    "    trainable=True,\n",
    "    seq_len=SEQ_LEN,)\n",
    "#model = TFBertForPreTraining.from_pretrained(checkpoint_path)\n",
    "#model = TFBertModel.from_pretrained(checkpoint_path, from_pt=True)\n",
    "#token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n",
    "#mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n",
    "#segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n",
    "#bert_outputs = model([token_inputs, mask_inputs, segment_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "oHxNtklJGR1u",
    "outputId": "051fa081-fb13-4c1c-96b6-3b8a93d89719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 512, 768), ( 23308032    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 512, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 512, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 512, 768)     393216      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 512, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 512, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 768)    2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 512, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 512, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 512, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 512, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 512, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 512, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Dense (Dense)               (None, 512, 768)     590592      Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Norm (LayerNormalization)   (None, 512, 768)     1536        MLM-Dense[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Sim (EmbeddingSimilarity)   (None, 512, 30349)   30349       MLM-Norm[0][0]                   \n",
      "                                                                 Embedding-Token[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Masked (InputLayer)       [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "MLM (Masked)                    (None, 512, 30349)   0           MLM-Sim[0][0]                    \n",
      "                                                                 Input-Masked[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "NSP (Dense)                     (None, 2)            1538        NSP-Dense[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,973,391\n",
      "Trainable params: 109,973,391\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "R5xDvnWqt3N1",
    "outputId": "abc3fbd4-c880-41da-ebbc-027e625bd6fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_pretrained_bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\r",
      "\u001b[K     |██▋                             | 10kB 15.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 20kB 3.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 30kB 3.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 40kB 4.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 51kB 4.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 61kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 71kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 81kB 5.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 92kB 5.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 102kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 112kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 122kB 5.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 133kB 5.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.48)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.48)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->pytorch_pretrained_bert) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->pytorch_pretrained_bert) (0.15.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.48->boto3->pytorch_pretrained_bert) (1.15.0)\n",
      "Installing collected packages: pytorch-pretrained-bert\n",
      "Successfully installed pytorch-pretrained-bert-0.6.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_pretrained_bert\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VCma6p5LHq-u"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvpuZNLGG8TA"
   },
   "outputs": [],
   "source": [
    "def get_bert_finetuning_model(model):\n",
    "  inputs = model.inputs[:2]\n",
    "  dense = model.layers[-3].output\n",
    "\n",
    "\n",
    "  outputs = keras.layers.Dense(1, activation='sigmoid',kernel_initializer=keras.initializers.TruncatedNormal(stddev=0.02),\n",
    "                              name = 'real_output')(dense)\n",
    "\n",
    "\n",
    "\n",
    "  bert_model = keras.models.Model(inputs, outputs)\n",
    "  bert_model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(),\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "  \n",
    "  return bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dHnITlgIHfc4"
   },
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eEMENS-GG8Y_",
    "outputId": "2dfff845-d66e-440d-93c9-9a0858053f7e"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"6895pt\" viewBox=\"0.00 0.00 549.50 7637.00\" width=\"496pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(.9028 .9028) rotate(0) translate(4 7633)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-7633 545.5,-7633 545.5,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 139650829171120 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>139650829171120</title>\n",
       "<polygon fill=\"none\" points=\"110.5,-7592.5 110.5,-7628.5 270.5,-7628.5 270.5,-7592.5 110.5,-7592.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190.5\" y=\"-7606.8\">Input-Token: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139650829170504 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>139650829170504</title>\n",
       "<polygon fill=\"none\" points=\"72,-7519.5 72,-7555.5 309,-7555.5 309,-7519.5 72,-7519.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190.5\" y=\"-7533.8\">Embedding-Token: TokenEmbedding</text>\n",
       "</g>\n",
       "<!-- 139650829171120&#45;&gt;139650829170504 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>139650829171120-&gt;139650829170504</title>\n",
       "<path d=\"M190.5,-7592.4551C190.5,-7584.3828 190.5,-7574.6764 190.5,-7565.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"194.0001,-7565.5903 190.5,-7555.5904 187.0001,-7565.5904 194.0001,-7565.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139650829205344 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>139650829205344</title>\n",
       "<polygon fill=\"none\" points=\"348,-7592.5 348,-7628.5 521,-7628.5 521,-7592.5 348,-7592.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"434.5\" y=\"-7606.8\">Input-Segment: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139650829386416 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>139650829386416</title>\n",
       "<polygon fill=\"none\" points=\"327.5,-7519.5 327.5,-7555.5 541.5,-7555.5 541.5,-7519.5 327.5,-7519.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"434.5\" y=\"-7533.8\">Embedding-Segment: Embedding</text>\n",
       "</g>\n",
       "<!-- 139650829205344&#45;&gt;139650829386416 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>139650829205344-&gt;139650829386416</title>\n",
       "<path d=\"M434.5,-7592.4551C434.5,-7584.3828 434.5,-7574.6764 434.5,-7565.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"438.0001,-7565.5903 434.5,-7555.5904 431.0001,-7565.5904 438.0001,-7565.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139650829388320 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>139650829388320</title>\n",
       "<polygon fill=\"none\" points=\"206.5,-7446.5 206.5,-7482.5 418.5,-7482.5 418.5,-7446.5 206.5,-7446.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.5\" y=\"-7460.8\">Embedding-Token-Segment: Add</text>\n",
       "</g>\n",
       "<!-- 139650829170504&#45;&gt;139650829388320 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>139650829170504-&gt;139650829388320</title>\n",
       "<path d=\"M220.6573,-7519.4551C236.6407,-7509.8912 256.4579,-7498.0334 273.5882,-7487.7833\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"275.4828,-7490.7284 282.2668,-7482.5904 271.8885,-7484.7216 275.4828,-7490.7284\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139650829386416&#45;&gt;139650829388320 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>139650829386416-&gt;139650829388320</title>\n",
       "<path d=\"M404.3427,-7519.4551C388.3593,-7509.8912 368.5421,-7498.0334 351.4118,-7487.7833\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"353.1115,-7484.7216 342.7332,-7482.5904 349.5172,-7490.7284 353.1115,-7484.7216\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139650829388768 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>139650829388768</title>\n",
       "<polygon fill=\"none\" points=\"183.5,-7373.5 183.5,-7409.5 441.5,-7409.5 441.5,-7373.5 183.5,-7373.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.5\" y=\"-7387.8\">Embedding-Position: PositionEmbedding</text>\n",
       "</g>\n",
       "<!-- 139650829388320&#45;&gt;139650829388768 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>139650829388320-&gt;139650829388768</title>\n",
       "<path d=\"M312.5,-7446.4551C312.5,-7438.3828 312.5,-7428.6764 312.5,-7419.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"316.0001,-7419.5903 312.5,-7409.5904 309.0001,-7419.5904 316.0001,-7419.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139650820504824 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>139650820504824</title>\n",
       "<polygon fill=\"none\" points=\"215.5,-7300.5 215.5,-7336.5 409.5,-7336.5 409.5,-7300.5 215.5,-7300.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.5\" y=\"-7314.8\">Embedding-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139650829388768&#45;&gt;139650820504824 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>139650829388768-&gt;139650820504824</title>\n",
       "<path d=\"M312.5,-7373.4551C312.5,-7365.3828 312.5,-7355.6764 312.5,-7346.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"316.0001,-7346.5903 312.5,-7336.5904 309.0001,-7346.5904 316.0001,-7346.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139650593462256 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>139650593462256</title>\n",
       "<polygon fill=\"none\" points=\"190,-7227.5 190,-7263.5 435,-7263.5 435,-7227.5 190,-7227.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.5\" y=\"-7241.8\">Embedding-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139650820504824&#45;&gt;139650593462256 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>139650820504824-&gt;139650593462256</title>\n",
       "<path d=\"M312.5,-7300.4551C312.5,-7292.3828 312.5,-7282.6764 312.5,-7273.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"316.0001,-7273.5903 312.5,-7263.5904 309.0001,-7273.5904 316.0001,-7273.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139650593533288 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>139650593533288</title>\n",
       "<polygon fill=\"none\" points=\"42.5,-7154.5 42.5,-7190.5 384.5,-7190.5 384.5,-7154.5 42.5,-7154.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-7168.8\">Encoder-1-MultiHeadSelfAttention: MultiHeadAttention</text>\n",
       "</g>\n",
       "<!-- 139650593462256&#45;&gt;139650593533288 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>139650593462256-&gt;139650593533288</title>\n",
       "<path d=\"M288.0281,-7227.4551C275.4149,-7218.1545 259.8597,-7206.6844 246.2286,-7196.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"248.1592,-7193.7082 238.0335,-7190.5904 244.0049,-7199.3421 248.1592,-7193.7082\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649284955664 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>139649284955664</title>\n",
       "<polygon fill=\"none\" points=\"173,-7008.5 173,-7044.5 454,-7044.5 454,-7008.5 173,-7008.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.5\" y=\"-7022.8\">Encoder-1-MultiHeadSelfAttention-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139650593462256&#45;&gt;139649284955664 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>139650593462256-&gt;139649284955664</title>\n",
       "<path d=\"M355.0685,-7227.3804C370.0065,-7218.7 385.1359,-7206.7088 393.5,-7191 401.1793,-7176.5774 400.9885,-7100.2923 390.5,-7081 383.7016,-7068.4953 372.6452,-7058.1998 361.0052,-7050.0548\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"362.7688,-7047.0266 352.4788,-7044.5031 358.9492,-7052.8927 362.7688,-7047.0266\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649285719040 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>139649285719040</title>\n",
       "<polygon fill=\"none\" points=\"53,-7081.5 53,-7117.5 382,-7117.5 382,-7081.5 53,-7081.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-7095.8\">Encoder-1-MultiHeadSelfAttention-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139650593533288&#45;&gt;139649285719040 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>139650593533288-&gt;139649285719040</title>\n",
       "<path d=\"M214.4888,-7154.4551C214.9311,-7146.3828 215.4629,-7136.6764 215.9558,-7127.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"219.4563,-7127.7669 216.5087,-7117.5904 212.4668,-7127.3839 219.4563,-7127.7669\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649285719040&#45;&gt;139649284955664 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>139649285719040-&gt;139649284955664</title>\n",
       "<path d=\"M241.2303,-7081.4551C253.3459,-7072.2422 268.2608,-7060.9006 281.3886,-7050.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"283.8684,-7053.4293 289.7099,-7044.5904 279.6314,-7047.8573 283.8684,-7053.4293\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649222225704 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>139649222225704</title>\n",
       "<polygon fill=\"none\" points=\"123.5,-6935.5 123.5,-6971.5 503.5,-6971.5 503.5,-6935.5 123.5,-6935.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.5\" y=\"-6949.8\">Encoder-1-MultiHeadSelfAttention-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649284955664&#45;&gt;139649222225704 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>139649284955664-&gt;139649222225704</title>\n",
       "<path d=\"M313.5,-7008.4551C313.5,-7000.3828 313.5,-6990.6764 313.5,-6981.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"317.0001,-6981.5903 313.5,-6971.5904 310.0001,-6981.5904 317.0001,-6981.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649285928384 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>139649285928384</title>\n",
       "<polygon fill=\"none\" points=\"118.5,-6862.5 118.5,-6898.5 360.5,-6898.5 360.5,-6862.5 118.5,-6862.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239.5\" y=\"-6876.8\">Encoder-1-FeedForward: FeedForward</text>\n",
       "</g>\n",
       "<!-- 139649222225704&#45;&gt;139649285928384 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>139649222225704-&gt;139649285928384</title>\n",
       "<path d=\"M295.2079,-6935.4551C286.1356,-6926.5054 275.0271,-6915.547 265.1232,-6905.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"267.4152,-6903.1215 257.8382,-6898.5904 262.4992,-6908.1049 267.4152,-6903.1215\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649286136272 -->\n",
       "<g class=\"node\" id=\"node15\">\n",
       "<title>139649286136272</title>\n",
       "<polygon fill=\"none\" points=\"203.5,-6716.5 203.5,-6752.5 423.5,-6752.5 423.5,-6716.5 203.5,-6716.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.5\" y=\"-6730.8\">Encoder-1-FeedForward-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139649222225704&#45;&gt;139649286136272 -->\n",
       "<g class=\"edge\" id=\"edge15\">\n",
       "<title>139649222225704-&gt;139649286136272</title>\n",
       "<path d=\"M339.1147,-6935.4444C350.4534,-6925.9752 362.7322,-6913.3575 369.5,-6899 390.3764,-6854.7122 395.6809,-6833.609 375.5,-6789 370.2852,-6777.4728 361.2939,-6767.4147 351.751,-6759.1833\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"353.6666,-6756.2331 343.676,-6752.7064 349.2868,-6761.6936 353.6666,-6756.2331\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649286207416 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>139649286207416</title>\n",
       "<polygon fill=\"none\" points=\"99,-6789.5 99,-6825.5 366,-6825.5 366,-6789.5 99,-6789.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.5\" y=\"-6803.8\">Encoder-1-FeedForward-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649285928384&#45;&gt;139649286207416 -->\n",
       "<g class=\"edge\" id=\"edge14\">\n",
       "<title>139649285928384-&gt;139649286207416</title>\n",
       "<path d=\"M237.7697,-6862.4551C236.9956,-6854.3828 236.0649,-6844.6764 235.2024,-6835.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"238.6733,-6835.2106 234.2347,-6825.5904 231.7053,-6835.8788 238.6733,-6835.2106\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649286207416&#45;&gt;139649286136272 -->\n",
       "<g class=\"edge\" id=\"edge16\">\n",
       "<title>139649286207416-&gt;139649286136272</title>\n",
       "<path d=\"M252.5225,-6789.4551C262.5502,-6780.4177 274.8509,-6769.3319 285.7714,-6759.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"288.3419,-6761.885 293.4271,-6752.5904 283.6556,-6756.6852 288.3419,-6761.885\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139650885899880 -->\n",
       "<g class=\"node\" id=\"node16\">\n",
       "<title>139650885899880</title>\n",
       "<polygon fill=\"none\" points=\"154.5,-6643.5 154.5,-6679.5 472.5,-6679.5 472.5,-6643.5 154.5,-6643.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"313.5\" y=\"-6657.8\">Encoder-1-FeedForward-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649286136272&#45;&gt;139650885899880 -->\n",
       "<g class=\"edge\" id=\"edge17\">\n",
       "<title>139649286136272-&gt;139650885899880</title>\n",
       "<path d=\"M313.5,-6716.4551C313.5,-6708.3828 313.5,-6698.6764 313.5,-6689.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"317.0001,-6689.5903 313.5,-6679.5904 310.0001,-6689.5904 317.0001,-6689.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649223404680 -->\n",
       "<g class=\"node\" id=\"node17\">\n",
       "<title>139649223404680</title>\n",
       "<polygon fill=\"none\" points=\"43.5,-6570.5 43.5,-6606.5 385.5,-6606.5 385.5,-6570.5 43.5,-6570.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214.5\" y=\"-6584.8\">Encoder-2-MultiHeadSelfAttention: MultiHeadAttention</text>\n",
       "</g>\n",
       "<!-- 139650885899880&#45;&gt;139649223404680 -->\n",
       "<g class=\"edge\" id=\"edge18\">\n",
       "<title>139650885899880-&gt;139649223404680</title>\n",
       "<path d=\"M289.0281,-6643.4551C276.4149,-6634.1545 260.8597,-6622.6844 247.2286,-6612.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"249.1592,-6609.7082 239.0335,-6606.5904 245.0049,-6615.3421 249.1592,-6609.7082\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649222953336 -->\n",
       "<g class=\"node\" id=\"node19\">\n",
       "<title>139649222953336</title>\n",
       "<polygon fill=\"none\" points=\"175,-6424.5 175,-6460.5 456,-6460.5 456,-6424.5 175,-6424.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"315.5\" y=\"-6438.8\">Encoder-2-MultiHeadSelfAttention-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139650885899880&#45;&gt;139649222953336 -->\n",
       "<g class=\"edge\" id=\"edge20\">\n",
       "<title>139650885899880-&gt;139649222953336</title>\n",
       "<path d=\"M356.0685,-6643.3804C371.0065,-6634.7 386.1359,-6622.7088 394.5,-6607 402.5894,-6591.8071 400.2511,-6514.9102 390.5,-6497 383.7494,-6484.601 372.8204,-6474.3006 361.3687,-6466.1162\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"363.2521,-6463.1654 352.99,-6460.531 359.3694,-6468.9899 363.2521,-6463.1654\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649285192000 -->\n",
       "<g class=\"node\" id=\"node18\">\n",
       "<title>139649285192000</title>\n",
       "<polygon fill=\"none\" points=\"53,-6497.5 53,-6533.5 382,-6533.5 382,-6497.5 53,-6497.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-6511.8\">Encoder-2-MultiHeadSelfAttention-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649223404680&#45;&gt;139649285192000 -->\n",
       "<g class=\"edge\" id=\"edge19\">\n",
       "<title>139649223404680-&gt;139649285192000</title>\n",
       "<path d=\"M215.2416,-6570.4551C215.5733,-6562.3828 215.9722,-6552.6764 216.3418,-6543.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"219.8429,-6543.7257 216.7566,-6533.5904 212.8488,-6543.4382 219.8429,-6543.7257\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649285192000&#45;&gt;139649222953336 -->\n",
       "<g class=\"edge\" id=\"edge21\">\n",
       "<title>139649285192000-&gt;139649222953336</title>\n",
       "<path d=\"M241.7247,-6497.4551C254.2105,-6488.1545 269.6086,-6476.6844 283.102,-6466.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"285.2855,-6469.371 291.2143,-6460.5904 281.1039,-6463.7573 285.2855,-6469.371\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649222309760 -->\n",
       "<g class=\"node\" id=\"node20\">\n",
       "<title>139649222309760</title>\n",
       "<polygon fill=\"none\" points=\"125.5,-6351.5 125.5,-6387.5 505.5,-6387.5 505.5,-6351.5 125.5,-6351.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"315.5\" y=\"-6365.8\">Encoder-2-MultiHeadSelfAttention-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649222953336&#45;&gt;139649222309760 -->\n",
       "<g class=\"edge\" id=\"edge22\">\n",
       "<title>139649222953336-&gt;139649222309760</title>\n",
       "<path d=\"M315.5,-6424.4551C315.5,-6416.3828 315.5,-6406.6764 315.5,-6397.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"319.0001,-6397.5903 315.5,-6387.5904 312.0001,-6397.5904 319.0001,-6397.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139650593495808 -->\n",
       "<g class=\"node\" id=\"node21\">\n",
       "<title>139650593495808</title>\n",
       "<polygon fill=\"none\" points=\"113.5,-6278.5 113.5,-6314.5 355.5,-6314.5 355.5,-6278.5 113.5,-6278.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234.5\" y=\"-6292.8\">Encoder-2-FeedForward: FeedForward</text>\n",
       "</g>\n",
       "<!-- 139649222309760&#45;&gt;139650593495808 -->\n",
       "<g class=\"edge\" id=\"edge23\">\n",
       "<title>139649222309760-&gt;139650593495808</title>\n",
       "<path d=\"M295.4775,-6351.4551C285.4498,-6342.4177 273.1491,-6331.3319 262.2286,-6321.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"264.3444,-6318.6852 254.5729,-6314.5904 259.6581,-6323.885 264.3444,-6318.6852\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139650593481280 -->\n",
       "<g class=\"node\" id=\"node23\">\n",
       "<title>139650593481280</title>\n",
       "<polygon fill=\"none\" points=\"199.5,-6132.5 199.5,-6168.5 419.5,-6168.5 419.5,-6132.5 199.5,-6132.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"309.5\" y=\"-6146.8\">Encoder-2-FeedForward-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139649222309760&#45;&gt;139650593481280 -->\n",
       "<g class=\"edge\" id=\"edge25\">\n",
       "<title>139649222309760-&gt;139650593481280</title>\n",
       "<path d=\"M337.3471,-6351.291C347.3936,-6341.6134 358.4097,-6328.8624 364.5,-6315 384.2044,-6270.1498 391.6917,-6249.6329 371.5,-6205 366.2852,-6193.4728 357.2939,-6183.4147 347.751,-6175.1833\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"349.6666,-6172.2331 339.676,-6168.7064 345.2868,-6177.6936 349.6666,-6172.2331\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139650593572008 -->\n",
       "<g class=\"node\" id=\"node22\">\n",
       "<title>139650593572008</title>\n",
       "<polygon fill=\"none\" points=\"95,-6205.5 95,-6241.5 362,-6241.5 362,-6205.5 95,-6205.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"228.5\" y=\"-6219.8\">Encoder-2-FeedForward-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139650593495808&#45;&gt;139650593572008 -->\n",
       "<g class=\"edge\" id=\"edge24\">\n",
       "<title>139650593495808-&gt;139650593572008</title>\n",
       "<path d=\"M233.0169,-6278.4551C232.3534,-6270.3828 231.5556,-6260.6764 230.8163,-6251.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"234.2944,-6251.27 229.9869,-6241.5904 227.3179,-6251.8435 234.2944,-6251.27\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139650593572008&#45;&gt;139650593481280 -->\n",
       "<g class=\"edge\" id=\"edge26\">\n",
       "<title>139650593572008-&gt;139650593481280</title>\n",
       "<path d=\"M248.5225,-6205.4551C258.5502,-6196.4177 270.8509,-6185.3319 281.7714,-6175.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"284.3419,-6177.885 289.4271,-6168.5904 279.6556,-6172.6852 284.3419,-6177.885\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139650593481112 -->\n",
       "<g class=\"node\" id=\"node24\">\n",
       "<title>139650593481112</title>\n",
       "<polygon fill=\"none\" points=\"150.5,-6059.5 150.5,-6095.5 468.5,-6095.5 468.5,-6059.5 150.5,-6059.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"309.5\" y=\"-6073.8\">Encoder-2-FeedForward-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139650593481280&#45;&gt;139650593481112 -->\n",
       "<g class=\"edge\" id=\"edge27\">\n",
       "<title>139650593481280-&gt;139650593481112</title>\n",
       "<path d=\"M309.5,-6132.4551C309.5,-6124.3828 309.5,-6114.6764 309.5,-6105.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"313.0001,-6105.5903 309.5,-6095.5904 306.0001,-6105.5904 313.0001,-6105.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649286310712 -->\n",
       "<g class=\"node\" id=\"node25\">\n",
       "<title>139649286310712</title>\n",
       "<polygon fill=\"none\" points=\"39.5,-5986.5 39.5,-6022.5 381.5,-6022.5 381.5,-5986.5 39.5,-5986.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210.5\" y=\"-6000.8\">Encoder-3-MultiHeadSelfAttention: MultiHeadAttention</text>\n",
       "</g>\n",
       "<!-- 139650593481112&#45;&gt;139649286310712 -->\n",
       "<g class=\"edge\" id=\"edge28\">\n",
       "<title>139650593481112-&gt;139649286310712</title>\n",
       "<path d=\"M285.0281,-6059.4551C272.4149,-6050.1545 256.8597,-6038.6844 243.2286,-6028.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"245.1592,-6025.7082 235.0335,-6022.5904 241.0049,-6031.3421 245.1592,-6025.7082\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649286321768 -->\n",
       "<g class=\"node\" id=\"node27\">\n",
       "<title>139649286321768</title>\n",
       "<polygon fill=\"none\" points=\"171,-5840.5 171,-5876.5 452,-5876.5 452,-5840.5 171,-5840.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311.5\" y=\"-5854.8\">Encoder-3-MultiHeadSelfAttention-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139650593481112&#45;&gt;139649286321768 -->\n",
       "<g class=\"edge\" id=\"edge30\">\n",
       "<title>139650593481112-&gt;139649286321768</title>\n",
       "<path d=\"M352.0685,-6059.3804C367.0065,-6050.7 382.1359,-6038.7088 390.5,-6023 398.5894,-6007.8071 396.2511,-5930.9102 386.5,-5913 379.7494,-5900.601 368.8204,-5890.3006 357.3687,-5882.1162\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"359.2521,-5879.1654 348.99,-5876.531 355.3694,-5884.9899 359.2521,-5879.1654\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649222953560 -->\n",
       "<g class=\"node\" id=\"node26\">\n",
       "<title>139649222953560</title>\n",
       "<polygon fill=\"none\" points=\"49,-5913.5 49,-5949.5 378,-5949.5 378,-5913.5 49,-5913.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-5927.8\">Encoder-3-MultiHeadSelfAttention-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649286310712&#45;&gt;139649222953560 -->\n",
       "<g class=\"edge\" id=\"edge29\">\n",
       "<title>139649286310712-&gt;139649222953560</title>\n",
       "<path d=\"M211.2416,-5986.4551C211.5733,-5978.3828 211.9722,-5968.6764 212.3418,-5959.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"215.8429,-5959.7257 212.7566,-5949.5904 208.8488,-5959.4382 215.8429,-5959.7257\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649222953560&#45;&gt;139649286321768 -->\n",
       "<g class=\"edge\" id=\"edge31\">\n",
       "<title>139649222953560-&gt;139649286321768</title>\n",
       "<path d=\"M237.7247,-5913.4551C250.2105,-5904.1545 265.6086,-5892.6844 279.102,-5882.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"281.2855,-5885.371 287.2143,-5876.5904 277.1039,-5879.7573 281.2855,-5885.371\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649285415600 -->\n",
       "<g class=\"node\" id=\"node28\">\n",
       "<title>139649285415600</title>\n",
       "<polygon fill=\"none\" points=\"121.5,-5767.5 121.5,-5803.5 501.5,-5803.5 501.5,-5767.5 121.5,-5767.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311.5\" y=\"-5781.8\">Encoder-3-MultiHeadSelfAttention-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649286321768&#45;&gt;139649285415600 -->\n",
       "<g class=\"edge\" id=\"edge32\">\n",
       "<title>139649286321768-&gt;139649285415600</title>\n",
       "<path d=\"M311.5,-5840.4551C311.5,-5832.3828 311.5,-5822.6764 311.5,-5813.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"315.0001,-5813.5903 311.5,-5803.5904 308.0001,-5813.5904 315.0001,-5813.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649223733992 -->\n",
       "<g class=\"node\" id=\"node29\">\n",
       "<title>139649223733992</title>\n",
       "<polygon fill=\"none\" points=\"109.5,-5694.5 109.5,-5730.5 351.5,-5730.5 351.5,-5694.5 109.5,-5694.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230.5\" y=\"-5708.8\">Encoder-3-FeedForward: FeedForward</text>\n",
       "</g>\n",
       "<!-- 139649285415600&#45;&gt;139649223733992 -->\n",
       "<g class=\"edge\" id=\"edge33\">\n",
       "<title>139649285415600-&gt;139649223733992</title>\n",
       "<path d=\"M291.4775,-5767.4551C281.4498,-5758.4177 269.1491,-5747.3319 258.2286,-5737.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"260.3444,-5734.6852 250.5729,-5730.5904 255.6581,-5739.885 260.3444,-5734.6852\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649222951040 -->\n",
       "<g class=\"node\" id=\"node31\">\n",
       "<title>139649222951040</title>\n",
       "<polygon fill=\"none\" points=\"195.5,-5548.5 195.5,-5584.5 415.5,-5584.5 415.5,-5548.5 195.5,-5548.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305.5\" y=\"-5562.8\">Encoder-3-FeedForward-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139649285415600&#45;&gt;139649222951040 -->\n",
       "<g class=\"edge\" id=\"edge35\">\n",
       "<title>139649285415600-&gt;139649222951040</title>\n",
       "<path d=\"M333.3471,-5767.291C343.3936,-5757.6134 354.4097,-5744.8624 360.5,-5731 380.2044,-5686.1498 387.6917,-5665.6329 367.5,-5621 362.2852,-5609.4728 353.2939,-5599.4147 343.751,-5591.1833\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"345.6666,-5588.2331 335.676,-5584.7064 341.2868,-5593.6936 345.6666,-5588.2331\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649223737240 -->\n",
       "<g class=\"node\" id=\"node30\">\n",
       "<title>139649223737240</title>\n",
       "<polygon fill=\"none\" points=\"91,-5621.5 91,-5657.5 358,-5657.5 358,-5621.5 91,-5621.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224.5\" y=\"-5635.8\">Encoder-3-FeedForward-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649223733992&#45;&gt;139649223737240 -->\n",
       "<g class=\"edge\" id=\"edge34\">\n",
       "<title>139649223733992-&gt;139649223737240</title>\n",
       "<path d=\"M229.0169,-5694.4551C228.3534,-5686.3828 227.5556,-5676.6764 226.8163,-5667.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"230.2944,-5667.27 225.9869,-5657.5904 223.3179,-5667.8435 230.2944,-5667.27\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649223737240&#45;&gt;139649222951040 -->\n",
       "<g class=\"edge\" id=\"edge36\">\n",
       "<title>139649223737240-&gt;139649222951040</title>\n",
       "<path d=\"M244.5225,-5621.4551C254.5502,-5612.4177 266.8509,-5601.3319 277.7714,-5591.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"280.3419,-5593.885 285.4271,-5584.5904 275.6556,-5588.6852 280.3419,-5593.885\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649223593152 -->\n",
       "<g class=\"node\" id=\"node32\">\n",
       "<title>139649223593152</title>\n",
       "<polygon fill=\"none\" points=\"146.5,-5475.5 146.5,-5511.5 464.5,-5511.5 464.5,-5475.5 146.5,-5475.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305.5\" y=\"-5489.8\">Encoder-3-FeedForward-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649222951040&#45;&gt;139649223593152 -->\n",
       "<g class=\"edge\" id=\"edge37\">\n",
       "<title>139649222951040-&gt;139649223593152</title>\n",
       "<path d=\"M305.5,-5548.4551C305.5,-5540.3828 305.5,-5530.6764 305.5,-5521.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"309.0001,-5521.5903 305.5,-5511.5904 302.0001,-5521.5904 309.0001,-5521.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649222860416 -->\n",
       "<g class=\"node\" id=\"node33\">\n",
       "<title>139649222860416</title>\n",
       "<polygon fill=\"none\" points=\"35.5,-5402.5 35.5,-5438.5 377.5,-5438.5 377.5,-5402.5 35.5,-5402.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206.5\" y=\"-5416.8\">Encoder-4-MultiHeadSelfAttention: MultiHeadAttention</text>\n",
       "</g>\n",
       "<!-- 139649223593152&#45;&gt;139649222860416 -->\n",
       "<g class=\"edge\" id=\"edge38\">\n",
       "<title>139649223593152-&gt;139649222860416</title>\n",
       "<path d=\"M281.0281,-5475.4551C268.4149,-5466.1545 252.8597,-5454.6844 239.2286,-5444.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"241.1592,-5441.7082 231.0335,-5438.5904 237.0049,-5447.3421 241.1592,-5441.7082\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649222922312 -->\n",
       "<g class=\"node\" id=\"node35\">\n",
       "<title>139649222922312</title>\n",
       "<polygon fill=\"none\" points=\"167,-5256.5 167,-5292.5 448,-5292.5 448,-5256.5 167,-5256.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307.5\" y=\"-5270.8\">Encoder-4-MultiHeadSelfAttention-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139649223593152&#45;&gt;139649222922312 -->\n",
       "<g class=\"edge\" id=\"edge40\">\n",
       "<title>139649223593152-&gt;139649222922312</title>\n",
       "<path d=\"M348.0685,-5475.3804C363.0065,-5466.7 378.1359,-5454.7088 386.5,-5439 394.5894,-5423.8071 392.2511,-5346.9102 382.5,-5329 375.7494,-5316.601 364.8204,-5306.3006 353.3687,-5298.1162\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"355.2521,-5295.1654 344.99,-5292.531 351.3694,-5300.9899 355.2521,-5295.1654\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649222893464 -->\n",
       "<g class=\"node\" id=\"node34\">\n",
       "<title>139649222893464</title>\n",
       "<polygon fill=\"none\" points=\"45,-5329.5 45,-5365.5 374,-5365.5 374,-5329.5 45,-5329.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-5343.8\">Encoder-4-MultiHeadSelfAttention-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649222860416&#45;&gt;139649222893464 -->\n",
       "<g class=\"edge\" id=\"edge39\">\n",
       "<title>139649222860416-&gt;139649222893464</title>\n",
       "<path d=\"M207.2416,-5402.4551C207.5733,-5394.3828 207.9722,-5384.6764 208.3418,-5375.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"211.8429,-5375.7257 208.7566,-5365.5904 204.8488,-5375.4382 211.8429,-5375.7257\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649222893464&#45;&gt;139649222922312 -->\n",
       "<g class=\"edge\" id=\"edge41\">\n",
       "<title>139649222893464-&gt;139649222922312</title>\n",
       "<path d=\"M233.7247,-5329.4551C246.2105,-5320.1545 261.6086,-5308.6844 275.102,-5298.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"277.2855,-5301.371 283.2143,-5292.5904 273.1039,-5295.7573 277.2855,-5301.371\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649221426256 -->\n",
       "<g class=\"node\" id=\"node36\">\n",
       "<title>139649221426256</title>\n",
       "<polygon fill=\"none\" points=\"117.5,-5183.5 117.5,-5219.5 497.5,-5219.5 497.5,-5183.5 117.5,-5183.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307.5\" y=\"-5197.8\">Encoder-4-MultiHeadSelfAttention-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649222922312&#45;&gt;139649221426256 -->\n",
       "<g class=\"edge\" id=\"edge42\">\n",
       "<title>139649222922312-&gt;139649221426256</title>\n",
       "<path d=\"M307.5,-5256.4551C307.5,-5248.3828 307.5,-5238.6764 307.5,-5229.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"311.0001,-5229.5903 307.5,-5219.5904 304.0001,-5229.5904 311.0001,-5229.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649221457904 -->\n",
       "<g class=\"node\" id=\"node37\">\n",
       "<title>139649221457904</title>\n",
       "<polygon fill=\"none\" points=\"105.5,-5110.5 105.5,-5146.5 347.5,-5146.5 347.5,-5110.5 105.5,-5110.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226.5\" y=\"-5124.8\">Encoder-4-FeedForward: FeedForward</text>\n",
       "</g>\n",
       "<!-- 139649221426256&#45;&gt;139649221457904 -->\n",
       "<g class=\"edge\" id=\"edge43\">\n",
       "<title>139649221426256-&gt;139649221457904</title>\n",
       "<path d=\"M287.4775,-5183.4551C277.4498,-5174.4177 265.1491,-5163.3319 254.2286,-5153.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"256.3444,-5150.6852 246.5729,-5146.5904 251.6581,-5155.885 256.3444,-5150.6852\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649221527592 -->\n",
       "<g class=\"node\" id=\"node39\">\n",
       "<title>139649221527592</title>\n",
       "<polygon fill=\"none\" points=\"191.5,-4964.5 191.5,-5000.5 411.5,-5000.5 411.5,-4964.5 191.5,-4964.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301.5\" y=\"-4978.8\">Encoder-4-FeedForward-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139649221426256&#45;&gt;139649221527592 -->\n",
       "<g class=\"edge\" id=\"edge45\">\n",
       "<title>139649221426256-&gt;139649221527592</title>\n",
       "<path d=\"M329.3471,-5183.291C339.3936,-5173.6134 350.4097,-5160.8624 356.5,-5147 376.2044,-5102.1498 383.6917,-5081.6329 363.5,-5037 358.2852,-5025.4728 349.2939,-5015.4147 339.751,-5007.1833\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"341.6666,-5004.2331 331.676,-5000.7064 337.2868,-5009.6936 341.6666,-5004.2331\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649221491400 -->\n",
       "<g class=\"node\" id=\"node38\">\n",
       "<title>139649221491400</title>\n",
       "<polygon fill=\"none\" points=\"87,-5037.5 87,-5073.5 354,-5073.5 354,-5037.5 87,-5037.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"220.5\" y=\"-5051.8\">Encoder-4-FeedForward-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649221457904&#45;&gt;139649221491400 -->\n",
       "<g class=\"edge\" id=\"edge44\">\n",
       "<title>139649221457904-&gt;139649221491400</title>\n",
       "<path d=\"M225.0169,-5110.4551C224.3534,-5102.3828 223.5556,-5092.6764 222.8163,-5083.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"226.2944,-5083.27 221.9869,-5073.5904 219.3179,-5083.8435 226.2944,-5083.27\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649221491400&#45;&gt;139649221527592 -->\n",
       "<g class=\"edge\" id=\"edge46\">\n",
       "<title>139649221491400-&gt;139649221527592</title>\n",
       "<path d=\"M240.5225,-5037.4551C250.5502,-5028.4177 262.8509,-5017.3319 273.7714,-5007.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.3419,-5009.885 281.4271,-5000.5904 271.6556,-5004.6852 276.3419,-5009.885\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649221527704 -->\n",
       "<g class=\"node\" id=\"node40\">\n",
       "<title>139649221527704</title>\n",
       "<polygon fill=\"none\" points=\"142.5,-4891.5 142.5,-4927.5 460.5,-4927.5 460.5,-4891.5 142.5,-4891.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301.5\" y=\"-4905.8\">Encoder-4-FeedForward-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649221527592&#45;&gt;139649221527704 -->\n",
       "<g class=\"edge\" id=\"edge47\">\n",
       "<title>139649221527592-&gt;139649221527704</title>\n",
       "<path d=\"M301.5,-4964.4551C301.5,-4956.3828 301.5,-4946.6764 301.5,-4937.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"305.0001,-4937.5903 301.5,-4927.5904 298.0001,-4937.5904 305.0001,-4937.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649221168544 -->\n",
       "<g class=\"node\" id=\"node41\">\n",
       "<title>139649221168544</title>\n",
       "<polygon fill=\"none\" points=\"31.5,-4818.5 31.5,-4854.5 373.5,-4854.5 373.5,-4818.5 31.5,-4818.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-4832.8\">Encoder-5-MultiHeadSelfAttention: MultiHeadAttention</text>\n",
       "</g>\n",
       "<!-- 139649221527704&#45;&gt;139649221168544 -->\n",
       "<g class=\"edge\" id=\"edge48\">\n",
       "<title>139649221527704-&gt;139649221168544</title>\n",
       "<path d=\"M277.0281,-4891.4551C264.4149,-4882.1545 248.8597,-4870.6844 235.2286,-4860.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"237.1592,-4857.7082 227.0335,-4854.5904 233.0049,-4863.3421 237.1592,-4857.7082\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649221205856 -->\n",
       "<g class=\"node\" id=\"node43\">\n",
       "<title>139649221205856</title>\n",
       "<polygon fill=\"none\" points=\"163,-4672.5 163,-4708.5 444,-4708.5 444,-4672.5 163,-4672.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303.5\" y=\"-4686.8\">Encoder-5-MultiHeadSelfAttention-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139649221527704&#45;&gt;139649221205856 -->\n",
       "<g class=\"edge\" id=\"edge50\">\n",
       "<title>139649221527704-&gt;139649221205856</title>\n",
       "<path d=\"M344.0685,-4891.3804C359.0065,-4882.7 374.1359,-4870.7088 382.5,-4855 390.5894,-4839.8071 388.2511,-4762.9102 378.5,-4745 371.7494,-4732.601 360.8204,-4722.3006 349.3687,-4714.1162\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"351.2521,-4711.1654 340.99,-4708.531 347.3694,-4716.9899 351.2521,-4711.1654\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649221204736 -->\n",
       "<g class=\"node\" id=\"node42\">\n",
       "<title>139649221204736</title>\n",
       "<polygon fill=\"none\" points=\"41,-4745.5 41,-4781.5 370,-4781.5 370,-4745.5 41,-4745.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-4759.8\">Encoder-5-MultiHeadSelfAttention-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649221168544&#45;&gt;139649221204736 -->\n",
       "<g class=\"edge\" id=\"edge49\">\n",
       "<title>139649221168544-&gt;139649221204736</title>\n",
       "<path d=\"M203.2416,-4818.4551C203.5733,-4810.3828 203.9722,-4800.6764 204.3418,-4791.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"207.8429,-4791.7257 204.7566,-4781.5904 200.8488,-4791.4382 207.8429,-4791.7257\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649221204736&#45;&gt;139649221205856 -->\n",
       "<g class=\"edge\" id=\"edge51\">\n",
       "<title>139649221204736-&gt;139649221205856</title>\n",
       "<path d=\"M229.7247,-4745.4551C242.2105,-4736.1545 257.6086,-4724.6844 271.102,-4714.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"273.2855,-4717.371 279.2143,-4708.5904 269.1039,-4711.7573 273.2855,-4717.371\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649221228640 -->\n",
       "<g class=\"node\" id=\"node44\">\n",
       "<title>139649221228640</title>\n",
       "<polygon fill=\"none\" points=\"113.5,-4599.5 113.5,-4635.5 493.5,-4635.5 493.5,-4599.5 113.5,-4599.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303.5\" y=\"-4613.8\">Encoder-5-MultiHeadSelfAttention-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649221205856&#45;&gt;139649221228640 -->\n",
       "<g class=\"edge\" id=\"edge52\">\n",
       "<title>139649221205856-&gt;139649221228640</title>\n",
       "<path d=\"M303.5,-4672.4551C303.5,-4664.3828 303.5,-4654.6764 303.5,-4645.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"307.0001,-4645.5903 303.5,-4635.5904 300.0001,-4645.5904 307.0001,-4645.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649220807816 -->\n",
       "<g class=\"node\" id=\"node45\">\n",
       "<title>139649220807816</title>\n",
       "<polygon fill=\"none\" points=\"101.5,-4526.5 101.5,-4562.5 343.5,-4562.5 343.5,-4526.5 101.5,-4526.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"222.5\" y=\"-4540.8\">Encoder-5-FeedForward: FeedForward</text>\n",
       "</g>\n",
       "<!-- 139649221228640&#45;&gt;139649220807816 -->\n",
       "<g class=\"edge\" id=\"edge53\">\n",
       "<title>139649221228640-&gt;139649220807816</title>\n",
       "<path d=\"M283.4775,-4599.4551C273.4498,-4590.4177 261.1491,-4579.3319 250.2286,-4569.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"252.3444,-4566.6852 242.5729,-4562.5904 247.6581,-4571.885 252.3444,-4566.6852\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649220411176 -->\n",
       "<g class=\"node\" id=\"node47\">\n",
       "<title>139649220411176</title>\n",
       "<polygon fill=\"none\" points=\"187.5,-4380.5 187.5,-4416.5 407.5,-4416.5 407.5,-4380.5 187.5,-4380.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-4394.8\">Encoder-5-FeedForward-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139649221228640&#45;&gt;139649220411176 -->\n",
       "<g class=\"edge\" id=\"edge55\">\n",
       "<title>139649221228640-&gt;139649220411176</title>\n",
       "<path d=\"M325.3471,-4599.291C335.3936,-4589.6134 346.4097,-4576.8624 352.5,-4563 372.2044,-4518.1498 379.6917,-4497.6329 359.5,-4453 354.2852,-4441.4728 345.2939,-4431.4147 335.751,-4423.1833\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"337.6666,-4420.2331 327.676,-4416.7064 333.2868,-4425.6936 337.6666,-4420.2331\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649220830768 -->\n",
       "<g class=\"node\" id=\"node46\">\n",
       "<title>139649220830768</title>\n",
       "<polygon fill=\"none\" points=\"83,-4453.5 83,-4489.5 350,-4489.5 350,-4453.5 83,-4453.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"216.5\" y=\"-4467.8\">Encoder-5-FeedForward-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649220807816&#45;&gt;139649220830768 -->\n",
       "<g class=\"edge\" id=\"edge54\">\n",
       "<title>139649220807816-&gt;139649220830768</title>\n",
       "<path d=\"M221.0169,-4526.4551C220.3534,-4518.3828 219.5556,-4508.6764 218.8163,-4499.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"222.2944,-4499.27 217.9869,-4489.5904 215.3179,-4499.8435 222.2944,-4499.27\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649220830768&#45;&gt;139649220411176 -->\n",
       "<g class=\"edge\" id=\"edge56\">\n",
       "<title>139649220830768-&gt;139649220411176</title>\n",
       "<path d=\"M236.5225,-4453.4551C246.5502,-4444.4177 258.8509,-4433.3319 269.7714,-4423.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"272.3419,-4425.885 277.4271,-4416.5904 267.6556,-4420.6852 272.3419,-4425.885\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649220334424 -->\n",
       "<g class=\"node\" id=\"node48\">\n",
       "<title>139649220334424</title>\n",
       "<polygon fill=\"none\" points=\"138.5,-4307.5 138.5,-4343.5 456.5,-4343.5 456.5,-4307.5 138.5,-4307.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-4321.8\">Encoder-5-FeedForward-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649220411176&#45;&gt;139649220334424 -->\n",
       "<g class=\"edge\" id=\"edge57\">\n",
       "<title>139649220411176-&gt;139649220334424</title>\n",
       "<path d=\"M297.5,-4380.4551C297.5,-4372.3828 297.5,-4362.6764 297.5,-4353.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"301.0001,-4353.5903 297.5,-4343.5904 294.0001,-4353.5904 301.0001,-4353.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649220517056 -->\n",
       "<g class=\"node\" id=\"node49\">\n",
       "<title>139649220517056</title>\n",
       "<polygon fill=\"none\" points=\"27.5,-4234.5 27.5,-4270.5 369.5,-4270.5 369.5,-4234.5 27.5,-4234.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198.5\" y=\"-4248.8\">Encoder-6-MultiHeadSelfAttention: MultiHeadAttention</text>\n",
       "</g>\n",
       "<!-- 139649220334424&#45;&gt;139649220517056 -->\n",
       "<g class=\"edge\" id=\"edge58\">\n",
       "<title>139649220334424-&gt;139649220517056</title>\n",
       "<path d=\"M273.0281,-4307.4551C260.4149,-4298.1545 244.8597,-4286.6844 231.2286,-4276.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"233.1592,-4273.7082 223.0335,-4270.5904 229.0049,-4279.3421 233.1592,-4273.7082\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649220076824 -->\n",
       "<g class=\"node\" id=\"node51\">\n",
       "<title>139649220076824</title>\n",
       "<polygon fill=\"none\" points=\"158,-4088.5 158,-4124.5 439,-4124.5 439,-4088.5 158,-4088.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298.5\" y=\"-4102.8\">Encoder-6-MultiHeadSelfAttention-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139649220334424&#45;&gt;139649220076824 -->\n",
       "<g class=\"edge\" id=\"edge60\">\n",
       "<title>139649220334424-&gt;139649220076824</title>\n",
       "<path d=\"M340.0685,-4307.3804C355.0065,-4298.7 370.1359,-4286.7088 378.5,-4271 386.1793,-4256.5774 385.9885,-4180.2923 375.5,-4161 368.7016,-4148.4953 357.6452,-4138.1998 346.0052,-4130.0548\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"347.7688,-4127.0266 337.4788,-4124.5031 343.9492,-4132.8927 347.7688,-4127.0266\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649220540008 -->\n",
       "<g class=\"node\" id=\"node50\">\n",
       "<title>139649220540008</title>\n",
       "<polygon fill=\"none\" points=\"38,-4161.5 38,-4197.5 367,-4197.5 367,-4161.5 38,-4161.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-4175.8\">Encoder-6-MultiHeadSelfAttention-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649220517056&#45;&gt;139649220540008 -->\n",
       "<g class=\"edge\" id=\"edge59\">\n",
       "<title>139649220517056-&gt;139649220540008</title>\n",
       "<path d=\"M199.4888,-4234.4551C199.9311,-4226.3828 200.4629,-4216.6764 200.9558,-4207.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"204.4563,-4207.7669 201.5087,-4197.5904 197.4668,-4207.3839 204.4563,-4207.7669\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649220540008&#45;&gt;139649220076824 -->\n",
       "<g class=\"edge\" id=\"edge61\">\n",
       "<title>139649220540008-&gt;139649220076824</title>\n",
       "<path d=\"M226.2303,-4161.4551C238.3459,-4152.2422 253.2608,-4140.9006 266.3886,-4130.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"268.8684,-4133.4293 274.7099,-4124.5904 264.6314,-4127.8573 268.8684,-4133.4293\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649220568064 -->\n",
       "<g class=\"node\" id=\"node52\">\n",
       "<title>139649220568064</title>\n",
       "<polygon fill=\"none\" points=\"108.5,-4015.5 108.5,-4051.5 488.5,-4051.5 488.5,-4015.5 108.5,-4015.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298.5\" y=\"-4029.8\">Encoder-6-MultiHeadSelfAttention-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649220076824&#45;&gt;139649220568064 -->\n",
       "<g class=\"edge\" id=\"edge62\">\n",
       "<title>139649220076824-&gt;139649220568064</title>\n",
       "<path d=\"M298.5,-4088.4551C298.5,-4080.3828 298.5,-4070.6764 298.5,-4061.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"302.0001,-4061.5903 298.5,-4051.5904 295.0001,-4061.5904 302.0001,-4061.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219617960 -->\n",
       "<g class=\"node\" id=\"node53\">\n",
       "<title>139649219617960</title>\n",
       "<polygon fill=\"none\" points=\"96.5,-3942.5 96.5,-3978.5 338.5,-3978.5 338.5,-3942.5 96.5,-3942.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-3956.8\">Encoder-6-FeedForward: FeedForward</text>\n",
       "</g>\n",
       "<!-- 139649220568064&#45;&gt;139649219617960 -->\n",
       "<g class=\"edge\" id=\"edge63\">\n",
       "<title>139649220568064-&gt;139649219617960</title>\n",
       "<path d=\"M278.4775,-4015.4551C268.4498,-4006.4177 256.1491,-3995.3319 245.2286,-3985.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"247.3444,-3982.6852 237.5729,-3978.5904 242.6581,-3987.885 247.3444,-3982.6852\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219637768 -->\n",
       "<g class=\"node\" id=\"node55\">\n",
       "<title>139649219637768</title>\n",
       "<polygon fill=\"none\" points=\"182.5,-3796.5 182.5,-3832.5 402.5,-3832.5 402.5,-3796.5 182.5,-3796.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-3810.8\">Encoder-6-FeedForward-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139649220568064&#45;&gt;139649219637768 -->\n",
       "<g class=\"edge\" id=\"edge65\">\n",
       "<title>139649220568064-&gt;139649219637768</title>\n",
       "<path d=\"M320.3471,-4015.291C330.3936,-4005.6134 341.4097,-3992.8624 347.5,-3979 367.2044,-3934.1498 374.6917,-3913.6329 354.5,-3869 349.2852,-3857.4728 340.2939,-3847.4147 330.751,-3839.1833\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"332.6666,-3836.2331 322.676,-3832.7064 328.2868,-3841.6936 332.6666,-3836.2331\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219618408 -->\n",
       "<g class=\"node\" id=\"node54\">\n",
       "<title>139649219618408</title>\n",
       "<polygon fill=\"none\" points=\"78,-3869.5 78,-3905.5 345,-3905.5 345,-3869.5 78,-3869.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-3883.8\">Encoder-6-FeedForward-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649219617960&#45;&gt;139649219618408 -->\n",
       "<g class=\"edge\" id=\"edge64\">\n",
       "<title>139649219617960-&gt;139649219618408</title>\n",
       "<path d=\"M216.0169,-3942.4551C215.3534,-3934.3828 214.5556,-3924.6764 213.8163,-3915.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"217.2944,-3915.27 212.9869,-3905.5904 210.3179,-3915.8435 217.2944,-3915.27\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219618408&#45;&gt;139649219637768 -->\n",
       "<g class=\"edge\" id=\"edge66\">\n",
       "<title>139649219618408-&gt;139649219637768</title>\n",
       "<path d=\"M231.5225,-3869.4551C241.5502,-3860.4177 253.8509,-3849.3319 264.7714,-3839.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"267.3419,-3841.885 272.4271,-3832.5904 262.6556,-3836.6852 267.3419,-3841.885\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219703752 -->\n",
       "<g class=\"node\" id=\"node56\">\n",
       "<title>139649219703752</title>\n",
       "<polygon fill=\"none\" points=\"133.5,-3723.5 133.5,-3759.5 451.5,-3759.5 451.5,-3723.5 133.5,-3723.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-3737.8\">Encoder-6-FeedForward-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649219637768&#45;&gt;139649219703752 -->\n",
       "<g class=\"edge\" id=\"edge67\">\n",
       "<title>139649219637768-&gt;139649219703752</title>\n",
       "<path d=\"M292.5,-3796.4551C292.5,-3788.3828 292.5,-3778.6764 292.5,-3769.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"296.0001,-3769.5903 292.5,-3759.5904 289.0001,-3769.5904 296.0001,-3769.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219317600 -->\n",
       "<g class=\"node\" id=\"node57\">\n",
       "<title>139649219317600</title>\n",
       "<polygon fill=\"none\" points=\"22.5,-3650.5 22.5,-3686.5 364.5,-3686.5 364.5,-3650.5 22.5,-3650.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193.5\" y=\"-3664.8\">Encoder-7-MultiHeadSelfAttention: MultiHeadAttention</text>\n",
       "</g>\n",
       "<!-- 139649219703752&#45;&gt;139649219317600 -->\n",
       "<g class=\"edge\" id=\"edge68\">\n",
       "<title>139649219703752-&gt;139649219317600</title>\n",
       "<path d=\"M268.0281,-3723.4551C255.4149,-3714.1545 239.8597,-3702.6844 226.2286,-3692.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"228.1592,-3689.7082 218.0335,-3686.5904 224.0049,-3695.3421 228.1592,-3689.7082\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219353288 -->\n",
       "<g class=\"node\" id=\"node59\">\n",
       "<title>139649219353288</title>\n",
       "<polygon fill=\"none\" points=\"153,-3504.5 153,-3540.5 434,-3540.5 434,-3504.5 153,-3504.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"293.5\" y=\"-3518.8\">Encoder-7-MultiHeadSelfAttention-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139649219703752&#45;&gt;139649219353288 -->\n",
       "<g class=\"edge\" id=\"edge70\">\n",
       "<title>139649219703752-&gt;139649219353288</title>\n",
       "<path d=\"M335.0685,-3723.3804C350.0065,-3714.7 365.1359,-3702.7088 373.5,-3687 381.1793,-3672.5774 380.9885,-3596.2923 370.5,-3577 363.7016,-3564.4953 352.6452,-3554.1998 341.0052,-3546.0548\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"342.7688,-3543.0266 332.4788,-3540.5031 338.9492,-3548.8927 342.7688,-3543.0266\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219315360 -->\n",
       "<g class=\"node\" id=\"node58\">\n",
       "<title>139649219315360</title>\n",
       "<polygon fill=\"none\" points=\"33,-3577.5 33,-3613.5 362,-3613.5 362,-3577.5 33,-3577.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197.5\" y=\"-3591.8\">Encoder-7-MultiHeadSelfAttention-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649219317600&#45;&gt;139649219315360 -->\n",
       "<g class=\"edge\" id=\"edge69\">\n",
       "<title>139649219317600-&gt;139649219315360</title>\n",
       "<path d=\"M194.4888,-3650.4551C194.9311,-3642.3828 195.4629,-3632.6764 195.9558,-3623.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"199.4563,-3623.7669 196.5087,-3613.5904 192.4668,-3623.3839 199.4563,-3623.7669\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219315360&#45;&gt;139649219353288 -->\n",
       "<g class=\"edge\" id=\"edge71\">\n",
       "<title>139649219315360-&gt;139649219353288</title>\n",
       "<path d=\"M221.2303,-3577.4551C233.3459,-3568.2422 248.2608,-3556.9006 261.3886,-3546.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"263.8684,-3549.4293 269.7099,-3540.5904 259.6314,-3543.8573 263.8684,-3549.4293\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219354296 -->\n",
       "<g class=\"node\" id=\"node60\">\n",
       "<title>139649219354296</title>\n",
       "<polygon fill=\"none\" points=\"103.5,-3431.5 103.5,-3467.5 483.5,-3467.5 483.5,-3431.5 103.5,-3431.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"293.5\" y=\"-3445.8\">Encoder-7-MultiHeadSelfAttention-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649219353288&#45;&gt;139649219354296 -->\n",
       "<g class=\"edge\" id=\"edge72\">\n",
       "<title>139649219353288-&gt;139649219354296</title>\n",
       "<path d=\"M293.5,-3504.4551C293.5,-3496.3828 293.5,-3486.6764 293.5,-3477.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"297.0001,-3477.5903 293.5,-3467.5904 290.0001,-3477.5904 297.0001,-3477.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219074760 -->\n",
       "<g class=\"node\" id=\"node61\">\n",
       "<title>139649219074760</title>\n",
       "<polygon fill=\"none\" points=\"91.5,-3358.5 91.5,-3394.5 333.5,-3394.5 333.5,-3358.5 91.5,-3358.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"212.5\" y=\"-3372.8\">Encoder-7-FeedForward: FeedForward</text>\n",
       "</g>\n",
       "<!-- 139649219354296&#45;&gt;139649219074760 -->\n",
       "<g class=\"edge\" id=\"edge73\">\n",
       "<title>139649219354296-&gt;139649219074760</title>\n",
       "<path d=\"M273.4775,-3431.4551C263.4498,-3422.4177 251.1491,-3411.3319 240.2286,-3401.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"242.3444,-3398.6852 232.5729,-3394.5904 237.6581,-3403.885 242.3444,-3398.6852\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219121616 -->\n",
       "<g class=\"node\" id=\"node63\">\n",
       "<title>139649219121616</title>\n",
       "<polygon fill=\"none\" points=\"177.5,-3212.5 177.5,-3248.5 397.5,-3248.5 397.5,-3212.5 177.5,-3212.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-3226.8\">Encoder-7-FeedForward-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139649219354296&#45;&gt;139649219121616 -->\n",
       "<g class=\"edge\" id=\"edge75\">\n",
       "<title>139649219354296-&gt;139649219121616</title>\n",
       "<path d=\"M315.3471,-3431.291C325.3936,-3421.6134 336.4097,-3408.8624 342.5,-3395 362.2044,-3350.1498 369.6917,-3329.6329 349.5,-3285 344.2852,-3273.4728 335.2939,-3263.4147 325.751,-3255.1833\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"327.6666,-3252.2331 317.676,-3248.7064 323.2868,-3257.6936 327.6666,-3252.2331\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219093616 -->\n",
       "<g class=\"node\" id=\"node62\">\n",
       "<title>139649219093616</title>\n",
       "<polygon fill=\"none\" points=\"73,-3285.5 73,-3321.5 340,-3321.5 340,-3285.5 73,-3285.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206.5\" y=\"-3299.8\">Encoder-7-FeedForward-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649219074760&#45;&gt;139649219093616 -->\n",
       "<g class=\"edge\" id=\"edge74\">\n",
       "<title>139649219074760-&gt;139649219093616</title>\n",
       "<path d=\"M211.0169,-3358.4551C210.3534,-3350.3828 209.5556,-3340.6764 208.8163,-3331.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"212.2944,-3331.27 207.9869,-3321.5904 205.3179,-3331.8435 212.2944,-3331.27\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219093616&#45;&gt;139649219121616 -->\n",
       "<g class=\"edge\" id=\"edge76\">\n",
       "<title>139649219093616-&gt;139649219121616</title>\n",
       "<path d=\"M226.5225,-3285.4551C236.5502,-3276.4177 248.8509,-3265.3319 259.7714,-3255.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"262.3419,-3257.885 267.4271,-3248.5904 257.6556,-3252.6852 262.3419,-3257.885\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649219121728 -->\n",
       "<g class=\"node\" id=\"node64\">\n",
       "<title>139649219121728</title>\n",
       "<polygon fill=\"none\" points=\"128.5,-3139.5 128.5,-3175.5 446.5,-3175.5 446.5,-3139.5 128.5,-3139.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-3153.8\">Encoder-7-FeedForward-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649219121616&#45;&gt;139649219121728 -->\n",
       "<g class=\"edge\" id=\"edge77\">\n",
       "<title>139649219121616-&gt;139649219121728</title>\n",
       "<path d=\"M287.5,-3212.4551C287.5,-3204.3828 287.5,-3194.6764 287.5,-3185.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"291.0001,-3185.5903 287.5,-3175.5904 284.0001,-3185.5904 291.0001,-3185.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649218767616 -->\n",
       "<g class=\"node\" id=\"node65\">\n",
       "<title>139649218767616</title>\n",
       "<polygon fill=\"none\" points=\"17.5,-3066.5 17.5,-3102.5 359.5,-3102.5 359.5,-3066.5 17.5,-3066.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-3080.8\">Encoder-8-MultiHeadSelfAttention: MultiHeadAttention</text>\n",
       "</g>\n",
       "<!-- 139649219121728&#45;&gt;139649218767616 -->\n",
       "<g class=\"edge\" id=\"edge78\">\n",
       "<title>139649219121728-&gt;139649218767616</title>\n",
       "<path d=\"M263.0281,-3139.4551C250.4149,-3130.1545 234.8597,-3118.6844 221.2286,-3108.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"223.1592,-3105.7082 213.0335,-3102.5904 219.0049,-3111.3421 223.1592,-3105.7082\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649218916304 -->\n",
       "<g class=\"node\" id=\"node67\">\n",
       "<title>139649218916304</title>\n",
       "<polygon fill=\"none\" points=\"149,-2920.5 149,-2956.5 430,-2956.5 430,-2920.5 149,-2920.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289.5\" y=\"-2934.8\">Encoder-8-MultiHeadSelfAttention-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139649219121728&#45;&gt;139649218916304 -->\n",
       "<g class=\"edge\" id=\"edge80\">\n",
       "<title>139649219121728-&gt;139649218916304</title>\n",
       "<path d=\"M330.0685,-3139.3804C345.0065,-3130.7 360.1359,-3118.7088 368.5,-3103 376.5894,-3087.8071 374.2511,-3010.9102 364.5,-2993 357.7494,-2980.601 346.8204,-2970.3006 335.3687,-2962.1162\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"337.2521,-2959.1654 326.99,-2956.531 333.3694,-2964.9899 337.2521,-2959.1654\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649218786472 -->\n",
       "<g class=\"node\" id=\"node66\">\n",
       "<title>139649218786472</title>\n",
       "<polygon fill=\"none\" points=\"27,-2993.5 27,-3029.5 356,-3029.5 356,-2993.5 27,-2993.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"191.5\" y=\"-3007.8\">Encoder-8-MultiHeadSelfAttention-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649218767616&#45;&gt;139649218786472 -->\n",
       "<g class=\"edge\" id=\"edge79\">\n",
       "<title>139649218767616-&gt;139649218786472</title>\n",
       "<path d=\"M189.2416,-3066.4551C189.5733,-3058.3828 189.9722,-3048.6764 190.3418,-3039.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"193.8429,-3039.7257 190.7566,-3029.5904 186.8488,-3039.4382 193.8429,-3039.7257\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649218786472&#45;&gt;139649218916304 -->\n",
       "<g class=\"edge\" id=\"edge81\">\n",
       "<title>139649218786472-&gt;139649218916304</title>\n",
       "<path d=\"M215.7247,-2993.4551C228.2105,-2984.1545 243.6086,-2972.6844 257.102,-2962.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"259.2855,-2965.371 265.2143,-2956.5904 255.1039,-2959.7573 259.2855,-2965.371\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649218826816 -->\n",
       "<g class=\"node\" id=\"node68\">\n",
       "<title>139649218826816</title>\n",
       "<polygon fill=\"none\" points=\"99.5,-2847.5 99.5,-2883.5 479.5,-2883.5 479.5,-2847.5 99.5,-2847.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289.5\" y=\"-2861.8\">Encoder-8-MultiHeadSelfAttention-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649218916304&#45;&gt;139649218826816 -->\n",
       "<g class=\"edge\" id=\"edge82\">\n",
       "<title>139649218916304-&gt;139649218826816</title>\n",
       "<path d=\"M289.5,-2920.4551C289.5,-2912.3828 289.5,-2902.6764 289.5,-2893.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"293.0001,-2893.5903 289.5,-2883.5904 286.0001,-2893.5904 293.0001,-2893.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649218401112 -->\n",
       "<g class=\"node\" id=\"node69\">\n",
       "<title>139649218401112</title>\n",
       "<polygon fill=\"none\" points=\"87.5,-2774.5 87.5,-2810.5 329.5,-2810.5 329.5,-2774.5 87.5,-2774.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"208.5\" y=\"-2788.8\">Encoder-8-FeedForward: FeedForward</text>\n",
       "</g>\n",
       "<!-- 139649218826816&#45;&gt;139649218401112 -->\n",
       "<g class=\"edge\" id=\"edge83\">\n",
       "<title>139649218826816-&gt;139649218401112</title>\n",
       "<path d=\"M269.4775,-2847.4551C259.4498,-2838.4177 247.1491,-2827.3319 236.2286,-2817.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"238.3444,-2814.6852 228.5729,-2810.5904 233.6581,-2819.885 238.3444,-2814.6852\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649218433208 -->\n",
       "<g class=\"node\" id=\"node71\">\n",
       "<title>139649218433208</title>\n",
       "<polygon fill=\"none\" points=\"173.5,-2628.5 173.5,-2664.5 393.5,-2664.5 393.5,-2628.5 173.5,-2628.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-2642.8\">Encoder-8-FeedForward-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139649218826816&#45;&gt;139649218433208 -->\n",
       "<g class=\"edge\" id=\"edge85\">\n",
       "<title>139649218826816-&gt;139649218433208</title>\n",
       "<path d=\"M311.3471,-2847.291C321.3936,-2837.6134 332.4097,-2824.8624 338.5,-2811 358.2044,-2766.1498 365.6917,-2745.6329 345.5,-2701 340.2852,-2689.4728 331.2939,-2679.4147 321.751,-2671.1833\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"323.6666,-2668.2331 313.676,-2664.7064 319.2868,-2673.6936 323.6666,-2668.2331\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649218401560 -->\n",
       "<g class=\"node\" id=\"node70\">\n",
       "<title>139649218401560</title>\n",
       "<polygon fill=\"none\" points=\"69,-2701.5 69,-2737.5 336,-2737.5 336,-2701.5 69,-2701.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-2715.8\">Encoder-8-FeedForward-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649218401112&#45;&gt;139649218401560 -->\n",
       "<g class=\"edge\" id=\"edge84\">\n",
       "<title>139649218401112-&gt;139649218401560</title>\n",
       "<path d=\"M207.0169,-2774.4551C206.3534,-2766.3828 205.5556,-2756.6764 204.8163,-2747.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"208.2944,-2747.27 203.9869,-2737.5904 201.3179,-2747.8435 208.2944,-2747.27\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649218401560&#45;&gt;139649218433208 -->\n",
       "<g class=\"edge\" id=\"edge86\">\n",
       "<title>139649218401560-&gt;139649218433208</title>\n",
       "<path d=\"M222.5225,-2701.4551C232.5502,-2692.4177 244.8509,-2681.3319 255.7714,-2671.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"258.3419,-2673.885 263.4271,-2664.5904 253.6556,-2668.6852 258.3419,-2673.885\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649218491112 -->\n",
       "<g class=\"node\" id=\"node72\">\n",
       "<title>139649218491112</title>\n",
       "<polygon fill=\"none\" points=\"124.5,-2555.5 124.5,-2591.5 442.5,-2591.5 442.5,-2555.5 124.5,-2555.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-2569.8\">Encoder-8-FeedForward-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649218433208&#45;&gt;139649218491112 -->\n",
       "<g class=\"edge\" id=\"edge87\">\n",
       "<title>139649218433208-&gt;139649218491112</title>\n",
       "<path d=\"M283.5,-2628.4551C283.5,-2620.3828 283.5,-2610.6764 283.5,-2601.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"287.0001,-2601.5903 283.5,-2591.5904 280.0001,-2601.5904 287.0001,-2601.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649218106256 -->\n",
       "<g class=\"node\" id=\"node73\">\n",
       "<title>139649218106256</title>\n",
       "<polygon fill=\"none\" points=\"13.5,-2482.5 13.5,-2518.5 355.5,-2518.5 355.5,-2482.5 13.5,-2482.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-2496.8\">Encoder-9-MultiHeadSelfAttention: MultiHeadAttention</text>\n",
       "</g>\n",
       "<!-- 139649218491112&#45;&gt;139649218106256 -->\n",
       "<g class=\"edge\" id=\"edge88\">\n",
       "<title>139649218491112-&gt;139649218106256</title>\n",
       "<path d=\"M259.0281,-2555.4551C246.4149,-2546.1545 230.8597,-2534.6844 217.2286,-2524.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"219.1592,-2521.7082 209.0335,-2518.5904 215.0049,-2527.3421 219.1592,-2521.7082\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649218121968 -->\n",
       "<g class=\"node\" id=\"node75\">\n",
       "<title>139649218121968</title>\n",
       "<polygon fill=\"none\" points=\"145,-2336.5 145,-2372.5 426,-2372.5 426,-2336.5 145,-2336.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"285.5\" y=\"-2350.8\">Encoder-9-MultiHeadSelfAttention-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139649218491112&#45;&gt;139649218121968 -->\n",
       "<g class=\"edge\" id=\"edge90\">\n",
       "<title>139649218491112-&gt;139649218121968</title>\n",
       "<path d=\"M326.0685,-2555.3804C341.0065,-2546.7 356.1359,-2534.7088 364.5,-2519 372.5894,-2503.8071 370.2511,-2426.9102 360.5,-2409 353.7494,-2396.601 342.8204,-2386.3006 331.3687,-2378.1162\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"333.2521,-2375.1654 322.99,-2372.531 329.3694,-2380.9899 333.2521,-2375.1654\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649218106704 -->\n",
       "<g class=\"node\" id=\"node74\">\n",
       "<title>139649218106704</title>\n",
       "<polygon fill=\"none\" points=\"23,-2409.5 23,-2445.5 352,-2445.5 352,-2409.5 23,-2409.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"187.5\" y=\"-2423.8\">Encoder-9-MultiHeadSelfAttention-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139649218106256&#45;&gt;139649218106704 -->\n",
       "<g class=\"edge\" id=\"edge89\">\n",
       "<title>139649218106256-&gt;139649218106704</title>\n",
       "<path d=\"M185.2416,-2482.4551C185.5733,-2474.3828 185.9722,-2464.6764 186.3418,-2455.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"189.8429,-2455.7257 186.7566,-2445.5904 182.8488,-2455.4382 189.8429,-2455.7257\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139649218106704&#45;&gt;139649218121968 -->\n",
       "<g class=\"edge\" id=\"edge91\">\n",
       "<title>139649218106704-&gt;139649218121968</title>\n",
       "<path d=\"M211.7247,-2409.4551C224.2105,-2400.1545 239.6086,-2388.6844 253.102,-2378.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"255.2855,-2381.371 261.2143,-2372.5904 251.1039,-2375.7573 255.2855,-2381.371\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648747658600 -->\n",
       "<g class=\"node\" id=\"node76\">\n",
       "<title>139648747658600</title>\n",
       "<polygon fill=\"none\" points=\"95.5,-2263.5 95.5,-2299.5 475.5,-2299.5 475.5,-2263.5 95.5,-2263.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"285.5\" y=\"-2277.8\">Encoder-9-MultiHeadSelfAttention-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139649218121968&#45;&gt;139648747658600 -->\n",
       "<g class=\"edge\" id=\"edge92\">\n",
       "<title>139649218121968-&gt;139648747658600</title>\n",
       "<path d=\"M285.5,-2336.4551C285.5,-2328.3828 285.5,-2318.6764 285.5,-2309.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"289.0001,-2309.5903 285.5,-2299.5904 282.0001,-2309.5904 289.0001,-2309.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648747691648 -->\n",
       "<g class=\"node\" id=\"node77\">\n",
       "<title>139648747691648</title>\n",
       "<polygon fill=\"none\" points=\"83.5,-2190.5 83.5,-2226.5 325.5,-2226.5 325.5,-2190.5 83.5,-2190.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"204.5\" y=\"-2204.8\">Encoder-9-FeedForward: FeedForward</text>\n",
       "</g>\n",
       "<!-- 139648747658600&#45;&gt;139648747691648 -->\n",
       "<g class=\"edge\" id=\"edge93\">\n",
       "<title>139648747658600-&gt;139648747691648</title>\n",
       "<path d=\"M265.4775,-2263.4551C255.4498,-2254.4177 243.1491,-2243.3319 232.2286,-2233.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"234.3444,-2230.6852 224.5729,-2226.5904 229.6581,-2235.885 234.3444,-2230.6852\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648747223360 -->\n",
       "<g class=\"node\" id=\"node79\">\n",
       "<title>139648747223360</title>\n",
       "<polygon fill=\"none\" points=\"169.5,-2044.5 169.5,-2080.5 389.5,-2080.5 389.5,-2044.5 169.5,-2044.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279.5\" y=\"-2058.8\">Encoder-9-FeedForward-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139648747658600&#45;&gt;139648747223360 -->\n",
       "<g class=\"edge\" id=\"edge95\">\n",
       "<title>139648747658600-&gt;139648747223360</title>\n",
       "<path d=\"M307.3471,-2263.291C317.3936,-2253.6134 328.4097,-2240.8624 334.5,-2227 354.2044,-2182.1498 361.6917,-2161.6329 341.5,-2117 336.2852,-2105.4728 327.2939,-2095.4147 317.751,-2087.1833\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"319.6666,-2084.2331 309.676,-2080.7064 315.2868,-2089.6936 319.6666,-2084.2331\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648747191264 -->\n",
       "<g class=\"node\" id=\"node78\">\n",
       "<title>139648747191264</title>\n",
       "<polygon fill=\"none\" points=\"65,-2117.5 65,-2153.5 332,-2153.5 332,-2117.5 65,-2117.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198.5\" y=\"-2131.8\">Encoder-9-FeedForward-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139648747691648&#45;&gt;139648747191264 -->\n",
       "<g class=\"edge\" id=\"edge94\">\n",
       "<title>139648747691648-&gt;139648747191264</title>\n",
       "<path d=\"M203.0169,-2190.4551C202.3534,-2182.3828 201.5556,-2172.6764 200.8163,-2163.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"204.2944,-2163.27 199.9869,-2153.5904 197.3179,-2163.8435 204.2944,-2163.27\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648747191264&#45;&gt;139648747223360 -->\n",
       "<g class=\"edge\" id=\"edge96\">\n",
       "<title>139648747191264-&gt;139648747223360</title>\n",
       "<path d=\"M218.5225,-2117.4551C228.5502,-2108.4177 240.8509,-2097.3319 251.7714,-2087.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"254.3419,-2089.885 259.4271,-2080.5904 249.6556,-2084.6852 254.3419,-2089.885\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648747223472 -->\n",
       "<g class=\"node\" id=\"node80\">\n",
       "<title>139648747223472</title>\n",
       "<polygon fill=\"none\" points=\"120.5,-1971.5 120.5,-2007.5 438.5,-2007.5 438.5,-1971.5 120.5,-1971.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279.5\" y=\"-1985.8\">Encoder-9-FeedForward-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139648747223360&#45;&gt;139648747223472 -->\n",
       "<g class=\"edge\" id=\"edge97\">\n",
       "<title>139648747223360-&gt;139648747223472</title>\n",
       "<path d=\"M279.5,-2044.4551C279.5,-2036.3828 279.5,-2026.6764 279.5,-2017.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"283.0001,-2017.5903 279.5,-2007.5904 276.0001,-2017.5904 283.0001,-2017.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648747376312 -->\n",
       "<g class=\"node\" id=\"node81\">\n",
       "<title>139648747376312</title>\n",
       "<polygon fill=\"none\" points=\"3.5,-1898.5 3.5,-1934.5 353.5,-1934.5 353.5,-1898.5 3.5,-1898.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178.5\" y=\"-1912.8\">Encoder-10-MultiHeadSelfAttention: MultiHeadAttention</text>\n",
       "</g>\n",
       "<!-- 139648747223472&#45;&gt;139648747376312 -->\n",
       "<g class=\"edge\" id=\"edge98\">\n",
       "<title>139648747223472-&gt;139648747376312</title>\n",
       "<path d=\"M254.5337,-1971.4551C241.6658,-1962.1545 225.7962,-1950.6844 211.8898,-1940.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"213.6841,-1937.6116 203.5291,-1934.5904 209.5836,-1943.2849 213.6841,-1937.6116\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648746946008 -->\n",
       "<g class=\"node\" id=\"node83\">\n",
       "<title>139648746946008</title>\n",
       "<polygon fill=\"none\" points=\"137,-1752.5 137,-1788.5 426,-1788.5 426,-1752.5 137,-1752.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281.5\" y=\"-1766.8\">Encoder-10-MultiHeadSelfAttention-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139648747223472&#45;&gt;139648746946008 -->\n",
       "<g class=\"edge\" id=\"edge100\">\n",
       "<title>139648747223472-&gt;139648746946008</title>\n",
       "<path d=\"M323.5299,-1971.3618C338.6906,-1962.7299 353.9854,-1950.7771 362.5,-1935 370.6814,-1919.8405 368.4328,-1842.9762 358.5,-1825 351.6163,-1812.542 340.5325,-1802.2616 328.8935,-1794.116\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"330.6612,-1791.0903 320.3726,-1788.5614 326.8385,-1796.9544 330.6612,-1791.0903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648747408408 -->\n",
       "<g class=\"node\" id=\"node82\">\n",
       "<title>139648747408408</title>\n",
       "<polygon fill=\"none\" points=\"13.5,-1825.5 13.5,-1861.5 349.5,-1861.5 349.5,-1825.5 13.5,-1825.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"181.5\" y=\"-1839.8\">Encoder-10-MultiHeadSelfAttention-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139648747376312&#45;&gt;139648747408408 -->\n",
       "<g class=\"edge\" id=\"edge99\">\n",
       "<title>139648747376312-&gt;139648747408408</title>\n",
       "<path d=\"M179.2416,-1898.4551C179.5733,-1890.3828 179.9722,-1880.6764 180.3418,-1871.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"183.8429,-1871.7257 180.7566,-1861.5904 176.8488,-1871.4382 183.8429,-1871.7257\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648747408408&#45;&gt;139648746946008 -->\n",
       "<g class=\"edge\" id=\"edge101\">\n",
       "<title>139648747408408-&gt;139648746946008</title>\n",
       "<path d=\"M206.2191,-1825.4551C218.9597,-1816.1545 234.6721,-1804.6844 248.4408,-1794.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"250.7055,-1797.3134 256.7187,-1788.5904 246.5781,-1791.6596 250.7055,-1797.3134\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648746916216 -->\n",
       "<g class=\"node\" id=\"node84\">\n",
       "<title>139648746916216</title>\n",
       "<polygon fill=\"none\" points=\"88,-1679.5 88,-1715.5 475,-1715.5 475,-1679.5 88,-1679.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281.5\" y=\"-1693.8\">Encoder-10-MultiHeadSelfAttention-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139648746946008&#45;&gt;139648746916216 -->\n",
       "<g class=\"edge\" id=\"edge102\">\n",
       "<title>139648746946008-&gt;139648746916216</title>\n",
       "<path d=\"M281.5,-1752.4551C281.5,-1744.3828 281.5,-1734.6764 281.5,-1725.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"285.0001,-1725.5903 281.5,-1715.5904 278.0001,-1725.5904 285.0001,-1725.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648746495504 -->\n",
       "<g class=\"node\" id=\"node85\">\n",
       "<title>139648746495504</title>\n",
       "<polygon fill=\"none\" points=\"74,-1606.5 74,-1642.5 323,-1642.5 323,-1606.5 74,-1606.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198.5\" y=\"-1620.8\">Encoder-10-FeedForward: FeedForward</text>\n",
       "</g>\n",
       "<!-- 139648746916216&#45;&gt;139648746495504 -->\n",
       "<g class=\"edge\" id=\"edge103\">\n",
       "<title>139648746916216-&gt;139648746495504</title>\n",
       "<path d=\"M260.9831,-1679.4551C250.608,-1670.3299 237.8584,-1659.1165 226.5877,-1649.2036\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"228.8889,-1646.5665 219.0685,-1642.5904 224.2659,-1651.8228 228.8889,-1646.5665\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648746558744 -->\n",
       "<g class=\"node\" id=\"node87\">\n",
       "<title>139648746558744</title>\n",
       "<polygon fill=\"none\" points=\"162,-1460.5 162,-1496.5 389,-1496.5 389,-1460.5 162,-1460.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275.5\" y=\"-1474.8\">Encoder-10-FeedForward-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139648746916216&#45;&gt;139648746558744 -->\n",
       "<g class=\"edge\" id=\"edge105\">\n",
       "<title>139648746916216-&gt;139648746558744</title>\n",
       "<path d=\"M303.7102,-1679.3371C313.9414,-1669.6709 325.1891,-1656.916 331.5,-1643 351.745,-1598.358 360.0543,-1577.5004 339.5,-1533 334.0436,-1521.1867 324.6242,-1510.9911 314.6643,-1502.7193\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"316.678,-1499.8521 306.6262,-1496.5038 312.396,-1505.3897 316.678,-1499.8521\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648746518456 -->\n",
       "<g class=\"node\" id=\"node86\">\n",
       "<title>139648746518456</title>\n",
       "<polygon fill=\"none\" points=\"55,-1533.5 55,-1569.5 330,-1569.5 330,-1533.5 55,-1533.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192.5\" y=\"-1547.8\">Encoder-10-FeedForward-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139648746495504&#45;&gt;139648746518456 -->\n",
       "<g class=\"edge\" id=\"edge104\">\n",
       "<title>139648746495504-&gt;139648746518456</title>\n",
       "<path d=\"M197.0169,-1606.4551C196.3534,-1598.3828 195.5556,-1588.6764 194.8163,-1579.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"198.2944,-1579.27 193.9869,-1569.5904 191.3179,-1579.8435 198.2944,-1579.27\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648746518456&#45;&gt;139648746558744 -->\n",
       "<g class=\"edge\" id=\"edge106\">\n",
       "<title>139648746518456-&gt;139648746558744</title>\n",
       "<path d=\"M213.0169,-1533.4551C223.392,-1524.3299 236.1416,-1513.1165 247.4123,-1503.2036\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"249.7341,-1505.8228 254.9315,-1496.5904 245.1111,-1500.5665 249.7341,-1505.8228\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648746558856 -->\n",
       "<g class=\"node\" id=\"node88\">\n",
       "<title>139648746558856</title>\n",
       "<polygon fill=\"none\" points=\"112.5,-1387.5 112.5,-1423.5 438.5,-1423.5 438.5,-1387.5 112.5,-1387.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275.5\" y=\"-1401.8\">Encoder-10-FeedForward-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139648746558744&#45;&gt;139648746558856 -->\n",
       "<g class=\"edge\" id=\"edge107\">\n",
       "<title>139648746558744-&gt;139648746558856</title>\n",
       "<path d=\"M275.5,-1460.4551C275.5,-1452.3828 275.5,-1442.6764 275.5,-1433.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"279.0001,-1433.5903 275.5,-1423.5904 272.0001,-1433.5904 279.0001,-1433.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648746200648 -->\n",
       "<g class=\"node\" id=\"node89\">\n",
       "<title>139648746200648</title>\n",
       "<polygon fill=\"none\" points=\"0,-1314.5 0,-1350.5 349,-1350.5 349,-1314.5 0,-1314.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"174.5\" y=\"-1328.8\">Encoder-11-MultiHeadSelfAttention: MultiHeadAttention</text>\n",
       "</g>\n",
       "<!-- 139648746558856&#45;&gt;139648746200648 -->\n",
       "<g class=\"edge\" id=\"edge108\">\n",
       "<title>139648746558856-&gt;139648746200648</title>\n",
       "<path d=\"M250.5337,-1387.4551C237.6658,-1378.1545 221.7962,-1366.6844 207.8898,-1356.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"209.6841,-1353.6116 199.5291,-1350.5904 205.5836,-1359.2849 209.6841,-1353.6116\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648746326504 -->\n",
       "<g class=\"node\" id=\"node91\">\n",
       "<title>139648746326504</title>\n",
       "<polygon fill=\"none\" points=\"133.5,-1168.5 133.5,-1204.5 421.5,-1204.5 421.5,-1168.5 133.5,-1168.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-1182.8\">Encoder-11-MultiHeadSelfAttention-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139648746558856&#45;&gt;139648746326504 -->\n",
       "<g class=\"edge\" id=\"edge110\">\n",
       "<title>139648746558856-&gt;139648746326504</title>\n",
       "<path d=\"M319.5299,-1387.3618C334.6906,-1378.7299 349.9854,-1366.7771 358.5,-1351 366.6814,-1335.8405 364.4328,-1258.9762 354.5,-1241 347.6163,-1228.542 336.5325,-1218.2616 324.8935,-1210.116\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"326.6612,-1207.0903 316.3726,-1204.5614 322.8385,-1212.9544 326.6612,-1207.0903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648746231792 -->\n",
       "<g class=\"node\" id=\"node90\">\n",
       "<title>139648746231792</title>\n",
       "<polygon fill=\"none\" points=\"10,-1241.5 10,-1277.5 345,-1277.5 345,-1241.5 10,-1241.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"177.5\" y=\"-1255.8\">Encoder-11-MultiHeadSelfAttention-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139648746200648&#45;&gt;139648746231792 -->\n",
       "<g class=\"edge\" id=\"edge109\">\n",
       "<title>139648746200648-&gt;139648746231792</title>\n",
       "<path d=\"M175.2416,-1314.4551C175.5733,-1306.3828 175.9722,-1296.6764 176.3418,-1287.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"179.8429,-1287.7257 176.7566,-1277.5904 172.8488,-1287.4382 179.8429,-1287.7257\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648746231792&#45;&gt;139648746326504 -->\n",
       "<g class=\"edge\" id=\"edge111\">\n",
       "<title>139648746231792-&gt;139648746326504</title>\n",
       "<path d=\"M202.2191,-1241.4551C214.9597,-1232.1545 230.6721,-1220.6844 244.4408,-1210.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"246.7055,-1213.3134 252.7187,-1204.5904 242.5781,-1207.6596 246.7055,-1213.3134\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648746251096 -->\n",
       "<g class=\"node\" id=\"node92\">\n",
       "<title>139648746251096</title>\n",
       "<polygon fill=\"none\" points=\"84.5,-1095.5 84.5,-1131.5 470.5,-1131.5 470.5,-1095.5 84.5,-1095.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-1109.8\">Encoder-11-MultiHeadSelfAttention-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139648746326504&#45;&gt;139648746251096 -->\n",
       "<g class=\"edge\" id=\"edge112\">\n",
       "<title>139648746326504-&gt;139648746251096</title>\n",
       "<path d=\"M277.5,-1168.4551C277.5,-1160.3828 277.5,-1150.6764 277.5,-1141.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"281.0001,-1141.5903 277.5,-1131.5904 274.0001,-1141.5904 281.0001,-1141.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648745843176 -->\n",
       "<g class=\"node\" id=\"node93\">\n",
       "<title>139648745843176</title>\n",
       "<polygon fill=\"none\" points=\"77.5,-1022.5 77.5,-1058.5 325.5,-1058.5 325.5,-1022.5 77.5,-1022.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"201.5\" y=\"-1036.8\">Encoder-11-FeedForward: FeedForward</text>\n",
       "</g>\n",
       "<!-- 139648746251096&#45;&gt;139648745843176 -->\n",
       "<g class=\"edge\" id=\"edge113\">\n",
       "<title>139648746251096-&gt;139648745843176</title>\n",
       "<path d=\"M258.7135,-1095.4551C249.3961,-1086.5054 237.9873,-1075.547 227.8157,-1065.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"229.9704,-1062.9935 220.3338,-1058.5904 225.1212,-1068.0419 229.9704,-1062.9935\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648745344696 -->\n",
       "<g class=\"node\" id=\"node95\">\n",
       "<title>139648745344696</title>\n",
       "<polygon fill=\"none\" points=\"163,-876.5 163,-912.5 390,-912.5 390,-876.5 163,-876.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276.5\" y=\"-890.8\">Encoder-11-FeedForward-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139648746251096&#45;&gt;139648745344696 -->\n",
       "<g class=\"edge\" id=\"edge115\">\n",
       "<title>139648746251096-&gt;139648745344696</title>\n",
       "<path d=\"M303.8634,-1095.2916C315.3206,-1085.8699 327.6647,-1073.3358 334.5,-1059 355.572,-1014.8049 361.0306,-993.4492 340.5,-949 335.0436,-937.1867 325.6242,-926.9911 315.6643,-918.7193\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"317.678,-915.8521 307.6262,-912.5038 313.396,-921.3897 317.678,-915.8521\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648745341840 -->\n",
       "<g class=\"node\" id=\"node94\">\n",
       "<title>139648745341840</title>\n",
       "<polygon fill=\"none\" points=\"57.5,-949.5 57.5,-985.5 331.5,-985.5 331.5,-949.5 57.5,-949.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-963.8\">Encoder-11-FeedForward-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139648745843176&#45;&gt;139648745341840 -->\n",
       "<g class=\"edge\" id=\"edge114\">\n",
       "<title>139648745843176-&gt;139648745341840</title>\n",
       "<path d=\"M199.7697,-1022.4551C198.9956,-1014.3828 198.0649,-1004.6764 197.2024,-995.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"200.6733,-995.2106 196.2347,-985.5904 193.7053,-995.8788 200.6733,-995.2106\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648745341840&#45;&gt;139648745344696 -->\n",
       "<g class=\"edge\" id=\"edge116\">\n",
       "<title>139648745341840-&gt;139648745344696</title>\n",
       "<path d=\"M214.7697,-949.4551C224.9212,-940.4177 237.3738,-929.3319 248.4291,-919.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"251.0375,-921.8539 256.1793,-912.5904 246.383,-916.6255 251.0375,-921.8539\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648745373880 -->\n",
       "<g class=\"node\" id=\"node96\">\n",
       "<title>139648745373880</title>\n",
       "<polygon fill=\"none\" points=\"114,-803.5 114,-839.5 439,-839.5 439,-803.5 114,-803.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276.5\" y=\"-817.8\">Encoder-11-FeedForward-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139648745344696&#45;&gt;139648745373880 -->\n",
       "<g class=\"edge\" id=\"edge117\">\n",
       "<title>139648745344696-&gt;139648745373880</title>\n",
       "<path d=\"M276.5,-876.4551C276.5,-868.3828 276.5,-858.6764 276.5,-849.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"280.0001,-849.5903 276.5,-839.5904 273.0001,-849.5904 280.0001,-849.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648745544224 -->\n",
       "<g class=\"node\" id=\"node97\">\n",
       "<title>139648745544224</title>\n",
       "<polygon fill=\"none\" points=\".5,-730.5 .5,-766.5 350.5,-766.5 350.5,-730.5 .5,-730.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.5\" y=\"-744.8\">Encoder-12-MultiHeadSelfAttention: MultiHeadAttention</text>\n",
       "</g>\n",
       "<!-- 139648745373880&#45;&gt;139648745544224 -->\n",
       "<g class=\"edge\" id=\"edge118\">\n",
       "<title>139648745373880-&gt;139648745544224</title>\n",
       "<path d=\"M251.5337,-803.4551C238.6658,-794.1545 222.7962,-782.6844 208.8898,-772.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"210.6841,-769.6116 200.5291,-766.5904 206.5836,-775.2849 210.6841,-769.6116\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648745172608 -->\n",
       "<g class=\"node\" id=\"node99\">\n",
       "<title>139648745172608</title>\n",
       "<polygon fill=\"none\" points=\"134,-584.5 134,-620.5 423,-620.5 423,-584.5 134,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-598.8\">Encoder-12-MultiHeadSelfAttention-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139648745373880&#45;&gt;139648745172608 -->\n",
       "<g class=\"edge\" id=\"edge120\">\n",
       "<title>139648745373880-&gt;139648745172608</title>\n",
       "<path d=\"M320.5299,-803.3618C335.6906,-794.7299 350.9854,-782.7771 359.5,-767 367.6814,-751.8405 365.4328,-674.9762 355.5,-657 348.6163,-644.542 337.5325,-634.2616 325.8935,-626.116\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"327.6612,-623.0903 317.3726,-620.5614 323.8385,-628.9544 327.6612,-623.0903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648745579464 -->\n",
       "<g class=\"node\" id=\"node98\">\n",
       "<title>139648745579464</title>\n",
       "<polygon fill=\"none\" points=\"10.5,-657.5 10.5,-693.5 346.5,-693.5 346.5,-657.5 10.5,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178.5\" y=\"-671.8\">Encoder-12-MultiHeadSelfAttention-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139648745544224&#45;&gt;139648745579464 -->\n",
       "<g class=\"edge\" id=\"edge119\">\n",
       "<title>139648745544224-&gt;139648745579464</title>\n",
       "<path d=\"M176.2416,-730.4551C176.5733,-722.3828 176.9722,-712.6764 177.3418,-703.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"180.8429,-703.7257 177.7566,-693.5904 173.8488,-703.4382 180.8429,-703.7257\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648745579464&#45;&gt;139648745172608 -->\n",
       "<g class=\"edge\" id=\"edge121\">\n",
       "<title>139648745579464-&gt;139648745172608</title>\n",
       "<path d=\"M203.2191,-657.4551C215.9597,-648.1545 231.6721,-636.6844 245.4408,-626.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"247.7055,-629.3134 253.7187,-620.5904 243.5781,-623.6596 247.7055,-629.3134\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648745599328 -->\n",
       "<g class=\"node\" id=\"node100\">\n",
       "<title>139648745599328</title>\n",
       "<polygon fill=\"none\" points=\"85,-511.5 85,-547.5 472,-547.5 472,-511.5 85,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-525.8\">Encoder-12-MultiHeadSelfAttention-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139648745172608&#45;&gt;139648745599328 -->\n",
       "<g class=\"edge\" id=\"edge122\">\n",
       "<title>139648745172608-&gt;139648745599328</title>\n",
       "<path d=\"M278.5,-584.4551C278.5,-576.3828 278.5,-566.6764 278.5,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"282.0001,-557.5903 278.5,-547.5904 275.0001,-557.5904 282.0001,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648744665720 -->\n",
       "<g class=\"node\" id=\"node101\">\n",
       "<title>139648744665720</title>\n",
       "<polygon fill=\"none\" points=\"71,-438.5 71,-474.5 320,-474.5 320,-438.5 71,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-452.8\">Encoder-12-FeedForward: FeedForward</text>\n",
       "</g>\n",
       "<!-- 139648745599328&#45;&gt;139648744665720 -->\n",
       "<g class=\"edge\" id=\"edge123\">\n",
       "<title>139648745599328-&gt;139648744665720</title>\n",
       "<path d=\"M257.9831,-511.4551C247.608,-502.3299 234.8584,-491.1165 223.5877,-481.2036\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"225.8889,-478.5665 216.0685,-474.5904 221.2659,-483.8228 225.8889,-478.5665\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648744701232 -->\n",
       "<g class=\"node\" id=\"node103\">\n",
       "<title>139648744701232</title>\n",
       "<polygon fill=\"none\" points=\"159,-292.5 159,-328.5 386,-328.5 386,-292.5 159,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.5\" y=\"-306.8\">Encoder-12-FeedForward-Add: Add</text>\n",
       "</g>\n",
       "<!-- 139648745599328&#45;&gt;139648744701232 -->\n",
       "<g class=\"edge\" id=\"edge125\">\n",
       "<title>139648745599328-&gt;139648744701232</title>\n",
       "<path d=\"M300.7102,-511.3371C310.9414,-501.6709 322.1891,-488.916 328.5,-475 348.745,-430.358 357.0543,-409.5004 336.5,-365 331.0436,-353.1867 321.6242,-342.9911 311.6643,-334.7193\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"313.678,-331.8521 303.6262,-328.5038 309.396,-337.3897 313.678,-331.8521\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648744668968 -->\n",
       "<g class=\"node\" id=\"node102\">\n",
       "<title>139648744668968</title>\n",
       "<polygon fill=\"none\" points=\"52,-365.5 52,-401.5 327,-401.5 327,-365.5 52,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"189.5\" y=\"-379.8\">Encoder-12-FeedForward-Dropout: Dropout</text>\n",
       "</g>\n",
       "<!-- 139648744665720&#45;&gt;139648744668968 -->\n",
       "<g class=\"edge\" id=\"edge124\">\n",
       "<title>139648744665720-&gt;139648744668968</title>\n",
       "<path d=\"M194.0169,-438.4551C193.3534,-430.3828 192.5556,-420.6764 191.8163,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"195.2944,-411.27 190.9869,-401.5904 188.3179,-411.8435 195.2944,-411.27\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648744668968&#45;&gt;139648744701232 -->\n",
       "<g class=\"edge\" id=\"edge126\">\n",
       "<title>139648744668968-&gt;139648744701232</title>\n",
       "<path d=\"M210.0169,-365.4551C220.392,-356.3299 233.1416,-345.1165 244.4123,-335.2036\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"246.7341,-337.8228 251.9315,-328.5904 242.1111,-332.5665 246.7341,-337.8228\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648744758968 -->\n",
       "<g class=\"node\" id=\"node104\">\n",
       "<title>139648744758968</title>\n",
       "<polygon fill=\"none\" points=\"109.5,-219.5 109.5,-255.5 435.5,-255.5 435.5,-219.5 109.5,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.5\" y=\"-233.8\">Encoder-12-FeedForward-Norm: LayerNormalization</text>\n",
       "</g>\n",
       "<!-- 139648744701232&#45;&gt;139648744758968 -->\n",
       "<g class=\"edge\" id=\"edge127\">\n",
       "<title>139648744701232-&gt;139648744758968</title>\n",
       "<path d=\"M272.5,-292.4551C272.5,-284.3828 272.5,-274.6764 272.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.0001,-265.5903 272.5,-255.5904 269.0001,-265.5904 276.0001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648744542104 -->\n",
       "<g class=\"node\" id=\"node105\">\n",
       "<title>139648744542104</title>\n",
       "<polygon fill=\"none\" points=\"220,-146.5 220,-182.5 325,-182.5 325,-146.5 220,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.5\" y=\"-160.8\">Extract: Extract</text>\n",
       "</g>\n",
       "<!-- 139648744758968&#45;&gt;139648744542104 -->\n",
       "<g class=\"edge\" id=\"edge128\">\n",
       "<title>139648744758968-&gt;139648744542104</title>\n",
       "<path d=\"M272.5,-219.4551C272.5,-211.3828 272.5,-201.6764 272.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.0001,-192.5903 272.5,-182.5904 269.0001,-192.5904 276.0001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648744255104 -->\n",
       "<g class=\"node\" id=\"node106\">\n",
       "<title>139648744255104</title>\n",
       "<polygon fill=\"none\" points=\"209.5,-73.5 209.5,-109.5 335.5,-109.5 335.5,-73.5 209.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.5\" y=\"-87.8\">NSP-Dense: Dense</text>\n",
       "</g>\n",
       "<!-- 139648744542104&#45;&gt;139648744255104 -->\n",
       "<g class=\"edge\" id=\"edge129\">\n",
       "<title>139648744542104-&gt;139648744255104</title>\n",
       "<path d=\"M272.5,-146.4551C272.5,-138.3828 272.5,-128.6764 272.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.0001,-119.5903 272.5,-109.5904 269.0001,-119.5904 276.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139647198449792 -->\n",
       "<g class=\"node\" id=\"node107\">\n",
       "<title>139647198449792</title>\n",
       "<polygon fill=\"none\" points=\"210,-.5 210,-36.5 335,-36.5 335,-.5 210,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.5\" y=\"-14.8\">real_output: Dense</text>\n",
       "</g>\n",
       "<!-- 139648744255104&#45;&gt;139647198449792 -->\n",
       "<g class=\"edge\" id=\"edge130\">\n",
       "<title>139648744255104-&gt;139647198449792</title>\n",
       "<path d=\"M272.5,-73.4551C272.5,-65.3828 272.5,-55.6764 272.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.0001,-46.5903 272.5,-36.5904 269.0001,-46.5904 276.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot\n",
    "\n",
    "\n",
    "SVG(model_to_dot(get_bert_finetuning_model(model), dpi=65).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VfEshzLzOZ9S",
    "outputId": "10ef7ab3-dec0-4d78-ae82-81cd5b0a38e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 131,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzXDLy0KHRWW"
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2rp0TNNwGEy5"
   },
   "outputs": [],
   "source": [
    "bert_model = get_bert_finetuning_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "grCzMchkHUMz",
    "outputId": "c3e136c8-dbc8-4f76-db48-8dc71937d71e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 512, 768), ( 23308032    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 512, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 512, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 512, 768)     393216      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 512, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 512, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 768)    2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 512, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 512, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 512, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 512, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 512, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 512, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "real_output (Dense)             (None, 1)            769         NSP-Dense[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,350,145\n",
      "Trainable params: 109,350,145\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "stjJWR8RNMFU",
    "outputId": "d81a5891-d227-4fe4-a8d2-e4c9fa1b6788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "113/113 [==============================] - 147s 1s/step - loss: 0.9094 - accuracy: 0.1089 - val_loss: 0.9769 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "113/113 [==============================] - 144s 1s/step - loss: 0.9070 - accuracy: 0.1978 - val_loss: 0.9769 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "113/113 [==============================] - 145s 1s/step - loss: 0.9071 - accuracy: 0.2467 - val_loss: 0.9769 - val_accuracy: 0.5437\n",
      "Epoch 4/5\n",
      "113/113 [==============================] - 144s 1s/step - loss: 0.9071 - accuracy: 0.3144 - val_loss: 0.9776 - val_accuracy: 0.4563\n",
      "Epoch 5/5\n",
      "113/113 [==============================] - 144s 1s/step - loss: 0.9072 - accuracy: 0.3222 - val_loss: 0.9769 - val_accuracy: 0.5437\n"
     ]
    }
   ],
   "source": [
    "bert_model = get_bert_finetuning_model(model)\n",
    "history = bert_model.fit([train_x[0][0],train_x[1][0]], train_y, epochs=5, batch_size=8, verbose = 1, validation_data=([test_x[0][0],test_x[1][0]], test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "colab_type": "code",
    "id": "dbQnBexHRurd",
    "outputId": "76349e6b-d540-4596-f898-50b8cbca987d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "113/113 [==============================] - 148s 1s/step - loss: 0.7107 - accuracy: 0.5067 - val_loss: 0.7087 - val_accuracy: 0.4563\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 144s 1s/step - loss: 0.7338 - accuracy: 0.5100 - val_loss: 0.7065 - val_accuracy: 0.5437\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 144s 1s/step - loss: 0.7237 - accuracy: 0.5178 - val_loss: 0.7000 - val_accuracy: 0.5437\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 144s 1s/step - loss: 0.7236 - accuracy: 0.4889 - val_loss: 0.6902 - val_accuracy: 0.5437\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 144s 1s/step - loss: 0.7100 - accuracy: 0.5000 - val_loss: 0.7071 - val_accuracy: 0.5437\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 144s 1s/step - loss: 0.7307 - accuracy: 0.4867 - val_loss: 0.6893 - val_accuracy: 0.5437\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 144s 1s/step - loss: 0.7320 - accuracy: 0.5156 - val_loss: 0.6931 - val_accuracy: 0.5437\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 144s 1s/step - loss: 0.7239 - accuracy: 0.4733 - val_loss: 0.7449 - val_accuracy: 0.4563\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 144s 1s/step - loss: 0.7207 - accuracy: 0.4667 - val_loss: 0.6895 - val_accuracy: 0.5437\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 144s 1s/step - loss: 0.7407 - accuracy: 0.5022 - val_loss: 0.7254 - val_accuracy: 0.4563\n"
     ]
    }
   ],
   "source": [
    "bert_model1 = get_bert_finetuning_model(model)\n",
    "history = bert_model1.fit([train_x[0][0],train_x[1][0]], train_y, epochs=10, batch_size=8, verbose = 1, validation_data=([test_x[0][0],test_x[1][0]], test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "CCxk3VVCfg6N",
    "outputId": "997f200a-2b81-4920-ffb1-ef5f017cae85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 280s 1s/step - loss: 0.7404 - accuracy: 0.4922 - val_loss: 0.7186 - val_accuracy: 0.4563\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 274s 1s/step - loss: 0.7349 - accuracy: 0.5133 - val_loss: 0.7309 - val_accuracy: 0.4563\n"
     ]
    }
   ],
   "source": [
    "bert_model2 = get_bert_finetuning_model(model)\n",
    "history = bert_model2.fit([train_x[0][0],train_x[1][0]], train_y, epochs=10, batch_size=4, verbose = 1, validation_data=([test_x[0][0],test_x[1][0]], test_y),\n",
    "                          callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "colab_type": "code",
    "id": "GJJBs7iqeg7w",
    "outputId": "6a0c122c-e818-4163-e440-2b05df06c388"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-4d6658bfc899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_model2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bert_finetuning_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-b63f9e70fb81>\u001b[0m in \u001b[0;36mget_bert_finetuning_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_bert_finetuning_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "bert_model2 = get_bert_finetuning_model(model)\n",
    "history = bert_model2.fit([train_x[0][0],train_x[1][0]], train_y, epochs=10, batch_size=4, verbose = 1, validation_data=([test_x[0][0],test_x[1][0]], test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwqPhO1VSTBY"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "colab_type": "code",
    "id": "ziCus07TsDdJ",
    "outputId": "6a5e57e4-6290-41f4-e604-4f3c702fdea9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-d21b8315574c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'korbert_model_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'korbert_model_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "model_loss = history.history['val_loss']\n",
    "model_accuracy = history.history['val_accuracy']\n",
    "epochs = range(1, 11)\n",
    "plt.plot(epochs, model_accuracy, 'b+', label='korbert_model_accuracy')\n",
    "plt.plot(epochs, model_loss, 'ro', label='korbert_model_loss')\n",
    "plt.xlabel('Epochs')\n",
    "#plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "W7Zk-ss0G8jq",
    "outputId": "f0b027f0-1011-48ac-8ca3-3d0894bbb5a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "113/113 [==============================] - 142s 1s/step - loss: 0.8274 - accuracy: 0.4844\n",
      "Epoch 2/2\n",
      "113/113 [==============================] - 141s 1s/step - loss: 0.7450 - accuracy: 0.5067\n"
     ]
    }
   ],
   "source": [
    "bert_model = get_bert_finetuning_model(model)\n",
    "history = bert_model.fit([train_x[0][0],train_x[1][0]], train_y, epochs=2, batch_size=8, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jm_drxOjG8rt",
    "outputId": "a0b822cc-779b-4834-de97-a1d7e6302173"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa=df['content1'].astype('str')\n",
    "#type(aa[0])\n",
    "\n",
    "type(df['content1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sH94UfiNG85V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cztOnXuvG89Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3IRwxGvG836"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "heX1RquxG8z7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jrMIGCw0G8xY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1QnJhWB7G8vI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4lQQQep7G8pW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2naCjR28G8nq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TkiLkzqG8hJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MLh6j9LvG8e7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aiLsgyNTG8cs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAveTbGwG8W0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0biUIfJ7G8RL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "8W1XRN_e-xix",
    "outputId": "76dcb0c7-ffc0-4b0a-d83a-fcf11cfc76bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-28 07:32:33--  https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.119.128, 108.177.126.128, 108.177.127.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.119.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 662903077 (632M) [application/zip]\n",
      "Saving to: ‘multi_cased_L-12_H-768_A-12.zip’\n",
      "\n",
      "multi_cased_L-12_H- 100%[===================>] 632.19M  51.0MB/s    in 12s     \n",
      "\n",
      "2020-08-28 07:32:46 (54.4 MB/s) - ‘multi_cased_L-12_H-768_A-12.zip’ saved [662903077/662903077]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# wget을 활용해서 bert 모델 다운로드 가능\n",
    "import os\n",
    "!wget https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
    "\n",
    "if \"bert\" not in os.listdir():\n",
    "  os.makedirs(\"bert\")\n",
    "else:\n",
    "  pass\n",
    "\n",
    "import zipfile\n",
    "import shutil\n",
    "         \n",
    "bert_zip = zipfile.ZipFile('multi_cased_L-12_H-768_A-12.zip')\n",
    "bert_zip.extractall('bert')\n",
    " \n",
    "bert_zip.close()\n",
    "\n",
    "def copytree(src, dst, symlinks=False, ignore=None):\n",
    "    for item in os.listdir(src):\n",
    "        s = os.path.join(src, item)\n",
    "        d = os.path.join(dst, item)\n",
    "        if os.path.isdir(s):\n",
    "            shutil.copytree(s, d, symlinks, ignore)\n",
    "        else:\n",
    "            shutil.copy2(s, d)\n",
    "\n",
    "copytree(\"bert/multi_cased_L-12_H-768_A-12\", \"bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbNzD-7s_66V"
   },
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ch_Z1PHG_BQY"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 2167\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS=2\n",
    "LR=1e-5\n",
    "\n",
    "pretrained_path ='/content/gdrive/My Drive/KorBERT'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(pretrained_path, 'model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.korean_morp.txt')\n",
    "\n",
    "DATA_COLUMN = \"content1\"\n",
    "LABEL_COLUMN = \"inform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0TrPn_r_BUa"
   },
   "outputs": [],
   "source": [
    "token_dict = {}\n",
    "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        if \"_\" in token:\n",
    "          token = token.replace(\"_\",\"\")\n",
    "          token = \"##\" + token\n",
    "        token_dict[token] = len(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FcquD8qX_BeO",
    "outputId": "c78bea66-691e-49ed-f07b-27151a7d11b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'##niters=10000': 0,\n",
       " '##maxlength=16': 1,\n",
       " '[PAD]': 2,\n",
       " '[UNK]': 3,\n",
       " '[CLS]': 4,\n",
       " '[SEP]': 5,\n",
       " '[MASK]': 6,\n",
       " '<S>': 7,\n",
       " '<T>': 8,\n",
       " '##./SF\\t20688850': 9,\n",
       " '##다/EF\\t17194907': 10,\n",
       " '##하/XSV\\t15918761': 11,\n",
       " '##ㄴ/ETM\\t13942053': 12,\n",
       " '##을/JKO\\t13654182': 13,\n",
       " '##었/EP\\t12912273': 14,\n",
       " '##의/JKG\\t12012373': 15,\n",
       " '##에/JKB\\t11360511': 16,\n",
       " '##이/VCP\\t8986000': 17,\n",
       " '##이/JKS\\t8938636': 18,\n",
       " '##,/SP\\t8614178': 19,\n",
       " '##는/JX\\t8594108': 20,\n",
       " '##를/JKO\\t8310256': 21,\n",
       " '##어/EC\\t7491203': 22,\n",
       " '##은/JX\\t7238132': 23,\n",
       " '##는/ETM\\t6614467': 24,\n",
       " '##고/EC\\t6544461': 25,\n",
       " '##가/JKS\\t5607159': 26,\n",
       " '##\"/SS\\t5290740': 27,\n",
       " \"##'/SS\\t5184635\": 28,\n",
       " '##에서/JKB\\t4984600': 29,\n",
       " '##으로/JKB\\t4775583': 30,\n",
       " '##(/SS\\t4605458': 31,\n",
       " '##)/SS\\t4593104': 32,\n",
       " '##로/JKB\\t4052049': 33,\n",
       " '##되/XSV\\t3866969': 34,\n",
       " '##것/NNB\\t3754581': 35,\n",
       " '##도/JX\\t3723164': 36,\n",
       " '##ㄹ/ETM\\t3607940': 37,\n",
       " '##들/XSN\\t3567985': 38,\n",
       " '##있/VX\\t2984347': 39,\n",
       " '##있/VA\\t2766956': 40,\n",
       " '##년/NNB\\t2692800': 41,\n",
       " '##하/VV\\t2640633': 42,\n",
       " '##ㄴ다/EF\\t2593343': 43,\n",
       " '##하/XSA\\t2417945': 44,\n",
       " '##았/EP\\t2248550': 45,\n",
       " '##일/NNB\\t2208697': 46,\n",
       " '##은/ETM\\t2165340': 47,\n",
       " '##과/JC\\t2080158': 48,\n",
       " '##게/EC\\t2045603': 49,\n",
       " '##지/EC\\t2021309': 50,\n",
       " '##기/ETN\\t1982615': 51,\n",
       " '##1/SN\\t1747264': 52,\n",
       " '##등/NNB\\t1741349': 53,\n",
       " '##자/XSN\\t1681880': 54,\n",
       " '##며/EC\\t1662426': 55,\n",
       " '##2/SN\\t1636258': 56,\n",
       " '##수/NNB\\t1612227': 57,\n",
       " '##와/JC\\t1612192': 58,\n",
       " '##되/VV\\t1609375': 59,\n",
       " '##적/XSN\\t1548432': 60,\n",
       " '##않/VX\\t1444034': 61,\n",
       " '##월/NNB\\t1425405': 62,\n",
       " '##하/VX\\t1411740': 63,\n",
       " '##아/EC\\t1383624': 64,\n",
       " '##3/SN\\t1290007': 65,\n",
       " '##고/JKQ\\t1258602': 66,\n",
       " '##‘/SS\\t1212860': 67,\n",
       " '##’/SS\\t1209357': 68,\n",
       " '##“/SS\\t1182769': 69,\n",
       " '##던/ETM\\t1178352': 70,\n",
       " '##”/SS\\t1173240': 71,\n",
       " '##없/VA\\t1148920': 72,\n",
       " '##면/EC\\t1125301': 73,\n",
       " '##말/NNG\\t1107849': 74,\n",
       " '##대하/VV\\t1079746': 75,\n",
       " '##지만/EC\\t1028024': 76,\n",
       " '##·/SP\\t1006405': 77,\n",
       " '##에게/JKB\\t982172': 78,\n",
       " '##이/NP\\t981850': 79,\n",
       " '##받/VV\\t977213': 80,\n",
       " '##까지/JX\\t971316': 81,\n",
       " '##이/MM\\t957430': 82,\n",
       " '##%/SW\\t956451': 83,\n",
       " '##4/SN\\t938271': 84,\n",
       " '##/NNG\\t894014': 85,\n",
       " '##과/JKB\\t874786': 86,\n",
       " '##만/NR\\t864133': 87,\n",
       " '##원/NNB\\t858532': 88,\n",
       " '##명/NNB\\t855315': 89,\n",
       " '##면서/EC\\t843722': 90,\n",
       " '##다는/ETM\\t805550': 91,\n",
       " '##그/NP\\t805446': 92,\n",
       " '##5/SN\\t802731': 93,\n",
       " '##한/MM\\t787247': 94,\n",
       " '##을/ETM\\t787028': 95,\n",
       " '##어서/EC\\t779069': 96,\n",
       " '##-/SS\\t777856': 97,\n",
       " '##다고/EC\\t754086': 98,\n",
       " '##위하/VV\\t739765': 99,\n",
       " '##만/JX\\t723456': 100,\n",
       " '##중/NNB\\t713776': 101,\n",
       " '##한국/NNP\\t709878': 102,\n",
       " '##와/JKB\\t707508': 103,\n",
       " '##보/VV\\t703712': 104,\n",
       " '##같/VA\\t693611': 105,\n",
       " '##라는/ETM\\t691482': 106,\n",
       " '##아니/VCN\\t687437': 107,\n",
       " '##경기/NNG\\t685541': 108,\n",
       " '##/NNP\\t671692': 109,\n",
       " '##6/SN\\t670735': 110,\n",
       " '##씨/NNB\\t660828': 111,\n",
       " '##때/NNG\\t649447': 112,\n",
       " '##지/VX\\t648477': 113,\n",
       " '##보이/VV\\t637950': 114,\n",
       " '##10/SN\\t633104': 115,\n",
       " '##이/JKC\\t627520': 116,\n",
       " '##지나/VV\\t617796': 117,\n",
       " '##습니다/EF\\t611429': 118,\n",
       " '##부터/JX\\t607988': 119,\n",
       " '##라고/EC\\t599245': 120,\n",
       " '##따르/VV\\t586569': 121,\n",
       " '##/SH\\t581383': 122,\n",
       " '##팀/NNG\\t578354': 123,\n",
       " '##그/MM\\t576061': 124,\n",
       " '##어야/EC\\t574199': 125,\n",
       " '##겠/EP\\t570700': 126,\n",
       " '##7/SN\\t560462': 127,\n",
       " '##때문/NNB\\t559888': 128,\n",
       " '##선수/NNG\\t553170': 129,\n",
       " '##으며/EC\\t550333': 130,\n",
       " '##주/VX\\t545951': 131,\n",
       " '##일/NNG\\t543902': 132,\n",
       " '##8/SN\\t539840': 133,\n",
       " '##:/SP\\t538556': 134,\n",
       " '##인/XSN\\t537704': 135,\n",
       " '이\\t529829': 136,\n",
       " '##전/NNG\\t524938': 137,\n",
       " '##대표/NNG\\t514041': 138,\n",
       " '##는데/EC\\t510663': 139,\n",
       " '##미국/NNP\\t506728': 140,\n",
       " '##사람/NNG\\t505904': 141,\n",
       " '##ㄴ/JX\\t501085': 142,\n",
       " '##크/VA\\t500062': 143,\n",
       " '##밝히/VV\\t499843': 144,\n",
       " '##성/XSN\\t496618': 145,\n",
       " '##많/VA\\t490401': 146,\n",
       " '##?/SF\\t488352': 147,\n",
       " '##적/NNG\\t477761': 148,\n",
       " '##장/XSN\\t477048': 149,\n",
       " '##통하/VV\\t476466': 150,\n",
       " '##9/SN\\t474022': 151,\n",
       " '##일본/NNP\\t470515': 152,\n",
       " '##억/NR\\t468647': 153,\n",
       " '##더/MAG\\t464774': 154,\n",
       " '##못하/VX\\t464739': 155,\n",
       " '##개/NNB\\t462925': 156,\n",
       " '##보다/JKB\\t456765': 157,\n",
       " '##[/SS\\t453915': 158,\n",
       " '##감독/NNG\\t453737': 159,\n",
       " '##ㅂ니다/EF\\t451203': 160,\n",
       " '##사/XSN\\t449675': 161,\n",
       " '##수/NNG\\t449487': 162,\n",
       " '##후/NNG\\t445303': 163,\n",
       " '##함께/MAG\\t444653': 164,\n",
       " '정\\t437997': 165,\n",
       " '##관계/NNG\\t436657': 166,\n",
       " '##]/SS\\t434989': 167,\n",
       " '##대통령/NNG\\t434283': 168,\n",
       " '수\\t433902': 169,\n",
       " '##가/JKC\\t433240': 170,\n",
       " '##이후/NNG\\t432488': 171,\n",
       " '##자신/NNG\\t431595': 172,\n",
       " '지\\t427879': 173,\n",
       " '시\\t425425': 174,\n",
       " '##해/NNG\\t425109': 175,\n",
       " '사\\t424735': 176,\n",
       " '##시간/NNG\\t423251': 177,\n",
       " '##나오/VV\\t422910': 178,\n",
       " '##문제/NNG\\t422592': 179,\n",
       " '##정부/NNG\\t422482': 180,\n",
       " '##또/MAG\\t417227': 181,\n",
       " '##전/MM\\t415048': 182,\n",
       " '##방송/NNG\\t412066': 183,\n",
       " '##…/SE\\t406394': 184,\n",
       " '##경우/NNG\\t402663': 185,\n",
       " '##~/SO\\t402314': 186,\n",
       " '##성/NNG\\t400688': 187,\n",
       " '아\\t399649': 188,\n",
       " '##점/NNG\\t389416': 189,\n",
       " '##분/NNB\\t389337': 190,\n",
       " '리\\t387817': 191,\n",
       " '##지난/NNG\\t386282': 192,\n",
       " '##나/NP\\t386005': 193,\n",
       " '##대/XPN\\t383510': 194,\n",
       " '##군/NNG\\t382262': 195,\n",
       " '고\\t381869': 196,\n",
       " '##뒤/NNG\\t379301': 197,\n",
       " '유\\t379170': 198,\n",
       " '##>/SS\\t378664': 199,\n",
       " '##리/NNG\\t376470': 200,\n",
       " '##두/MM\\t373640': 201,\n",
       " '스\\t370437': 202,\n",
       " '가\\t368650': 203,\n",
       " '기\\t368060': 204,\n",
       " '##생각/NNG\\t367400': 205,\n",
       " '##좋/VA\\t363855': 206,\n",
       " '##가/VV\\t362746': 207,\n",
       " '##/VV\\t359788': 208,\n",
       " '오\\t358717': 209,\n",
       " '##차/NNG\\t357802': 210,\n",
       " '##서울/NNP\\t354707': 211,\n",
       " '##기/NNG\\t351424': 212,\n",
       " '##주/NNG\\t351293': 213,\n",
       " '##만들/VV\\t350030': 214,\n",
       " '##다른/MM\\t349565': 215,\n",
       " '##20/SN\\t348681': 216,\n",
       " '##이번/NNG\\t348145': 217,\n",
       " '##중국/NNP\\t347666': 218,\n",
       " '##이날/NNG\\t346659': 219,\n",
       " '##기록/NNG\\t346185': 220,\n",
       " '##오/VV\\t344835': 221,\n",
       " '##자/EC\\t343463': 222,\n",
       " '##시즌/NNG\\t343035': 223,\n",
       " '##사용/NNG\\t342762': 224,\n",
       " '##위/NNB\\t342622': 225,\n",
       " '##시작/NNG\\t340760': 226,\n",
       " '##\\\\/SW\\t340088': 227,\n",
       " '##가능/NNG\\t338142': 228,\n",
       " '미\\t336336': 229,\n",
       " '##/MAG\\t336296': 230,\n",
       " '##가장/MAG\\t335625': 231,\n",
       " '자\\t333540': 232,\n",
       " '##우리/NP\\t333357': 233,\n",
       " '##}/SS\\t333105': 234,\n",
       " '##상황/NNG\\t333085': 235,\n",
       " '##{/SS\\t333039': 236,\n",
       " '소\\t331756': 237,\n",
       " '##12/SN\\t331605': 238,\n",
       " '##이상/NNG\\t331118': 239,\n",
       " '마\\t330885': 240,\n",
       " '##//SP\\t330880': 241,\n",
       " '##위원/NNG\\t330183': 242,\n",
       " '대\\t330075': 243,\n",
       " '##11/SN\\t329306': 244,\n",
       " '##원/XSN\\t328831': 245,\n",
       " '도\\t328605': 246,\n",
       " '##회/XSN\\t327470': 247,\n",
       " '비\\t327304': 248,\n",
       " '##30/SN\\t325868': 249,\n",
       " '##하/VA\\t325702': 250,\n",
       " '##대/NNB\\t325418': 251,\n",
       " '##사/NNG\\t325090': 252,\n",
       " '##하지만/MAJ\\t324562': 253,\n",
       " '##모습/NNG\\t323986': 254,\n",
       " '서\\t323200': 255,\n",
       " '##권/XSN\\t321275': 256,\n",
       " '##화/XSN\\t320998': 257,\n",
       " '##리그/NNG\\t320689': 258,\n",
       " '##경찰/NNG\\t318325': 259,\n",
       " '##최근/NNG\\t318079': 260,\n",
       " '##지역/NNG\\t317877': 261,\n",
       " '##ㅁ/ETN\\t317719': 262,\n",
       " '##들/VV\\t317577': 263,\n",
       " '##시/NNG\\t316907': 264,\n",
       " '##시장/NNG\\t316724': 265,\n",
       " '##의원/NNG\\t316310': 266,\n",
       " '##라/EC\\t313906': 267,\n",
       " '##관련/NNG\\t312151': 268,\n",
       " '##상/NNG\\t311482': 269,\n",
       " '##조사/NNG\\t310287': 270,\n",
       " '##그러나/MAJ\\t309088': 271,\n",
       " '성\\t308847': 272,\n",
       " '라\\t306685': 273,\n",
       " '조\\t305986': 274,\n",
       " '##공개/NNG\\t303039': 275,\n",
       " '동\\t302165': 276,\n",
       " '##학교/NNG\\t299818': 277,\n",
       " '##전하/VV\\t298288': 278,\n",
       " '##세계/NNG\\t297972': 279,\n",
       " '##시키/XSV\\t296605': 280,\n",
       " '##부/NNG\\t296105': 281,\n",
       " '##전/XSN\\t296074': 282,\n",
       " '##보/VX\\t295838': 283,\n",
       " '하\\t295533': 284,\n",
       " '##사실/NNG\\t294621': 285,\n",
       " '##기/XSN\\t292973': 286,\n",
       " '전\\t292705': 287,\n",
       " '한\\t291300': 288,\n",
       " '##사진/NNG\\t290140': 289,\n",
       " '우\\t290021': 290,\n",
       " '##지/NNG\\t289498': 291,\n",
       " '##골/NNG\\t286380': 292,\n",
       " '신\\t285338': 293,\n",
       " '##당시/NNG\\t284916': 294,\n",
       " '부\\t284683': 295,\n",
       " '노\\t284335': 296,\n",
       " '##이/NNG\\t282459': 297,\n",
       " '로\\t281731': 298,\n",
       " '어\\t280925': 299,\n",
       " '##시/NNB\\t280602': 300,\n",
       " '##정도/NNG\\t279637': 301,\n",
       " '##스/NNG\\t279599': 302,\n",
       " '##번/NNB\\t279538': 303,\n",
       " '##대/NNG\\t279488': 304,\n",
       " '상\\t278741': 305,\n",
       " '나\\t278134': 306,\n",
       " '##당/NNG\\t277766': 307,\n",
       " '##안/NNG\\t276672': 308,\n",
       " '##-/SO\\t276374': 309,\n",
       " '##동안/NNG\\t275123': 310,\n",
       " '##부/XSN\\t274795': 311,\n",
       " '무\\t273652': 312,\n",
       " '##이나/JC\\t273200': 313,\n",
       " '##라며/EC\\t271971': 314,\n",
       " '##A/SL\\t271318': 315,\n",
       " '##ㄴ다는/ETM\\t270874': 316,\n",
       " '모\\t269580': 317,\n",
       " '##부분/NNG\\t269368': 318,\n",
       " '##선/NNG\\t267334': 319,\n",
       " '##알/VV\\t266828': 320,\n",
       " '##안/MAG\\t266693': 321,\n",
       " '##천/NR\\t265874': 322,\n",
       " '주\\t265004': 323,\n",
       " '일\\t264868': 324,\n",
       " '##결과/NNG\\t264457': 325,\n",
       " '##및/MAJ\\t262624': 326,\n",
       " '##속/NNG\\t261805': 327,\n",
       " '인\\t261558': 328,\n",
       " '세\\t261368': 329,\n",
       " '##열리/VV\\t260800': 330,\n",
       " '구\\t259435': 331,\n",
       " '##잇/VV\\t258932': 332,\n",
       " '장\\t258819': 333,\n",
       " '##으나/EC\\t258072': 334,\n",
       " '##인/NNG\\t257211': 335,\n",
       " '##잘/MAG\\t256678': 336,\n",
       " '##제/XPN\\t255798': 337,\n",
       " '##비/NNG\\t253956': 338,\n",
       " '다\\t253674': 339,\n",
       " '##스/NNP\\t250714': 340,\n",
       " '##폰/NNG\\t249555': 341,\n",
       " '##특히/MAG\\t249525': 342,\n",
       " '제\\t249363': 343,\n",
       " '##다시/MAG\\t249043': 344,\n",
       " '##나/JC\\t247970': 345,\n",
       " '##다음/NNG\\t246052': 346,\n",
       " '##위/NNG\\t246006': 347,\n",
       " '보\\t245006': 348,\n",
       " '##아이/NNG\\t244324': 349,\n",
       " '##가/XSN\\t243972': 350,\n",
       " '##첫/MM\\t243840': 351,\n",
       " '##모두/MAG\\t242128': 352,\n",
       " '진\\t241700': 353,\n",
       " '##현재/MAG\\t241699': 354,\n",
       " '##이라고/JKQ\\t241510': 355,\n",
       " '##서/NNG\\t240624': 356,\n",
       " '원\\t239823': 357,\n",
       " '##도/NNG\\t239562': 358,\n",
       " '##김/NNP\\t236837': 359,\n",
       " '##진행/NNG\\t236424': 360,\n",
       " '##주/VV\\t236405': 361,\n",
       " '##산/NNG\\t235889': 362,\n",
       " '##후보/NNG\\t235819': 363,\n",
       " '##높/VA\\t235670': 364,\n",
       " '##자/NNG\\t235077': 365,\n",
       " '##자리/NNG\\t234754': 366,\n",
       " '##법/NNG\\t233395': 367,\n",
       " '안\\t232649': 368,\n",
       " '##회/NNB\\t231835': 369,\n",
       " '##여성/NNG\\t231414': 370,\n",
       " '##경제/NNG\\t230767': 371,\n",
       " '##국민/NNG\\t230749': 372,\n",
       " '##구/NNG\\t230468': 373,\n",
       " '##기자/NNG\\t230375': 374,\n",
       " '##국가/NNG\\t229924': 375,\n",
       " '##사회/NNG\\t229664': 376,\n",
       " '##역/NNG\\t229126': 377,\n",
       " '##앞/NNG\\t228800': 378,\n",
       " '##알려지/VV\\t228520': 379,\n",
       " '##최고/NNG\\t228482': 380,\n",
       " '##북한/NNP\\t228389': 381,\n",
       " '경\\t228071': 382,\n",
       " '포\\t227556': 383,\n",
       " '##관/XSN\\t227023': 384,\n",
       " '##기업/NNG\\t226328': 385,\n",
       " '##15/SN\\t225606': 386,\n",
       " '카\\t225427': 387,\n",
       " '##집/NNG\\t224936': 388,\n",
       " '##이런/MM\\t224867': 389,\n",
       " '##시/EP\\t224241': 390,\n",
       " '##영화/NNG\\t223966': 391,\n",
       " '##주장/NNG\\t223474': 392,\n",
       " '##연구/NNG\\t222982': 393,\n",
       " '##가지/VV\\t222752': 394,\n",
       " '##쓰/VV\\t222440': 395,\n",
       " '##도록/EC\\t222266': 396,\n",
       " '##사건/NNG\\t222115': 397,\n",
       " '##측/NNB\\t220376': 398,\n",
       " '##데/NNB\\t220295': 399,\n",
       " '##필요/NNG\\t219525': 400,\n",
       " '##오/VX\\t219402': 401,\n",
       " '강\\t219170': 402,\n",
       " '호\\t218996': 403,\n",
       " '##활동/NNG\\t218709': 404,\n",
       " '재\\t218709': 405,\n",
       " '선\\t218452': 406,\n",
       " '##화/NNG\\t218441': 407,\n",
       " '##내/VV\\t218103': 408,\n",
       " '##오르/VV\\t217927': 409,\n",
       " '타\\t217107': 410,\n",
       " '##국내/NNG\\t216228': 411,\n",
       " '##그렇/VA\\t215861': 412,\n",
       " '##설명/NNG\\t215629': 413,\n",
       " '바\\t214832': 414,\n",
       " '영\\t214491': 415,\n",
       " '해\\t213780': 416,\n",
       " '##지원/NNG\\t213718': 417,\n",
       " '##</SS\\t213363': 418,\n",
       " '##축구/NNG\\t212832': 419,\n",
       " '김\\t212459': 420,\n",
       " '##이유/NNG\\t212449': 421,\n",
       " '##라고/JKQ\\t212372': 422,\n",
       " '##장/NNG\\t212016': 423,\n",
       " '##싶/VX\\t211223': 424,\n",
       " '##상대/NNG\\t211153': 425,\n",
       " '##여/XSN\\t209888': 426,\n",
       " '공\\t209106': 427,\n",
       " '##동/NNG\\t208670': 428,\n",
       " '파\\t208578': 429,\n",
       " '##정치/NNG\\t208369': 430,\n",
       " '##오후/NNG\\t207569': 431,\n",
       " '##아서/EC\\t207270': 432,\n",
       " '##올해/NNG\\t206502': 433,\n",
       " '##많이/MAG\\t206082': 434,\n",
       " '3\\t205856': 435,\n",
       " '##처럼/JKB\\t205371': 436,\n",
       " '##트/NNG\\t204143': 437,\n",
       " '양\\t203940': 438,\n",
       " '##처음/NNG\\t203729': 439,\n",
       " '##력/XSN\\t202669': 440,\n",
       " '##사업/NNG\\t202319': 441,\n",
       " '##발표/NNG\\t201749': 442,\n",
       " '##세/NNG\\t200329': 443,\n",
       " '##맞/VV\\t200132': 444,\n",
       " '##가운데/NNG\\t199580': 445,\n",
       " '박\\t198679': 446,\n",
       " '##신/NNG\\t198670': 447,\n",
       " '##결정/NNG\\t198288': 448,\n",
       " '##팬/NNG\\t197925': 449,\n",
       " '##16/SN\\t197248': 450,\n",
       " '##문/NNG\\t197196': 451,\n",
       " '코\\t197048': 452,\n",
       " '##예정/NNG\\t196963': 453,\n",
       " '##곳/NNG\\t196037': 454,\n",
       " '##정/NNG\\t194738': 455,\n",
       " '에\\t193504': 456,\n",
       " '##는다/EF\\t193035': 457,\n",
       " '##이용/NNG\\t192475': 458,\n",
       " '##차/NNB\\t192331': 459,\n",
       " '##세/NNB\\t192236': 460,\n",
       " '##가격/NNG\\t192113': 461,\n",
       " '레\\t191200': 462,\n",
       " '##요/JX\\t190999': 463,\n",
       " '##상/XSN\\t190780': 464,\n",
       " '##올리/VV\\t190717': 465,\n",
       " '##어도/EC\\t189981': 466,\n",
       " '피\\t189731': 467,\n",
       " '##조/NNG\\t188628': 468,\n",
       " '##계획/NNG\\t187998': 469,\n",
       " '산\\t187956': 470,\n",
       " '##공격/NNG\\t186195': 471,\n",
       " '불\\t185465': 472,\n",
       " '##출연/NNG\\t185164': 473,\n",
       " '##달/NNG\\t185068': 474,\n",
       " '##만나/VV\\t185062': 475,\n",
       " '##상태/NNG\\t184704': 476,\n",
       " '##=/SW\\t184678': 477,\n",
       " '##나서/VV\\t183598': 478,\n",
       " '##전문/NNG\\t183493': 479,\n",
       " '##없이/MAG\\t183405': 480,\n",
       " '발\\t183147': 481,\n",
       " '##가/NNG\\t183068': 482,\n",
       " '##거나/EC\\t182954': 483,\n",
       " '2\\t182635': 484,\n",
       " '##평가/NNG\\t182258': 485,\n",
       " '##확인/NNG\\t182044': 486,\n",
       " '##만/NNB\\t181791': 487,\n",
       " '##또한/MAG\\t181750': 488,\n",
       " '##원/NNG\\t181332': 489,\n",
       " '##판매/NNG\\t181160': 490,\n",
       " '##이름/NNG\\t180695': 491,\n",
       " '##일부/NNG\\t180570': 492,\n",
       " '##보도/NNG\\t179829': 493,\n",
       " '트\\t179660': 494,\n",
       " '##강/NNG\\t179212': 495,\n",
       " '##교육/NNG\\t179016': 496,\n",
       " '치\\t178933': 497,\n",
       " '##모든/MM\\t178770': 498,\n",
       " '##ㄴ다고/EC\\t178273': 499,\n",
       " '##살/VV\\t178050': 500,\n",
       " '##번째/NNB\\t178049': 501,\n",
       " '##금/XSN\\t177737': 502,\n",
       " '##중/NNG\\t177246': 503,\n",
       " '##내용/NNG\\t177095': 504,\n",
       " '##18/SN\\t176997': 505,\n",
       " '##배우/NNG\\t176785': 506,\n",
       " 'S\\t176573': 507,\n",
       " '중\\t176272': 508,\n",
       " '##소/NNG\\t176147': 509,\n",
       " '##찾/VV\\t175795': 510,\n",
       " '##대회/NNG\\t175644': 511,\n",
       " '##그리고/MAJ\\t175545': 512,\n",
       " '##역시/MAG\\t175431': 513,\n",
       " '##면/NNG\\t174987': 514,\n",
       " '##기준/NNG\\t174821': 515,\n",
       " '##대학/NNG\\t174611': 516,\n",
       " '##나/VV\\t174411': 517,\n",
       " '##물/NNG\\t174204': 518,\n",
       " '##정보/NNG\\t173529': 519,\n",
       " '##포함/NNG\\t173306': 520,\n",
       " '##25/SN\\t173226': 521,\n",
       " '여\\t172915': 522,\n",
       " '연\\t172354': 523,\n",
       " '내\\t171840': 524,\n",
       " '니\\t171253': 525,\n",
       " '##!/SF\\t171063': 526,\n",
       " '##13/SN\\t170815': 527,\n",
       " '##어요/EF\\t170608': 528,\n",
       " '##대상/NNG\\t170606': 529,\n",
       " '드\\t170530': 530,\n",
       " '##으면/EC\\t170297': 531,\n",
       " '##회사/NNG\\t170224': 532,\n",
       " '##국/XSN\\t170005': 533,\n",
       " '##`/SW\\t169979': 534,\n",
       " '##한/NNG\\t169720': 535,\n",
       " '##계약/NNG\\t169684': 536,\n",
       " '##게임/NNG\\t169499': 537,\n",
       " '##잡/VV\\t169107': 538,\n",
       " '토\\t169066': 539,\n",
       " '##다가/EC\\t168898': 540,\n",
       " '개\\t168559': 541,\n",
       " '화\\t168293': 542,\n",
       " '##사랑/NNG\\t167977': 543,\n",
       " '##제/XSN\\t167490': 544,\n",
       " '##과정/NNG\\t167236': 545,\n",
       " '##입장/NNG\\t167142': 546,\n",
       " '##미/NNG\\t167072': 547,\n",
       " '##방/NNG\\t166862': 548,\n",
       " '##TV/SL\\t166808': 549,\n",
       " '4\\t166130': 550,\n",
       " '##사이/NNG\\t166085': 551,\n",
       " '##진/NNG\\t165624': 552,\n",
       " '##발생/NNG\\t165319': 553,\n",
       " 'M\\t165284': 554,\n",
       " '방\\t164958': 555,\n",
       " '##간/XSN\\t164639': 556,\n",
       " '##《/SS\\t164149': 557,\n",
       " '##》/SS\\t164146': 558,\n",
       " '##제품/NNG\\t164006': 559,\n",
       " '##100/SN\\t163529': 560,\n",
       " '##날/NNG\\t163468': 561,\n",
       " '저\\t163059': 562,\n",
       " '##보내/VV\\t162971': 563,\n",
       " '##돈/NNG\\t162960': 564,\n",
       " '##14/SN\\t162716': 565,\n",
       " 'C\\t162662': 566,\n",
       " 'A\\t162555': 567,\n",
       " '##기술/NNG\\t162290': 568,\n",
       " '##개발/NNG\\t162046': 569,\n",
       " '##치/NNG\\t161803': 570,\n",
       " '##사고/NNG\\t161628': 571,\n",
       " '##결혼/NNG\\t161453': 572,\n",
       " '##급/NNG\\t161366': 573,\n",
       " '##약/MM\\t161122': 574,\n",
       " '##어렵/VA\\t160560': 575,\n",
       " '##관심/NNG\\t160520': 576,\n",
       " '##손/NNG\\t160516': 577,\n",
       " '##고/NNG\\t160450': 578,\n",
       " '##공/NNG\\t159934': 579,\n",
       " '##24/SN\\t159790': 580,\n",
       " '##0/SN\\t159742': 581,\n",
       " '교\\t159312': 582,\n",
       " '##박/NNP\\t159277': 583,\n",
       " '##17/SN\\t159272': 584,\n",
       " '문\\t158909': 585,\n",
       " '##19/SN\\t158703': 586,\n",
       " '##학생/NNG\\t158530': 587,\n",
       " '거\\t158166': 588,\n",
       " '##/XSN\\t157720': 589,\n",
       " '##마음/NNG\\t157274': 590,\n",
       " '##국회/NNG\\t157007': 591,\n",
       " '##드/NNG\\t156810': 592,\n",
       " '반\\t156662': 593,\n",
       " '##지/XSN\\t156522': 594,\n",
       " '##생활/NNG\\t156464': 595,\n",
       " '##50/SN\\t156427': 596,\n",
       " '5\\t155958': 597,\n",
       " '##배/NNG\\t155878': 598,\n",
       " '예\\t155705': 599,\n",
       " '차\\t154789': 600,\n",
       " '##의하/VV\\t154366': 601,\n",
       " '##지적/NNG\\t154344': 602,\n",
       " '##새롭/VA\\t154186': 603,\n",
       " '위\\t153586': 604,\n",
       " '##국제/NNG\\t153175': 605,\n",
       " '##한편/MAG\\t152798': 606,\n",
       " '##S/SL\\t152653': 607,\n",
       " '##기간/NNG\\t152525': 608,\n",
       " '##결국/NNG\\t152418': 609,\n",
       " '민\\t151776': 610,\n",
       " '##발/NNG\\t151685': 611,\n",
       " '##드라마/NNG\\t151355': 612,\n",
       " '##프로그램/NNG\\t151168': 613,\n",
       " '##대한민국/NNP\\t150942': 614,\n",
       " '태\\t150934': 615,\n",
       " '##업체/NNG\\t150692': 616,\n",
       " '최\\t150503': 617,\n",
       " '##피해/NNG\\t150203': 618,\n",
       " '##시청/NNG\\t149923': 619,\n",
       " '##가족/NNG\\t149866': 620,\n",
       " '##량/NNG\\t149747': 621,\n",
       " '은\\t149747': 622,\n",
       " '##이루/VV\\t149708': 623,\n",
       " '##식/NNG\\t149690': 624,\n",
       " '매\\t149619': 625,\n",
       " '##형/NNG\\t149580': 626,\n",
       " '##영국/NNP\\t149437': 627,\n",
       " '남\\t149412': 628,\n",
       " '##소속/NNG\\t149266': 629,\n",
       " '##논란/NNG\\t149049': 630,\n",
       " '티\\t148533': 631,\n",
       " '배\\t148279': 632,\n",
       " '##관리/NNG\\t148078': 633,\n",
       " '##회장/NNG\\t147992': 634,\n",
       " '##야구/NNG\\t147902': 635,\n",
       " '##기대/NNG\\t147777': 636,\n",
       " '##수사/NNG\\t147632': 637,\n",
       " '윤\\t147435': 638,\n",
       " '##연기/NNG\\t147395': 639,\n",
       " '단\\t147078': 640,\n",
       " '##니/EC\\t146747': 641,\n",
       " '버\\t146741': 642,\n",
       " '투\\t146209': 643,\n",
       " '##정책/NNG\\t146083': 644,\n",
       " '##내/VX\\t145497': 645,\n",
       " '##금/NNG\\t145157': 646,\n",
       " '두\\t145046': 647,\n",
       " '디\\t144482': 648,\n",
       " '##언론/NNG\\t144465': 649,\n",
       " '##지금/NNG\\t144224': 650,\n",
       " '##준비/NNG\\t144215': 651,\n",
       " '##재/XPN\\t144147': 652,\n",
       " '##식/XSN\\t143869': 653,\n",
       " '##40/SN\\t143774': 654,\n",
       " '##선발/NNG\\t143769': 655,\n",
       " 'P\\t143444': 656,\n",
       " '##치/VV\\t143440': 657,\n",
       " '##스타/NNG\\t143439': 658,\n",
       " '##현지/NNG\\t142911': 659,\n",
       " '##나타나/VV\\t142881': 660,\n",
       " '##현/NNP\\t142743': 661,\n",
       " '##21/SN\\t142686': 662,\n",
       " '##스럽/XSA\\t142681': 663,\n",
       " '##이야기/NNG\\t142631': 664,\n",
       " '##우승/NNG\\t142297': 665,\n",
       " '##오전/NNG\\t141950': 666,\n",
       " '##문화/NNG\\t141920': 667,\n",
       " '##떨어지/VV\\t141717': 668,\n",
       " '##두/VV\\t141592': 669,\n",
       " '##명/NNG\\t141587': 670,\n",
       " '##아직/MAG\\t141493': 671,\n",
       " '##영상/NNG\\t141472': 672,\n",
       " '##서비스/NNG\\t140638': 673,\n",
       " '의\\t140575': 674,\n",
       " '##운영/NNG\\t140567': 675,\n",
       " '##달러/NNB\\t140553': 676,\n",
       " '천\\t140422': 677,\n",
       " '루\\t140347': 678,\n",
       " '##K/SL\\t140176': 679,\n",
       " '##과/NNG\\t139982': 680,\n",
       " '##모르/VV\\t139968': 681,\n",
       " '##소/XSN\\t139341': 682,\n",
       " '##성공/NNG\\t139233': 683,\n",
       " '##수준/NNG\\t138479': 684,\n",
       " '##인기/NNG\\t138314': 685,\n",
       " '##제작/NNG\\t138220': 686,\n",
       " '##색/NNG\\t137874': 687,\n",
       " '##눈/NNG\\t137861': 688,\n",
       " '##하/NNG\\t137805': 689,\n",
       " '##여러/MM\\t137743': 690,\n",
       " '##먹/VV\\t137545': 691,\n",
       " '##계/XSN\\t137485': 692,\n",
       " '##률/XSN\\t137462': 693,\n",
       " '##전망/NNG\\t137319': 694,\n",
       " '##판/NNG\\t137205': 695,\n",
       " '##연/NNG\\t137147': 696,\n",
       " '##22/SN\\t137098': 697,\n",
       " 'D\\t136957': 698,\n",
       " '##승리/NNG\\t136930': 699,\n",
       " '##서/JKB\\t136773': 700,\n",
       " '##로서/JKB\\t136523': 701,\n",
       " '##감/XSN\\t136372': 702,\n",
       " '##파/NNG\\t136314': 703,\n",
       " 'B\\t136286': 704,\n",
       " '##요구/NNG\\t136244': 705,\n",
       " '##주의/NNG\\t136197': 706,\n",
       " '##선거/NNG\\t135976': 707,\n",
       " '##직/NNG\\t135926': 708,\n",
       " '##반/NNG\\t135786': 709,\n",
       " '종\\t135636': 710,\n",
       " '##시대/NNG\\t135556': 711,\n",
       " '##미/NNP\\t135475': 712,\n",
       " '국\\t135297': 713,\n",
       " '##소비/NNG\\t134867': 714,\n",
       " '##병/NNG\\t134595': 715,\n",
       " '##23/SN\\t134485': 716,\n",
       " '##중요/NNG\\t134364': 717,\n",
       " '##여자/NNG\\t134317': 718,\n",
       " '##경쟁/NNG\\t134249': 719,\n",
       " '##전체/NNG\\t134234': 720,\n",
       " '##관/NNG\\t134229': 721,\n",
       " '##몸/NNG\\t134117': 722,\n",
       " '##영/NNP\\t133934': 723,\n",
       " '##예상/NNG\\t133863': 724,\n",
       " '##최대/NNG\\t133623': 725,\n",
       " '##이/NNP\\t133581': 726,\n",
       " 'E\\t133571': 727,\n",
       " '임\\t133376': 728,\n",
       " '##교수/NNG\\t133372': 729,\n",
       " '##얻/VV\\t133003': 730,\n",
       " '##/VA\\t132881': 731,\n",
       " '##촬영/NNG\\t132832': 732,\n",
       " '##갖/VV\\t132742': 733,\n",
       " '관\\t132630': 734,\n",
       " '##어떤/MM\\t132482': 735,\n",
       " '##길/NNG\\t132474': 736,\n",
       " '##그런/MM\\t132426': 737,\n",
       " '##혐의/NNG\\t132334': 738,\n",
       " '베\\t132271': 739,\n",
       " '##운동/NNG\\t132257': 740,\n",
       " '초\\t132084': 741,\n",
       " '##B/SL\\t132008': 742,\n",
       " '##추가/NNG\\t131976': 743,\n",
       " '##분석/NNG\\t131817': 744,\n",
       " '##친구/NNG\\t131804': 745,\n",
       " '##삼성/NNP\\t131757': 746,\n",
       " '##내리/VV\\t131721': 747,\n",
       " '##위치/NNG\\t131720': 748,\n",
       " '##개인/NNG\\t131498': 749,\n",
       " '##타/NNG\\t131361': 750,\n",
       " '##개월/NNB\\t131218': 751,\n",
       " '##남자/NNG\\t131145': 752,\n",
       " '##아야/EC\\t131027': 753,\n",
       " '##◇/SW\\t130782': 754,\n",
       " '##넘/VV\\t130578': 755,\n",
       " '##저/NP\\t130571': 756,\n",
       " '##단/NNG\\t130313': 757,\n",
       " '##금융/NNG\\t129464': 758,\n",
       " '##죠/EF\\t129326': 759,\n",
       " '만\\t129233': 760,\n",
       " '##히/MAG\\t129162': 761,\n",
       " '##27/SN\\t129108': 762,\n",
       " '##주/NNP\\t128936': 763,\n",
       " '##훈련/NNG\\t128788': 764,\n",
       " '간\\t128706': 765,\n",
       " '##형/XSN\\t128683': 766,\n",
       " '##공식/NNG\\t128460': 767,\n",
       " '분\\t128449': 768,\n",
       " '##28/SN\\t128381': 769,\n",
       " '##영향/NNG\\t128320': 770,\n",
       " '##검찰/NNG\\t128196': 771,\n",
       " '##투자/NNG\\t128152': 772,\n",
       " '##양/NNG\\t128108': 773,\n",
       " '##어떻/VA\\t127970': 774,\n",
       " '##26/SN\\t127430': 775,\n",
       " '현\\t127418': 776,\n",
       " '승\\t127382': 777,\n",
       " '##이미/MAG\\t127341': 778,\n",
       " '##올/NNG\\t127317': 779,\n",
       " '##지방/NNG\\t127200': 780,\n",
       " '##수/NNP\\t127132': 781,\n",
       " '##ㄴ데/EC\\t126759': 782,\n",
       " '##점/XSN\\t126599': 783,\n",
       " '##모/NNG\\t126515': 784,\n",
       " '##중심/NNG\\t126441': 785,\n",
       " '##인하/VV\\t126341': 786,\n",
       " '##규모/NNG\\t126288': 787,\n",
       " '##들어가/VV\\t126215': 788,\n",
       " '##터/NNG\\t126171': 789,\n",
       " '##지/VV\\t126166': 790,\n",
       " '##제/NNG\\t125987': 791,\n",
       " '실\\t125707': 792,\n",
       " '##일반/NNG\\t125492': 793,\n",
       " '##다양/NNG\\t125297': 794,\n",
       " '메\\t125223': 795,\n",
       " 'T\\t125160': 796,\n",
       " '##m/SL\\t125010': 797,\n",
       " '##직접/MAG\\t124878': 798,\n",
       " '##프로/NNG\\t124833': 799,\n",
       " '##는지/EC\\t124831': 800,\n",
       " '##율/XSN\\t124622': 801,\n",
       " '##회의/NNG\\t124481': 802,\n",
       " '##동/NNP\\t124447': 803,\n",
       " '##글/NNG\\t124395': 804,\n",
       " '##통신/NNG\\t124392': 805,\n",
       " '##올림픽/NNG\\t124327': 806,\n",
       " '##장관/NNG\\t124316': 807,\n",
       " '##못/MAG\\t124238': 808,\n",
       " '##맡/VV\\t124238': 809,\n",
       " '##발견/NNG\\t123984': 810,\n",
       " '##부/XPN\\t123874': 811,\n",
       " '그\\t123778': 812,\n",
       " '##/NNB\\t123706': 813,\n",
       " '##보/NNG\\t123356': 814,\n",
       " '##생/XSN\\t123278': 815,\n",
       " '##이하/NNG\\t123036': 816,\n",
       " '##입/VV\\t122962': 817,\n",
       " '##남/VV\\t122606': 818,\n",
       " '##루/NNG\\t122601': 819,\n",
       " '##아들/NNG\\t122531': 820,\n",
       " '##초/NNB\\t122527': 821,\n",
       " '##투수/NNG\\t122521': 822,\n",
       " '##차례/NNG\\t122446': 823,\n",
       " '##너무/MAG\\t122384': 824,\n",
       " '##전화/NNG\\t122286': 825,\n",
       " '##스마트/NNG\\t122180': 826,\n",
       " '금\\t121776': 827,\n",
       " '요\\t121741': 828,\n",
       " 'G\\t121702': 829,\n",
       " '##호/NNP\\t121544': 830,\n",
       " '##리/NNP\\t121155': 831,\n",
       " '##모델/NNG\\t121008': 832,\n",
       " '용\\t120999': 833,\n",
       " '##기관/NNG\\t120971': 834,\n",
       " '##29/SN\\t120938': 835,\n",
       " '6\\t120756': 836,\n",
       " '##강조/NNG\\t120502': 837,\n",
       " '##정상/NNG\\t120402': 838,\n",
       " '##진/NNP\\t120361': 839,\n",
       " '##/XPN\\t120316': 840,\n",
       " '##물/XSN\\t120256': 841,\n",
       " '##였/EP\\t119891': 842,\n",
       " '##뉴스/NNG\\t119808': 843,\n",
       " '##감/NNG\\t119753': 844,\n",
       " '##멤버/NNG\\t119630': 845,\n",
       " '##해당/NNG\\t119569': 846,\n",
       " '##출시/NNG\\t119501': 847,\n",
       " '##이렇/VA\\t119270': 848,\n",
       " '##가/VX\\t119257': 849,\n",
       " '##제공/NNG\\t119239': 850,\n",
       " '손\\t119068': 851,\n",
       " '야\\t118989': 852,\n",
       " '##점/NNB\\t118877': 853,\n",
       " '##참여/NNG\\t118790': 854,\n",
       " '애\\t118732': 855,\n",
       " '송\\t118301': 856,\n",
       " '심\\t118226': 857,\n",
       " '##월드컵/NNG\\t118053': 858,\n",
       " '##의미/NNG\\t118052': 859,\n",
       " '##체/NNG\\t118046': 860,\n",
       " '명\\t118007': 861,\n",
       " '##어/NNG\\t117901': 862,\n",
       " '##누구/NP\\t117890': 863,\n",
       " '##심/NNG\\t117889': 864,\n",
       " '르\\t117801': 865,\n",
       " '##ㄹ/JKO\\t117752': 866,\n",
       " '##종/NNG\\t117702': 867,\n",
       " '##바/NNB\\t117691': 868,\n",
       " '광\\t117676': 869,\n",
       " '##인터뷰/NNG\\t117586': 870,\n",
       " '##마지막/NNG\\t117574': 871,\n",
       " '##무대/NNG\\t117551': 872,\n",
       " '후\\t117396': 873,\n",
       " 'O\\t117358': 874,\n",
       " '##만큼/NNB\\t117102': 875,\n",
       " '추\\t117039': 876,\n",
       " '##실/XSN\\t116948': 877,\n",
       " '7\\t116823': 878,\n",
       " '##거리/NNG\\t116749': 879,\n",
       " '##열/VV\\t116652': 880,\n",
       " '백\\t116452': 881,\n",
       " '##정/NNP\\t116355': 882,\n",
       " '알\\t116344': 883,\n",
       " '##비/XSN\\t116238': 884,\n",
       " '##증가/NNG\\t116192': 885,\n",
       " '##마/NNG\\t116160': 886,\n",
       " '##그것/NP\\t115935': 887,\n",
       " '##인사/NNG\\t115847': 888,\n",
       " '##평균/NNG\\t115741': 889,\n",
       " '##카드/NNG\\t115405': 890,\n",
       " '##무/NNG\\t115031': 891,\n",
       " '##도시/NNG\\t114822': 892,\n",
       " '##또는/MAJ\\t114661': 893,\n",
       " '##뿐/NNB\\t114661': 894,\n",
       " '##구조/NNG\\t114601': 895,\n",
       " '##희/NNP\\t114509': 896,\n",
       " '데\\t114123': 897,\n",
       " '##▲/SW\\t114121': 898,\n",
       " '##끝/NNG\\t114110': 899,\n",
       " '##경/NNG\\t113830': 900,\n",
       " '##스포츠/NNG\\t113692': 901,\n",
       " '##로/NNG\\t113664': 902,\n",
       " '##아/NNG\\t113600': 903,\n",
       " '##독일/NNP\\t113578': 904,\n",
       " '##대/XSN\\t113490': 905,\n",
       " '난\\t113215': 906,\n",
       " '##표/NNG\\t113020': 907,\n",
       " '##이어지/VV\\t112915': 908,\n",
       " '##출전/NNG\\t112892': 909,\n",
       " '##타/VV\\t112630': 910,\n",
       " '##활약/NNG\\t112491': 911,\n",
       " '##유/NNG\\t112475': 912,\n",
       " '##다/MAG\\t112462': 913,\n",
       " '##실/NNG\\t112362': 914,\n",
       " '더\\t112219': 915,\n",
       " '##드/NNP\\t112207': 916,\n",
       " '허\\t111807': 917,\n",
       " '##인터넷/NNG\\t111754': 918,\n",
       " '##/SW\\t111344': 919,\n",
       " '##청/NNG\\t111199': 920,\n",
       " '##단/XSN\\t111178': 921,\n",
       " '##홈/NNG\\t111175': 922,\n",
       " '##가수/NNG\\t111116': 923,\n",
       " '##직원/NNG\\t110902': 924,\n",
       " '##등장/NNG\\t110769': 925,\n",
       " '##하나/NNG\\t110394': 926,\n",
       " '##청/XSN\\t110336': 927,\n",
       " '##차지/NNG\\t110326': 928,\n",
       " '##교/NNG\\t110218': 929,\n",
       " '##층/NNG\\t110020': 930,\n",
       " 'R\\t110004': 931,\n",
       " '##현장/NNG\\t110001': 932,\n",
       " '##수/XSN\\t109896': 933,\n",
       " 'H\\t109699': 934,\n",
       " '##ㄴ지/EC\\t109418': 935,\n",
       " '##◆/SW\\t109370': 936,\n",
       " '순\\t109258': 937,\n",
       " '##물론/MAG\\t109228': 938,\n",
       " '##행사/NNG\\t109145': 939,\n",
       " '##분/NNG\\t109137': 940,\n",
       " '테\\t109112': 941,\n",
       " '##다르/VA\\t108944': 942,\n",
       " '##병원/NNG\\t108870': 943,\n",
       " '네\\t108792': 944,\n",
       " '체\\t108616': 945,\n",
       " '##부상/NNG\\t108429': 946,\n",
       " '##단체/NNG\\t108414': 947,\n",
       " '##다면/EC\\t108400': 948,\n",
       " '##강하/VA\\t108354': 949,\n",
       " '##의/NNG\\t108322': 950,\n",
       " '##출신/NNG\\t108288': 951,\n",
       " '##LG/SL\\t107752': 952,\n",
       " '##인정/NNG\\t107700': 953,\n",
       " '##부르/VV\\t107586': 954,\n",
       " '##MBC/SL\\t107524': 955,\n",
       " '러\\t107508': 956,\n",
       " '##로부터/JKB\\t107504': 957,\n",
       " '##쉽/VA\\t107106': 958,\n",
       " '##구단/NNG\\t106924': 959,\n",
       " '##듣/VV\\t106900': 960,\n",
       " '##상승/NNG\\t106875': 961,\n",
       " '##주택/NNG\\t106750': 962,\n",
       " '##그/NNG\\t106745': 963,\n",
       " '##새/MM\\t106571': 964,\n",
       " '##시/NNP\\t106224': 965,\n",
       " '##더욱/MAG\\t106223': 966,\n",
       " '##이것/NP\\t106062': 967,\n",
       " '##구성/NNG\\t105775': 968,\n",
       " '##우/NNG\\t105716': 969,\n",
       " '##반대/NNG\\t105347': 970,\n",
       " '##총리/NNG\\t105305': 971,\n",
       " '##라/NNG\\t105302': 972,\n",
       " '##진출/NNG\\t105134': 973,\n",
       " '##성장/NNG\\t104664': 974,\n",
       " '##안전/NNG\\t104614': 975,\n",
       " '##부담/NNG\\t104600': 976,\n",
       " '##반응/NNG\\t104489': 977,\n",
       " '##우/NNP\\t104340': 978,\n",
       " '##얘기/NNG\\t104332': 979,\n",
       " '##승/NNB\\t104106': 980,\n",
       " '##이어/MAG\\t104055': 981,\n",
       " '##가지/NNB\\t103987': 982,\n",
       " '##G/SL\\t103976': 983,\n",
       " 'F\\t103925': 984,\n",
       " '19\\t103816': 985,\n",
       " '외\\t103810': 986,\n",
       " '##느끼/VV\\t103620': 987,\n",
       " '##프랑스/NNP\\t103617': 988,\n",
       " '##뜻/NNG\\t103527': 989,\n",
       " '##당하/VV\\t103388': 990,\n",
       " '##기사/NNG\\t103377': 991,\n",
       " '##왕/NNG\\t103194': 992,\n",
       " '##진/XSN\\t103043': 993,\n",
       " '황\\t102954': 994,\n",
       " 'L\\t102811': 995,\n",
       " '##은행/NNG\\t102801': 996,\n",
       " '##e/SL\\t102689': 997,\n",
       " '##유지/NNG\\t102678': 998,\n",
       " '##사망/NNG\\t102596': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BDp-33KJ_BcA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPp0cUvR_BaO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D96o4I50_BX3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4Irgpux_BOY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iDKMs8Pa8fIw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## 토큰화, zero-padding\n",
    "\n",
    "def toktok(df, column):\n",
    "\n",
    "\n",
    "  maxlen = 512\n",
    "\n",
    "  ipt_ids1 = []\n",
    "  ipt_ids2 = []\n",
    "  ipt_ids3 = []\n",
    "  ipt_ids4 = []\n",
    "  ipt_ids5 = []\n",
    "\n",
    "  ipt_mask1 = []\n",
    "  ipt_mask2 = []\n",
    "  ipt_mask3 = []\n",
    "  ipt_mask4 = []\n",
    "  ipt_mask5 = []\n",
    "   \n",
    "  sgm_ids1 = []\n",
    "  sgm_ids2 = []\n",
    "  sgm_ids3 = []\n",
    "  sgm_ids4 = []\n",
    "  sgm_ids5 = []\n",
    "\n",
    "\n",
    "  \n",
    "  for content in tqdm(range(len(df['content1']))):\n",
    "    text = do_lang(api_key, content)\n",
    "    split_tokens = ftk.tokenize(text)\n",
    "    k = round(len(split_tokens)/5)\n",
    "    spt1 = split_tokens[:k]\n",
    "    spt2 = split_tokens[k:(2*k)]\n",
    "    spt3 = split_tokens[(2*k):(3*k)]\n",
    "    spt4 = split_tokens[(3*k):]\n",
    "    spt5 = split_tokens[(4*k):]\n",
    "\n",
    "    tokens1 = [\"[CLS]\"] + spt1 + [\"[SEP]\"]\n",
    "    tokens2 = [\"[CLS]\"] + spt2 + [\"[SEP]\"]\n",
    "    tokens3 = [\"[CLS]\"] + spt3 + [\"[SEP]\"]\n",
    "    tokens4 = [\"[CLS]\"] + spt4 + [\"[SEP]\"]\n",
    "    tokens5 = [\"[CLS]\"] + spt5 + [\"[SEP]\"]\n",
    "\n",
    "    input_ids1 = [morph_vocab[token] for token in tokens1]\n",
    "    input_ids2 = [morph_vocab[token] for token in tokens2]\n",
    "    input_ids3 = [morph_vocab[token] for token in tokens3]\n",
    "    input_ids4 = [morph_vocab[token] for token in tokens4]\n",
    "    input_ids5 = [morph_vocab[token] for token in tokens5]\n",
    "\n",
    "    input_mask1 = [1] * len(input_ids1)\n",
    "    input_mask2 = [1] * len(input_ids2)\n",
    "    input_mask3 = [1] * len(input_ids3)\n",
    "    input_mask4 = [1] * len(input_ids4)\n",
    "    input_mask5 = [1] * len(input_ids5)\n",
    "\n",
    "    segment_ids1 = [0] * len(tokens1)\n",
    "    segment_ids2 = [0] * len(tokens2)\n",
    "    segment_ids3 = [0] * len(tokens3)\n",
    "    segment_ids4 = [0] * len(tokens4)\n",
    "    segment_ids5 = [0] * len(tokens5)\n",
    "    \n",
    "    padding1 = [0] * (maxlen - len(input_ids1))\n",
    "    padding2 = [0] * (maxlen - len(input_ids2))\n",
    "    padding3 = [0] * (maxlen - len(input_ids3))\n",
    "    padding4 = [0] * (maxlen - len(input_ids4))\n",
    "    padding5 = [0] * (maxlen - len(input_ids5))\n",
    "  \n",
    "    input_ids1 += padding1\n",
    "    input_ids2 += padding2\n",
    "    input_ids3 += padding3\n",
    "    input_ids4 += padding4\n",
    "    input_ids5 += padding5\n",
    "    \n",
    "    input_mask1 += padding1\n",
    "    input_mask2 += padding2\n",
    "    input_mask3 += padding3\n",
    "    input_mask4 += padding4\n",
    "    input_mask5 += padding5\n",
    "\n",
    "    segment_ids1 += padding1\n",
    "    segment_ids2 += padding2\n",
    "    segment_ids3 += padding3\n",
    "    segment_ids4 += padding4\n",
    "    segment_ids5 += padding5\n",
    "\n",
    "    ipt_ids1.append(input_ids1) # 토큰\n",
    "    ipt_ids2.append(input_ids2)\n",
    "    ipt_ids3.append(input_ids3)\n",
    "    ipt_ids4.append(input_ids4)\n",
    "    ipt_ids5.append(input_ids5)\n",
    "\n",
    "    ipt_mask1.append(input_mask1)\n",
    "    ipt_mask2.append(input_mask2)\n",
    "    ipt_mask3.append(input_mask3)\n",
    "    ipt_mask4.append(input_mask4)\n",
    "    ipt_mask5.append(input_mask5)\n",
    "\n",
    "\n",
    "    sgm_ids1.append(segment_ids1) # 문장 분류\n",
    "    sgm_ids2.append(segment_ids2)\n",
    "    sgm_ids3.append(segment_ids3)\n",
    "    sgm_ids4.append(segment_ids4)\n",
    "    sgm_ids5.append(segment_ids5)\n",
    "\n",
    "\n",
    "    ar_tok1 = np.array(ipt_ids1)\n",
    "    ar_tok2 = np.array(ipt_ids2)\n",
    "    ar_tok3 = np.array(ipt_ids3)\n",
    "    ar_tok4 = np.array(ipt_ids4)\n",
    "    ar_tok5 = np.array(ipt_ids5)\n",
    "\n",
    "\n",
    "    ar_seg1 = np.array(sgm_ids1)\n",
    "    ar_seg2 = np.array(sgm_ids2)\n",
    "    ar_seg3 = np.array(sgm_ids3)\n",
    "    ar_seg4 = np.array(sgm_ids4)\n",
    "    ar_seg5 = np.array(sgm_ids5)\n",
    "    \n",
    "    \n",
    "    train_x = [[ar_tok1[:900], ar_tok2[:900], ar_tok3[:900], ar_tok4[:900], ar_tok5[:900]], [ar_seg1[:900], ar_seg2[:900], ar_seg3[:900], ar_seg4[:900], ar_seg5[:900]]]\n",
    "\n",
    "    test_x = [[ar_tok1[900:], ar_tok2[900:], ar_tok3[900:], ar_tok4[900:], ar_tok5[900:]], [ar_seg1[900:], ar_seg2[900:], ar_seg3[900:], ar_seg4[900:], ar_seg5[900:]]]\n",
    "\n",
    "    y = df[column]\n",
    "    train_y = np.array(y[:900])\n",
    "    test_y = np.array(y[900:])\n",
    "\n",
    "    return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8D_opGO4w8Yh",
    "outputId": "3295b759-0b41-49f6-eaed-caa2a1bb91f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 203,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ab2tHiGxADO"
   },
   "outputs": [],
   "source": [
    "#!pip install keras-bert\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras_bert import load_trained_model_from_checkpoint, load_vocabulary\n",
    "#from keras_bert import Tokenizer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "#from keras_radam import RAdam\n",
    "\n",
    "\n",
    "config_path = '/content/gdrive/My Drive/KorBERT/bert_config.json'\n",
    "checkpoint_path = '/content/gdrive/My Drive/KorBERT/model.ckpt'\n",
    "SEQ_LEN = 512\n",
    "\n",
    "layer_num = 12\n",
    "\n",
    "model = load_trained_model_from_checkpoint(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    "    training=True,\n",
    "    trainable=True,\n",
    "    seq_len=SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SjpJoTsAyOyu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#1단락 버트 pre-training\n",
    "token_inputs1 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids1')\n",
    "mask_inputs1 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks1')\n",
    "segment_inputs1 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment1')\n",
    "bert_outputs1 = model([token_inputs1, segment_inputs1, mask_inputs1])[1]\n",
    "bert_outputs11 = tf.keras.layers.Dropout(0.5)(bert_outputs1)\n",
    "\n",
    "\n",
    "#2단락 버트 pre-training\n",
    "token_inputs2 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids2')\n",
    "mask_inputs2 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks2')\n",
    "segment_inputs2 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment2')\n",
    "bert_outputs2 = model([token_inputs2, segment_inputs2, mask_inputs2])[1]\n",
    "bert_outputs22 = tf.keras.layers.Dropout(0.5)(bert_outputs2)\n",
    "\n",
    "\n",
    "#3단락 버트 pre-training\n",
    "token_inputs3 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids3')\n",
    "mask_inputs3 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks3')\n",
    "segment_inputs3 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment3')\n",
    "bert_outputs3 = model([token_inputs3, segment_inputs3, mask_inputs3])[1]\n",
    "bert_outputs33 = tf.keras.layers.Dropout(0.5)(bert_outputs3)\n",
    "\n",
    "#4단락 버트 pre-training\n",
    "token_inputs4 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids4')\n",
    "mask_inputs4 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks4')\n",
    "segment_inputs4 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment4')\n",
    "bert_outputs4 = model([token_inputs4, segment_inputs4, mask_inputs4])[1]\n",
    "bert_outputs44 = tf.keras.layers.Dropout(0.5)(bert_outputs4)\n",
    "\n",
    "#5단락 버트 pre-training\n",
    "token_inputs5 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids5')\n",
    "mask_inputs5 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks5')\n",
    "segment_inputs5 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment5')\n",
    "bert_outputs5 = model([token_inputs5, segment_inputs5, mask_inputs5])[1]\n",
    "bert_outputs55 = tf.keras.layers.Dropout(0.5)(bert_outputs5)\n",
    "\n",
    "\n",
    "concatenated = layers.concatenate([bert_outputs11,bert_outputs22,bert_outputs33,bert_outputs44,bert_outputs55])\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "# 총 batch size * 4 epoch = 2344 * 4\n",
    "opt = tfa.optimizers.RectifiedAdam(lr=5.0e-5, total_steps = 2344*4, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "\n",
    "token_inputs = [token_inputs1,token_inputs2,token_inputs3,token_inputs4,token_inputs5]\n",
    "mask_inputs = [mask_inputs1,mask_inputs2,mask_inputs3,mask_inputs4,mask_inputs5]\n",
    "segment_inputs = [segment_inputs1,segment_inputs2,segment_inputs3,segment_inputs4,segment_inputs5]\n",
    "\n",
    "sentiment_first = tf.keras.layers.Dense(5, activation='softmax')(concatenated)\n",
    "sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\n",
    "sentiment_model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BbsuE8oIyXsc",
    "outputId": "315a8ffd-24cc-4537-f6c9-39c09e0f83ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_37\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids1 (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_segment1 (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks1 (InputLayer)       [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_word_ids2 (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_segment2 (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks2 (InputLayer)       [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_word_ids3 (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_segment3 (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks3 (InputLayer)       [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_word_ids4 (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_segment4 (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks4 (InputLayer)       [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_word_ids5 (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_segment5 (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks5 (InputLayer)       [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "functional_35 (Functional)      [(None, 512, 30349), 109973391   input_word_ids1[0][0]            \n",
      "                                                                 input_segment1[0][0]             \n",
      "                                                                 input_masks1[0][0]               \n",
      "                                                                 input_word_ids2[0][0]            \n",
      "                                                                 input_segment2[0][0]             \n",
      "                                                                 input_masks2[0][0]               \n",
      "                                                                 input_word_ids3[0][0]            \n",
      "                                                                 input_segment3[0][0]             \n",
      "                                                                 input_masks3[0][0]               \n",
      "                                                                 input_word_ids4[0][0]            \n",
      "                                                                 input_segment4[0][0]             \n",
      "                                                                 input_masks4[0][0]               \n",
      "                                                                 input_word_ids5[0][0]            \n",
      "                                                                 input_segment5[0][0]             \n",
      "                                                                 input_masks5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 2)            0           functional_35[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 2)            0           functional_35[1][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 2)            0           functional_35[2][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 2)            0           functional_35[3][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 2)            0           functional_35[4][1]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 10)           0           dropout_15[0][0]                 \n",
      "                                                                 dropout_16[0][0]                 \n",
      "                                                                 dropout_17[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            55          concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 109,973,446\n",
      "Trainable params: 109,973,446\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sentiment_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "colab_type": "code",
    "id": "Uz44gIKGyc1h",
    "outputId": "26cf4802-fbf4-4c33-f858-b34e23f14197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-214-9e08b75637ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:517 _run_internal_graph\n        assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output Tensor(\"dense_2/Softmax:0\", shape=(None, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "history = sentiment_model.fit(train_x, train_y, epochs=2, batch_size=8, verbose = 1, validation_data=(test_x, test_y), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "diBVaA-SzVWP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xx7ZMU2N10Jl"
   },
   "source": [
    "### KoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "OHYzJhG9412T",
    "outputId": "d9c278b0-16da-4cf7-ec48-e85c5d8180f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ikjrlOaI114y"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import unicodedata\n",
    "from shutil import copyfile\n",
    "\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n",
    "                     \"vocab_txt\": \"vocab.txt\"}\n",
    "\n",
    "PRETRAINED_VOCAB_FILES_MAP = {\n",
    "    \"vocab_file\": {\n",
    "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n",
    "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n",
    "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n",
    "    },\n",
    "    \"vocab_txt\": {\n",
    "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n",
    "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n",
    "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n",
    "    }\n",
    "}\n",
    "\n",
    "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n",
    "    \"monologg/kobert\": 512,\n",
    "    \"monologg/kobert-lm\": 512,\n",
    "    \"monologg/distilkobert\": 512\n",
    "}\n",
    "\n",
    "PRETRAINED_INIT_CONFIGURATION = {\n",
    "    \"monologg/kobert\": {\"do_lower_case\": False},\n",
    "    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n",
    "    \"monologg/distilkobert\": {\"do_lower_case\": False}\n",
    "}\n",
    "\n",
    "SPIECE_UNDERLINE = u'▁'\n",
    "\n",
    "\n",
    "class KoBertTokenizer(PreTrainedTokenizer):\n",
    "    \"\"\"\n",
    "        SentencePiece based tokenizer. Peculiarities:\n",
    "            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\n",
    "    \"\"\"\n",
    "    vocab_files_names = VOCAB_FILES_NAMES\n",
    "    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n",
    "    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n",
    "    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_file,\n",
    "            vocab_txt,\n",
    "            do_lower_case=False,\n",
    "            remove_space=True,\n",
    "            keep_accents=False,\n",
    "            unk_token=\"[UNK]\",\n",
    "            sep_token=\"[SEP]\",\n",
    "            pad_token=\"[PAD]\",\n",
    "            cls_token=\"[CLS]\",\n",
    "            mask_token=\"[MASK]\",\n",
    "            **kwargs):\n",
    "        super().__init__(\n",
    "            unk_token=unk_token,\n",
    "            sep_token=sep_token,\n",
    "            pad_token=pad_token,\n",
    "            cls_token=cls_token,\n",
    "            mask_token=mask_token,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # Build vocab\n",
    "        self.token2idx = dict()\n",
    "        self.idx2token = []\n",
    "        with open(vocab_txt, 'r', encoding='utf-8') as f:\n",
    "            for idx, token in enumerate(f):\n",
    "                token = token.strip()\n",
    "                self.token2idx[token] = idx\n",
    "                self.idx2token.append(token)\n",
    "\n",
    "        self.max_len_single_sentence = self.max_len - 2  # take into account special tokens\n",
    "        self.max_len_sentences_pair = self.max_len - 3  # take into account special tokens\n",
    "\n",
    "        try:\n",
    "            import sentencepiece as spm\n",
    "        except ImportError:\n",
    "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
    "                           \"pip install sentencepiece\")\n",
    "\n",
    "        self.do_lower_case = do_lower_case\n",
    "        self.remove_space = remove_space\n",
    "        self.keep_accents = keep_accents\n",
    "        self.vocab_file = vocab_file\n",
    "        self.vocab_txt = vocab_txt\n",
    "\n",
    "        self.sp_model = spm.SentencePieceProcessor()\n",
    "        self.sp_model.Load(vocab_file)\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.idx2token)\n",
    "\n",
    "    def __getstate__(self):\n",
    "        state = self.__dict__.copy()\n",
    "        state[\"sp_model\"] = None\n",
    "        return state\n",
    "\n",
    "    def __setstate__(self, d):\n",
    "        self.__dict__ = d\n",
    "        try:\n",
    "            import sentencepiece as spm\n",
    "        except ImportError:\n",
    "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
    "                           \"pip install sentencepiece\")\n",
    "        self.sp_model = spm.SentencePieceProcessor()\n",
    "        self.sp_model.Load(self.vocab_file)\n",
    "\n",
    "    def preprocess_text(self, inputs):\n",
    "        if self.remove_space:\n",
    "            outputs = \" \".join(inputs.strip().split())\n",
    "        else:\n",
    "            outputs = inputs\n",
    "        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n",
    "\n",
    "        if not self.keep_accents:\n",
    "            outputs = unicodedata.normalize('NFKD', outputs)\n",
    "            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n",
    "        if self.do_lower_case:\n",
    "            outputs = outputs.lower()\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def _tokenize(self, text, return_unicode=True, sample=False):\n",
    "        \"\"\" Tokenize a string. \"\"\"\n",
    "        text = self.preprocess_text(text)\n",
    "\n",
    "        if not sample:\n",
    "            pieces = self.sp_model.EncodeAsPieces(text)\n",
    "        else:\n",
    "            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n",
    "        new_pieces = []\n",
    "        for piece in pieces:\n",
    "            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n",
    "                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n",
    "                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n",
    "                    if len(cur_pieces[0]) == 1:\n",
    "                        cur_pieces = cur_pieces[1:]\n",
    "                    else:\n",
    "                        cur_pieces[0] = cur_pieces[0][1:]\n",
    "                cur_pieces.append(piece[-1])\n",
    "                new_pieces.extend(cur_pieces)\n",
    "            else:\n",
    "                new_pieces.append(piece)\n",
    "\n",
    "        return new_pieces\n",
    "\n",
    "    def _convert_token_to_id(self, token):\n",
    "        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n",
    "        return self.token2idx.get(token, self.token2idx[self.unk_token])\n",
    "\n",
    "    def _convert_id_to_token(self, index, return_unicode=True):\n",
    "        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n",
    "        return self.idx2token[index]\n",
    "\n",
    "    def convert_tokens_to_string(self, tokens):\n",
    "        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n",
    "        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n",
    "        return out_string\n",
    "\n",
    "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "        \"\"\"\n",
    "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n",
    "        by concatenating and adding special tokens.\n",
    "        A RoBERTa sequence has the following format:\n",
    "            single sequence: [CLS] X [SEP]\n",
    "            pair of sequences: [CLS] A [SEP] B [SEP]\n",
    "        \"\"\"\n",
    "        if token_ids_1 is None:\n",
    "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
    "        cls = [self.cls_token_id]\n",
    "        sep = [self.sep_token_id]\n",
    "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
    "\n",
    "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n",
    "        \"\"\"\n",
    "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n",
    "        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n",
    "        Args:\n",
    "            token_ids_0: list of ids (must not contain special tokens)\n",
    "            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n",
    "                for sequence pairs\n",
    "            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n",
    "                special tokens for the model\n",
    "        Returns:\n",
    "            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n",
    "        \"\"\"\n",
    "\n",
    "        if already_has_special_tokens:\n",
    "            if token_ids_1 is not None:\n",
    "                raise ValueError(\n",
    "                    \"You should not supply a second sequence if the provided sequence of \"\n",
    "                    \"ids is already formated with special tokens for the model.\"\n",
    "                )\n",
    "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n",
    "\n",
    "        if token_ids_1 is not None:\n",
    "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
    "        return [1] + ([0] * len(token_ids_0)) + [1]\n",
    "\n",
    "    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n",
    "        \"\"\"\n",
    "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n",
    "        A BERT sequence pair mask has the following format:\n",
    "        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
    "        | first sequence    | second sequence\n",
    "        if token_ids_1 is None, only returns the first portion of the mask (0's).\n",
    "        \"\"\"\n",
    "        sep = [self.sep_token_id]\n",
    "        cls = [self.cls_token_id]\n",
    "        if token_ids_1 is None:\n",
    "            return len(cls + token_ids_0 + sep) * [0]\n",
    "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n",
    "\n",
    "    def save_vocabulary(self, save_directory):\n",
    "        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n",
    "            to a directory.\n",
    "        \"\"\"\n",
    "        if not os.path.isdir(save_directory):\n",
    "            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n",
    "            return\n",
    "\n",
    "        # 1. Save sentencepiece model\n",
    "        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n",
    "\n",
    "        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n",
    "            copyfile(self.vocab_file, out_vocab_model)\n",
    "\n",
    "        # 2. Save vocab.txt\n",
    "        index = 0\n",
    "        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n",
    "        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n",
    "            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n",
    "                if index != token_index:\n",
    "                    logger.warning(\n",
    "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
    "                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n",
    "                    )\n",
    "                    index = token_index\n",
    "                writer.write(token + \"\\n\")\n",
    "                index += 1\n",
    "\n",
    "        return out_vocab_model, out_vocab_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151,
     "referenced_widgets": [
      "ec57e59e25d248e7970d95131ae46b3d",
      "5209d984217747dea7f10d4159470ae8",
      "0e6142df085342eba8fb131a6781b286",
      "05cbb615c88d4c1db69d618835b76a01",
      "0834455e82164704ae7bf7213bb34738",
      "e76951c143df4ece837dcb8751ea6030",
      "70cf344a34a94f239ae84259054a94d0",
      "bc9c88d7d40f4fbeb04caeba39ba0bde",
      "43b176cc11784880889e17c2c6568721",
      "cea3abb6dd4948ce887de40ada21fc1d",
      "b3220312556d4530afd92a94d04ab038",
      "37fdd6b591274c78a53b00bf7e2523e1",
      "244f5d58c1ad4d2d858acaa35253182c",
      "56c271355ec84deea236bedf2d260f15",
      "431b8d54fbf94c7f98b775a4c6a8a1d0",
      "1738a6c11b0a47d69dade4d9b932643e"
     ]
    },
    "colab_type": "code",
    "id": "ECcUOiTG4yu2",
    "outputId": "78eb106f-0be2-401b-ef61-ce1c894d6816"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec57e59e25d248e7970d95131ae46b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=371391.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b176cc11784880889e17c2c6568721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=77779.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting 'max_len_single_sentence' is now deprecated. This value is automatically set up.\n",
      "Setting 'max_len_sentences_pair' is now deprecated. This value is automatically set up.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SfkL8mSB5CCM",
    "outputId": "c6336cfe-e241-46b5-8237-f81c4a6aba05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2366, 5678, 5678, 1192, 1804, 6166, 5760, 3415, 4638, 3272, 3133, 6926, 3]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Kj61kFQC5K5j",
    "outputId": "50c3489e-739e-43bb-9edf-0f5c75cffa9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁보는', '내', '내', '▁그대로', '▁들어', '맞', '는', '▁예측', '▁카리스마', '▁없는', '▁악', '역']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "X1CPi6WqLfi6",
    "outputId": "e989b7c8-9902-4a70-eec1-2893a5a5e9a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁송', '주', '현', '▁', '기자', '▁왼쪽', '▁위', '부터', ')', '김', '운', '용', ',', '▁이', '현', '옥', ',', '▁이', '흥', '민', ',', '▁노', '양', '호', ',', '▁정', '종', '현', ',', '▁신', '승', '일', '.', '▁특', '례', '시', '▁지정', '을', '▁앞둔', '▁10', '5', '만', '▁고양', '시', '의', '▁발전', '을', '▁위해', '▁', '땀', '과', '▁열정', '을', '▁쏟아', '온', '▁6', '명의', '▁공', '직', '자', '(', '서', '기관', ')', '들이', '▁아름다운', '▁퇴', '장을', '▁앞두고', '▁있다', '.', '▁경기', '북부', '의', '▁중심', '도시', '인', '▁고양', '시', '가', '▁', '되기', '까지', '▁', '쉼', '없이', '▁달려', '왔던', '▁이들은', '▁이제', '▁후', '배', '들에게', '▁자리를', '▁물', '려', '주', '고', '▁인생', '▁2', '막', '을', '▁준비', '▁중이다', '.', '▁김', '운', '용', '▁고양', '시', '▁푸', '른', '도시', '사업', '소', '장은', '▁19', '83', '년', '▁공', '직', '에', '▁입', '문', '해', '▁고양', '시', '가', '▁자연', '을', '▁품', '은', '▁도시', '가', '▁될', '▁수', '▁있도록', '▁많은', '▁연구', '와', '▁노력을', '▁기울', '여', '왔다', '.', '▁지난', '▁28', '일', '▁명예', '퇴', '직', '한', '▁그는', '▁산', '림', '보호', '유', '공', '을', '▁인정받', '아', '▁받은', '▁산', '림', '청', '장', '표', '창', '을', '▁비롯해', ',', '▁국무총리', '와', '▁국방부', '장관', ',', '▁', '도지사', '▁표', '창', '들이', '▁', '묵', '묵', '히', '▁업무', '에', '▁충실', '해', '▁온', '▁그의', '▁공', '직', '생활', '을', '▁보여준', '다', '.', '▁40', '년', '▁세', '월', '동안', '▁고양', '시', '를', '▁지켜', '온', '▁이', '현', '옥', '▁교육', '문화', '국장', '도', '▁공', '직', '을', '▁마무리', '하기', '▁위해', '▁공', '로', '연', '수', '에', '▁들어간', '다', '.', '▁부', '드', '럽', '고', '▁섬', '세', '한', '▁그의', '▁업무', '스타', '일', '은', '▁후', '배', '들에게', '도', '▁많은', '▁신뢰', '와', '▁박수', '를', '▁받아', '왔다', '.', '▁정부', '부처', '▁등', '으로부터', '▁표', '창', '을', '▁13', '회', '나', '▁받은', '▁이', '흥', '민', '▁민생', '경제', '국장', '▁역시', '▁고양', '시', '에게는', '▁아', '까', '운', '▁인재', '다', '.', '▁그는', '▁고양', '지역', '▁주민', '들이', '▁원활', '한', '▁생활', '지원', '을', '▁받을', '▁수', '▁있도록', '▁늘', '▁주민', '들과', '▁함께', '하며', '▁고양', '시', '▁행정', '에', '▁현장', '의', '▁목소리', '를', '▁담아', '왔다', '.', '▁노', '양', '호', '▁여성', '가족', '국장', '도', '▁고양', '지역', '▁발전', '을', '▁위해', '▁40', '년', '▁넘게', '▁예산', '법', '무', '과', '▁등', '▁주요', '부', '서', '에서', '▁활약', '해', '▁왔다', '.', '▁특히', '▁교육', '지원', '과', '장', '▁시절', '에는', '▁고양', '지역', '▁학생들', '의', '▁교육', '환경', '▁개선', '을', '▁위해', '▁노력을', '▁아끼', '지', '▁않았다', '.', '▁농업', '▁분야', '▁전문가', '인', '▁정', '종', '현', '▁농업', '기술', '센터', '소', '장', '도', '▁고양', '지역', '의', '▁농업', '이', '▁활성화', '되기', '까지', '▁많은', '▁자', '취', '를', '▁남겼다', '.', '▁2016', '년에는', '▁녹', '조', '근', '정', '훈', '장', '▁영', '예', '를', '▁받기', '도', '▁했다', '.', '▁신', '승', '일', '▁시민', '안전', '주택', '국장', '도', '▁이들', '과', '▁함께', '▁공', '로', '연', '수', '에', '▁들어간', '다', '.', '▁신', '▁국', '장은', '▁경기', '북부', '▁중심', '▁도시', '가', '▁된', '▁고양', '시', '의', '▁미래', '설', '계', '를', '▁담당', '해', '▁온', '▁일', '등', '▁공', '신', '▁인물', '이다', '.', '▁그동안', '▁고양', '시', '▁발전', '을', '▁위해서는', '▁해당', '▁업무를', '▁담당', '하는', '▁공', '직', '자', '▁역시', '▁계속', '적인', '▁발전', '이', '▁필요하다', '고', '▁강조', '해', '▁온', '▁그는', '▁2011', '년에는', '▁경', '희', '대', '에서', '▁경영', '학', '을', '▁전', '공', '하고', '▁2014', '년에는', '▁고려', '대', '에서', '▁건축', '공', '학과', '▁석', '사', '과정', '을', '▁마쳤다', '.', '▁풍부한', '▁학', '식', '과', '▁오랜', '▁행정', '경', '험', '을', '▁통해', '▁쌓', '은', '▁노하우', ',', '▁업무를', '▁추진', '하는', '▁뜨거운', '▁열정', ',', '▁뛰어난', '▁리더', '쉽', ',', '▁신', '▁국', '장이', '▁공', '직', '사회', '▁후', '배', '들에게', '▁받는', '▁평가', '다', '.', '▁고양', '시', '관계', '자는', '▁19', '59', '년생', '▁선배', '들', '인', '▁여', '섯', '분', '에게', '▁많은', '▁감사', '와', '▁응원', '을', '▁드', '린다', '며', '▁이제', '▁고양', '시', '의', '▁다음', '일', '은', '▁후', '배', '들에게', '▁맡', '기', '고', '▁새로운', '▁인생', '에서', '▁또', '▁다른', '▁성공', '이', '▁있', '길', '▁기', '원', '한다고', '▁말했다', '.', '▁고양', '유', '제', '원', '송', '주', '현', '기자', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(df['content1'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "l08amvMI5NJ7",
    "outputId": "ed281993-08ab-433b-f359-6d738d67e1d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4012, 7071, 3815, 5760, 3394, 54, 1574, 2358, 6751, 7086, 3394, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\", max_length=64, pad_to_max_length=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KLgnIY8t5UOv",
    "outputId": "0680a1d5-0b73-4308-b61c-b9251adae3e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 세그멘트 인풋\n",
    "print([0]*64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7STRjqpW5XMG",
    "outputId": "ccc14b99-8176-490e-9fd0-3d00d3545e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "valid_num = len(tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\"))\n",
    "print(valid_num * [1] + (64 - valid_num) * [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "afJf2uqS5ZiN",
    "outputId": "da69fe8f-258a-41b8-de76-3f64bfbc96b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4yAAcxng5fJx"
   },
   "outputs": [],
   "source": [
    "def convert_data(data_df):\n",
    "    global tokenizer\n",
    "    \n",
    "    SEQ_LEN = 512 #SEQ_LEN : 버트에 들어갈 인풋의 길이\n",
    "    \n",
    "    tokens, masks, segments, targets = [], [], [], []\n",
    "    \n",
    "    for i in tqdm(range(len(data_df))):\n",
    "        # token : 문장을 토큰화함\n",
    "        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, pad_to_max_length=True)\n",
    "       \n",
    "        # 마스크는 토큰화한 문장에서 패딩이 아닌 부분은 1, 패딩인 부분은 0으로 통일\n",
    "        num_zeros = token.count(0)\n",
    "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n",
    "        \n",
    "        # 문장의 전후관계를 구분해주는 세그먼트는 문장이 1개밖에 없으므로 모두 0\n",
    "        segment = [0]*SEQ_LEN\n",
    "\n",
    "        # 버트 인풋으로 들어가는 token, mask, segment를 tokens, segments에 각각 저장\n",
    "        tokens.append(token)\n",
    "        masks.append(mask)\n",
    "        segments.append(segment)\n",
    "        \n",
    "        # 정답(긍정 : 1 부정 0)을 targets 변수에 저장해 줌\n",
    "        targets.append(data_df[LABEL_COLUMN][i])\n",
    "\n",
    "    # tokens, masks, segments, 정답 변수 targets를 numpy array로 지정    \n",
    "    tokens = np.array(tokens)\n",
    "    masks = np.array(masks)\n",
    "    segments = np.array(segments)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    return [tokens, masks, segments], targets\n",
    "\n",
    "# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\n",
    "def load_data(pandas_dataframe):\n",
    "    data_df = pandas_dataframe\n",
    "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
    "    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\n",
    "    data_x, data_y = convert_data(data_df)\n",
    "    return data_x, data_y\n",
    "\n",
    "SEQ_LEN =512\n",
    "BATCH_SIZE = 8\n",
    "# 긍부정 문장을 포함하고 있는 칼럼\n",
    "DATA_COLUMN = \"content1\"\n",
    "# 긍정인지 부정인지를 (1=긍정,0=부정) 포함하고 있는 칼럼\n",
    "LABEL_COLUMN = \"quality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "4xCnu4lW7m5b",
    "outputId": "76ea1929-ddc5-49d1-e7e9-4d877024f7be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content1</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>송주현 기자 왼쪽 위부터)김운용, 이현옥, 이흥민, 노양호, 정종현, 신승일. 특례...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>송주현 기자. 고양시민들이 출퇴근길 겪고 있는 교통 불편이 새해에는 개선될 수 있을...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>박준상 기자. 기해년을 맞은 안양시가 향후 4년간 일자리 10만6천여개 창출을 목표...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>최현호 기자. 경기도의회 건설교통위원회 소속 오명근 의원(더불어민주당평택4)은 지난...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>홍완식 기자. 화성시가 새해를 맞아 민선7기 지역맞춤형 일자리 대책의 청사진을 공개...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            content1  quality\n",
       "0  송주현 기자 왼쪽 위부터)김운용, 이현옥, 이흥민, 노양호, 정종현, 신승일. 특례...        1\n",
       "1  송주현 기자. 고양시민들이 출퇴근길 겪고 있는 교통 불편이 새해에는 개선될 수 있을...        1\n",
       "2  박준상 기자. 기해년을 맞은 안양시가 향후 4년간 일자리 10만6천여개 창출을 목표...        1\n",
       "3  최현호 기자. 경기도의회 건설교통위원회 소속 오명근 의원(더불어민주당평택4)은 지난...        1\n",
       "4  홍완식 기자. 화성시가 새해를 맞아 민선7기 지역맞춤형 일자리 대책의 청사진을 공개...        1"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.loc[:,['content1','quality']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "noZOvrd48WMI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df1, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9A_ksqt83LZ"
   },
   "outputs": [],
   "source": [
    "train = train.reset_index()\n",
    "train.drop('index', axis=1, inplace=True)\n",
    "test = test.reset_index()\n",
    "test.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3HfcmDU45w3l",
    "outputId": "91eb7444-d159-4718-a7af-96a8b5df0ebb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/902 [00:00<?, ?it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  3%|▎         | 27/902 [00:00<00:03, 260.48it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  6%|▌         | 51/902 [00:00<00:03, 250.66it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  8%|▊         | 74/902 [00:00<00:03, 243.00it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 11%|█         | 97/902 [00:00<00:03, 236.13it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 13%|█▎        | 121/902 [00:00<00:03, 235.96it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 16%|█▌        | 145/902 [00:00<00:03, 235.20it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 19%|█▉        | 171/902 [00:00<00:03, 240.03it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 22%|██▏       | 197/902 [00:00<00:02, 245.30it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 25%|██▍       | 221/902 [00:00<00:02, 239.96it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 27%|██▋       | 245/902 [00:01<00:02, 239.56it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 30%|██▉       | 269/902 [00:01<00:02, 229.44it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 32%|███▏      | 292/902 [00:01<00:02, 226.06it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 35%|███▌      | 317/902 [00:01<00:02, 231.55it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 38%|███▊      | 343/902 [00:01<00:02, 237.92it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 41%|████▏     | 373/902 [00:01<00:02, 253.21it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 44%|████▍     | 399/902 [00:01<00:02, 244.80it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 48%|████▊     | 429/902 [00:01<00:01, 256.12it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 50%|█████     | 455/902 [00:01<00:01, 256.58it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 53%|█████▎    | 481/902 [00:01<00:01, 247.79it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 56%|█████▌    | 507/902 [00:02<00:01, 248.87it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 59%|█████▉    | 535/902 [00:02<00:01, 255.86it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 62%|██████▏   | 561/902 [00:02<00:01, 253.65it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 65%|██████▌   | 587/902 [00:02<00:01, 254.96it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 68%|██████▊   | 614/902 [00:02<00:01, 256.83it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 71%|███████▏  | 643/902 [00:02<00:00, 262.87it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 74%|███████▍  | 670/902 [00:02<00:00, 258.73it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 77%|███████▋  | 697/902 [00:02<00:00, 260.03it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 80%|████████  | 724/902 [00:02<00:00, 260.31it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 83%|████████▎ | 751/902 [00:03<00:00, 254.51it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 86%|████████▋ | 779/902 [00:03<00:00, 260.08it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 89%|████████▉ | 806/902 [00:03<00:00, 253.33it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 92%|█████████▏| 832/902 [00:03<00:00, 253.10it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 95%|█████████▌| 858/902 [00:03<00:00, 254.05it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 98%|█████████▊| 886/902 [00:03<00:00, 261.03it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 902/902 [00:03<00:00, 249.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# train 데이터를 버트 인풋에 맞게 변환\n",
    "train_x, train_y = load_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "j-R7zIjiHwSd",
    "outputId": "bb4f9226-818f-4ae1-ee3a-897d0ea95539"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/101 [00:00<?, ?it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 25%|██▍       | 25/101 [00:00<00:00, 241.83it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 50%|████▉     | 50/101 [00:00<00:00, 243.69it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 74%|███████▍  | 75/101 [00:00<00:00, 245.20it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 101/101 [00:00<00:00, 247.88it/s]\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = load_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-mzTxO3z9iPB"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186,
     "referenced_widgets": [
      "53aaf732d70b411f8339f69d9931b72c",
      "bb86a7c4a255439396f12e6c508575f4",
      "2936c6a120cd408886668a0cfa5bc104",
      "10611e4df18f4fa7b71239e2673cf6c6",
      "5c181b3b6a34448e8fcb20d10d90f4b4",
      "24ff8eae473d4b748a3fbf851e88bf44",
      "07bcb4a3d2b24237b3ac23e3fcc8d8ac",
      "06caa90078164dcdb1975cf359534caa",
      "70a43b0bf75d42e7a826d51ef008839d",
      "8f0e56f9f7db45ae83636b1c24fed99a",
      "f97788f302d54ee9a1f5bfa4821cb25d",
      "9c0ed2056f624347ba44eab8c9f1625a",
      "8e0967c2f08b4377a6aedc6672575ede",
      "d4e63a59106a41fa9220a6bc87879467",
      "55dae1efed9d481c9ad209fcff827b2c",
      "b30d3815a92447428f765fb2dd73ee70"
     ]
    },
    "colab_type": "code",
    "id": "ipEuCF__8hwE",
    "outputId": "f8adbfb8-ec0d-4f1e-8cb7-290ac4409773"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53aaf732d70b411f8339f69d9931b72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=426.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a43b0bf75d42e7a826d51ef008839d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=368792146.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertModel.\n",
      "\n",
      "All the weights of TFBertModel were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertModel.from_pretrained(\"monologg/kobert\", from_pt=True)\n",
    "# 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\n",
    "token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n",
    "mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n",
    "segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n",
    "# 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\n",
    "bert_outputs = model([token_inputs, mask_inputs, segment_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "cNBTp82o9Q1u",
    "outputId": "5f68dc8f-48ba-4766-bc1a-63e4c5d322e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0' shape=(None, 512, 768) dtype=float32>,\n",
       " <tf.Tensor 'tf_bert_model/bert/pooler/dense/Tanh:0' shape=(None, 768) dtype=float32>)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E45oGruc9Q5a"
   },
   "outputs": [],
   "source": [
    "bert_outputs = bert_outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZQC_CGk9Q8_"
   },
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "# 총 batch size * 4 epoch = 2344 * 4\n",
    "opt = tfa.optimizers.RectifiedAdam(lr=5.0e-5, total_steps = 2344*4, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-08, clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s6rEmSwJ6Cvw",
    "outputId": "6137430e-9f72-4d21-938a-8450a76c70f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5e-5 == 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sL5vCiMv9RAu"
   },
   "outputs": [],
   "source": [
    "sentiment_drop = tf.keras.layers.Dropout(0.5)(bert_outputs)\n",
    "sentiment_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(sentiment_drop)\n",
    "sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\n",
    "sentiment_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "I7UzJcBwqXSE",
    "outputId": "ac203f87-fae0-4b3c-e4c4-47c019f45b65"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"238pt\" viewBox=\"0.00 0.00 557.00 264.00\" width=\"503pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(.9028 .9028) rotate(0) translate(4 260)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 553,-260 553,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 139647192858920 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>139647192858920</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 179,-255.5 179,-219.5 0,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"89.5\" y=\"-233.8\">input_word_ids: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139647192860992 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>139647192860992</title>\n",
       "<polygon fill=\"none\" points=\"185.5,-146.5 185.5,-182.5 369.5,-182.5 369.5,-146.5 185.5,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-160.8\">tf_bert_model: TFBertModel</text>\n",
       "</g>\n",
       "<!-- 139647192858920&#45;&gt;139647192860992 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>139647192858920-&gt;139647192860992</title>\n",
       "<path d=\"M135.9719,-219.4551C161.8448,-209.4087 194.2369,-196.8309 221.5006,-186.2445\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"222.8561,-189.4728 230.9111,-182.5904 220.3223,-182.9474 222.8561,-189.4728\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139648744061696 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>139648744061696</title>\n",
       "<polygon fill=\"none\" points=\"197,-219.5 197,-255.5 358,-255.5 358,-219.5 197,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-233.8\">input_masks: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139648744061696&#45;&gt;139647192860992 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>139648744061696-&gt;139647192860992</title>\n",
       "<path d=\"M277.5,-219.4551C277.5,-211.3828 277.5,-201.6764 277.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"281.0001,-192.5903 277.5,-182.5904 274.0001,-192.5904 281.0001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139647189974880 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>139647189974880</title>\n",
       "<polygon fill=\"none\" points=\"376,-219.5 376,-255.5 549,-255.5 549,-219.5 376,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"462.5\" y=\"-233.8\">input_segment: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139647189974880&#45;&gt;139647192860992 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>139647189974880-&gt;139647192860992</title>\n",
       "<path d=\"M416.7697,-219.4551C391.4208,-209.4525 359.7127,-196.9407 332.9576,-186.3833\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"333.9321,-183.0052 323.3454,-182.5904 331.3627,-189.5166 333.9321,-183.0052\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139647193492616 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>139647193492616</title>\n",
       "<polygon fill=\"none\" points=\"207,-73.5 207,-109.5 348,-109.5 348,-73.5 207,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-87.8\">dropout_37: Dropout</text>\n",
       "</g>\n",
       "<!-- 139647192860992&#45;&gt;139647193492616 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>139647192860992-&gt;139647193492616</title>\n",
       "<path d=\"M277.5,-146.4551C277.5,-138.3828 277.5,-128.6764 277.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"281.0001,-119.5903 277.5,-109.5904 274.0001,-119.5904 281.0001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139647037184096 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>139647037184096</title>\n",
       "<polygon fill=\"none\" points=\"231.5,-.5 231.5,-36.5 323.5,-36.5 323.5,-.5 231.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-14.8\">dense: Dense</text>\n",
       "</g>\n",
       "<!-- 139647193492616&#45;&gt;139647037184096 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>139647193492616-&gt;139647037184096</title>\n",
       "<path d=\"M277.5,-73.4551C277.5,-65.3828 277.5,-55.6764 277.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"281.0001,-46.5903 277.5,-36.5904 274.0001,-46.5904 281.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(sentiment_model, dpi=65).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jpjE59iFWizR",
    "outputId": "dd5788e3-96f7-48f4-dabb-e8cfef7714d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rfgJ65-_WE_a",
    "outputId": "c5f811ac-0f6c-49b7-b796-5322866dfb6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.30000000000001"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1003*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "hcNf02B_91o7",
    "outputId": "aa8fc119-6ec0-4b9c-f791-6933c26c4a66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_segment (InputLayer)      [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_2 (TFBertModel)   ((None, 512, 768), ( 92186880    input_word_ids[0][0]             \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 input_segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 768)          0           tf_bert_model_2[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            769         dropout_113[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 92,187,649\n",
      "Trainable params: 92,187,649\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sentiment_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "bkIlgpzl932n",
    "outputId": "9e9d2287-c400-4d40-e42e-d003632057a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "15/15 [==============================] - 15s 999ms/step - loss: 0.7055 - accuracy: 0.5122 - val_loss: 0.6965 - val_accuracy: 0.4752\n",
      "Epoch 2/4\n",
      "15/15 [==============================] - 13s 849ms/step - loss: 0.7054 - accuracy: 0.4922 - val_loss: 0.6958 - val_accuracy: 0.4653\n",
      "Epoch 3/4\n",
      "15/15 [==============================] - 12s 824ms/step - loss: 0.6993 - accuracy: 0.5177 - val_loss: 0.6953 - val_accuracy: 0.4752\n",
      "Epoch 4/4\n",
      "15/15 [==============================] - 12s 807ms/step - loss: 0.7092 - accuracy: 0.5144 - val_loss: 0.6954 - val_accuracy: 0.4752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6fba800ef0>"
      ]
     },
     "execution_count": 224,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.fit(train_x, train_y, epochs=4, shuffle=True, batch_size=64, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "id": "4g7FnAEqJ22H",
    "outputId": "4816467c-3cd6-40d3-a701-93a234db15af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "57/57 [==============================] - 18s 313ms/step - loss: 0.7039 - accuracy: 0.5122 - val_loss: 0.6868 - val_accuracy: 0.5248\n",
      "Epoch 2/4\n",
      "57/57 [==============================] - 18s 320ms/step - loss: 0.7015 - accuracy: 0.4989 - val_loss: 0.6786 - val_accuracy: 0.5743\n",
      "Epoch 3/4\n",
      "57/57 [==============================] - 18s 316ms/step - loss: 0.6886 - accuracy: 0.5477 - val_loss: 0.6677 - val_accuracy: 0.5743\n",
      "Epoch 4/4\n",
      "57/57 [==============================] - 18s 313ms/step - loss: 0.6823 - accuracy: 0.5576 - val_loss: 0.6639 - val_accuracy: 0.6139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6f16b01160>"
      ]
     },
     "execution_count": 225,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.fit(train_x, train_y, epochs=4, shuffle=True, batch_size=16, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "colab_type": "code",
    "id": "V66TGMN5NJ_m",
    "outputId": "7870c842-4019-49c7-984f-aa2d0deb9f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "226/226 [==============================] - 257s 1s/step - loss: 0.7112 - accuracy: 0.5211 - val_loss: 0.6882 - val_accuracy: 0.5248\n",
      "Epoch 2/10\n",
      "226/226 [==============================] - 253s 1s/step - loss: 0.6917 - accuracy: 0.5388 - val_loss: 0.6886 - val_accuracy: 0.5446\n",
      "Epoch 3/10\n",
      "226/226 [==============================] - 254s 1s/step - loss: 0.6842 - accuracy: 0.5831 - val_loss: 0.6955 - val_accuracy: 0.5050\n",
      "Epoch 4/10\n",
      "226/226 [==============================] - 253s 1s/step - loss: 0.7010 - accuracy: 0.5288 - val_loss: 0.6897 - val_accuracy: 0.5149\n",
      "Epoch 5/10\n",
      "226/226 [==============================] - 253s 1s/step - loss: 0.6989 - accuracy: 0.5643 - val_loss: 0.6787 - val_accuracy: 0.5743\n",
      "Epoch 6/10\n",
      "226/226 [==============================] - 253s 1s/step - loss: 0.7020 - accuracy: 0.5277 - val_loss: 0.6981 - val_accuracy: 0.5050\n",
      "Epoch 7/10\n",
      "226/226 [==============================] - 253s 1s/step - loss: 0.6990 - accuracy: 0.5067 - val_loss: 0.6970 - val_accuracy: 0.4950\n",
      "Epoch 8/10\n",
      "226/226 [==============================] - 253s 1s/step - loss: 0.7058 - accuracy: 0.4878 - val_loss: 0.6977 - val_accuracy: 0.5050\n",
      "Epoch 9/10\n",
      "226/226 [==============================] - 253s 1s/step - loss: 0.7032 - accuracy: 0.4823 - val_loss: 0.7053 - val_accuracy: 0.4950\n",
      "Epoch 10/10\n",
      "226/226 [==============================] - 253s 1s/step - loss: 0.7031 - accuracy: 0.4823 - val_loss: 0.6999 - val_accuracy: 0.5050\n"
     ]
    }
   ],
   "source": [
    "his = sentiment_model.fit(train_x, train_y, epochs=10, shuffle=True, batch_size=4, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "k43IwJt2Pnkc",
    "outputId": "05208842-4b2e-4645-db7a-274ae589f5cc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kobert_model_loss = his.history['val_loss']\n",
    "kobert_model_accuracy = his.history['val_accuracy']\n",
    "\n",
    "epochs = range(1, 11)\n",
    "plt.plot(epochs, kobert_model_loss, 'b+', label='kobert_model_loss')\n",
    "plt.plot(epochs, kobert_model_accuracy, 'ro', label='kobert_model_accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "#plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "Bp75q6lFRusY",
    "outputId": "c0197641-eb87-4c62-e956-e95e5bce4c1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 19s 325ms/step - loss: 0.1096 - accuracy: 0.9678 - val_loss: 0.9603 - val_accuracy: 0.7030\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 18s 321ms/step - loss: 0.1952 - accuracy: 0.9290 - val_loss: 1.0312 - val_accuracy: 0.6238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6f15a72ef0>"
      ]
     },
     "execution_count": 227,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.fit(train_x, train_y, epochs=10, shuffle=True, batch_size=16, validation_data=(test_x, test_y),\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "bSvwhsWdql5z",
    "outputId": "cf97bf3d-0b5c-4e6b-a456-88af7f3d37bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "226/226 [==============================] - 258s 1s/step - loss: 0.6996 - accuracy: 0.5344 - val_loss: 0.7130 - val_accuracy: 0.5050\n",
      "Epoch 2/5\n",
      "226/226 [==============================] - 252s 1s/step - loss: 0.6968 - accuracy: 0.4956 - val_loss: 0.6739 - val_accuracy: 0.5842\n",
      "Epoch 3/5\n",
      "226/226 [==============================] - 253s 1s/step - loss: 0.6916 - accuracy: 0.5477 - val_loss: 0.6521 - val_accuracy: 0.6436\n",
      "Epoch 4/5\n",
      "226/226 [==============================] - 252s 1s/step - loss: 0.6939 - accuracy: 0.5532 - val_loss: 0.6988 - val_accuracy: 0.5050\n",
      "Epoch 5/5\n",
      "226/226 [==============================] - 252s 1s/step - loss: 0.7003 - accuracy: 0.5333 - val_loss: 0.6625 - val_accuracy: 0.5743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f716c6a9ba8>"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.fit(train_x, train_y, epochs=5, shuffle=True, batch_size=4, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "gFuyuNlPCGWD",
    "outputId": "224b4c6c-97ea-4de4-8d2a-1a00a93366b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "226/226 [==============================] - 254s 1s/step - loss: 0.6903 - accuracy: 0.5399 - val_loss: 0.6977 - val_accuracy: 0.5446\n",
      "Epoch 2/5\n",
      "226/226 [==============================] - 254s 1s/step - loss: 0.6866 - accuracy: 0.5399 - val_loss: 0.6993 - val_accuracy: 0.5743\n",
      "Epoch 3/5\n",
      "226/226 [==============================] - 253s 1s/step - loss: 0.7091 - accuracy: 0.5177 - val_loss: 0.6930 - val_accuracy: 0.5050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7180ba3320>"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.fit(train_x, train_y, epochs=5, shuffle=True, batch_size=4, validation_data=(test_x, test_y),\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "6dvMhMXINKh4",
    "outputId": "fc8c3a91-4c83-4454-a783-1389a7a44b9f"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-8272bdcb0adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m###여기를 shape을 못하겟다~\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mcon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_outputs1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reshape() missing 1 required positional argument: 'shape'"
     ]
    }
   ],
   "source": [
    "# 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\n",
    "token_inputs1 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids1')\n",
    "mask_inputs1 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks1')\n",
    "segment_inputs1 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment1')\n",
    "\n",
    "token_inputs2 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids2')\n",
    "mask_inputs2 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks2')\n",
    "segment_inputs2 = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment2')\n",
    "'''\n",
    "token_inputs = [token_inputs1, token_inputs2]\n",
    "mask_inputs = [mask_inputs1, mask_inputs2]\n",
    "segment_inputs = [segment_inputs, segment_inputs2]\n",
    "'''\n",
    "# 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\n",
    "\n",
    "bert_outputs1 = model([token_inputs1, mask_inputs1, segment_inputs1])[1]\n",
    "bert_outputs2 = model([token_inputs2,mask_inputs2,segment_inputs2])[1]\n",
    "\n",
    "concatenate = tf.keras.layers.concatenate([bert_outputs1,bert_outputs2])\n",
    "\n",
    "###여기를 shape을 못하겟다~\n",
    "con = tf.reshape(bert_outputs1[768,])\n",
    "\n",
    "\n",
    "lstm = tf.keras.layers.LSTM(768)(con)\n",
    "dense = tf.keras.layers.Dense(64, activation='relu')(lstm)\n",
    "sentiment_first = tf.keras.layers.Dense(5, activation='softmax', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(dense)\n",
    "\n",
    "#token_inputs = [token_inputs1,token_inputs2]\n",
    "#mask_inputs = [mask_inputs1,mask_inputs2]\n",
    "#segment_inputs = [segment_inputs1,segment_inputs2]\n",
    "\n",
    "\n",
    "sentiment_model = tf.keras.Model([token_inputs1, mask_inputs1, segment_inputs1], sentiment_first)\n",
    "sentiment_model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KfocVVYfNKm1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fYLg28YYtuJ"
   },
   "source": [
    "### BERT Long Document Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "colab_type": "code",
    "id": "LG_ouIpZNKpo",
    "outputId": "01238770-ed40-43d0-80c1-b641a849e192"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert_document_classification\n",
      "  Downloading https://files.pythonhosted.org/packages/f9/e0/bfce41dcb17179d538c46093e04a8925b63c913dae9a269aca51b0e2d701/bert_document_classification-1.0.0-py3-none-any.whl\n",
      "Collecting pytorch-transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 4.0MB/s \n",
      "\u001b[?25hCollecting configargparse\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/79/3045743bb26ca2e44a1d317c37395462bfed82dbbd38e69a3280b63696ce/ConfigArgParse-1.2.3.tar.gz (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from bert_document_classification) (0.22.2.post1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from bert_document_classification) (1.6.0+cu101)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->bert_document_classification) (2.23.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->bert_document_classification) (2019.12.20)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->bert_document_classification) (4.41.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->bert_document_classification) (1.18.5)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 27.9MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 46.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->bert_document_classification) (1.14.48)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->bert_document_classification) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->bert_document_classification) (1.4.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->bert_document_classification) (0.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->bert_document_classification) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->bert_document_classification) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->bert_document_classification) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers->bert_document_classification) (2.10)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers->bert_document_classification) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers->bert_document_classification) (7.1.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->bert_document_classification) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->bert_document_classification) (1.17.48)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers->bert_document_classification) (0.3.3)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->pytorch-transformers->bert_document_classification) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->pytorch-transformers->bert_document_classification) (2.8.1)\n",
      "Building wheels for collected packages: configargparse, sacremoses\n",
      "  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for configargparse: filename=ConfigArgParse-1.2.3-cp36-none-any.whl size=19329 sha256=916b1e31faca51b6c717a8260ddc38b7901b75e67cb5b025636b6792433584b4\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/d6/53/034032da9498bda2385cd50a51a289e88090b5da2d592b1fdf\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=6f4306eafb9c5e5dfb87c2acc7e804175dfd03466bf2a00bd8daa54b39453651\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built configargparse sacremoses\n",
      "Installing collected packages: sacremoses, sentencepiece, pytorch-transformers, configargparse, bert-document-classification\n",
      "Successfully installed bert-document-classification-1.0.0 configargparse-1.2.3 pytorch-transformers-1.2.0 sacremoses-0.0.43 sentencepiece-0.1.91\n"
     ]
    }
   ],
   "source": [
    "!pip install bert_document_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pnny-mlUZmpX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "colab_type": "code",
    "id": "267tePz_ZlCc",
    "outputId": "191d6f0b-c5f4-4bc0-86af-22f64b9f4c3c"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-629f53f29376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbert_document_classification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSmokerPhenotypingBert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert_document_classification/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mobesity_document_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mObesityPhenotypingBert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msmoker_document_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSmokerPhenotypingBert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert_document_classification/models/obesity_document_bert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertForDocumentClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mObesityPhenotypingBert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBertForDocumentClassification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"n2c2_2008_obesity_lstm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert_document_classification/document_bert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdocument_bert_architectures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocumentBertLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocumentBertLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocumentBertTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocumentBertMaxPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_input_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert_document_classification/document_bert_architectures.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformerEncoderLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert_document_classification/transformer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxavier_normal_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_VF'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from bert_document_classification.models import SmokerPhenotypingBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "hkGxsQQQNKkr",
    "outputId": "2ea75d9e-6608-48a8-93cb-c1c97cde5d92"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-19a3cb46662e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbert_document_classification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSmokerPhenotypingBert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbert_document_classification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mObesityPhenotypingBert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msmoking_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSmokerPhenotypingBert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#defaults to GPU prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert_document_classification/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mobesity_document_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mObesityPhenotypingBert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msmoker_document_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSmokerPhenotypingBert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert_document_classification/models/obesity_document_bert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_bert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertForDocumentClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mObesityPhenotypingBert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBertForDocumentClassification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"n2c2_2008_obesity_lstm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert_document_classification/document_bert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdocument_bert_architectures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocumentBertLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocumentBertLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocumentBertTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocumentBertMaxPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_input_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert_document_classification/document_bert_architectures.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformerEncoderLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert_document_classification/transformer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxavier_normal_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_VF'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from bert_document_classification.models import SmokerPhenotypingBert\n",
    "from bert_document_classification.models import ObesityPhenotypingBert\n",
    "\n",
    "smoking_classifier = SmokerPhenotypingBert(device='cuda', batch_size=10) #defaults to GPU prediction\n",
    "\n",
    "obesity_classifier = ObesityPhenotypingBert(device='cpu', batch_size=10) #or CPU if you would like.\n",
    "\n",
    "smoking_classifier.predict([\"I'm a document! Make me long and the model can still perform well!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yr8AhzFI--yL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-KT7hwqyDqKu"
   },
   "source": [
    "### 리스트 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bsacVC9ODqsZ"
   },
   "outputs": [],
   "source": [
    "depend_list = ['SBJ', 'OBJ', 'VP']\n",
    "\n",
    "def do_lang1 ( openapi_key, text ) :\n",
    "    \n",
    "    openApiURL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "    \n",
    "    requestJson = { \"access_key\": openapi_key, \"argument\": { \"text\": text, \"analysis_code\": \"dparse\" } }\n",
    "    \n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request( \"POST\", openApiURL, headers={\"Content-Type\": \"application/json; charset=UTF-8\"}, body=json.dumps(requestJson))\n",
    "    \n",
    "    json_data = json.loads(response.data.decode('utf-8'))\n",
    "    json_result = json_data[\"result\"]\n",
    "    \n",
    "    if json_result == -1:\n",
    "        json_reason = json_data[\"reason\"]\n",
    "        if \"Invalid Access Key\" in json_reason:\n",
    "            logger.info(json_reason)\n",
    "            logger.info(\"Please check the openapi access key.\")\n",
    "            sys.exit()\n",
    "        return \"openapi error - \" + json_reason      \n",
    "    else:\n",
    "        json_data = json.loads(response.data.decode('utf-8'))\n",
    "    \n",
    "        json_return_obj = json_data[\"return_object\"]\n",
    "        \n",
    "        return_result = \"\"\n",
    "        ls_return = []\n",
    "        json_sentence = json_return_obj[\"sentence\"]\n",
    "        for json_morp in json_sentence:                        \n",
    "            for morp in json_morp[\"dependency\"]:\n",
    "              for depend in depend_list:\n",
    "                if depend in morp[\"label\"]:\n",
    "                  if 'VP' and 'OBJ' in morp[\"label\"]:\n",
    "                    return_result = return_result+str(morp[\"text\"])+\"/\"+str(morp[\"label\"])+\" \"\n",
    "                    ls_return.append(str(morp[\"text\"])+\"/\"+str(morp[\"label\"]))\n",
    "        set_dodo = set(ls_return)\n",
    "        ls_set = list(set_dodo)\n",
    "                  \n",
    "\n",
    "        return ls_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mYjc2fNIEduP"
   },
   "outputs": [],
   "source": [
    "def do_lang ( openapi_key, text ) :\n",
    "    \n",
    "    openApiURL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "    \n",
    "    requestJson = { \"access_key\": openapi_key, \"argument\": { \"text\": text, \"analysis_code\": \"dparse\" } }\n",
    "    \n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request( \"POST\", openApiURL, headers={\"Content-Type\": \"application/json; charset=UTF-8\"}, body=json.dumps(requestJson))\n",
    "    \n",
    "    json_data = json.loads(response.data.decode('utf-8'))\n",
    "    json_result = json_data[\"result\"]\n",
    "    \n",
    "    if json_result == -1:\n",
    "        json_reason = json_data[\"reason\"]\n",
    "        if \"Invalid Access Key\" in json_reason:\n",
    "            logger.info(json_reason)\n",
    "            logger.info(\"Please check the openapi access key.\")\n",
    "            sys.exit()\n",
    "        return \"openapi error - \" + json_reason      \n",
    "    else:\n",
    "        json_data = json.loads(response.data.decode('utf-8'))\n",
    "    \n",
    "        json_return_obj = json_data[\"return_object\"]\n",
    "        \n",
    "        return_result = \"\"\n",
    "        json_sentence = json_return_obj[\"sentence\"]\n",
    "        for json_morp in json_sentence:                        \n",
    "            for morp in json_morp[\"dependency\"]:\n",
    "              for depend in depend_list:\n",
    "                if depend in morp[\"label\"]:\n",
    "                  return_result = return_result+str(morp[\"text\"])+\"/\"+str(morp[\"label\"])+\" \"\n",
    "\n",
    "        return return_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "bCMTNLIdDu8X",
    "outputId": "6ff019fc-33f8-4886-c344-9d5dfa2b16d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['석사과정을/NP_OBJ',\n",
       " '지정을/NP_OBJ',\n",
       " '자리를/NP_OBJ',\n",
       " '생활지원을/NP_OBJ',\n",
       " '열정을/NP_OBJ',\n",
       " '2막을/NP_OBJ',\n",
       " '업무를/NP_OBJ',\n",
       " '산림보호유공을/NP_OBJ',\n",
       " '목소리를/NP_OBJ',\n",
       " '발전을/NP_OBJ',\n",
       " '자연을/NP_OBJ',\n",
       " '응원을/NP_OBJ',\n",
       " '미래설계를/NP_OBJ',\n",
       " '행정경험을/NP_OBJ',\n",
       " '공직을/NP_OBJ',\n",
       " '퇴장을/NP_OBJ',\n",
       " '경영학을/NP_OBJ',\n",
       " '영예를/NP_OBJ',\n",
       " '박수를/NP_OBJ',\n",
       " '개선을/NP_OBJ',\n",
       " '13회나/NP_OBJ',\n",
       " '표창을/NP_OBJ',\n",
       " '산림청장표창을/NP_OBJ',\n",
       " '있길/VP_OBJ',\n",
       " '고양시를/NP_OBJ',\n",
       " '노력을/NP_OBJ',\n",
       " '공직생활을/NP_OBJ',\n",
       " '마무리하기/VP_OBJ',\n",
       " '자취를/NP_OBJ']"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_lang1(api_key, df['content1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xG_KiI4vD6Ym"
   },
   "outputs": [],
   "source": [
    "depend_list = ['SBJ', 'OBJ']\n",
    "\n",
    "def do_lang2 ( openapi_key, text ) :\n",
    "    \n",
    "    openApiURL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "    \n",
    "    requestJson = { \"access_key\": openapi_key, \"argument\": { \"text\": text, \"analysis_code\": \"dparse\" } }\n",
    "    \n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request( \"POST\", openApiURL, headers={\"Content-Type\": \"application/json; charset=UTF-8\"}, body=json.dumps(requestJson))\n",
    "    \n",
    "    json_data = json.loads(response.data.decode('utf-8'))\n",
    "    json_result = json_data[\"result\"]\n",
    "    \n",
    "    if json_result == -1:\n",
    "        json_reason = json_data[\"reason\"]\n",
    "        if \"Invalid Access Key\" in json_reason:\n",
    "            logger.info(json_reason)\n",
    "            logger.info(\"Please check the openapi access key.\")\n",
    "            sys.exit()\n",
    "        return \"openapi error - \" + json_reason      \n",
    "    else:\n",
    "        json_data = json.loads(response.data.decode('utf-8'))\n",
    "    \n",
    "        json_return_obj = json_data[\"return_object\"]\n",
    "        \n",
    "        return_result = \"\"\n",
    "        ls_return = []\n",
    "        sentence = json_return_obj['sentence']\n",
    "        for morp in sentence:\n",
    "          for dep in morp['dependency']:\n",
    "            if dep['label'] == 'VP':\n",
    "              return_result = return_result+str(dep[\"text\"])#+\"/\"+str(dep[\"label\"])+\" \"\n",
    "              #ls_return.append(str(dep[\"text\"])+\"/\"+str(dep[\"label\"]))\n",
    "            for depend in depend_list:\n",
    "              if depend in dep['label']:\n",
    "                return_result = return_result+str(dep[\"text\"])#+\"/\"+str(dep[\"label\"])+\" \"\n",
    "                #ls_return.append(str(dep[\"text\"])+\"/\"+str(dep[\"label\"]))\n",
    "          \n",
    "\n",
    "\n",
    "        return return_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "2-aScG_-SlAt",
    "outputId": "dc443e8f-67fd-4fc4-b668-ac152582dd46"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'지정을/NP_OBJ 발전을/NP_OBJ 위해/VP 열정을/NP_OBJ 공직자(서기관)들이/NP_SBJ 퇴장을/NP_OBJ 앞두고/VP 있다./VP 되기까지/VP 이들은/NP_SBJ 자리를/NP_OBJ 물려주고/VP 2막을/NP_OBJ 푸른도시사업소장은/NP_SBJ 입문해/VP 고양시가/NP_SBJ 자연을/NP_OBJ 수/NP_SBJ 있도록/VP 노력을/NP_OBJ 기울여왔다./VP 그는/NP_SBJ 산림보호유공을/NP_OBJ 인정받아/VP 산림청장표창을/NP_OBJ 비롯해,/VP 표창들이/NP_SBJ 충실해/VP 공직생활을/NP_OBJ 보여준다./VP 고양시를/NP_OBJ 교육문화국장도/NP_SBJ 공직을/NP_OBJ 마무리하기/VP_OBJ 위해/VP 들어간다./VP 부드럽고/VP 업무스타일은/NP_SBJ 박수를/NP_OBJ 받아왔다./VP 표창을/NP_OBJ 13회나/NP_OBJ 민생경제국장/NP_SBJ 그는/NP_SBJ 주민들이/NP_SBJ 생활지원을/NP_OBJ 수/NP_SBJ 있도록/VP 함께하며/VP 목소리를/NP_OBJ 담아왔다./VP 여성가족국장도/NP_SBJ 발전을/NP_OBJ 위해/VP 40년/NP_SBJ 넘게/VP 활약해/VP 왔다./VP 개선을/NP_OBJ 위해/VP 노력을/NP_OBJ 아끼지/VP 않았다./VP 농업기술센터소장도/NP_SBJ 농업이/NP_SBJ 활성화되기까지/VP 자취를/NP_OBJ 남겼다./VP 영예를/NP_OBJ 받기도/VP 했다./VP 시민안전주택국장도/NP_SBJ 들어간다./VP 국장은/NP_SBJ 미래설계를/NP_OBJ 담당해/VP 발전을/NP_OBJ 위해서는/VP 업무를/NP_OBJ 공직자/NP_SBJ 발전이/NP_SBJ 강조해/VP 그는/NP_SBJ 경영학을/NP_OBJ 전공하고/VP 석사과정을/NP_OBJ 마쳤다./VP 행정경험을/NP_OBJ 통해/VP 업무를/NP_OBJ 국장이/NP_SBJ 고양시관계자는/NP_SBJ 응원을/NP_OBJ 드린다며/VP 다음일은/NP_SBJ 맡기고/VP 성공이/NP_SBJ 있길/VP_OBJ 말했다./VP '"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_lang2(api_key, df['content1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bujMz-ztU0JI"
   },
   "outputs": [],
   "source": [
    "df['depend'] = df['content1'].apply(lambda x: do_lang2(api_key, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBN58l5AVFuz"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUsCViOsYkfA"
   },
   "outputs": [],
   "source": [
    "from tokenization_morp import FullTokenizer\n",
    "\n",
    "# FullTokenizer\n",
    "ftk = FullTokenizer(vocab_file, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "colab_type": "code",
    "id": "CJ8VxowIVg5N",
    "outputId": "0f001a80-302d-43c8-aa58-269cb0a4c629"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-9af389362ca0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlsls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'depend'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mftk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mlsls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ftk' is not defined"
     ]
    }
   ],
   "source": [
    "lsls = []\n",
    "for text in df['depend']:\n",
    "  split_tokens = ftk.tokenize(text)\n",
    "  lsls.append(split_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bHfPSTrZVhVG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "miGcIAyZVht2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tPaBQI0VhcE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVkcLHkWVhLe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17Ca6ZNUVgtd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "11g1rR0XOLI0"
   },
   "outputs": [],
   "source": [
    "depend_list = ['SBJ_NP', 'OBJ', 'VP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5i5hQ6NOI-s"
   },
   "outputs": [],
   "source": [
    "'SB' in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ILhMnubWNAQl",
    "outputId": "fd0efbaf-8ba9-421d-e2cc-fb4808f5e487"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'SBJ' in depend_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqocUyWEKzHs"
   },
   "outputs": [],
   "source": [
    "\n",
    "openApiURL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "    \n",
    "requestJson = { \"access_key\": api_key, \"argument\": { \"text\": df['content1'][0], \"analysis_code\": \"dparse\" } }\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "response = http.request( \"POST\", openApiURL, headers={\"Content-Type\": \"application/json; charset=UTF-8\"}, body=json.dumps(requestJson))\n",
    "\n",
    "json_data = json.loads(response.data.decode('utf-8'))\n",
    "json_result = json_data[\"result\"]\n",
    "\n",
    "if json_result == -1:\n",
    "    json_reason = json_data[\"reason\"]\n",
    "    if \"Invalid Access Key\" in json_reason:\n",
    "        logger.info(json_reason)\n",
    "        logger.info(\"Please check the openapi access key.\")\n",
    "        sys.exit()\n",
    "\n",
    "else:\n",
    "    json_data = json.loads(response.data.decode('utf-8'))\n",
    "\n",
    "    json_return_obj = json_data[\"return_object\"]\n",
    "    \n",
    "    return_result = \"\"\n",
    "    ls_return = []\n",
    "    json_sentence = json_return_obj[\"sentence\"]\n",
    "    sentence = json_return_obj['sentence']\n",
    "\n",
    "    for morp in sentence:\n",
    "      for dep in morp['dependency']:\n",
    "        for lmp in dep['label']:\n",
    "          if 'VP' in lmp:\n",
    "            return_result = return_result+str(dep[\"text\"])+\"/\"+str(dep[\"label\"])+\" \"\n",
    "            ls_return_append(str(dep[\"text\"])+\"/\"+str(dep[\"label\"]))\n",
    "          for depend in depend_list:\n",
    "            if depend in lmp:\n",
    "              return_result = return_result+str(dep[\"text\"])+\"/\"+str(dep[\"label\"])+\" \"\n",
    "              ls_return.append(str(dep[\"text\"])+\"/\"+str(dep[\"label\"]))\n",
    "      set_dodo = set(ls_return)\n",
    "      ls_set = list(set_dodo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "P3Ip6LfbPofe",
    "outputId": "e5956044-6c95-46ea-e45e-9006f2c50206"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'NE': [{'begin': 0.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'text': '송주현',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.620646},\n",
       "   {'begin': 1.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'text': '기자',\n",
       "    'type': 'CV_OCCUPATION',\n",
       "    'weight': 0.602677},\n",
       "   {'begin': 2.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'text': '왼쪽',\n",
       "    'type': 'TM_DIRECTION',\n",
       "    'weight': 0.516759},\n",
       "   {'begin': 6.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 6.0,\n",
       "    'id': 3.0,\n",
       "    'text': '김운용',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.774615},\n",
       "   {'begin': 8.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 8.0,\n",
       "    'id': 4.0,\n",
       "    'text': '이현옥',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.587024},\n",
       "   {'begin': 10.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 10.0,\n",
       "    'id': 5.0,\n",
       "    'text': '이흥민',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.48841},\n",
       "   {'begin': 12.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 12.0,\n",
       "    'id': 6.0,\n",
       "    'text': '노양호',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.364307},\n",
       "   {'begin': 14.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 14.0,\n",
       "    'id': 7.0,\n",
       "    'text': '정종현',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.802612},\n",
       "   {'begin': 16.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 16.0,\n",
       "    'id': 8.0,\n",
       "    'text': '신승일',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.448303}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 0.0,\n",
       "    'scode': '00',\n",
       "    'text': '송주현',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 10.0,\n",
       "    'scode': '05',\n",
       "    'text': '기자',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 17.0,\n",
       "    'scode': '00',\n",
       "    'text': '왼쪽',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 24.0,\n",
       "    'scode': '01',\n",
       "    'text': '위',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.03851},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 27.0,\n",
       "    'scode': '00',\n",
       "    'text': '부터',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 5.0,\n",
       "    'position': 33.0,\n",
       "    'scode': '00',\n",
       "    'text': ')',\n",
       "    'type': 'SS',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 6.0,\n",
       "    'position': 34.0,\n",
       "    'scode': '00',\n",
       "    'text': '김운용',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 7.0,\n",
       "    'position': 43.0,\n",
       "    'scode': '00',\n",
       "    'text': ',',\n",
       "    'type': 'SP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 8.0,\n",
       "    'position': 45.0,\n",
       "    'scode': '00',\n",
       "    'text': '이현옥',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 9.0,\n",
       "    'position': 54.0,\n",
       "    'scode': '00',\n",
       "    'text': ',',\n",
       "    'type': 'SP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 10.0,\n",
       "    'position': 56.0,\n",
       "    'scode': '00',\n",
       "    'text': '이흥민',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 11.0,\n",
       "    'position': 65.0,\n",
       "    'scode': '00',\n",
       "    'text': ',',\n",
       "    'type': 'SP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 12.0,\n",
       "    'position': 67.0,\n",
       "    'scode': '00',\n",
       "    'text': '노양호',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 13.0,\n",
       "    'position': 76.0,\n",
       "    'scode': '00',\n",
       "    'text': ',',\n",
       "    'type': 'SP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 14.0,\n",
       "    'position': 78.0,\n",
       "    'scode': '00',\n",
       "    'text': '정종현',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 15.0,\n",
       "    'end': 15.0,\n",
       "    'id': 15.0,\n",
       "    'position': 87.0,\n",
       "    'scode': '00',\n",
       "    'text': ',',\n",
       "    'type': 'SP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 16.0,\n",
       "    'position': 89.0,\n",
       "    'scode': '00',\n",
       "    'text': '신승일',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 17.0,\n",
       "    'end': 17.0,\n",
       "    'id': 17.0,\n",
       "    'position': 98.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 1.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '송주현',\n",
       "    'weight': 0.618235},\n",
       "   {'head': 2.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [0.0],\n",
       "    'text': '기자',\n",
       "    'weight': 0.438543},\n",
       "   {'head': 3.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [1.0],\n",
       "    'text': '왼쪽',\n",
       "    'weight': 0.751633},\n",
       "   {'head': 8.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [2.0],\n",
       "    'text': '위부터)김운용,',\n",
       "    'weight': 0.170749},\n",
       "   {'head': 8.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'NP_CNJ',\n",
       "    'mod': [],\n",
       "    'text': '이현옥,',\n",
       "    'weight': 0.429838},\n",
       "   {'head': 8.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'NP_CNJ',\n",
       "    'mod': [],\n",
       "    'text': '이흥민,',\n",
       "    'weight': 0.585637},\n",
       "   {'head': 8.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'NP_CNJ',\n",
       "    'mod': [],\n",
       "    'text': '노양호,',\n",
       "    'weight': 0.508906},\n",
       "   {'head': 8.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'NP_CNJ',\n",
       "    'mod': [],\n",
       "    'text': '정종현,',\n",
       "    'weight': 0.358688},\n",
       "   {'head': -1.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [3.0, 4.0, 5.0, 6.0, 7.0],\n",
       "    'text': '신승일.',\n",
       "    'weight': 0.000866793}],\n",
       "  'id': 0.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '송주현',\n",
       "    'position': 0.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0718234},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '기자',\n",
       "    'position': 10.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0674813},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '왼쪽',\n",
       "    'position': 17.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.040396},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '위',\n",
       "    'position': 24.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0731358},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '부터',\n",
       "    'position': 27.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.0420098},\n",
       "   {'id': 5.0, 'lemma': ')', 'position': 33.0, 'type': 'SS', 'weight': 1.0},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '김운용',\n",
       "    'position': 34.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0218297},\n",
       "   {'id': 7.0, 'lemma': ',', 'position': 43.0, 'type': 'SP', 'weight': 1.0},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '이현옥',\n",
       "    'position': 45.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0447042},\n",
       "   {'id': 9.0, 'lemma': ',', 'position': 54.0, 'type': 'SP', 'weight': 1.0},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '이흥민',\n",
       "    'position': 56.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0351699},\n",
       "   {'id': 11.0, 'lemma': ',', 'position': 65.0, 'type': 'SP', 'weight': 1.0},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '노양호',\n",
       "    'position': 67.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0393358},\n",
       "   {'id': 13.0, 'lemma': ',', 'position': 76.0, 'type': 'SP', 'weight': 1.0},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '정종현',\n",
       "    'position': 78.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0734248},\n",
       "   {'id': 15.0, 'lemma': ',', 'position': 87.0, 'type': 'SP', 'weight': 1.0},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '신승일',\n",
       "    'position': 89.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0213686},\n",
       "   {'id': 17.0, 'lemma': '.', 'position': 98.0, 'type': 'SF', 'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': '송주현 기자 왼쪽 위부터)김운용, 이현옥, 이흥민, 노양호, 정종현, 신승일.',\n",
       "  'word': [{'begin': 0.0, 'end': 0.0, 'id': 0.0, 'text': '송주현', 'type': ''},\n",
       "   {'begin': 1.0, 'end': 1.0, 'id': 1.0, 'text': '기자', 'type': ''},\n",
       "   {'begin': 2.0, 'end': 2.0, 'id': 2.0, 'text': '왼쪽', 'type': ''},\n",
       "   {'begin': 3.0, 'end': 7.0, 'id': 3.0, 'text': '위부터)김운용,', 'type': ''},\n",
       "   {'begin': 8.0, 'end': 9.0, 'id': 4.0, 'text': '이현옥,', 'type': ''},\n",
       "   {'begin': 10.0, 'end': 11.0, 'id': 5.0, 'text': '이흥민,', 'type': ''},\n",
       "   {'begin': 12.0, 'end': 13.0, 'id': 6.0, 'text': '노양호,', 'type': ''},\n",
       "   {'begin': 14.0, 'end': 15.0, 'id': 7.0, 'text': '정종현,', 'type': ''},\n",
       "   {'begin': 16.0, 'end': 17.0, 'id': 8.0, 'text': '신승일.', 'type': ''}]},\n",
       " {'NE': [{'begin': 0.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 1.0,\n",
       "    'id': 0.0,\n",
       "    'text': '특례시',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 6.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 7.0,\n",
       "    'id': 1.0,\n",
       "    'text': '105만',\n",
       "    'type': 'QT_MAN_COUNT',\n",
       "    'weight': 0.479627},\n",
       "   {'begin': 8.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 8.0,\n",
       "    'id': 2.0,\n",
       "    'text': '고양시',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.419784},\n",
       "   {'begin': 22.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 23.0,\n",
       "    'id': 3.0,\n",
       "    'text': '6명',\n",
       "    'type': 'QT_MAN_COUNT',\n",
       "    'weight': 0.73004},\n",
       "   {'begin': 25.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 26.0,\n",
       "    'id': 4.0,\n",
       "    'text': '공직자',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.602736},\n",
       "   {'begin': 28.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 29.0,\n",
       "    'id': 5.0,\n",
       "    'text': '서기관',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.500018}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 100.0,\n",
       "    'scode': '00',\n",
       "    'text': '특례',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 106.0,\n",
       "    'scode': '10',\n",
       "    'text': '시',\n",
       "    'type': 'NNB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 110.0,\n",
       "    'scode': '14',\n",
       "    'text': '지정',\n",
       "    'type': 'NNG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 116.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 120.0,\n",
       "    'scode': '00',\n",
       "    'text': '앞두',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 5.0,\n",
       "    'position': 123.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 6.0,\n",
       "    'position': 127.0,\n",
       "    'scode': '00',\n",
       "    'text': '105',\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 7.0,\n",
       "    'position': 130.0,\n",
       "    'scode': '06',\n",
       "    'text': '만',\n",
       "    'type': 'NR',\n",
       "    'weight': 3.5},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 8.0,\n",
       "    'position': 134.0,\n",
       "    'scode': '00',\n",
       "    'text': '고양시',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 9.0,\n",
       "    'position': 143.0,\n",
       "    'scode': '00',\n",
       "    'text': '의',\n",
       "    'type': 'JKG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 10.0,\n",
       "    'position': 147.0,\n",
       "    'scode': '01',\n",
       "    'text': '발전',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.83599},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 11.0,\n",
       "    'position': 153.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 12.0,\n",
       "    'position': 157.0,\n",
       "    'scode': '01',\n",
       "    'text': '위하',\n",
       "    'type': 'VV',\n",
       "    'weight': 6.6},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 13.0,\n",
       "    'position': 160.0,\n",
       "    'scode': '00',\n",
       "    'text': '어',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 14.0,\n",
       "    'position': 164.0,\n",
       "    'scode': '01',\n",
       "    'text': '땀',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.71667},\n",
       "   {'begin': 15.0,\n",
       "    'end': 15.0,\n",
       "    'id': 15.0,\n",
       "    'position': 167.0,\n",
       "    'scode': '00',\n",
       "    'text': '과',\n",
       "    'type': 'JC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 16.0,\n",
       "    'position': 171.0,\n",
       "    'scode': '02',\n",
       "    'text': '열정',\n",
       "    'type': 'NNG',\n",
       "    'weight': 4.4},\n",
       "   {'begin': 17.0,\n",
       "    'end': 17.0,\n",
       "    'id': 17.0,\n",
       "    'position': 177.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 18.0,\n",
       "    'end': 18.0,\n",
       "    'id': 18.0,\n",
       "    'position': 181.0,\n",
       "    'scode': '00',\n",
       "    'text': '쏟',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 19.0,\n",
       "    'end': 19.0,\n",
       "    'id': 19.0,\n",
       "    'position': 184.0,\n",
       "    'scode': '00',\n",
       "    'text': '아',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 20.0,\n",
       "    'position': 187.0,\n",
       "    'scode': '01',\n",
       "    'text': '오',\n",
       "    'type': 'VX',\n",
       "    'weight': 6.0},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 21.0,\n",
       "    'position': 187.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 22.0,\n",
       "    'end': 22.0,\n",
       "    'id': 22.0,\n",
       "    'position': 191.0,\n",
       "    'scode': '00',\n",
       "    'text': '6',\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 23.0,\n",
       "    'end': 23.0,\n",
       "    'id': 23.0,\n",
       "    'position': 192.0,\n",
       "    'scode': '03',\n",
       "    'text': '명',\n",
       "    'type': 'NNB',\n",
       "    'weight': 5.2},\n",
       "   {'begin': 24.0,\n",
       "    'end': 24.0,\n",
       "    'id': 24.0,\n",
       "    'position': 195.0,\n",
       "    'scode': '00',\n",
       "    'text': '의',\n",
       "    'type': 'JKG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 25.0,\n",
       "    'end': 26.0,\n",
       "    'id': 25.0,\n",
       "    'position': 199.0,\n",
       "    'scode': '00',\n",
       "    'text': '공직자',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 27.0,\n",
       "    'end': 27.0,\n",
       "    'id': 26.0,\n",
       "    'position': 208.0,\n",
       "    'scode': '00',\n",
       "    'text': '(',\n",
       "    'type': 'SS',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 28.0,\n",
       "    'end': 29.0,\n",
       "    'id': 27.0,\n",
       "    'position': 209.0,\n",
       "    'scode': '00',\n",
       "    'text': '서기관',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 30.0,\n",
       "    'end': 30.0,\n",
       "    'id': 28.0,\n",
       "    'position': 218.0,\n",
       "    'scode': '00',\n",
       "    'text': ')',\n",
       "    'type': 'SS',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 31.0,\n",
       "    'end': 31.0,\n",
       "    'id': 29.0,\n",
       "    'position': 219.0,\n",
       "    'scode': '09',\n",
       "    'text': '들',\n",
       "    'type': 'XSN',\n",
       "    'weight': 7.0},\n",
       "   {'begin': 32.0,\n",
       "    'end': 32.0,\n",
       "    'id': 30.0,\n",
       "    'position': 222.0,\n",
       "    'scode': '00',\n",
       "    'text': '이',\n",
       "    'type': 'JKS',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 33.0,\n",
       "    'end': 34.0,\n",
       "    'id': 31.0,\n",
       "    'position': 226.0,\n",
       "    'scode': '00',\n",
       "    'text': '아름답',\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 35.0,\n",
       "    'end': 35.0,\n",
       "    'id': 32.0,\n",
       "    'position': 235.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 36.0,\n",
       "    'end': 36.0,\n",
       "    'id': 33.0,\n",
       "    'position': 239.0,\n",
       "    'scode': '02',\n",
       "    'text': '퇴장',\n",
       "    'type': 'NNG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 37.0,\n",
       "    'end': 37.0,\n",
       "    'id': 34.0,\n",
       "    'position': 245.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 38.0,\n",
       "    'end': 38.0,\n",
       "    'id': 35.0,\n",
       "    'position': 249.0,\n",
       "    'scode': '00',\n",
       "    'text': '앞두',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 39.0,\n",
       "    'end': 39.0,\n",
       "    'id': 36.0,\n",
       "    'position': 255.0,\n",
       "    'scode': '00',\n",
       "    'text': '고',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 40.0,\n",
       "    'end': 40.0,\n",
       "    'id': 37.0,\n",
       "    'position': 259.0,\n",
       "    'scode': '01',\n",
       "    'text': '있',\n",
       "    'type': 'VX',\n",
       "    'weight': 3.2},\n",
       "   {'begin': 41.0,\n",
       "    'end': 41.0,\n",
       "    'id': 38.0,\n",
       "    'position': 262.0,\n",
       "    'scode': '00',\n",
       "    'text': '다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 42.0,\n",
       "    'end': 42.0,\n",
       "    'id': 39.0,\n",
       "    'position': 265.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 1.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '특례시',\n",
       "    'weight': 0.238887},\n",
       "   {'head': 2.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [0.0],\n",
       "    'text': '지정을',\n",
       "    'weight': 0.455433},\n",
       "   {'head': 4.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [1.0],\n",
       "    'text': '앞둔',\n",
       "    'weight': 0.326141},\n",
       "   {'head': 4.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '105만',\n",
       "    'weight': 0.512135},\n",
       "   {'head': 5.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'NP_MOD',\n",
       "    'mod': [2.0, 3.0],\n",
       "    'text': '고양시의',\n",
       "    'weight': 0.64694},\n",
       "   {'head': 6.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [4.0],\n",
       "    'text': '발전을',\n",
       "    'weight': 0.682906},\n",
       "   {'head': 9.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [5.0],\n",
       "    'text': '위해',\n",
       "    'weight': 0.625582},\n",
       "   {'head': 8.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'NP_CNJ',\n",
       "    'mod': [],\n",
       "    'text': '땀과',\n",
       "    'weight': 0.742481},\n",
       "   {'head': 9.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [7.0],\n",
       "    'text': '열정을',\n",
       "    'weight': 0.758713},\n",
       "   {'head': 11.0,\n",
       "    'id': 9.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [6.0, 8.0],\n",
       "    'text': '쏟아온',\n",
       "    'weight': 0.702712},\n",
       "   {'head': 11.0,\n",
       "    'id': 10.0,\n",
       "    'label': 'NP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '6명의',\n",
       "    'weight': 0.674267},\n",
       "   {'head': 14.0,\n",
       "    'id': 11.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [9.0, 10.0],\n",
       "    'text': '공직자(서기관)들이',\n",
       "    'weight': 0.726809},\n",
       "   {'head': 13.0,\n",
       "    'id': 12.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '아름다운',\n",
       "    'weight': 0.689657},\n",
       "   {'head': 14.0,\n",
       "    'id': 13.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [12.0],\n",
       "    'text': '퇴장을',\n",
       "    'weight': 0.683548},\n",
       "   {'head': 15.0,\n",
       "    'id': 14.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [11.0, 13.0],\n",
       "    'text': '앞두고',\n",
       "    'weight': 0.687865},\n",
       "   {'head': -1.0,\n",
       "    'id': 15.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [14.0],\n",
       "    'text': '있다.',\n",
       "    'weight': 0.00025235}],\n",
       "  'id': 1.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '특례',\n",
       "    'position': 100.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0940307},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '시',\n",
       "    'position': 106.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.0185931},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '지정',\n",
       "    'position': 110.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0952375},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '을',\n",
       "    'position': 116.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0929647},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '앞두',\n",
       "    'position': 120.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0739523},\n",
       "   {'id': 5.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 123.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0446133},\n",
       "   {'id': 6.0, 'lemma': '105', 'position': 127.0, 'type': 'SN', 'weight': 1.0},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '만',\n",
       "    'position': 130.0,\n",
       "    'type': 'NR',\n",
       "    'weight': 0.0390491},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '고양시',\n",
       "    'position': 134.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0573831},\n",
       "   {'id': 9.0,\n",
       "    'lemma': '의',\n",
       "    'position': 143.0,\n",
       "    'type': 'JKG',\n",
       "    'weight': 0.0806884},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '발전',\n",
       "    'position': 147.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0873932},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '을',\n",
       "    'position': 153.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0953326},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '위하',\n",
       "    'position': 157.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.114276},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '어',\n",
       "    'position': 160.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0954842},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '땀',\n",
       "    'position': 164.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0578831},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '과',\n",
       "    'position': 167.0,\n",
       "    'type': 'JC',\n",
       "    'weight': 0.06294},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '열정',\n",
       "    'position': 171.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0715766},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '을',\n",
       "    'position': 177.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0892933},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '쏟',\n",
       "    'position': 181.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.101958},\n",
       "   {'id': 19.0,\n",
       "    'lemma': '아',\n",
       "    'position': 184.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0528974},\n",
       "   {'id': 20.0,\n",
       "    'lemma': '오',\n",
       "    'position': 187.0,\n",
       "    'type': 'VX',\n",
       "    'weight': 0.0262734},\n",
       "   {'id': 21.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 187.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0262734},\n",
       "   {'id': 22.0, 'lemma': '6', 'position': 191.0, 'type': 'SN', 'weight': 1.0},\n",
       "   {'id': 23.0,\n",
       "    'lemma': '명',\n",
       "    'position': 192.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.0733494},\n",
       "   {'id': 24.0,\n",
       "    'lemma': '의',\n",
       "    'position': 195.0,\n",
       "    'type': 'JKG',\n",
       "    'weight': 0.108658},\n",
       "   {'id': 25.0,\n",
       "    'lemma': '공직',\n",
       "    'position': 199.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.12325},\n",
       "   {'id': 26.0,\n",
       "    'lemma': '자',\n",
       "    'position': 205.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.12325},\n",
       "   {'id': 27.0, 'lemma': '(', 'position': 208.0, 'type': 'SS', 'weight': 1.0},\n",
       "   {'id': 28.0,\n",
       "    'lemma': '서기',\n",
       "    'position': 209.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0804729},\n",
       "   {'id': 29.0,\n",
       "    'lemma': '관',\n",
       "    'position': 215.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0804729},\n",
       "   {'id': 30.0, 'lemma': ')', 'position': 218.0, 'type': 'SS', 'weight': 1.0},\n",
       "   {'id': 31.0,\n",
       "    'lemma': '들',\n",
       "    'position': 219.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0962877},\n",
       "   {'id': 32.0,\n",
       "    'lemma': '이',\n",
       "    'position': 222.0,\n",
       "    'type': 'JKS',\n",
       "    'weight': 0.0558637},\n",
       "   {'id': 33.0,\n",
       "    'lemma': '아름',\n",
       "    'position': 226.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0653759},\n",
       "   {'id': 34.0,\n",
       "    'lemma': '답',\n",
       "    'position': 232.0,\n",
       "    'type': 'XSA',\n",
       "    'weight': 0.0653759},\n",
       "   {'id': 35.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 235.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0563553},\n",
       "   {'id': 36.0,\n",
       "    'lemma': '퇴장',\n",
       "    'position': 239.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.150974},\n",
       "   {'id': 37.0,\n",
       "    'lemma': '을',\n",
       "    'position': 245.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.10161},\n",
       "   {'id': 38.0,\n",
       "    'lemma': '앞두',\n",
       "    'position': 249.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0777981},\n",
       "   {'id': 39.0,\n",
       "    'lemma': '고',\n",
       "    'position': 255.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.141023},\n",
       "   {'id': 40.0,\n",
       "    'lemma': '있',\n",
       "    'position': 259.0,\n",
       "    'type': 'VX',\n",
       "    'weight': 0.104292},\n",
       "   {'id': 41.0,\n",
       "    'lemma': '다',\n",
       "    'position': 262.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0991963},\n",
       "   {'id': 42.0, 'lemma': '.', 'position': 265.0, 'type': 'SF', 'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': ' 특례시 지정을 앞둔 105만 고양시의 발전을 위해 땀과 열정을 쏟아온 6명의 공직자(서기관)들이 아름다운 퇴장을 앞두고 있다.',\n",
       "  'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '특례시', 'type': ''},\n",
       "   {'begin': 2.0, 'end': 3.0, 'id': 1.0, 'text': '지정을', 'type': ''},\n",
       "   {'begin': 4.0, 'end': 5.0, 'id': 2.0, 'text': '앞둔', 'type': ''},\n",
       "   {'begin': 6.0, 'end': 7.0, 'id': 3.0, 'text': '105만', 'type': ''},\n",
       "   {'begin': 8.0, 'end': 9.0, 'id': 4.0, 'text': '고양시의', 'type': ''},\n",
       "   {'begin': 10.0, 'end': 11.0, 'id': 5.0, 'text': '발전을', 'type': ''},\n",
       "   {'begin': 12.0, 'end': 13.0, 'id': 6.0, 'text': '위해', 'type': ''},\n",
       "   {'begin': 14.0, 'end': 15.0, 'id': 7.0, 'text': '땀과', 'type': ''},\n",
       "   {'begin': 16.0, 'end': 17.0, 'id': 8.0, 'text': '열정을', 'type': ''},\n",
       "   {'begin': 18.0, 'end': 21.0, 'id': 9.0, 'text': '쏟아온', 'type': ''},\n",
       "   {'begin': 22.0, 'end': 24.0, 'id': 10.0, 'text': '6명의', 'type': ''},\n",
       "   {'begin': 25.0, 'end': 32.0, 'id': 11.0, 'text': '공직자(서기관)들이', 'type': ''},\n",
       "   {'begin': 33.0, 'end': 35.0, 'id': 12.0, 'text': '아름다운', 'type': ''},\n",
       "   {'begin': 36.0, 'end': 37.0, 'id': 13.0, 'text': '퇴장을', 'type': ''},\n",
       "   {'begin': 38.0, 'end': 39.0, 'id': 14.0, 'text': '앞두고', 'type': ''},\n",
       "   {'begin': 40.0, 'end': 42.0, 'id': 15.0, 'text': '있다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 0.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 1.0,\n",
       "    'id': 0.0,\n",
       "    'text': '경기북부',\n",
       "    'type': 'LCP_PROVINCE',\n",
       "    'weight': 0.167595},\n",
       "   {'begin': 7.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 7.0,\n",
       "    'id': 1.0,\n",
       "    'text': '고양시',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.333063},\n",
       "   {'begin': 21.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 21.0,\n",
       "    'id': 2.0,\n",
       "    'text': '후배',\n",
       "    'type': 'CV_RELATION',\n",
       "    'weight': 0.538012},\n",
       "   {'begin': 29.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 30.0,\n",
       "    'id': 3.0,\n",
       "    'text': '2막',\n",
       "    'type': 'QT_COUNT',\n",
       "    'weight': 0.402024}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 267.0,\n",
       "    'scode': '02',\n",
       "    'text': '경기',\n",
       "    'type': 'NNP',\n",
       "    'weight': 7.7},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 273.0,\n",
       "    'scode': '01',\n",
       "    'text': '북부',\n",
       "    'type': 'NNG',\n",
       "    'weight': 9.7},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 279.0,\n",
       "    'scode': '00',\n",
       "    'text': '의',\n",
       "    'type': 'JKG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 283.0,\n",
       "    'scode': '01',\n",
       "    'text': '중심',\n",
       "    'type': 'NNG',\n",
       "    'weight': 10.6798},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 289.0,\n",
       "    'scode': '03',\n",
       "    'text': '도시',\n",
       "    'type': 'NNG',\n",
       "    'weight': 9.4},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 5.0,\n",
       "    'position': 295.0,\n",
       "    'scode': '01',\n",
       "    'text': '이',\n",
       "    'type': 'VCP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 6.0,\n",
       "    'position': 295.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 7.0,\n",
       "    'position': 299.0,\n",
       "    'scode': '00',\n",
       "    'text': '고양시',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 8.0,\n",
       "    'position': 308.0,\n",
       "    'scode': '00',\n",
       "    'text': '가',\n",
       "    'type': 'JKC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 9.0,\n",
       "    'position': 312.0,\n",
       "    'scode': '01',\n",
       "    'text': '되',\n",
       "    'type': 'VV',\n",
       "    'weight': 7.6},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 10.0,\n",
       "    'position': 315.0,\n",
       "    'scode': '00',\n",
       "    'text': '기',\n",
       "    'type': 'ETN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 11.0,\n",
       "    'position': 318.0,\n",
       "    'scode': '00',\n",
       "    'text': '까지',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 12.0,\n",
       "    'position': 325.0,\n",
       "    'scode': '00',\n",
       "    'text': '쉼',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 13.0,\n",
       "    'position': 328.0,\n",
       "    'scode': '00',\n",
       "    'text': '없이',\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 14.0,\n",
       "    'position': 335.0,\n",
       "    'scode': '00',\n",
       "    'text': '달려오',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 15.0,\n",
       "    'end': 15.0,\n",
       "    'id': 15.0,\n",
       "    'position': 341.0,\n",
       "    'scode': '00',\n",
       "    'text': '았',\n",
       "    'type': 'EP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 16.0,\n",
       "    'position': 344.0,\n",
       "    'scode': '00',\n",
       "    'text': '던',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 17.0,\n",
       "    'end': 17.0,\n",
       "    'id': 17.0,\n",
       "    'position': 348.0,\n",
       "    'scode': '05',\n",
       "    'text': '이',\n",
       "    'type': 'NP',\n",
       "    'weight': 5.2},\n",
       "   {'begin': 18.0,\n",
       "    'end': 18.0,\n",
       "    'id': 18.0,\n",
       "    'position': 351.0,\n",
       "    'scode': '09',\n",
       "    'text': '들',\n",
       "    'type': 'XSN',\n",
       "    'weight': 4.0},\n",
       "   {'begin': 19.0,\n",
       "    'end': 19.0,\n",
       "    'id': 19.0,\n",
       "    'position': 354.0,\n",
       "    'scode': '00',\n",
       "    'text': '은',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 20.0,\n",
       "    'position': 358.0,\n",
       "    'scode': '01',\n",
       "    'text': '이제',\n",
       "    'type': 'MAG',\n",
       "    'weight': 5.4},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 21.0,\n",
       "    'position': 365.0,\n",
       "    'scode': '06',\n",
       "    'text': '후배',\n",
       "    'type': 'NNG',\n",
       "    'weight': 4.2},\n",
       "   {'begin': 22.0,\n",
       "    'end': 22.0,\n",
       "    'id': 22.0,\n",
       "    'position': 371.0,\n",
       "    'scode': '09',\n",
       "    'text': '들',\n",
       "    'type': 'XSN',\n",
       "    'weight': 5.0},\n",
       "   {'begin': 23.0,\n",
       "    'end': 23.0,\n",
       "    'id': 23.0,\n",
       "    'position': 374.0,\n",
       "    'scode': '00',\n",
       "    'text': '에게',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 24.0,\n",
       "    'end': 24.0,\n",
       "    'id': 24.0,\n",
       "    'position': 381.0,\n",
       "    'scode': '01',\n",
       "    'text': '자리',\n",
       "    'type': 'NNG',\n",
       "    'weight': 7.54444},\n",
       "   {'begin': 25.0,\n",
       "    'end': 25.0,\n",
       "    'id': 25.0,\n",
       "    'position': 387.0,\n",
       "    'scode': '00',\n",
       "    'text': '를',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 26.0,\n",
       "    'end': 26.0,\n",
       "    'id': 26.0,\n",
       "    'position': 391.0,\n",
       "    'scode': '00',\n",
       "    'text': '물려주',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 27.0,\n",
       "    'end': 27.0,\n",
       "    'id': 27.0,\n",
       "    'position': 400.0,\n",
       "    'scode': '00',\n",
       "    'text': '고',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 28.0,\n",
       "    'end': 28.0,\n",
       "    'id': 28.0,\n",
       "    'position': 404.0,\n",
       "    'scode': '01',\n",
       "    'text': '인생',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 29.0,\n",
       "    'end': 29.0,\n",
       "    'id': 29.0,\n",
       "    'position': 411.0,\n",
       "    'scode': '00',\n",
       "    'text': '2',\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 30.0,\n",
       "    'end': 30.0,\n",
       "    'id': 30.0,\n",
       "    'position': 412.0,\n",
       "    'scode': '05',\n",
       "    'text': '막',\n",
       "    'type': 'NNB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 31.0,\n",
       "    'end': 31.0,\n",
       "    'id': 31.0,\n",
       "    'position': 415.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 32.0,\n",
       "    'end': 32.0,\n",
       "    'id': 32.0,\n",
       "    'position': 419.0,\n",
       "    'scode': '00',\n",
       "    'text': '준비',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 33.0,\n",
       "    'end': 33.0,\n",
       "    'id': 33.0,\n",
       "    'position': 426.0,\n",
       "    'scode': '04',\n",
       "    'text': '중',\n",
       "    'type': 'NNB',\n",
       "    'weight': 2.2},\n",
       "   {'begin': 34.0,\n",
       "    'end': 34.0,\n",
       "    'id': 34.0,\n",
       "    'position': 429.0,\n",
       "    'scode': '01',\n",
       "    'text': '이',\n",
       "    'type': 'VCP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 35.0,\n",
       "    'end': 35.0,\n",
       "    'id': 35.0,\n",
       "    'position': 432.0,\n",
       "    'scode': '00',\n",
       "    'text': '다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 36.0,\n",
       "    'end': 36.0,\n",
       "    'id': 36.0,\n",
       "    'position': 435.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 1.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '경기북부의',\n",
       "    'weight': 0.255136},\n",
       "   {'head': 2.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'VNP_MOD',\n",
       "    'mod': [0.0],\n",
       "    'text': '중심도시인',\n",
       "    'weight': 0.435945},\n",
       "   {'head': 3.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'NP_CMP',\n",
       "    'mod': [1.0],\n",
       "    'text': '고양시가',\n",
       "    'weight': 0.477354},\n",
       "   {'head': 10.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [2.0],\n",
       "    'text': '되기까지',\n",
       "    'weight': 0.085665},\n",
       "   {'head': 5.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'AP',\n",
       "    'mod': [],\n",
       "    'text': '쉼없이',\n",
       "    'weight': 0.24795},\n",
       "   {'head': 6.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [4.0],\n",
       "    'text': '달려왔던',\n",
       "    'weight': 0.642505},\n",
       "   {'head': 10.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [5.0],\n",
       "    'text': '이들은',\n",
       "    'weight': 0.582525},\n",
       "   {'head': 10.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'AP',\n",
       "    'mod': [],\n",
       "    'text': '이제',\n",
       "    'weight': 0.702037},\n",
       "   {'head': 10.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '후배들에게',\n",
       "    'weight': 0.688299},\n",
       "   {'head': 10.0,\n",
       "    'id': 9.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [],\n",
       "    'text': '자리를',\n",
       "    'weight': 0.586633},\n",
       "   {'head': 14.0,\n",
       "    'id': 10.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [3.0, 6.0, 7.0, 8.0, 9.0],\n",
       "    'text': '물려주고',\n",
       "    'weight': 0.853554},\n",
       "   {'head': 12.0,\n",
       "    'id': 11.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '인생',\n",
       "    'weight': 0.552956},\n",
       "   {'head': 14.0,\n",
       "    'id': 12.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [11.0],\n",
       "    'text': '2막을',\n",
       "    'weight': 0.786685},\n",
       "   {'head': 14.0,\n",
       "    'id': 13.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '준비',\n",
       "    'weight': 0.478475},\n",
       "   {'head': -1.0,\n",
       "    'id': 14.0,\n",
       "    'label': 'VNP',\n",
       "    'mod': [10.0, 12.0, 13.0],\n",
       "    'text': '중이다.',\n",
       "    'weight': 1.71678e-05}],\n",
       "  'id': 2.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '경기',\n",
       "    'position': 267.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0735863},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '북부',\n",
       "    'position': 273.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0486974},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '의',\n",
       "    'position': 279.0,\n",
       "    'type': 'JKG',\n",
       "    'weight': 0.155895},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '중심',\n",
       "    'position': 283.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0756438},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '도시',\n",
       "    'position': 289.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0393359},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '이',\n",
       "    'position': 295.0,\n",
       "    'type': 'VCP',\n",
       "    'weight': 0.0651511},\n",
       "   {'id': 6.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 295.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0651511},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '고양시',\n",
       "    'position': 299.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0692494},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '가',\n",
       "    'position': 308.0,\n",
       "    'type': 'JKC',\n",
       "    'weight': 0.121098},\n",
       "   {'id': 9.0,\n",
       "    'lemma': '되',\n",
       "    'position': 312.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.105734},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '기',\n",
       "    'position': 315.0,\n",
       "    'type': 'ETN',\n",
       "    'weight': 0.0789256},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '까지',\n",
       "    'position': 318.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.07388},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '쉼',\n",
       "    'position': 325.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0343709},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '없이',\n",
       "    'position': 328.0,\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0502394},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '달려오',\n",
       "    'position': 335.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0599902},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '았',\n",
       "    'position': 341.0,\n",
       "    'type': 'EP',\n",
       "    'weight': 0.043681},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '던',\n",
       "    'position': 344.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.10417},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '이',\n",
       "    'position': 348.0,\n",
       "    'type': 'NP',\n",
       "    'weight': 0.096199},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '들',\n",
       "    'position': 351.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0765447},\n",
       "   {'id': 19.0,\n",
       "    'lemma': '은',\n",
       "    'position': 354.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.118022},\n",
       "   {'id': 20.0,\n",
       "    'lemma': '이제',\n",
       "    'position': 358.0,\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0946292},\n",
       "   {'id': 21.0,\n",
       "    'lemma': '후배',\n",
       "    'position': 365.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0646672},\n",
       "   {'id': 22.0,\n",
       "    'lemma': '들',\n",
       "    'position': 371.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0727001},\n",
       "   {'id': 23.0,\n",
       "    'lemma': '에게',\n",
       "    'position': 374.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0756487},\n",
       "   {'id': 24.0,\n",
       "    'lemma': '자리',\n",
       "    'position': 381.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.116745},\n",
       "   {'id': 25.0,\n",
       "    'lemma': '를',\n",
       "    'position': 387.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.138704},\n",
       "   {'id': 26.0,\n",
       "    'lemma': '물려주',\n",
       "    'position': 391.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0625751},\n",
       "   {'id': 27.0,\n",
       "    'lemma': '고',\n",
       "    'position': 400.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0747157},\n",
       "   {'id': 28.0,\n",
       "    'lemma': '인생',\n",
       "    'position': 404.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0857949},\n",
       "   {'id': 29.0, 'lemma': '2', 'position': 411.0, 'type': 'SN', 'weight': 1.0},\n",
       "   {'id': 30.0,\n",
       "    'lemma': '막',\n",
       "    'position': 412.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.0385147},\n",
       "   {'id': 31.0,\n",
       "    'lemma': '을',\n",
       "    'position': 415.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0758765},\n",
       "   {'id': 32.0,\n",
       "    'lemma': '준비',\n",
       "    'position': 419.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0843675},\n",
       "   {'id': 33.0,\n",
       "    'lemma': '중',\n",
       "    'position': 426.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.110531},\n",
       "   {'id': 34.0,\n",
       "    'lemma': '이',\n",
       "    'position': 429.0,\n",
       "    'type': 'VCP',\n",
       "    'weight': 0.0740337},\n",
       "   {'id': 35.0,\n",
       "    'lemma': '다',\n",
       "    'position': 432.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0782521},\n",
       "   {'id': 36.0, 'lemma': '.', 'position': 435.0, 'type': 'SF', 'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': ' 경기북부의 중심도시인 고양시가 되기까지 쉼없이 달려왔던 이들은 이제 후배들에게 자리를 물려주고 인생 2막을 준비 중이다.',\n",
       "  'word': [{'begin': 0.0, 'end': 2.0, 'id': 0.0, 'text': '경기북부의', 'type': ''},\n",
       "   {'begin': 3.0, 'end': 6.0, 'id': 1.0, 'text': '중심도시인', 'type': ''},\n",
       "   {'begin': 7.0, 'end': 8.0, 'id': 2.0, 'text': '고양시가', 'type': ''},\n",
       "   {'begin': 9.0, 'end': 11.0, 'id': 3.0, 'text': '되기까지', 'type': ''},\n",
       "   {'begin': 12.0, 'end': 13.0, 'id': 4.0, 'text': '쉼없이', 'type': ''},\n",
       "   {'begin': 14.0, 'end': 16.0, 'id': 5.0, 'text': '달려왔던', 'type': ''},\n",
       "   {'begin': 17.0, 'end': 19.0, 'id': 6.0, 'text': '이들은', 'type': ''},\n",
       "   {'begin': 20.0, 'end': 20.0, 'id': 7.0, 'text': '이제', 'type': ''},\n",
       "   {'begin': 21.0, 'end': 23.0, 'id': 8.0, 'text': '후배들에게', 'type': ''},\n",
       "   {'begin': 24.0, 'end': 25.0, 'id': 9.0, 'text': '자리를', 'type': ''},\n",
       "   {'begin': 26.0, 'end': 27.0, 'id': 10.0, 'text': '물려주고', 'type': ''},\n",
       "   {'begin': 28.0, 'end': 28.0, 'id': 11.0, 'text': '인생', 'type': ''},\n",
       "   {'begin': 29.0, 'end': 31.0, 'id': 12.0, 'text': '2막을', 'type': ''},\n",
       "   {'begin': 32.0, 'end': 32.0, 'id': 13.0, 'text': '준비', 'type': ''},\n",
       "   {'begin': 33.0, 'end': 36.0, 'id': 14.0, 'text': '중이다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 0.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'text': '김운용',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.64914},\n",
       "   {'begin': 1.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'text': '고양시',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.473747},\n",
       "   {'begin': 2.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 5.0,\n",
       "    'id': 2.0,\n",
       "    'text': '푸른도시사업소장',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.113445},\n",
       "   {'begin': 7.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 8.0,\n",
       "    'id': 3.0,\n",
       "    'text': '1983년',\n",
       "    'type': 'DT_YEAR',\n",
       "    'weight': 0.819285},\n",
       "   {'begin': 14.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 14.0,\n",
       "    'id': 4.0,\n",
       "    'text': '고양시',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.408767}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 437.0,\n",
       "    'scode': '00',\n",
       "    'text': '김운용',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 447.0,\n",
       "    'scode': '00',\n",
       "    'text': '고양시',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 457.0,\n",
       "    'scode': '00',\n",
       "    'text': '푸른',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 463.0,\n",
       "    'scode': '03',\n",
       "    'text': '도시',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 469.0,\n",
       "    'scode': '04',\n",
       "    'text': '사업',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 5.0,\n",
       "    'position': 475.0,\n",
       "    'scode': '08',\n",
       "    'text': '소장',\n",
       "    'type': 'NNG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 6.0,\n",
       "    'position': 481.0,\n",
       "    'scode': '00',\n",
       "    'text': '은',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 7.0,\n",
       "    'position': 485.0,\n",
       "    'scode': '00',\n",
       "    'text': '1983',\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 8.0,\n",
       "    'position': 489.0,\n",
       "    'scode': '02',\n",
       "    'text': '년',\n",
       "    'type': 'NNB',\n",
       "    'weight': 11.3},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 9.0,\n",
       "    'position': 493.0,\n",
       "    'scode': '02',\n",
       "    'text': '공직',\n",
       "    'type': 'NNG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 10.0,\n",
       "    'position': 499.0,\n",
       "    'scode': '00',\n",
       "    'text': '에',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 12.0,\n",
       "    'id': 11.0,\n",
       "    'position': 503.0,\n",
       "    'scode': '01',\n",
       "    'text': '입문하',\n",
       "    'type': 'VV',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 12.0,\n",
       "    'position': 509.0,\n",
       "    'scode': '00',\n",
       "    'text': '어',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 13.0,\n",
       "    'position': 513.0,\n",
       "    'scode': '00',\n",
       "    'text': '고양시',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 15.0,\n",
       "    'end': 15.0,\n",
       "    'id': 14.0,\n",
       "    'position': 522.0,\n",
       "    'scode': '00',\n",
       "    'text': '가',\n",
       "    'type': 'JKS',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 15.0,\n",
       "    'position': 526.0,\n",
       "    'scode': '01',\n",
       "    'text': '자연',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.2},\n",
       "   {'begin': 17.0,\n",
       "    'end': 17.0,\n",
       "    'id': 16.0,\n",
       "    'position': 532.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 18.0,\n",
       "    'end': 18.0,\n",
       "    'id': 17.0,\n",
       "    'position': 536.0,\n",
       "    'scode': '01',\n",
       "    'text': '품',\n",
       "    'type': 'VV',\n",
       "    'weight': 4.2},\n",
       "   {'begin': 19.0,\n",
       "    'end': 19.0,\n",
       "    'id': 18.0,\n",
       "    'position': 539.0,\n",
       "    'scode': '00',\n",
       "    'text': '은',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 19.0,\n",
       "    'position': 543.0,\n",
       "    'scode': '03',\n",
       "    'text': '도시',\n",
       "    'type': 'NNG',\n",
       "    'weight': 5.9},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 20.0,\n",
       "    'position': 549.0,\n",
       "    'scode': '00',\n",
       "    'text': '가',\n",
       "    'type': 'JKC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 22.0,\n",
       "    'end': 22.0,\n",
       "    'id': 21.0,\n",
       "    'position': 553.0,\n",
       "    'scode': '01',\n",
       "    'text': '되',\n",
       "    'type': 'VV',\n",
       "    'weight': 7.6},\n",
       "   {'begin': 23.0,\n",
       "    'end': 23.0,\n",
       "    'id': 22.0,\n",
       "    'position': 553.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄹ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 24.0,\n",
       "    'end': 24.0,\n",
       "    'id': 23.0,\n",
       "    'position': 557.0,\n",
       "    'scode': '02',\n",
       "    'text': '수',\n",
       "    'type': 'NNB',\n",
       "    'weight': 7.59923},\n",
       "   {'begin': 25.0,\n",
       "    'end': 25.0,\n",
       "    'id': 24.0,\n",
       "    'position': 561.0,\n",
       "    'scode': '01',\n",
       "    'text': '있',\n",
       "    'type': 'VA',\n",
       "    'weight': 7.6},\n",
       "   {'begin': 26.0,\n",
       "    'end': 26.0,\n",
       "    'id': 25.0,\n",
       "    'position': 564.0,\n",
       "    'scode': '00',\n",
       "    'text': '도록',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 27.0,\n",
       "    'end': 27.0,\n",
       "    'id': 26.0,\n",
       "    'position': 571.0,\n",
       "    'scode': '00',\n",
       "    'text': '많',\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 28.0,\n",
       "    'end': 28.0,\n",
       "    'id': 27.0,\n",
       "    'position': 574.0,\n",
       "    'scode': '00',\n",
       "    'text': '은',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 29.0,\n",
       "    'end': 29.0,\n",
       "    'id': 28.0,\n",
       "    'position': 578.0,\n",
       "    'scode': '03',\n",
       "    'text': '연구',\n",
       "    'type': 'NNG',\n",
       "    'weight': 8.1},\n",
       "   {'begin': 30.0,\n",
       "    'end': 30.0,\n",
       "    'id': 29.0,\n",
       "    'position': 584.0,\n",
       "    'scode': '00',\n",
       "    'text': '와',\n",
       "    'type': 'JC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 31.0,\n",
       "    'end': 31.0,\n",
       "    'id': 30.0,\n",
       "    'position': 588.0,\n",
       "    'scode': '01',\n",
       "    'text': '노력',\n",
       "    'type': 'NNG',\n",
       "    'weight': 5.4},\n",
       "   {'begin': 32.0,\n",
       "    'end': 32.0,\n",
       "    'id': 31.0,\n",
       "    'position': 594.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 33.0,\n",
       "    'end': 33.0,\n",
       "    'id': 32.0,\n",
       "    'position': 598.0,\n",
       "    'scode': '00',\n",
       "    'text': '기울이',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 34.0,\n",
       "    'end': 34.0,\n",
       "    'id': 33.0,\n",
       "    'position': 604.0,\n",
       "    'scode': '00',\n",
       "    'text': '어',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 35.0,\n",
       "    'end': 35.0,\n",
       "    'id': 34.0,\n",
       "    'position': 607.0,\n",
       "    'scode': '01',\n",
       "    'text': '오',\n",
       "    'type': 'VX',\n",
       "    'weight': 5.2},\n",
       "   {'begin': 36.0,\n",
       "    'end': 36.0,\n",
       "    'id': 35.0,\n",
       "    'position': 607.0,\n",
       "    'scode': '00',\n",
       "    'text': '았',\n",
       "    'type': 'EP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 37.0,\n",
       "    'end': 37.0,\n",
       "    'id': 36.0,\n",
       "    'position': 610.0,\n",
       "    'scode': '00',\n",
       "    'text': '다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 38.0,\n",
       "    'end': 38.0,\n",
       "    'id': 37.0,\n",
       "    'position': 613.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 1.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '김운용',\n",
       "    'weight': 0.189354},\n",
       "   {'head': 2.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [0.0],\n",
       "    'text': '고양시',\n",
       "    'weight': 0.450608},\n",
       "   {'head': 10.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [1.0],\n",
       "    'text': '푸른도시사업소장은',\n",
       "    'weight': 0.242854},\n",
       "   {'head': 5.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '1983년',\n",
       "    'weight': 0.476616},\n",
       "   {'head': 5.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '공직에',\n",
       "    'weight': 0.60747},\n",
       "   {'head': 10.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [3.0, 4.0],\n",
       "    'text': '입문해',\n",
       "    'weight': 0.831563},\n",
       "   {'head': 10.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [],\n",
       "    'text': '고양시가',\n",
       "    'weight': 0.837649},\n",
       "   {'head': 8.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [],\n",
       "    'text': '자연을',\n",
       "    'weight': 0.756616},\n",
       "   {'head': 9.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [7.0],\n",
       "    'text': '품은',\n",
       "    'weight': 0.591793},\n",
       "   {'head': 10.0,\n",
       "    'id': 9.0,\n",
       "    'label': 'NP_CMP',\n",
       "    'mod': [8.0],\n",
       "    'text': '도시가',\n",
       "    'weight': 0.553355},\n",
       "   {'head': 11.0,\n",
       "    'id': 10.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [2.0, 5.0, 6.0, 9.0],\n",
       "    'text': '될',\n",
       "    'weight': 0.722573},\n",
       "   {'head': 12.0,\n",
       "    'id': 11.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [10.0],\n",
       "    'text': '수',\n",
       "    'weight': 0.582944},\n",
       "   {'head': 16.0,\n",
       "    'id': 12.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [11.0],\n",
       "    'text': '있도록',\n",
       "    'weight': 0.54814},\n",
       "   {'head': 15.0,\n",
       "    'id': 13.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '많은',\n",
       "    'weight': 0.656456},\n",
       "   {'head': 15.0,\n",
       "    'id': 14.0,\n",
       "    'label': 'NP_CNJ',\n",
       "    'mod': [],\n",
       "    'text': '연구와',\n",
       "    'weight': 0.727066},\n",
       "   {'head': 16.0,\n",
       "    'id': 15.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [13.0, 14.0],\n",
       "    'text': '노력을',\n",
       "    'weight': 0.687592},\n",
       "   {'head': -1.0,\n",
       "    'id': 16.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [12.0, 15.0],\n",
       "    'text': '기울여왔다.',\n",
       "    'weight': 5.64663e-05}],\n",
       "  'id': 3.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '김운용',\n",
       "    'position': 437.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0748456},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '고양시',\n",
       "    'position': 447.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0527326},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '푸른',\n",
       "    'position': 457.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0312592},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '도시',\n",
       "    'position': 463.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0278652},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '사업',\n",
       "    'position': 469.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0805918},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '소장',\n",
       "    'position': 475.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0448367},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '은',\n",
       "    'position': 481.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.0970794},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '1983',\n",
       "    'position': 485.0,\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '년',\n",
       "    'position': 489.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.065533},\n",
       "   {'id': 9.0,\n",
       "    'lemma': '공직',\n",
       "    'position': 493.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0861151},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '에',\n",
       "    'position': 499.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0898719},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '입문',\n",
       "    'position': 503.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0992509},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '하',\n",
       "    'position': 509.0,\n",
       "    'type': 'XSV',\n",
       "    'weight': 0.0402947},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '어',\n",
       "    'position': 509.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0402947},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '고양시',\n",
       "    'position': 513.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0539177},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '가',\n",
       "    'position': 522.0,\n",
       "    'type': 'JKS',\n",
       "    'weight': 0.0965236},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '자연',\n",
       "    'position': 526.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.087804},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '을',\n",
       "    'position': 532.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0885779},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '품',\n",
       "    'position': 536.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.106293},\n",
       "   {'id': 19.0,\n",
       "    'lemma': '은',\n",
       "    'position': 539.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0620383},\n",
       "   {'id': 20.0,\n",
       "    'lemma': '도시',\n",
       "    'position': 543.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0983781},\n",
       "   {'id': 21.0,\n",
       "    'lemma': '가',\n",
       "    'position': 549.0,\n",
       "    'type': 'JKC',\n",
       "    'weight': 0.102474},\n",
       "   {'id': 22.0,\n",
       "    'lemma': '되',\n",
       "    'position': 553.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.126803},\n",
       "   {'id': 23.0,\n",
       "    'lemma': 'ㄹ',\n",
       "    'position': 553.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.126803},\n",
       "   {'id': 24.0,\n",
       "    'lemma': '수',\n",
       "    'position': 557.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.190736},\n",
       "   {'id': 25.0,\n",
       "    'lemma': '있',\n",
       "    'position': 561.0,\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0969874},\n",
       "   {'id': 26.0,\n",
       "    'lemma': '도록',\n",
       "    'position': 564.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0989595},\n",
       "   {'id': 27.0,\n",
       "    'lemma': '많',\n",
       "    'position': 571.0,\n",
       "    'type': 'VA',\n",
       "    'weight': 0.164127},\n",
       "   {'id': 28.0,\n",
       "    'lemma': '은',\n",
       "    'position': 574.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0971838},\n",
       "   {'id': 29.0,\n",
       "    'lemma': '연구',\n",
       "    'position': 578.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.140999},\n",
       "   {'id': 30.0,\n",
       "    'lemma': '와',\n",
       "    'position': 584.0,\n",
       "    'type': 'JC',\n",
       "    'weight': 0.057918},\n",
       "   {'id': 31.0,\n",
       "    'lemma': '노력',\n",
       "    'position': 588.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0697194},\n",
       "   {'id': 32.0,\n",
       "    'lemma': '을',\n",
       "    'position': 594.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0844299},\n",
       "   {'id': 33.0,\n",
       "    'lemma': '기울이',\n",
       "    'position': 598.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0474764},\n",
       "   {'id': 34.0,\n",
       "    'lemma': '어',\n",
       "    'position': 604.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0245038},\n",
       "   {'id': 35.0,\n",
       "    'lemma': '오',\n",
       "    'position': 607.0,\n",
       "    'type': 'VX',\n",
       "    'weight': 0.0245038},\n",
       "   {'id': 36.0,\n",
       "    'lemma': '았',\n",
       "    'position': 607.0,\n",
       "    'type': 'EP',\n",
       "    'weight': 0.0245038},\n",
       "   {'id': 37.0,\n",
       "    'lemma': '다',\n",
       "    'position': 610.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0808567},\n",
       "   {'id': 38.0, 'lemma': '.', 'position': 613.0, 'type': 'SF', 'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': ' 김운용 고양시 푸른도시사업소장은 1983년 공직에 입문해 고양시가 자연을 품은 도시가 될 수 있도록 많은 연구와 노력을 기울여왔다.',\n",
       "  'word': [{'begin': 0.0, 'end': 0.0, 'id': 0.0, 'text': '김운용', 'type': ''},\n",
       "   {'begin': 1.0, 'end': 1.0, 'id': 1.0, 'text': '고양시', 'type': ''},\n",
       "   {'begin': 2.0, 'end': 6.0, 'id': 2.0, 'text': '푸른도시사업소장은', 'type': ''},\n",
       "   {'begin': 7.0, 'end': 8.0, 'id': 3.0, 'text': '1983년', 'type': ''},\n",
       "   {'begin': 9.0, 'end': 10.0, 'id': 4.0, 'text': '공직에', 'type': ''},\n",
       "   {'begin': 11.0, 'end': 13.0, 'id': 5.0, 'text': '입문해', 'type': ''},\n",
       "   {'begin': 14.0, 'end': 15.0, 'id': 6.0, 'text': '고양시가', 'type': ''},\n",
       "   {'begin': 16.0, 'end': 17.0, 'id': 7.0, 'text': '자연을', 'type': ''},\n",
       "   {'begin': 18.0, 'end': 19.0, 'id': 8.0, 'text': '품은', 'type': ''},\n",
       "   {'begin': 20.0, 'end': 21.0, 'id': 9.0, 'text': '도시가', 'type': ''},\n",
       "   {'begin': 22.0, 'end': 23.0, 'id': 10.0, 'text': '될', 'type': ''},\n",
       "   {'begin': 24.0, 'end': 24.0, 'id': 11.0, 'text': '수', 'type': ''},\n",
       "   {'begin': 25.0, 'end': 26.0, 'id': 12.0, 'text': '있도록', 'type': ''},\n",
       "   {'begin': 27.0, 'end': 28.0, 'id': 13.0, 'text': '많은', 'type': ''},\n",
       "   {'begin': 29.0, 'end': 30.0, 'id': 14.0, 'text': '연구와', 'type': ''},\n",
       "   {'begin': 31.0, 'end': 32.0, 'id': 15.0, 'text': '노력을', 'type': ''},\n",
       "   {'begin': 33.0, 'end': 38.0, 'id': 16.0, 'text': '기울여왔다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 0.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 3.0,\n",
       "    'id': 0.0,\n",
       "    'text': '지난 28일',\n",
       "    'type': 'DT_DAY',\n",
       "    'weight': 0.893865},\n",
       "   {'begin': 19.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 20.0,\n",
       "    'id': 1.0,\n",
       "    'text': '산림청장표창',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.196843},\n",
       "   {'begin': 25.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 26.0,\n",
       "    'id': 2.0,\n",
       "    'text': '국무총리',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.565509},\n",
       "   {'begin': 28.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 29.0,\n",
       "    'id': 3.0,\n",
       "    'text': '국방부',\n",
       "    'type': 'OGG_POLITICS',\n",
       "    'weight': 0.625059},\n",
       "   {'begin': 30.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 30.0,\n",
       "    'id': 4.0,\n",
       "    'text': '장관',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.418697},\n",
       "   {'begin': 32.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 33.0,\n",
       "    'id': 5.0,\n",
       "    'text': '도지사',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.710788},\n",
       "   {'begin': 34.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 34.0,\n",
       "    'id': 6.0,\n",
       "    'text': '표창',\n",
       "    'type': 'CV_PRIZE',\n",
       "    'weight': 0.190505}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 616.0,\n",
       "    'scode': '00',\n",
       "    'text': '지나',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 619.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 623.0,\n",
       "    'scode': '00',\n",
       "    'text': '28',\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 625.0,\n",
       "    'scode': '07',\n",
       "    'text': '일',\n",
       "    'type': 'NNB',\n",
       "    'weight': 3.2},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 629.0,\n",
       "    'scode': '01',\n",
       "    'text': '명예',\n",
       "    'type': 'NNG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 5.0,\n",
       "    'end': 6.0,\n",
       "    'id': 5.0,\n",
       "    'position': 635.0,\n",
       "    'scode': '00',\n",
       "    'text': '퇴직하',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 6.0,\n",
       "    'position': 641.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 7.0,\n",
       "    'position': 645.0,\n",
       "    'scode': '01',\n",
       "    'text': '그',\n",
       "    'type': 'NP',\n",
       "    'weight': 5.4},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 8.0,\n",
       "    'position': 648.0,\n",
       "    'scode': '00',\n",
       "    'text': '는',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 9.0,\n",
       "    'position': 652.0,\n",
       "    'scode': '00',\n",
       "    'text': '산림',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 10.0,\n",
       "    'position': 658.0,\n",
       "    'scode': '01',\n",
       "    'text': '보호',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.2},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 11.0,\n",
       "    'position': 664.0,\n",
       "    'scode': '02',\n",
       "    'text': '유공',\n",
       "    'type': 'NNG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 12.0,\n",
       "    'position': 670.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 14.0,\n",
       "    'end': 15.0,\n",
       "    'id': 13.0,\n",
       "    'position': 674.0,\n",
       "    'scode': '00',\n",
       "    'text': '인정받',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 14.0,\n",
       "    'position': 683.0,\n",
       "    'scode': '00',\n",
       "    'text': '아',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 17.0,\n",
       "    'end': 17.0,\n",
       "    'id': 15.0,\n",
       "    'position': 687.0,\n",
       "    'scode': '01',\n",
       "    'text': '받',\n",
       "    'type': 'VV',\n",
       "    'weight': 5.2},\n",
       "   {'begin': 18.0,\n",
       "    'end': 18.0,\n",
       "    'id': 16.0,\n",
       "    'position': 690.0,\n",
       "    'scode': '00',\n",
       "    'text': '은',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 19.0,\n",
       "    'end': 19.0,\n",
       "    'id': 17.0,\n",
       "    'position': 694.0,\n",
       "    'scode': '00',\n",
       "    'text': '산림청장',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 18.0,\n",
       "    'position': 706.0,\n",
       "    'scode': '01',\n",
       "    'text': '표창',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.2},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 19.0,\n",
       "    'position': 712.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 22.0,\n",
       "    'end': 22.0,\n",
       "    'id': 20.0,\n",
       "    'position': 716.0,\n",
       "    'scode': '00',\n",
       "    'text': '비롯하',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 23.0,\n",
       "    'end': 23.0,\n",
       "    'id': 21.0,\n",
       "    'position': 722.0,\n",
       "    'scode': '00',\n",
       "    'text': '어',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 24.0,\n",
       "    'end': 24.0,\n",
       "    'id': 22.0,\n",
       "    'position': 725.0,\n",
       "    'scode': '00',\n",
       "    'text': ',',\n",
       "    'type': 'SP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 25.0,\n",
       "    'end': 26.0,\n",
       "    'id': 23.0,\n",
       "    'position': 727.0,\n",
       "    'scode': '00',\n",
       "    'text': '국무총리',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 27.0,\n",
       "    'end': 27.0,\n",
       "    'id': 24.0,\n",
       "    'position': 739.0,\n",
       "    'scode': '00',\n",
       "    'text': '와',\n",
       "    'type': 'JC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 28.0,\n",
       "    'end': 29.0,\n",
       "    'id': 25.0,\n",
       "    'position': 743.0,\n",
       "    'scode': '00',\n",
       "    'text': '국방부',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 30.0,\n",
       "    'end': 30.0,\n",
       "    'id': 26.0,\n",
       "    'position': 752.0,\n",
       "    'scode': '02',\n",
       "    'text': '장관',\n",
       "    'type': 'NNG',\n",
       "    'weight': 15.8},\n",
       "   {'begin': 31.0,\n",
       "    'end': 31.0,\n",
       "    'id': 27.0,\n",
       "    'position': 758.0,\n",
       "    'scode': '00',\n",
       "    'text': ',',\n",
       "    'type': 'SP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 32.0,\n",
       "    'end': 33.0,\n",
       "    'id': 28.0,\n",
       "    'position': 760.0,\n",
       "    'scode': '00',\n",
       "    'text': '도지사',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 34.0,\n",
       "    'end': 34.0,\n",
       "    'id': 29.0,\n",
       "    'position': 770.0,\n",
       "    'scode': '01',\n",
       "    'text': '표창',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 35.0,\n",
       "    'end': 35.0,\n",
       "    'id': 30.0,\n",
       "    'position': 776.0,\n",
       "    'scode': '09',\n",
       "    'text': '들',\n",
       "    'type': 'XSN',\n",
       "    'weight': 7.0},\n",
       "   {'begin': 36.0,\n",
       "    'end': 36.0,\n",
       "    'id': 31.0,\n",
       "    'position': 779.0,\n",
       "    'scode': '00',\n",
       "    'text': '이',\n",
       "    'type': 'JKS',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 37.0,\n",
       "    'end': 37.0,\n",
       "    'id': 32.0,\n",
       "    'position': 783.0,\n",
       "    'scode': '00',\n",
       "    'text': '묵묵히',\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 38.0,\n",
       "    'end': 38.0,\n",
       "    'id': 33.0,\n",
       "    'position': 793.0,\n",
       "    'scode': '02',\n",
       "    'text': '업무',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.2},\n",
       "   {'begin': 39.0,\n",
       "    'end': 39.0,\n",
       "    'id': 34.0,\n",
       "    'position': 799.0,\n",
       "    'scode': '00',\n",
       "    'text': '에',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 40.0,\n",
       "    'end': 41.0,\n",
       "    'id': 35.0,\n",
       "    'position': 803.0,\n",
       "    'scode': '02',\n",
       "    'text': '충실하',\n",
       "    'type': 'VA',\n",
       "    'weight': 1.86667},\n",
       "   {'begin': 42.0,\n",
       "    'end': 42.0,\n",
       "    'id': 36.0,\n",
       "    'position': 809.0,\n",
       "    'scode': '00',\n",
       "    'text': '어',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 43.0,\n",
       "    'end': 43.0,\n",
       "    'id': 37.0,\n",
       "    'position': 813.0,\n",
       "    'scode': '01',\n",
       "    'text': '오',\n",
       "    'type': 'VX',\n",
       "    'weight': 5.2},\n",
       "   {'begin': 44.0,\n",
       "    'end': 44.0,\n",
       "    'id': 38.0,\n",
       "    'position': 813.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 45.0,\n",
       "    'end': 45.0,\n",
       "    'id': 39.0,\n",
       "    'position': 817.0,\n",
       "    'scode': '01',\n",
       "    'text': '그',\n",
       "    'type': 'NP',\n",
       "    'weight': 7.6},\n",
       "   {'begin': 46.0,\n",
       "    'end': 46.0,\n",
       "    'id': 40.0,\n",
       "    'position': 820.0,\n",
       "    'scode': '00',\n",
       "    'text': '의',\n",
       "    'type': 'JKG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 47.0,\n",
       "    'end': 47.0,\n",
       "    'id': 41.0,\n",
       "    'position': 824.0,\n",
       "    'scode': '02',\n",
       "    'text': '공직',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 48.0,\n",
       "    'end': 48.0,\n",
       "    'id': 42.0,\n",
       "    'position': 830.0,\n",
       "    'scode': '00',\n",
       "    'text': '생활',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 49.0,\n",
       "    'end': 49.0,\n",
       "    'id': 43.0,\n",
       "    'position': 836.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 50.0,\n",
       "    'end': 50.0,\n",
       "    'id': 44.0,\n",
       "    'position': 840.0,\n",
       "    'scode': '01',\n",
       "    'text': '보이',\n",
       "    'type': 'VV',\n",
       "    'weight': 1.59107},\n",
       "   {'begin': 51.0,\n",
       "    'end': 51.0,\n",
       "    'id': 45.0,\n",
       "    'position': 843.0,\n",
       "    'scode': '00',\n",
       "    'text': '어',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 52.0,\n",
       "    'end': 52.0,\n",
       "    'id': 46.0,\n",
       "    'position': 846.0,\n",
       "    'scode': '01',\n",
       "    'text': '주',\n",
       "    'type': 'VX',\n",
       "    'weight': 7.6},\n",
       "   {'begin': 53.0,\n",
       "    'end': 53.0,\n",
       "    'id': 47.0,\n",
       "    'position': 846.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 54.0,\n",
       "    'end': 54.0,\n",
       "    'id': 48.0,\n",
       "    'position': 852.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 1.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '지난',\n",
       "    'weight': 0.547704},\n",
       "   {'head': 2.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [0.0],\n",
       "    'text': '28일',\n",
       "    'weight': 0.683389},\n",
       "   {'head': 3.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [1.0],\n",
       "    'text': '명예퇴직한',\n",
       "    'weight': 0.654602},\n",
       "   {'head': 8.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [2.0],\n",
       "    'text': '그는',\n",
       "    'weight': 0.498012},\n",
       "   {'head': 5.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [],\n",
       "    'text': '산림보호유공을',\n",
       "    'weight': 0.454183},\n",
       "   {'head': 6.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [4.0],\n",
       "    'text': '인정받아',\n",
       "    'weight': 0.224991},\n",
       "   {'head': 7.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [5.0],\n",
       "    'text': '받은',\n",
       "    'weight': 0.677448},\n",
       "   {'head': 8.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [6.0],\n",
       "    'text': '산림청장표창을',\n",
       "    'weight': 0.706745},\n",
       "   {'head': 19.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [3.0, 7.0],\n",
       "    'text': '비롯해,',\n",
       "    'weight': 0.737569},\n",
       "   {'head': 11.0,\n",
       "    'id': 9.0,\n",
       "    'label': 'NP_CNJ',\n",
       "    'mod': [],\n",
       "    'text': '국무총리와',\n",
       "    'weight': 0.751998},\n",
       "   {'head': 11.0,\n",
       "    'id': 10.0,\n",
       "    'label': 'NP_CNJ',\n",
       "    'mod': [],\n",
       "    'text': '국방부장관,',\n",
       "    'weight': 0.105319},\n",
       "   {'head': 12.0,\n",
       "    'id': 11.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [10.0, 9.0],\n",
       "    'text': '도지사',\n",
       "    'weight': 0.58355},\n",
       "   {'head': 15.0,\n",
       "    'id': 12.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [11.0],\n",
       "    'text': '표창들이',\n",
       "    'weight': 0.347706},\n",
       "   {'head': 15.0,\n",
       "    'id': 13.0,\n",
       "    'label': 'AP',\n",
       "    'mod': [],\n",
       "    'text': '묵묵히',\n",
       "    'weight': 0.636801},\n",
       "   {'head': 15.0,\n",
       "    'id': 14.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '업무에',\n",
       "    'weight': 0.59592},\n",
       "   {'head': 16.0,\n",
       "    'id': 15.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [12.0, 13.0, 14.0],\n",
       "    'text': '충실해',\n",
       "    'weight': 0.791105},\n",
       "   {'head': 18.0,\n",
       "    'id': 16.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [15.0],\n",
       "    'text': '온',\n",
       "    'weight': 0.558214},\n",
       "   {'head': 18.0,\n",
       "    'id': 17.0,\n",
       "    'label': 'NP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '그의',\n",
       "    'weight': 0.633813},\n",
       "   {'head': 19.0,\n",
       "    'id': 18.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [16.0, 17.0],\n",
       "    'text': '공직생활을',\n",
       "    'weight': 0.62751},\n",
       "   {'head': -1.0,\n",
       "    'id': 19.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [8.0, 18.0],\n",
       "    'text': '보여준다.',\n",
       "    'weight': 3.7114e-06}],\n",
       "  'id': 4.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '지나',\n",
       "    'position': 616.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0769696},\n",
       "   {'id': 1.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 619.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0581092},\n",
       "   {'id': 2.0, 'lemma': '28', 'position': 623.0, 'type': 'SN', 'weight': 1.0},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '일',\n",
       "    'position': 625.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.0461482},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '명예',\n",
       "    'position': 629.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0345652},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '퇴직',\n",
       "    'position': 635.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0345652},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '하',\n",
       "    'position': 641.0,\n",
       "    'type': 'XSV',\n",
       "    'weight': 0.0246647},\n",
       "   {'id': 7.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 641.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0246647},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '그',\n",
       "    'position': 645.0,\n",
       "    'type': 'NP',\n",
       "    'weight': 0.115441},\n",
       "   {'id': 9.0,\n",
       "    'lemma': '는',\n",
       "    'position': 648.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.103728},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '산림',\n",
       "    'position': 652.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0848682},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '보호',\n",
       "    'position': 658.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.032685},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '유공',\n",
       "    'position': 664.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0182877},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '을',\n",
       "    'position': 670.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0832244},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '인정',\n",
       "    'position': 674.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.074037},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '받',\n",
       "    'position': 680.0,\n",
       "    'type': 'XSV',\n",
       "    'weight': 0.0247723},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '아',\n",
       "    'position': 683.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.056703},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '받',\n",
       "    'position': 687.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.114572},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '은',\n",
       "    'position': 690.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.11425},\n",
       "   {'id': 19.0,\n",
       "    'lemma': '산림청장',\n",
       "    'position': 694.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0588786},\n",
       "   {'id': 20.0,\n",
       "    'lemma': '표창',\n",
       "    'position': 706.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0347575},\n",
       "   {'id': 21.0,\n",
       "    'lemma': '을',\n",
       "    'position': 712.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0976257},\n",
       "   {'id': 22.0,\n",
       "    'lemma': '비롯하',\n",
       "    'position': 716.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0368364},\n",
       "   {'id': 23.0,\n",
       "    'lemma': '어',\n",
       "    'position': 722.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0251946},\n",
       "   {'id': 24.0, 'lemma': ',', 'position': 725.0, 'type': 'SP', 'weight': 1.0},\n",
       "   {'id': 25.0,\n",
       "    'lemma': '국무',\n",
       "    'position': 727.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.105662},\n",
       "   {'id': 26.0,\n",
       "    'lemma': '총리',\n",
       "    'position': 733.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.105662},\n",
       "   {'id': 27.0,\n",
       "    'lemma': '와',\n",
       "    'position': 739.0,\n",
       "    'type': 'JC',\n",
       "    'weight': 0.0627067},\n",
       "   {'id': 28.0,\n",
       "    'lemma': '국방',\n",
       "    'position': 743.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.140389},\n",
       "   {'id': 29.0,\n",
       "    'lemma': '부',\n",
       "    'position': 749.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.140389},\n",
       "   {'id': 30.0,\n",
       "    'lemma': '장관',\n",
       "    'position': 752.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0628887},\n",
       "   {'id': 31.0, 'lemma': ',', 'position': 758.0, 'type': 'SP', 'weight': 1.0},\n",
       "   {'id': 32.0,\n",
       "    'lemma': '도',\n",
       "    'position': 760.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0955113},\n",
       "   {'id': 33.0,\n",
       "    'lemma': '지사',\n",
       "    'position': 763.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0955113},\n",
       "   {'id': 34.0,\n",
       "    'lemma': '표창',\n",
       "    'position': 770.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0532685},\n",
       "   {'id': 35.0,\n",
       "    'lemma': '들',\n",
       "    'position': 776.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0700378},\n",
       "   {'id': 36.0,\n",
       "    'lemma': '이',\n",
       "    'position': 779.0,\n",
       "    'type': 'JKS',\n",
       "    'weight': 0.063019},\n",
       "   {'id': 37.0,\n",
       "    'lemma': '묵묵히',\n",
       "    'position': 783.0,\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0492452},\n",
       "   {'id': 38.0,\n",
       "    'lemma': '업무',\n",
       "    'position': 793.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0986893},\n",
       "   {'id': 39.0,\n",
       "    'lemma': '에',\n",
       "    'position': 799.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0909971},\n",
       "   {'id': 40.0,\n",
       "    'lemma': '충실',\n",
       "    'position': 803.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0429959},\n",
       "   {'id': 41.0,\n",
       "    'lemma': '하',\n",
       "    'position': 809.0,\n",
       "    'type': 'XSA',\n",
       "    'weight': 0.0429959},\n",
       "   {'id': 42.0,\n",
       "    'lemma': '어',\n",
       "    'position': 809.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0382715},\n",
       "   {'id': 43.0,\n",
       "    'lemma': '오',\n",
       "    'position': 813.0,\n",
       "    'type': 'VX',\n",
       "    'weight': 0.0739748},\n",
       "   {'id': 44.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 813.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0739748},\n",
       "   {'id': 45.0,\n",
       "    'lemma': '그',\n",
       "    'position': 817.0,\n",
       "    'type': 'NP',\n",
       "    'weight': 0.0896799},\n",
       "   {'id': 46.0,\n",
       "    'lemma': '의',\n",
       "    'position': 820.0,\n",
       "    'type': 'JKG',\n",
       "    'weight': 0.118274},\n",
       "   {'id': 47.0,\n",
       "    'lemma': '공직',\n",
       "    'position': 824.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0889909},\n",
       "   {'id': 48.0,\n",
       "    'lemma': '생활',\n",
       "    'position': 830.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0490292},\n",
       "   {'id': 49.0,\n",
       "    'lemma': '을',\n",
       "    'position': 836.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0868579},\n",
       "   {'id': 50.0,\n",
       "    'lemma': '보이',\n",
       "    'position': 840.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0778142},\n",
       "   {'id': 51.0,\n",
       "    'lemma': '어',\n",
       "    'position': 843.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0313283},\n",
       "   {'id': 52.0,\n",
       "    'lemma': '주',\n",
       "    'position': 846.0,\n",
       "    'type': 'VX',\n",
       "    'weight': 0.0313283},\n",
       "   {'id': 53.0,\n",
       "    'lemma': 'ㄴ다',\n",
       "    'position': 846.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0485559},\n",
       "   {'id': 54.0, 'lemma': '.', 'position': 852.0, 'type': 'SF', 'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': '  지난 28일 명예퇴직한 그는 산림보호유공을 인정받아 받은 산림청장표창을 비롯해, 국무총리와 국방부장관, 도지사 표창들이 묵묵히 업무에 충실해 온 그의 공직생활을 보여준다.',\n",
       "  'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '지난', 'type': ''},\n",
       "   {'begin': 2.0, 'end': 3.0, 'id': 1.0, 'text': '28일', 'type': ''},\n",
       "   {'begin': 4.0, 'end': 7.0, 'id': 2.0, 'text': '명예퇴직한', 'type': ''},\n",
       "   {'begin': 8.0, 'end': 9.0, 'id': 3.0, 'text': '그는', 'type': ''},\n",
       "   {'begin': 10.0, 'end': 13.0, 'id': 4.0, 'text': '산림보호유공을', 'type': ''},\n",
       "   {'begin': 14.0, 'end': 16.0, 'id': 5.0, 'text': '인정받아', 'type': ''},\n",
       "   {'begin': 17.0, 'end': 18.0, 'id': 6.0, 'text': '받은', 'type': ''},\n",
       "   {'begin': 19.0, 'end': 21.0, 'id': 7.0, 'text': '산림청장표창을', 'type': ''},\n",
       "   {'begin': 22.0, 'end': 24.0, 'id': 8.0, 'text': '비롯해,', 'type': ''},\n",
       "   {'begin': 25.0, 'end': 27.0, 'id': 9.0, 'text': '국무총리와', 'type': ''},\n",
       "   {'begin': 28.0, 'end': 31.0, 'id': 10.0, 'text': '국방부장관,', 'type': ''},\n",
       "   {'begin': 32.0, 'end': 33.0, 'id': 11.0, 'text': '도지사', 'type': ''},\n",
       "   {'begin': 34.0, 'end': 36.0, 'id': 12.0, 'text': '표창들이', 'type': ''},\n",
       "   {'begin': 37.0, 'end': 37.0, 'id': 13.0, 'text': '묵묵히', 'type': ''},\n",
       "   {'begin': 38.0, 'end': 39.0, 'id': 14.0, 'text': '업무에', 'type': ''},\n",
       "   {'begin': 40.0, 'end': 42.0, 'id': 15.0, 'text': '충실해', 'type': ''},\n",
       "   {'begin': 43.0, 'end': 44.0, 'id': 16.0, 'text': '온', 'type': ''},\n",
       "   {'begin': 45.0, 'end': 46.0, 'id': 17.0, 'text': '그의', 'type': ''},\n",
       "   {'begin': 47.0, 'end': 49.0, 'id': 18.0, 'text': '공직생활을', 'type': ''},\n",
       "   {'begin': 50.0, 'end': 54.0, 'id': 19.0, 'text': '보여준다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 0.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 3.0,\n",
       "    'id': 0.0,\n",
       "    'text': '40년 세월동안',\n",
       "    'type': 'DT_DURATION',\n",
       "    'weight': 0.511448},\n",
       "   {'begin': 4.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 4.0,\n",
       "    'id': 1.0,\n",
       "    'text': '고양시',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.482232},\n",
       "   {'begin': 10.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 10.0,\n",
       "    'id': 2.0,\n",
       "    'text': '이현옥',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.532402},\n",
       "   {'begin': 11.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 13.0,\n",
       "    'id': 3.0,\n",
       "    'text': '교육문화국장',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.685573}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 854.0,\n",
       "    'scode': '00',\n",
       "    'text': '40',\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 856.0,\n",
       "    'scode': '02',\n",
       "    'text': '년',\n",
       "    'type': 'NNB',\n",
       "    'weight': 4.4},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 860.0,\n",
       "    'scode': '02',\n",
       "    'text': '세월',\n",
       "    'type': 'NNG',\n",
       "    'weight': 4.2},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 866.0,\n",
       "    'scode': '01',\n",
       "    'text': '동안',\n",
       "    'type': 'NNG',\n",
       "    'weight': 4.2},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 873.0,\n",
       "    'scode': '00',\n",
       "    'text': '고양시',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 5.0,\n",
       "    'position': 882.0,\n",
       "    'scode': '00',\n",
       "    'text': '를',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 6.0,\n",
       "    'position': 886.0,\n",
       "    'scode': '01',\n",
       "    'text': '지키',\n",
       "    'type': 'VV',\n",
       "    'weight': 8.8},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 7.0,\n",
       "    'position': 889.0,\n",
       "    'scode': '00',\n",
       "    'text': '어',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 8.0,\n",
       "    'position': 892.0,\n",
       "    'scode': '01',\n",
       "    'text': '오',\n",
       "    'type': 'VX',\n",
       "    'weight': 11.8},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 9.0,\n",
       "    'position': 892.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 10.0,\n",
       "    'position': 896.0,\n",
       "    'scode': '00',\n",
       "    'text': '이현옥',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 11.0,\n",
       "    'position': 906.0,\n",
       "    'scode': '00',\n",
       "    'text': '교육',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 12.0,\n",
       "    'position': 912.0,\n",
       "    'scode': '01',\n",
       "    'text': '문화',\n",
       "    'type': 'NNG',\n",
       "    'weight': 7.2},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 13.0,\n",
       "    'position': 918.0,\n",
       "    'scode': '01',\n",
       "    'text': '국장',\n",
       "    'type': 'NNG',\n",
       "    'weight': 5.0},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 14.0,\n",
       "    'position': 924.0,\n",
       "    'scode': '00',\n",
       "    'text': '도',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 15.0,\n",
       "    'end': 15.0,\n",
       "    'id': 15.0,\n",
       "    'position': 928.0,\n",
       "    'scode': '02',\n",
       "    'text': '공직',\n",
       "    'type': 'NNG',\n",
       "    'weight': 4.0},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 16.0,\n",
       "    'position': 934.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 17.0,\n",
       "    'end': 18.0,\n",
       "    'id': 17.0,\n",
       "    'position': 938.0,\n",
       "    'scode': '00',\n",
       "    'text': '마무리하',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 19.0,\n",
       "    'end': 19.0,\n",
       "    'id': 18.0,\n",
       "    'position': 950.0,\n",
       "    'scode': '00',\n",
       "    'text': '기',\n",
       "    'type': 'ETN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 19.0,\n",
       "    'position': 954.0,\n",
       "    'scode': '01',\n",
       "    'text': '위하',\n",
       "    'type': 'VV',\n",
       "    'weight': 8.6},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 20.0,\n",
       "    'position': 957.0,\n",
       "    'scode': '00',\n",
       "    'text': '어',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 22.0,\n",
       "    'end': 22.0,\n",
       "    'id': 21.0,\n",
       "    'position': 961.0,\n",
       "    'scode': '04',\n",
       "    'text': '공로',\n",
       "    'type': 'NNG',\n",
       "    'weight': 4.10909},\n",
       "   {'begin': 23.0,\n",
       "    'end': 23.0,\n",
       "    'id': 22.0,\n",
       "    'position': 967.0,\n",
       "    'scode': '08',\n",
       "    'text': '연수',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.5},\n",
       "   {'begin': 24.0,\n",
       "    'end': 24.0,\n",
       "    'id': 23.0,\n",
       "    'position': 973.0,\n",
       "    'scode': '00',\n",
       "    'text': '에',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 25.0,\n",
       "    'end': 25.0,\n",
       "    'id': 24.0,\n",
       "    'position': 977.0,\n",
       "    'scode': '01',\n",
       "    'text': '들어가',\n",
       "    'type': 'VV',\n",
       "    'weight': 3.2},\n",
       "   {'begin': 26.0,\n",
       "    'end': 26.0,\n",
       "    'id': 25.0,\n",
       "    'position': 983.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 27.0,\n",
       "    'end': 27.0,\n",
       "    'id': 26.0,\n",
       "    'position': 989.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 1.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '40년',\n",
       "    'weight': 0.59692},\n",
       "   {'head': 3.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [0.0],\n",
       "    'text': '세월동안',\n",
       "    'weight': 0.476202},\n",
       "   {'head': 3.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [],\n",
       "    'text': '고양시를',\n",
       "    'weight': 0.762293},\n",
       "   {'head': 5.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [1.0, 2.0],\n",
       "    'text': '지켜온',\n",
       "    'weight': 0.807895},\n",
       "   {'head': 5.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '이현옥',\n",
       "    'weight': 0.567486},\n",
       "   {'head': 7.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [3.0, 4.0],\n",
       "    'text': '교육문화국장도',\n",
       "    'weight': 0.263154},\n",
       "   {'head': 7.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [],\n",
       "    'text': '공직을',\n",
       "    'weight': 0.62883},\n",
       "   {'head': 8.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'VP_OBJ',\n",
       "    'mod': [5.0, 6.0],\n",
       "    'text': '마무리하기',\n",
       "    'weight': 0.567291},\n",
       "   {'head': 10.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [7.0],\n",
       "    'text': '위해',\n",
       "    'weight': 0.711053},\n",
       "   {'head': 10.0,\n",
       "    'id': 9.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '공로연수에',\n",
       "    'weight': 0.699732},\n",
       "   {'head': -1.0,\n",
       "    'id': 10.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [8.0, 9.0],\n",
       "    'text': '들어간다.',\n",
       "    'weight': 0.00397418}],\n",
       "  'id': 5.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '40',\n",
       "    'position': 854.0,\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '년',\n",
       "    'position': 856.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.0620024},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '세월',\n",
       "    'position': 860.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0653524},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '동안',\n",
       "    'position': 866.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0530216},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '고양시',\n",
       "    'position': 873.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0555228},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '를',\n",
       "    'position': 882.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.116286},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '지키',\n",
       "    'position': 886.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0585379},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '어',\n",
       "    'position': 889.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0297251},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '오',\n",
       "    'position': 892.0,\n",
       "    'type': 'VX',\n",
       "    'weight': 0.0297251},\n",
       "   {'id': 9.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 892.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0297251},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '이현옥',\n",
       "    'position': 896.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0653221},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '교육',\n",
       "    'position': 906.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.105517},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '문화',\n",
       "    'position': 912.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.100961},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '국장',\n",
       "    'position': 918.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0314261},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '도',\n",
       "    'position': 924.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.0995007},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '공직',\n",
       "    'position': 928.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0827499},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '을',\n",
       "    'position': 934.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0894116},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '마무리',\n",
       "    'position': 938.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0325706},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '하',\n",
       "    'position': 947.0,\n",
       "    'type': 'XSV',\n",
       "    'weight': 0.0325706},\n",
       "   {'id': 19.0,\n",
       "    'lemma': '기',\n",
       "    'position': 950.0,\n",
       "    'type': 'ETN',\n",
       "    'weight': 0.237182},\n",
       "   {'id': 20.0,\n",
       "    'lemma': '위하',\n",
       "    'position': 954.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.111879},\n",
       "   {'id': 21.0,\n",
       "    'lemma': '어',\n",
       "    'position': 957.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0749282},\n",
       "   {'id': 22.0,\n",
       "    'lemma': '공로',\n",
       "    'position': 961.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0710124},\n",
       "   {'id': 23.0,\n",
       "    'lemma': '연수',\n",
       "    'position': 967.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.070642},\n",
       "   {'id': 24.0,\n",
       "    'lemma': '에',\n",
       "    'position': 973.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.104803},\n",
       "   {'id': 25.0,\n",
       "    'lemma': '들어가',\n",
       "    'position': 977.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.107452},\n",
       "   {'id': 26.0,\n",
       "    'lemma': 'ㄴ다',\n",
       "    'position': 983.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0500818},\n",
       "   {'id': 27.0, 'lemma': '.', 'position': 989.0, 'type': 'SF', 'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': ' 40년 세월동안 고양시를 지켜온 이현옥 교육문화국장도 공직을 마무리하기 위해 공로연수에 들어간다.',\n",
       "  'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '40년', 'type': ''},\n",
       "   {'begin': 2.0, 'end': 3.0, 'id': 1.0, 'text': '세월동안', 'type': ''},\n",
       "   {'begin': 4.0, 'end': 5.0, 'id': 2.0, 'text': '고양시를', 'type': ''},\n",
       "   {'begin': 6.0, 'end': 9.0, 'id': 3.0, 'text': '지켜온', 'type': ''},\n",
       "   {'begin': 10.0, 'end': 10.0, 'id': 4.0, 'text': '이현옥', 'type': ''},\n",
       "   {'begin': 11.0, 'end': 14.0, 'id': 5.0, 'text': '교육문화국장도', 'type': ''},\n",
       "   {'begin': 15.0, 'end': 16.0, 'id': 6.0, 'text': '공직을', 'type': ''},\n",
       "   {'begin': 17.0, 'end': 19.0, 'id': 7.0, 'text': '마무리하기', 'type': ''},\n",
       "   {'begin': 20.0, 'end': 21.0, 'id': 8.0, 'text': '위해', 'type': ''},\n",
       "   {'begin': 22.0, 'end': 24.0, 'id': 9.0, 'text': '공로연수에', 'type': ''},\n",
       "   {'begin': 25.0, 'end': 27.0, 'id': 10.0, 'text': '들어간다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 10.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 10.0,\n",
       "    'id': 0.0,\n",
       "    'text': '후배',\n",
       "    'type': 'CV_RELATION',\n",
       "    'weight': 0.584798}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 992.0,\n",
       "    'scode': '00',\n",
       "    'text': '부드럽',\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 1001.0,\n",
       "    'scode': '00',\n",
       "    'text': '고',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 2.0,\n",
       "    'end': 3.0,\n",
       "    'id': 2.0,\n",
       "    'position': 1005.0,\n",
       "    'scode': '00',\n",
       "    'text': '섬세하',\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 3.0,\n",
       "    'position': 1011.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 4.0,\n",
       "    'position': 1015.0,\n",
       "    'scode': '01',\n",
       "    'text': '그',\n",
       "    'type': 'NP',\n",
       "    'weight': 9.8},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 5.0,\n",
       "    'position': 1018.0,\n",
       "    'scode': '00',\n",
       "    'text': '의',\n",
       "    'type': 'JKG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 6.0,\n",
       "    'position': 1022.0,\n",
       "    'scode': '02',\n",
       "    'text': '업무',\n",
       "    'type': 'NNG',\n",
       "    'weight': 4.2},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 7.0,\n",
       "    'position': 1028.0,\n",
       "    'scode': '00',\n",
       "    'text': '스타일',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 8.0,\n",
       "    'position': 1037.0,\n",
       "    'scode': '00',\n",
       "    'text': '은',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 9.0,\n",
       "    'position': 1041.0,\n",
       "    'scode': '06',\n",
       "    'text': '후배',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.2},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 10.0,\n",
       "    'position': 1047.0,\n",
       "    'scode': '09',\n",
       "    'text': '들',\n",
       "    'type': 'XSN',\n",
       "    'weight': 6.0},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 11.0,\n",
       "    'position': 1050.0,\n",
       "    'scode': '00',\n",
       "    'text': '에게',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 12.0,\n",
       "    'position': 1056.0,\n",
       "    'scode': '00',\n",
       "    'text': '도',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 13.0,\n",
       "    'position': 1060.0,\n",
       "    'scode': '00',\n",
       "    'text': '많',\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 15.0,\n",
       "    'end': 15.0,\n",
       "    'id': 14.0,\n",
       "    'position': 1063.0,\n",
       "    'scode': '00',\n",
       "    'text': '은',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 15.0,\n",
       "    'position': 1067.0,\n",
       "    'scode': '02',\n",
       "    'text': '신뢰',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.2},\n",
       "   {'begin': 17.0,\n",
       "    'end': 17.0,\n",
       "    'id': 16.0,\n",
       "    'position': 1073.0,\n",
       "    'scode': '00',\n",
       "    'text': '와',\n",
       "    'type': 'JC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 18.0,\n",
       "    'end': 18.0,\n",
       "    'id': 17.0,\n",
       "    'position': 1077.0,\n",
       "    'scode': '02',\n",
       "    'text': '박수',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.83929},\n",
       "   {'begin': 19.0,\n",
       "    'end': 19.0,\n",
       "    'id': 18.0,\n",
       "    'position': 1083.0,\n",
       "    'scode': '00',\n",
       "    'text': '를',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 19.0,\n",
       "    'position': 1087.0,\n",
       "    'scode': '01',\n",
       "    'text': '받',\n",
       "    'type': 'VV',\n",
       "    'weight': 4.4},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 20.0,\n",
       "    'position': 1090.0,\n",
       "    'scode': '00',\n",
       "    'text': '아',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 22.0,\n",
       "    'end': 22.0,\n",
       "    'id': 21.0,\n",
       "    'position': 1093.0,\n",
       "    'scode': '01',\n",
       "    'text': '오',\n",
       "    'type': 'VX',\n",
       "    'weight': 5.2},\n",
       "   {'begin': 23.0,\n",
       "    'end': 23.0,\n",
       "    'id': 22.0,\n",
       "    'position': 1093.0,\n",
       "    'scode': '00',\n",
       "    'text': '았',\n",
       "    'type': 'EP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 24.0,\n",
       "    'end': 24.0,\n",
       "    'id': 23.0,\n",
       "    'position': 1096.0,\n",
       "    'scode': '00',\n",
       "    'text': '다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 25.0,\n",
       "    'end': 25.0,\n",
       "    'id': 24.0,\n",
       "    'position': 1099.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 1.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [],\n",
       "    'text': '부드럽고',\n",
       "    'weight': 0.723763},\n",
       "   {'head': 3.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [0.0],\n",
       "    'text': '섬세한',\n",
       "    'weight': 0.651086},\n",
       "   {'head': 3.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'NP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '그의',\n",
       "    'weight': 0.610304},\n",
       "   {'head': 8.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [1.0, 2.0],\n",
       "    'text': '업무스타일은',\n",
       "    'weight': 0.779938},\n",
       "   {'head': 8.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '후배들에게도',\n",
       "    'weight': 0.584133},\n",
       "   {'head': 7.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '많은',\n",
       "    'weight': 0.561973},\n",
       "   {'head': 7.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'NP_CNJ',\n",
       "    'mod': [],\n",
       "    'text': '신뢰와',\n",
       "    'weight': 0.720678},\n",
       "   {'head': 8.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [5.0, 6.0],\n",
       "    'text': '박수를',\n",
       "    'weight': 0.645041},\n",
       "   {'head': -1.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [3.0, 4.0, 7.0],\n",
       "    'text': '받아왔다.',\n",
       "    'weight': 0.0237885}],\n",
       "  'id': 6.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '부드럽',\n",
       "    'position': 992.0,\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0462247},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '고',\n",
       "    'position': 1001.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0590407},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '섬세',\n",
       "    'position': 1005.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0554714},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '하',\n",
       "    'position': 1011.0,\n",
       "    'type': 'XSA',\n",
       "    'weight': 0.0554714},\n",
       "   {'id': 4.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 1011.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0283526},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '그',\n",
       "    'position': 1015.0,\n",
       "    'type': 'NP',\n",
       "    'weight': 0.0997758},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '의',\n",
       "    'position': 1018.0,\n",
       "    'type': 'JKG',\n",
       "    'weight': 0.123432},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '업무',\n",
       "    'position': 1022.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.107745},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '스타일',\n",
       "    'position': 1028.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0869361},\n",
       "   {'id': 9.0,\n",
       "    'lemma': '은',\n",
       "    'position': 1037.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.0880177},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '후배',\n",
       "    'position': 1041.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0770732},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '들',\n",
       "    'position': 1047.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0784122},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '에게',\n",
       "    'position': 1050.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0583923},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '도',\n",
       "    'position': 1056.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.178251},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '많',\n",
       "    'position': 1060.0,\n",
       "    'type': 'VA',\n",
       "    'weight': 0.193986},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '은',\n",
       "    'position': 1063.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0942571},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '신뢰',\n",
       "    'position': 1067.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0793142},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '와',\n",
       "    'position': 1073.0,\n",
       "    'type': 'JC',\n",
       "    'weight': 0.0589239},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '박수',\n",
       "    'position': 1077.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.066423},\n",
       "   {'id': 19.0,\n",
       "    'lemma': '를',\n",
       "    'position': 1083.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.125048},\n",
       "   {'id': 20.0,\n",
       "    'lemma': '받',\n",
       "    'position': 1087.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.113869},\n",
       "   {'id': 21.0,\n",
       "    'lemma': '아',\n",
       "    'position': 1090.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0600462},\n",
       "   {'id': 22.0,\n",
       "    'lemma': '오',\n",
       "    'position': 1093.0,\n",
       "    'type': 'VX',\n",
       "    'weight': 0.0396257},\n",
       "   {'id': 23.0,\n",
       "    'lemma': '았',\n",
       "    'position': 1093.0,\n",
       "    'type': 'EP',\n",
       "    'weight': 0.0396257},\n",
       "   {'id': 24.0,\n",
       "    'lemma': '다',\n",
       "    'position': 1096.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0911348},\n",
       "   {'id': 25.0,\n",
       "    'lemma': '.',\n",
       "    'position': 1099.0,\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': '  부드럽고 섬세한 그의 업무스타일은 후배들에게도 많은 신뢰와 박수를 받아왔다.',\n",
       "  'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '부드럽고', 'type': ''},\n",
       "   {'begin': 2.0, 'end': 4.0, 'id': 1.0, 'text': '섬세한', 'type': ''},\n",
       "   {'begin': 5.0, 'end': 6.0, 'id': 2.0, 'text': '그의', 'type': ''},\n",
       "   {'begin': 7.0, 'end': 9.0, 'id': 3.0, 'text': '업무스타일은', 'type': ''},\n",
       "   {'begin': 10.0, 'end': 13.0, 'id': 4.0, 'text': '후배들에게도', 'type': ''},\n",
       "   {'begin': 14.0, 'end': 15.0, 'id': 5.0, 'text': '많은', 'type': ''},\n",
       "   {'begin': 16.0, 'end': 17.0, 'id': 6.0, 'text': '신뢰와', 'type': ''},\n",
       "   {'begin': 18.0, 'end': 19.0, 'id': 7.0, 'text': '박수를', 'type': ''},\n",
       "   {'begin': 20.0, 'end': 25.0, 'id': 8.0, 'text': '받아왔다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 0.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 1.0,\n",
       "    'id': 0.0,\n",
       "    'text': '정부부처',\n",
       "    'type': 'OGG_POLITICS',\n",
       "    'weight': 0.298825},\n",
       "   {'begin': 6.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 7.0,\n",
       "    'id': 1.0,\n",
       "    'text': '13회',\n",
       "    'type': 'QT_COUNT',\n",
       "    'weight': 0.595865},\n",
       "   {'begin': 11.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 11.0,\n",
       "    'id': 2.0,\n",
       "    'text': '이흥민',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.413754},\n",
       "   {'begin': 12.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 14.0,\n",
       "    'id': 3.0,\n",
       "    'text': '민생경제국장',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.262842},\n",
       "   {'begin': 16.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 16.0,\n",
       "    'id': 4.0,\n",
       "    'text': '고양시',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.265124}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 1101.0,\n",
       "    'scode': '08',\n",
       "    'text': '정부',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 1107.0,\n",
       "    'scode': '04',\n",
       "    'text': '부처',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.0},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 1114.0,\n",
       "    'scode': '05',\n",
       "    'text': '등',\n",
       "    'type': 'NNB',\n",
       "    'weight': 5.4},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 1117.0,\n",
       "    'scode': '00',\n",
       "    'text': '으로부터',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 1130.0,\n",
       "    'scode': '01',\n",
       "    'text': '표창',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.2},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 5.0,\n",
       "    'position': 1136.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 6.0,\n",
       "    'position': 1140.0,\n",
       "    'scode': '00',\n",
       "    'text': '13',\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 7.0,\n",
       "    'position': 1142.0,\n",
       "    'scode': '08',\n",
       "    'text': '회',\n",
       "    'type': 'NNB',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 8.0,\n",
       "    'position': 1145.0,\n",
       "    'scode': '00',\n",
       "    'text': '나',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 9.0,\n",
       "    'position': 1149.0,\n",
       "    'scode': '01',\n",
       "    'text': '받',\n",
       "    'type': 'VV',\n",
       "    'weight': 4.4},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 10.0,\n",
       "    'position': 1152.0,\n",
       "    'scode': '00',\n",
       "    'text': '은',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 11.0,\n",
       "    'position': 1156.0,\n",
       "    'scode': '00',\n",
       "    'text': '이흥민',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 12.0,\n",
       "    'position': 1166.0,\n",
       "    'scode': '00',\n",
       "    'text': '민생',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 13.0,\n",
       "    'position': 1172.0,\n",
       "    'scode': '04',\n",
       "    'text': '경제',\n",
       "    'type': 'NNG',\n",
       "    'weight': 5.2},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 14.0,\n",
       "    'position': 1178.0,\n",
       "    'scode': '01',\n",
       "    'text': '국장',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.0},\n",
       "   {'begin': 15.0,\n",
       "    'end': 15.0,\n",
       "    'id': 15.0,\n",
       "    'position': 1185.0,\n",
       "    'scode': '01',\n",
       "    'text': '역시',\n",
       "    'type': 'MAG',\n",
       "    'weight': 3.0},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 16.0,\n",
       "    'position': 1192.0,\n",
       "    'scode': '00',\n",
       "    'text': '고양시',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 17.0,\n",
       "    'end': 17.0,\n",
       "    'id': 17.0,\n",
       "    'position': 1201.0,\n",
       "    'scode': '00',\n",
       "    'text': '에게',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 18.0,\n",
       "    'end': 18.0,\n",
       "    'id': 18.0,\n",
       "    'position': 1207.0,\n",
       "    'scode': '00',\n",
       "    'text': '는',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 19.0,\n",
       "    'end': 19.0,\n",
       "    'id': 19.0,\n",
       "    'position': 1211.0,\n",
       "    'scode': '00',\n",
       "    'text': '아깝',\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 20.0,\n",
       "    'position': 1217.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 21.0,\n",
       "    'position': 1221.0,\n",
       "    'scode': '02',\n",
       "    'text': '인재',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.2},\n",
       "   {'begin': 22.0,\n",
       "    'end': 22.0,\n",
       "    'id': 22.0,\n",
       "    'position': 1227.0,\n",
       "    'scode': '01',\n",
       "    'text': '이',\n",
       "    'type': 'VCP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 23.0,\n",
       "    'end': 23.0,\n",
       "    'id': 23.0,\n",
       "    'position': 1227.0,\n",
       "    'scode': '00',\n",
       "    'text': '다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 24.0,\n",
       "    'end': 24.0,\n",
       "    'id': 24.0,\n",
       "    'position': 1230.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 1.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '정부부처',\n",
       "    'weight': 0.575132},\n",
       "   {'head': 4.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [0.0],\n",
       "    'text': '등으로부터',\n",
       "    'weight': 0.536978},\n",
       "   {'head': 4.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [],\n",
       "    'text': '표창을',\n",
       "    'weight': 0.712637},\n",
       "   {'head': 4.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [],\n",
       "    'text': '13회나',\n",
       "    'weight': 0.497727},\n",
       "   {'head': 6.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [1.0, 2.0, 3.0],\n",
       "    'text': '받은',\n",
       "    'weight': 0.752247},\n",
       "   {'head': 6.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '이흥민',\n",
       "    'weight': 0.624862},\n",
       "   {'head': 9.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [4.0, 5.0],\n",
       "    'text': '민생경제국장',\n",
       "    'weight': 0.356399},\n",
       "   {'head': 9.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'AP',\n",
       "    'mod': [],\n",
       "    'text': '역시',\n",
       "    'weight': 0.780702},\n",
       "   {'head': 9.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '고양시에게는',\n",
       "    'weight': 0.670933},\n",
       "   {'head': 10.0,\n",
       "    'id': 9.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [6.0, 7.0, 8.0],\n",
       "    'text': '아까운',\n",
       "    'weight': 0.684296},\n",
       "   {'head': -1.0,\n",
       "    'id': 10.0,\n",
       "    'label': 'VNP',\n",
       "    'mod': [9.0],\n",
       "    'text': '인재다.',\n",
       "    'weight': 0.00512573}],\n",
       "  'id': 7.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '정부',\n",
       "    'position': 1101.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0786011},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '부처',\n",
       "    'position': 1107.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0610427},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '등',\n",
       "    'position': 1114.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.153512},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '으로부터',\n",
       "    'position': 1117.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0663022},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '표창',\n",
       "    'position': 1130.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.074908},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '을',\n",
       "    'position': 1136.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0830249},\n",
       "   {'id': 6.0, 'lemma': '13', 'position': 1140.0, 'type': 'SN', 'weight': 1.0},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '회',\n",
       "    'position': 1142.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.0417621},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '나',\n",
       "    'position': 1145.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.026281},\n",
       "   {'id': 9.0,\n",
       "    'lemma': '받',\n",
       "    'position': 1149.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.141768},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '은',\n",
       "    'position': 1152.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.116126},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '이흥민',\n",
       "    'position': 1156.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0525572},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '민생',\n",
       "    'position': 1166.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0574642},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '경제',\n",
       "    'position': 1172.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0488646},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '국장',\n",
       "    'position': 1178.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0433426},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '역시',\n",
       "    'position': 1185.0,\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0790521},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '고양시',\n",
       "    'position': 1192.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0728245},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '에게',\n",
       "    'position': 1201.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.057028},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '는',\n",
       "    'position': 1207.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.142711},\n",
       "   {'id': 19.0,\n",
       "    'lemma': '아깝',\n",
       "    'position': 1211.0,\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0473776},\n",
       "   {'id': 20.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 1217.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0570711},\n",
       "   {'id': 21.0,\n",
       "    'lemma': '인재',\n",
       "    'position': 1221.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0680801},\n",
       "   {'id': 22.0,\n",
       "    'lemma': '이',\n",
       "    'position': 1227.0,\n",
       "    'type': 'VCP',\n",
       "    'weight': 0.0578411},\n",
       "   {'id': 23.0,\n",
       "    'lemma': '다',\n",
       "    'position': 1227.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0616223},\n",
       "   {'id': 24.0,\n",
       "    'lemma': '.',\n",
       "    'position': 1230.0,\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': ' 정부부처 등으로부터 표창을 13회나 받은 이흥민 민생경제국장 역시 고양시에게는 아까운 인재다.',\n",
       "  'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '정부부처', 'type': ''},\n",
       "   {'begin': 2.0, 'end': 3.0, 'id': 1.0, 'text': '등으로부터', 'type': ''},\n",
       "   {'begin': 4.0, 'end': 5.0, 'id': 2.0, 'text': '표창을', 'type': ''},\n",
       "   {'begin': 6.0, 'end': 8.0, 'id': 3.0, 'text': '13회나', 'type': ''},\n",
       "   {'begin': 9.0, 'end': 10.0, 'id': 4.0, 'text': '받은', 'type': ''},\n",
       "   {'begin': 11.0, 'end': 11.0, 'id': 5.0, 'text': '이흥민', 'type': ''},\n",
       "   {'begin': 12.0, 'end': 14.0, 'id': 6.0, 'text': '민생경제국장', 'type': ''},\n",
       "   {'begin': 15.0, 'end': 15.0, 'id': 7.0, 'text': '역시', 'type': ''},\n",
       "   {'begin': 16.0, 'end': 18.0, 'id': 8.0, 'text': '고양시에게는', 'type': ''},\n",
       "   {'begin': 19.0, 'end': 20.0, 'id': 9.0, 'text': '아까운', 'type': ''},\n",
       "   {'begin': 21.0, 'end': 24.0, 'id': 10.0, 'text': '인재다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 2.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 2.0,\n",
       "    'id': 0.0,\n",
       "    'text': '고양',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.435763},\n",
       "   {'begin': 4.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 4.0,\n",
       "    'id': 1.0,\n",
       "    'text': '주민',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.461411},\n",
       "   {'begin': 19.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 19.0,\n",
       "    'id': 2.0,\n",
       "    'text': '주민',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.461171},\n",
       "   {'begin': 25.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 25.0,\n",
       "    'id': 3.0,\n",
       "    'text': '고양시',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.451072}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 1233.0,\n",
       "    'scode': '01',\n",
       "    'text': '그',\n",
       "    'type': 'NP',\n",
       "    'weight': 4.4},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 1236.0,\n",
       "    'scode': '00',\n",
       "    'text': '는',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 1240.0,\n",
       "    'scode': '06',\n",
       "    'text': '고양',\n",
       "    'type': 'NNP',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 1246.0,\n",
       "    'scode': '03',\n",
       "    'text': '지역',\n",
       "    'type': 'NNG',\n",
       "    'weight': 4.2},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 1253.0,\n",
       "    'scode': '00',\n",
       "    'text': '주민',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 5.0,\n",
       "    'position': 1259.0,\n",
       "    'scode': '09',\n",
       "    'text': '들',\n",
       "    'type': 'XSN',\n",
       "    'weight': 6.0},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 6.0,\n",
       "    'position': 1262.0,\n",
       "    'scode': '00',\n",
       "    'text': '이',\n",
       "    'type': 'JKS',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 7.0,\n",
       "    'end': 8.0,\n",
       "    'id': 7.0,\n",
       "    'position': 1266.0,\n",
       "    'scode': '00',\n",
       "    'text': '원활하',\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 8.0,\n",
       "    'position': 1272.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 9.0,\n",
       "    'position': 1276.0,\n",
       "    'scode': '00',\n",
       "    'text': '생활',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 10.0,\n",
       "    'position': 1282.0,\n",
       "    'scode': '02',\n",
       "    'text': '지원',\n",
       "    'type': 'NNG',\n",
       "    'weight': 6.2},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 11.0,\n",
       "    'position': 1288.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 12.0,\n",
       "    'position': 1292.0,\n",
       "    'scode': '01',\n",
       "    'text': '받',\n",
       "    'type': 'VV',\n",
       "    'weight': 7.59036},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 13.0,\n",
       "    'position': 1295.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 15.0,\n",
       "    'end': 15.0,\n",
       "    'id': 14.0,\n",
       "    'position': 1299.0,\n",
       "    'scode': '02',\n",
       "    'text': '수',\n",
       "    'type': 'NNB',\n",
       "    'weight': 10.9992},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 15.0,\n",
       "    'position': 1303.0,\n",
       "    'scode': '01',\n",
       "    'text': '있',\n",
       "    'type': 'VA',\n",
       "    'weight': 6.6},\n",
       "   {'begin': 17.0,\n",
       "    'end': 17.0,\n",
       "    'id': 16.0,\n",
       "    'position': 1306.0,\n",
       "    'scode': '00',\n",
       "    'text': '도록',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 18.0,\n",
       "    'end': 18.0,\n",
       "    'id': 17.0,\n",
       "    'position': 1313.0,\n",
       "    'scode': '00',\n",
       "    'text': '늘',\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 19.0,\n",
       "    'end': 19.0,\n",
       "    'id': 18.0,\n",
       "    'position': 1317.0,\n",
       "    'scode': '00',\n",
       "    'text': '주민',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 19.0,\n",
       "    'position': 1323.0,\n",
       "    'scode': '09',\n",
       "    'text': '들',\n",
       "    'type': 'XSN',\n",
       "    'weight': 5.0},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 20.0,\n",
       "    'position': 1326.0,\n",
       "    'scode': '00',\n",
       "    'text': '과',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 22.0,\n",
       "    'end': 23.0,\n",
       "    'id': 21.0,\n",
       "    'position': 1330.0,\n",
       "    'scode': '00',\n",
       "    'text': '함께하',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 24.0,\n",
       "    'end': 24.0,\n",
       "    'id': 22.0,\n",
       "    'position': 1339.0,\n",
       "    'scode': '00',\n",
       "    'text': '며',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 25.0,\n",
       "    'end': 25.0,\n",
       "    'id': 23.0,\n",
       "    'position': 1343.0,\n",
       "    'scode': '00',\n",
       "    'text': '고양시',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 26.0,\n",
       "    'end': 26.0,\n",
       "    'id': 24.0,\n",
       "    'position': 1353.0,\n",
       "    'scode': '01',\n",
       "    'text': '행정',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 27.0,\n",
       "    'end': 27.0,\n",
       "    'id': 25.0,\n",
       "    'position': 1359.0,\n",
       "    'scode': '00',\n",
       "    'text': '에',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 28.0,\n",
       "    'end': 28.0,\n",
       "    'id': 26.0,\n",
       "    'position': 1363.0,\n",
       "    'scode': '03',\n",
       "    'text': '현장',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.0},\n",
       "   {'begin': 29.0,\n",
       "    'end': 29.0,\n",
       "    'id': 27.0,\n",
       "    'position': 1369.0,\n",
       "    'scode': '00',\n",
       "    'text': '의',\n",
       "    'type': 'JKG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 30.0,\n",
       "    'end': 31.0,\n",
       "    'id': 28.0,\n",
       "    'position': 1373.0,\n",
       "    'scode': '00',\n",
       "    'text': '목소리',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 32.0,\n",
       "    'end': 32.0,\n",
       "    'id': 29.0,\n",
       "    'position': 1382.0,\n",
       "    'scode': '00',\n",
       "    'text': '를',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 33.0,\n",
       "    'end': 33.0,\n",
       "    'id': 30.0,\n",
       "    'position': 1386.0,\n",
       "    'scode': '00',\n",
       "    'text': '담아오',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 34.0,\n",
       "    'end': 34.0,\n",
       "    'id': 31.0,\n",
       "    'position': 1392.0,\n",
       "    'scode': '00',\n",
       "    'text': '았',\n",
       "    'type': 'EP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 35.0,\n",
       "    'end': 35.0,\n",
       "    'id': 32.0,\n",
       "    'position': 1395.0,\n",
       "    'scode': '00',\n",
       "    'text': '다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 36.0,\n",
       "    'end': 36.0,\n",
       "    'id': 33.0,\n",
       "    'position': 1398.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 7.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [],\n",
       "    'text': '그는',\n",
       "    'weight': 0.212},\n",
       "   {'head': 2.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '고양지역',\n",
       "    'weight': 0.41661},\n",
       "   {'head': 5.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [1.0],\n",
       "    'text': '주민들이',\n",
       "    'weight': 0.565949},\n",
       "   {'head': 4.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '원활한',\n",
       "    'weight': 0.696276},\n",
       "   {'head': 5.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [3.0],\n",
       "    'text': '생활지원을',\n",
       "    'weight': 0.60839},\n",
       "   {'head': 6.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [2.0, 4.0],\n",
       "    'text': '받을',\n",
       "    'weight': 0.722259},\n",
       "   {'head': 7.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [5.0],\n",
       "    'text': '수',\n",
       "    'weight': 0.668727},\n",
       "   {'head': 10.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [0.0, 6.0],\n",
       "    'text': '있도록',\n",
       "    'weight': 0.698144},\n",
       "   {'head': 10.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'AP',\n",
       "    'mod': [],\n",
       "    'text': '늘',\n",
       "    'weight': 0.69933},\n",
       "   {'head': 10.0,\n",
       "    'id': 9.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '주민들과',\n",
       "    'weight': 0.715647},\n",
       "   {'head': 15.0,\n",
       "    'id': 10.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [7.0, 8.0, 9.0],\n",
       "    'text': '함께하며',\n",
       "    'weight': 0.564753},\n",
       "   {'head': 12.0,\n",
       "    'id': 11.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '고양시',\n",
       "    'weight': 0.579028},\n",
       "   {'head': 15.0,\n",
       "    'id': 12.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [11.0],\n",
       "    'text': '행정에',\n",
       "    'weight': 0.743706},\n",
       "   {'head': 14.0,\n",
       "    'id': 13.0,\n",
       "    'label': 'NP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '현장의',\n",
       "    'weight': 0.535362},\n",
       "   {'head': 15.0,\n",
       "    'id': 14.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [13.0],\n",
       "    'text': '목소리를',\n",
       "    'weight': 0.687593},\n",
       "   {'head': -1.0,\n",
       "    'id': 15.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [10.0, 12.0, 14.0],\n",
       "    'text': '담아왔다.',\n",
       "    'weight': 0.000232658}],\n",
       "  'id': 8.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '그',\n",
       "    'position': 1233.0,\n",
       "    'type': 'NP',\n",
       "    'weight': 0.109226},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '는',\n",
       "    'position': 1236.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.1124},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '고양',\n",
       "    'position': 1240.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0771626},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '지역',\n",
       "    'position': 1246.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0616679},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '주민',\n",
       "    'position': 1253.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.110431},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '들',\n",
       "    'position': 1259.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0857102},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '이',\n",
       "    'position': 1262.0,\n",
       "    'type': 'JKS',\n",
       "    'weight': 0.0708404},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '원활',\n",
       "    'position': 1266.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0463476},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '하',\n",
       "    'position': 1272.0,\n",
       "    'type': 'XSA',\n",
       "    'weight': 0.0463476},\n",
       "   {'id': 9.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 1272.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0473384},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '생활',\n",
       "    'position': 1276.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0928478},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '지원',\n",
       "    'position': 1282.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0845234},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '을',\n",
       "    'position': 1288.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.101296},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '받',\n",
       "    'position': 1292.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.146405},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '을',\n",
       "    'position': 1295.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.149223},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '수',\n",
       "    'position': 1299.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.244943},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '있',\n",
       "    'position': 1303.0,\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0992615},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '도록',\n",
       "    'position': 1306.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.10274},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '늘',\n",
       "    'position': 1313.0,\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0774975},\n",
       "   {'id': 19.0,\n",
       "    'lemma': '주민',\n",
       "    'position': 1317.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0929645},\n",
       "   {'id': 20.0,\n",
       "    'lemma': '들',\n",
       "    'position': 1323.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0771089},\n",
       "   {'id': 21.0,\n",
       "    'lemma': '과',\n",
       "    'position': 1326.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0677364},\n",
       "   {'id': 22.0,\n",
       "    'lemma': '함께',\n",
       "    'position': 1330.0,\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0921061},\n",
       "   {'id': 23.0,\n",
       "    'lemma': '하',\n",
       "    'position': 1336.0,\n",
       "    'type': 'XSV',\n",
       "    'weight': 0.0453254},\n",
       "   {'id': 24.0,\n",
       "    'lemma': '며',\n",
       "    'position': 1339.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.12918},\n",
       "   {'id': 25.0,\n",
       "    'lemma': '고양시',\n",
       "    'position': 1343.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0688935},\n",
       "   {'id': 26.0,\n",
       "    'lemma': '행정',\n",
       "    'position': 1353.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.106702},\n",
       "   {'id': 27.0,\n",
       "    'lemma': '에',\n",
       "    'position': 1359.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.077173},\n",
       "   {'id': 28.0,\n",
       "    'lemma': '현장',\n",
       "    'position': 1363.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.114015},\n",
       "   {'id': 29.0,\n",
       "    'lemma': '의',\n",
       "    'position': 1369.0,\n",
       "    'type': 'JKG',\n",
       "    'weight': 0.0990535},\n",
       "   {'id': 30.0,\n",
       "    'lemma': '목',\n",
       "    'position': 1373.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.256853},\n",
       "   {'id': 31.0,\n",
       "    'lemma': '소리',\n",
       "    'position': 1376.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.256853},\n",
       "   {'id': 32.0,\n",
       "    'lemma': '를',\n",
       "    'position': 1382.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.142369},\n",
       "   {'id': 33.0,\n",
       "    'lemma': '담아오',\n",
       "    'position': 1386.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0433565},\n",
       "   {'id': 34.0,\n",
       "    'lemma': '았',\n",
       "    'position': 1392.0,\n",
       "    'type': 'EP',\n",
       "    'weight': 0.0265464},\n",
       "   {'id': 35.0,\n",
       "    'lemma': '다',\n",
       "    'position': 1395.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0881576},\n",
       "   {'id': 36.0,\n",
       "    'lemma': '.',\n",
       "    'position': 1398.0,\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': '  그는 고양지역 주민들이 원활한 생활지원을 받을 수 있도록 늘 주민들과 함께하며 고양시 행정에 현장의 목소리를 담아왔다.',\n",
       "  'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '그는', 'type': ''},\n",
       "   {'begin': 2.0, 'end': 3.0, 'id': 1.0, 'text': '고양지역', 'type': ''},\n",
       "   {'begin': 4.0, 'end': 6.0, 'id': 2.0, 'text': '주민들이', 'type': ''},\n",
       "   {'begin': 7.0, 'end': 9.0, 'id': 3.0, 'text': '원활한', 'type': ''},\n",
       "   {'begin': 10.0, 'end': 12.0, 'id': 4.0, 'text': '생활지원을', 'type': ''},\n",
       "   {'begin': 13.0, 'end': 14.0, 'id': 5.0, 'text': '받을', 'type': ''},\n",
       "   {'begin': 15.0, 'end': 15.0, 'id': 6.0, 'text': '수', 'type': ''},\n",
       "   {'begin': 16.0, 'end': 17.0, 'id': 7.0, 'text': '있도록', 'type': ''},\n",
       "   {'begin': 18.0, 'end': 18.0, 'id': 8.0, 'text': '늘', 'type': ''},\n",
       "   {'begin': 19.0, 'end': 21.0, 'id': 9.0, 'text': '주민들과', 'type': ''},\n",
       "   {'begin': 22.0, 'end': 24.0, 'id': 10.0, 'text': '함께하며', 'type': ''},\n",
       "   {'begin': 25.0, 'end': 25.0, 'id': 11.0, 'text': '고양시', 'type': ''},\n",
       "   {'begin': 26.0, 'end': 27.0, 'id': 12.0, 'text': '행정에', 'type': ''},\n",
       "   {'begin': 28.0, 'end': 29.0, 'id': 13.0, 'text': '현장의', 'type': ''},\n",
       "   {'begin': 30.0, 'end': 32.0, 'id': 14.0, 'text': '목소리를', 'type': ''},\n",
       "   {'begin': 33.0, 'end': 36.0, 'id': 15.0, 'text': '담아왔다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 0.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'text': '노양호',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.333467},\n",
       "   {'begin': 1.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 3.0,\n",
       "    'id': 1.0,\n",
       "    'text': '여성가족국장',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.378504},\n",
       "   {'begin': 5.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 5.0,\n",
       "    'id': 2.0,\n",
       "    'text': '고양',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.481313},\n",
       "   {'begin': 11.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 12.0,\n",
       "    'id': 3.0,\n",
       "    'text': '40년',\n",
       "    'type': 'DT_DURATION',\n",
       "    'weight': 0.557002}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 1400.0,\n",
       "    'scode': '00',\n",
       "    'text': '노양호',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 1410.0,\n",
       "    'scode': '01',\n",
       "    'text': '여성',\n",
       "    'type': 'NNG',\n",
       "    'weight': 6.0},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 1416.0,\n",
       "    'scode': '01',\n",
       "    'text': '가족',\n",
       "    'type': 'NNG',\n",
       "    'weight': 6.4},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 1422.0,\n",
       "    'scode': '01',\n",
       "    'text': '국장',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.0},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 1428.0,\n",
       "    'scode': '00',\n",
       "    'text': '도',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 5.0,\n",
       "    'position': 1432.0,\n",
       "    'scode': '06',\n",
       "    'text': '고양',\n",
       "    'type': 'NNP',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 6.0,\n",
       "    'position': 1438.0,\n",
       "    'scode': '03',\n",
       "    'text': '지역',\n",
       "    'type': 'NNG',\n",
       "    'weight': 10.6},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 7.0,\n",
       "    'position': 1445.0,\n",
       "    'scode': '01',\n",
       "    'text': '발전',\n",
       "    'type': 'NNG',\n",
       "    'weight': 7.56933},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 8.0,\n",
       "    'position': 1451.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 9.0,\n",
       "    'position': 1455.0,\n",
       "    'scode': '01',\n",
       "    'text': '위하',\n",
       "    'type': 'VV',\n",
       "    'weight': 5.4},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 10.0,\n",
       "    'position': 1458.0,\n",
       "    'scode': '00',\n",
       "    'text': '어',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 11.0,\n",
       "    'position': 1462.0,\n",
       "    'scode': '00',\n",
       "    'text': '40',\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 12.0,\n",
       "    'position': 1464.0,\n",
       "    'scode': '02',\n",
       "    'text': '년',\n",
       "    'type': 'NNB',\n",
       "    'weight': 10.9979},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 13.0,\n",
       "    'position': 1468.0,\n",
       "    'scode': '01',\n",
       "    'text': '넘',\n",
       "    'type': 'VV',\n",
       "    'weight': 3.2},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 14.0,\n",
       "    'position': 1471.0,\n",
       "    'scode': '00',\n",
       "    'text': '게',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 15.0,\n",
       "    'end': 15.0,\n",
       "    'id': 15.0,\n",
       "    'position': 1475.0,\n",
       "    'scode': '02',\n",
       "    'text': '예산',\n",
       "    'type': 'NNG',\n",
       "    'weight': 4.2},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 16.0,\n",
       "    'position': 1481.0,\n",
       "    'scode': '01',\n",
       "    'text': '법무',\n",
       "    'type': 'NNG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 17.0,\n",
       "    'end': 17.0,\n",
       "    'id': 17.0,\n",
       "    'position': 1487.0,\n",
       "    'scode': '14',\n",
       "    'text': '과',\n",
       "    'type': 'XSN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 18.0,\n",
       "    'end': 18.0,\n",
       "    'id': 18.0,\n",
       "    'position': 1491.0,\n",
       "    'scode': '05',\n",
       "    'text': '등',\n",
       "    'type': 'NNB',\n",
       "    'weight': 8.4},\n",
       "   {'begin': 19.0,\n",
       "    'end': 19.0,\n",
       "    'id': 19.0,\n",
       "    'position': 1495.0,\n",
       "    'scode': '01',\n",
       "    'text': '주요',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 20.0,\n",
       "    'position': 1501.0,\n",
       "    'scode': '12',\n",
       "    'text': '부서',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.0},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 21.0,\n",
       "    'position': 1507.0,\n",
       "    'scode': '00',\n",
       "    'text': '에서',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 22.0,\n",
       "    'end': 23.0,\n",
       "    'id': 22.0,\n",
       "    'position': 1514.0,\n",
       "    'scode': '00',\n",
       "    'text': '활약하',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 24.0,\n",
       "    'end': 24.0,\n",
       "    'id': 23.0,\n",
       "    'position': 1520.0,\n",
       "    'scode': '00',\n",
       "    'text': '어',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 25.0,\n",
       "    'end': 25.0,\n",
       "    'id': 24.0,\n",
       "    'position': 1524.0,\n",
       "    'scode': '01',\n",
       "    'text': '오',\n",
       "    'type': 'VX',\n",
       "    'weight': 4.2},\n",
       "   {'begin': 26.0,\n",
       "    'end': 26.0,\n",
       "    'id': 25.0,\n",
       "    'position': 1524.0,\n",
       "    'scode': '00',\n",
       "    'text': '았',\n",
       "    'type': 'EP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 27.0,\n",
       "    'end': 27.0,\n",
       "    'id': 26.0,\n",
       "    'position': 1527.0,\n",
       "    'scode': '00',\n",
       "    'text': '다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 28.0,\n",
       "    'end': 28.0,\n",
       "    'id': 27.0,\n",
       "    'position': 1530.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 1.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '노양호',\n",
       "    'weight': 0.472935},\n",
       "   {'head': 4.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [0.0],\n",
       "    'text': '여성가족국장도',\n",
       "    'weight': 0.296624},\n",
       "   {'head': 3.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '고양지역',\n",
       "    'weight': 0.665069},\n",
       "   {'head': 4.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [2.0],\n",
       "    'text': '발전을',\n",
       "    'weight': 0.710175},\n",
       "   {'head': 6.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [1.0, 3.0],\n",
       "    'text': '위해',\n",
       "    'weight': 0.713761},\n",
       "   {'head': 6.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [],\n",
       "    'text': '40년',\n",
       "    'weight': 0.180268},\n",
       "   {'head': 10.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [4.0, 5.0],\n",
       "    'text': '넘게',\n",
       "    'weight': 0.25906},\n",
       "   {'head': 8.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '예산법무과',\n",
       "    'weight': 0.732728},\n",
       "   {'head': 9.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [7.0],\n",
       "    'text': '등',\n",
       "    'weight': 0.0252941},\n",
       "   {'head': 10.0,\n",
       "    'id': 9.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [8.0],\n",
       "    'text': '주요부서에서',\n",
       "    'weight': 0.738762},\n",
       "   {'head': 11.0,\n",
       "    'id': 10.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [6.0, 9.0],\n",
       "    'text': '활약해',\n",
       "    'weight': 0.73942},\n",
       "   {'head': -1.0,\n",
       "    'id': 11.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [10.0],\n",
       "    'text': '왔다.',\n",
       "    'weight': 1.86152e-05}],\n",
       "  'id': 9.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '노양호',\n",
       "    'position': 1400.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0601613},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '여성',\n",
       "    'position': 1410.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0976816},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '가족',\n",
       "    'position': 1416.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0594258},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '국장',\n",
       "    'position': 1422.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0415428},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '도',\n",
       "    'position': 1428.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.113391},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '고양',\n",
       "    'position': 1432.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0600651},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '지역',\n",
       "    'position': 1438.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0726147},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '발전',\n",
       "    'position': 1445.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0805563},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '을',\n",
       "    'position': 1451.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0944437},\n",
       "   {'id': 9.0,\n",
       "    'lemma': '위하',\n",
       "    'position': 1455.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0945465},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '어',\n",
       "    'position': 1458.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0679444},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '40',\n",
       "    'position': 1462.0,\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '년',\n",
       "    'position': 1464.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.0652439},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '넘',\n",
       "    'position': 1468.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0538848},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '게',\n",
       "    'position': 1471.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0637545},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '예산',\n",
       "    'position': 1475.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.123562},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '법무',\n",
       "    'position': 1481.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0257218},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '과',\n",
       "    'position': 1487.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0257218},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '등',\n",
       "    'position': 1491.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.132083},\n",
       "   {'id': 19.0,\n",
       "    'lemma': '주요',\n",
       "    'position': 1495.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0642861},\n",
       "   {'id': 20.0,\n",
       "    'lemma': '부서',\n",
       "    'position': 1501.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0562746},\n",
       "   {'id': 21.0,\n",
       "    'lemma': '에서',\n",
       "    'position': 1507.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0824276},\n",
       "   {'id': 22.0,\n",
       "    'lemma': '활약',\n",
       "    'position': 1514.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0375543},\n",
       "   {'id': 23.0,\n",
       "    'lemma': '하',\n",
       "    'position': 1520.0,\n",
       "    'type': 'XSV',\n",
       "    'weight': 0.0375543},\n",
       "   {'id': 24.0,\n",
       "    'lemma': '어',\n",
       "    'position': 1520.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0460888},\n",
       "   {'id': 25.0,\n",
       "    'lemma': '오',\n",
       "    'position': 1524.0,\n",
       "    'type': 'VX',\n",
       "    'weight': 0.083447},\n",
       "   {'id': 26.0,\n",
       "    'lemma': '았',\n",
       "    'position': 1524.0,\n",
       "    'type': 'EP',\n",
       "    'weight': 0.083447},\n",
       "   {'id': 27.0,\n",
       "    'lemma': '다',\n",
       "    'position': 1527.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0906551},\n",
       "   {'id': 28.0,\n",
       "    'lemma': '.',\n",
       "    'position': 1530.0,\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': ' 노양호 여성가족국장도 고양지역 발전을 위해 40년 넘게 예산법무과 등 주요부서에서 활약해 왔다.',\n",
       "  'word': [{'begin': 0.0, 'end': 0.0, 'id': 0.0, 'text': '노양호', 'type': ''},\n",
       "   {'begin': 1.0, 'end': 4.0, 'id': 1.0, 'text': '여성가족국장도', 'type': ''},\n",
       "   {'begin': 5.0, 'end': 6.0, 'id': 2.0, 'text': '고양지역', 'type': ''},\n",
       "   {'begin': 7.0, 'end': 8.0, 'id': 3.0, 'text': '발전을', 'type': ''},\n",
       "   {'begin': 9.0, 'end': 10.0, 'id': 4.0, 'text': '위해', 'type': ''},\n",
       "   {'begin': 11.0, 'end': 12.0, 'id': 5.0, 'text': '40년', 'type': ''},\n",
       "   {'begin': 13.0, 'end': 14.0, 'id': 6.0, 'text': '넘게', 'type': ''},\n",
       "   {'begin': 15.0, 'end': 17.0, 'id': 7.0, 'text': '예산법무과', 'type': ''},\n",
       "   {'begin': 18.0, 'end': 18.0, 'id': 8.0, 'text': '등', 'type': ''},\n",
       "   {'begin': 19.0, 'end': 21.0, 'id': 9.0, 'text': '주요부서에서', 'type': ''},\n",
       "   {'begin': 22.0, 'end': 24.0, 'id': 10.0, 'text': '활약해', 'type': ''},\n",
       "   {'begin': 25.0, 'end': 28.0, 'id': 11.0, 'text': '왔다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 1.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 3.0,\n",
       "    'id': 0.0,\n",
       "    'text': '교육지원과장',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.508763},\n",
       "   {'begin': 7.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 7.0,\n",
       "    'id': 1.0,\n",
       "    'text': '고양',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.496913},\n",
       "   {'begin': 9.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 9.0,\n",
       "    'id': 2.0,\n",
       "    'text': '학생',\n",
       "    'type': 'CV_OCCUPATION',\n",
       "    'weight': 0.650918}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 1533.0,\n",
       "    'scode': '00',\n",
       "    'text': '특히',\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 1540.0,\n",
       "    'scode': '00',\n",
       "    'text': '교육',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 1546.0,\n",
       "    'scode': '02',\n",
       "    'text': '지원',\n",
       "    'type': 'NNG',\n",
       "    'weight': 6.0},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 1552.0,\n",
       "    'scode': '07',\n",
       "    'text': '과장',\n",
       "    'type': 'NNG',\n",
       "    'weight': 5.23077},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 1559.0,\n",
       "    'scode': '01',\n",
       "    'text': '시절',\n",
       "    'type': 'NNG',\n",
       "    'weight': 6.2},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 5.0,\n",
       "    'position': 1565.0,\n",
       "    'scode': '00',\n",
       "    'text': '에',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 6.0,\n",
       "    'position': 1568.0,\n",
       "    'scode': '00',\n",
       "    'text': '는',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 7.0,\n",
       "    'position': 1572.0,\n",
       "    'scode': '06',\n",
       "    'text': '고양',\n",
       "    'type': 'NNP',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 8.0,\n",
       "    'position': 1578.0,\n",
       "    'scode': '03',\n",
       "    'text': '지역',\n",
       "    'type': 'NNG',\n",
       "    'weight': 13.8},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 9.0,\n",
       "    'position': 1585.0,\n",
       "    'scode': '00',\n",
       "    'text': '학생',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 10.0,\n",
       "    'position': 1591.0,\n",
       "    'scode': '09',\n",
       "    'text': '들',\n",
       "    'type': 'XSN',\n",
       "    'weight': 7.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 11.0,\n",
       "    'position': 1594.0,\n",
       "    'scode': '00',\n",
       "    'text': '의',\n",
       "    'type': 'JKG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 12.0,\n",
       "    'position': 1598.0,\n",
       "    'scode': '00',\n",
       "    'text': '교육',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 13.0,\n",
       "    'position': 1604.0,\n",
       "    'scode': '02',\n",
       "    'text': '환경',\n",
       "    'type': 'NNG',\n",
       "    'weight': 10.8},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 14.0,\n",
       "    'position': 1611.0,\n",
       "    'scode': '01',\n",
       "    'text': '개선',\n",
       "    'type': 'NNG',\n",
       "    'weight': 9.8},\n",
       "   {'begin': 15.0,\n",
       "    'end': 15.0,\n",
       "    'id': 15.0,\n",
       "    'position': 1617.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 16.0,\n",
       "    'position': 1621.0,\n",
       "    'scode': '01',\n",
       "    'text': '위하',\n",
       "    'type': 'VV',\n",
       "    'weight': 11.0},\n",
       "   {'begin': 17.0,\n",
       "    'end': 17.0,\n",
       "    'id': 17.0,\n",
       "    'position': 1624.0,\n",
       "    'scode': '00',\n",
       "    'text': '어',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 18.0,\n",
       "    'end': 18.0,\n",
       "    'id': 18.0,\n",
       "    'position': 1628.0,\n",
       "    'scode': '01',\n",
       "    'text': '노력',\n",
       "    'type': 'NNG',\n",
       "    'weight': 7.6},\n",
       "   {'begin': 19.0,\n",
       "    'end': 19.0,\n",
       "    'id': 19.0,\n",
       "    'position': 1634.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 20.0,\n",
       "    'position': 1638.0,\n",
       "    'scode': '00',\n",
       "    'text': '아끼',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 21.0,\n",
       "    'position': 1644.0,\n",
       "    'scode': '00',\n",
       "    'text': '지',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 22.0,\n",
       "    'end': 22.0,\n",
       "    'id': 22.0,\n",
       "    'position': 1648.0,\n",
       "    'scode': '00',\n",
       "    'text': '않',\n",
       "    'type': 'VX',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 23.0,\n",
       "    'end': 23.0,\n",
       "    'id': 23.0,\n",
       "    'position': 1651.0,\n",
       "    'scode': '00',\n",
       "    'text': '았',\n",
       "    'type': 'EP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 24.0,\n",
       "    'end': 24.0,\n",
       "    'id': 24.0,\n",
       "    'position': 1654.0,\n",
       "    'scode': '00',\n",
       "    'text': '다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 25.0,\n",
       "    'end': 25.0,\n",
       "    'id': 25.0,\n",
       "    'position': 1657.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 7.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'AP',\n",
       "    'mod': [],\n",
       "    'text': '특히',\n",
       "    'weight': 0.628373},\n",
       "   {'head': 2.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '교육지원과장',\n",
       "    'weight': 0.592826},\n",
       "   {'head': 7.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [1.0],\n",
       "    'text': '시절에는',\n",
       "    'weight': 0.53014},\n",
       "   {'head': 4.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '고양지역',\n",
       "    'weight': 0.448153},\n",
       "   {'head': 6.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'NP_MOD',\n",
       "    'mod': [3.0],\n",
       "    'text': '학생들의',\n",
       "    'weight': 0.656003},\n",
       "   {'head': 6.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '교육환경',\n",
       "    'weight': 0.586248},\n",
       "   {'head': 7.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [4.0, 5.0],\n",
       "    'text': '개선을',\n",
       "    'weight': 0.652301},\n",
       "   {'head': 9.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [0.0, 2.0, 6.0],\n",
       "    'text': '위해',\n",
       "    'weight': 0.760105},\n",
       "   {'head': 9.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [],\n",
       "    'text': '노력을',\n",
       "    'weight': 0.655741},\n",
       "   {'head': 10.0,\n",
       "    'id': 9.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [7.0, 8.0],\n",
       "    'text': '아끼지',\n",
       "    'weight': 0.670569},\n",
       "   {'head': -1.0,\n",
       "    'id': 10.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [9.0],\n",
       "    'text': '않았다.',\n",
       "    'weight': 0.00581716}],\n",
       "  'id': 10.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '특히',\n",
       "    'position': 1533.0,\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0875818},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '교육',\n",
       "    'position': 1540.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0855396},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '지원',\n",
       "    'position': 1546.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0898435},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '과장',\n",
       "    'position': 1552.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0356463},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '시절',\n",
       "    'position': 1559.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0940224},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '에',\n",
       "    'position': 1565.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0720916},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '는',\n",
       "    'position': 1568.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.134751},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '고양',\n",
       "    'position': 1572.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0642053},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '지역',\n",
       "    'position': 1578.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0648163},\n",
       "   {'id': 9.0,\n",
       "    'lemma': '학생',\n",
       "    'position': 1585.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.107385},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '들',\n",
       "    'position': 1591.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0838698},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '의',\n",
       "    'position': 1594.0,\n",
       "    'type': 'JKG',\n",
       "    'weight': 0.0934142},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '교육',\n",
       "    'position': 1598.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0871301},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '환경',\n",
       "    'position': 1604.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0440539},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '개선',\n",
       "    'position': 1611.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.108937},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '을',\n",
       "    'position': 1617.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.093356},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '위하',\n",
       "    'position': 1621.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.101799},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '어',\n",
       "    'position': 1624.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.083466},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '노력',\n",
       "    'position': 1628.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0857289},\n",
       "   {'id': 19.0,\n",
       "    'lemma': '을',\n",
       "    'position': 1634.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0891093},\n",
       "   {'id': 20.0,\n",
       "    'lemma': '아끼',\n",
       "    'position': 1638.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0425844},\n",
       "   {'id': 21.0,\n",
       "    'lemma': '지',\n",
       "    'position': 1644.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.1324},\n",
       "   {'id': 22.0,\n",
       "    'lemma': '않',\n",
       "    'position': 1648.0,\n",
       "    'type': 'VX',\n",
       "    'weight': 0.117938},\n",
       "   {'id': 23.0,\n",
       "    'lemma': '았',\n",
       "    'position': 1651.0,\n",
       "    'type': 'EP',\n",
       "    'weight': 0.0689724},\n",
       "   {'id': 24.0,\n",
       "    'lemma': '다',\n",
       "    'position': 1654.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0735122},\n",
       "   {'id': 25.0,\n",
       "    'lemma': '.',\n",
       "    'position': 1657.0,\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': '  특히 교육지원과장 시절에는 고양지역 학생들의 교육환경 개선을 위해 노력을 아끼지 않았다.',\n",
       "  'word': [{'begin': 0.0, 'end': 0.0, 'id': 0.0, 'text': '특히', 'type': ''},\n",
       "   {'begin': 1.0, 'end': 3.0, 'id': 1.0, 'text': '교육지원과장', 'type': ''},\n",
       "   {'begin': 4.0, 'end': 6.0, 'id': 2.0, 'text': '시절에는', 'type': ''},\n",
       "   {'begin': 7.0, 'end': 8.0, 'id': 3.0, 'text': '고양지역', 'type': ''},\n",
       "   {'begin': 9.0, 'end': 11.0, 'id': 4.0, 'text': '학생들의', 'type': ''},\n",
       "   {'begin': 12.0, 'end': 13.0, 'id': 5.0, 'text': '교육환경', 'type': ''},\n",
       "   {'begin': 14.0, 'end': 15.0, 'id': 6.0, 'text': '개선을', 'type': ''},\n",
       "   {'begin': 16.0, 'end': 17.0, 'id': 7.0, 'text': '위해', 'type': ''},\n",
       "   {'begin': 18.0, 'end': 19.0, 'id': 8.0, 'text': '노력을', 'type': ''},\n",
       "   {'begin': 20.0, 'end': 21.0, 'id': 9.0, 'text': '아끼지', 'type': ''},\n",
       "   {'begin': 22.0, 'end': 25.0, 'id': 10.0, 'text': '않았다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 2.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 3.0,\n",
       "    'id': 0.0,\n",
       "    'text': '전문가',\n",
       "    'type': 'CV_OCCUPATION',\n",
       "    'weight': 0.69013},\n",
       "   {'begin': 6.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 6.0,\n",
       "    'id': 1.0,\n",
       "    'text': '정종현',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.7836},\n",
       "   {'begin': 7.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 9.0,\n",
       "    'id': 2.0,\n",
       "    'text': '농업기술센터',\n",
       "    'type': 'OGG_POLITICS',\n",
       "    'weight': 0.931462},\n",
       "   {'begin': 12.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 12.0,\n",
       "    'id': 3.0,\n",
       "    'text': '고양',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.504681}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 1659.0,\n",
       "    'scode': '00',\n",
       "    'text': '농업',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 1666.0,\n",
       "    'scode': '00',\n",
       "    'text': '분야',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 2.0,\n",
       "    'end': 3.0,\n",
       "    'id': 2.0,\n",
       "    'position': 1673.0,\n",
       "    'scode': '00',\n",
       "    'text': '전문가',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 3.0,\n",
       "    'position': 1682.0,\n",
       "    'scode': '01',\n",
       "    'text': '이',\n",
       "    'type': 'VCP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 4.0,\n",
       "    'position': 1682.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 5.0,\n",
       "    'position': 1686.0,\n",
       "    'scode': '00',\n",
       "    'text': '정종현',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 7.0,\n",
       "    'end': 8.0,\n",
       "    'id': 6.0,\n",
       "    'position': 1696.0,\n",
       "    'scode': '00',\n",
       "    'text': '농업기술',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 7.0,\n",
       "    'position': 1708.0,\n",
       "    'scode': '02',\n",
       "    'text': '센터',\n",
       "    'type': 'NNG',\n",
       "    'weight': 8.0},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 8.0,\n",
       "    'position': 1714.0,\n",
       "    'scode': '08',\n",
       "    'text': '소장',\n",
       "    'type': 'NNG',\n",
       "    'weight': 4.33333},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 9.0,\n",
       "    'position': 1720.0,\n",
       "    'scode': '00',\n",
       "    'text': '도',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 10.0,\n",
       "    'position': 1724.0,\n",
       "    'scode': '06',\n",
       "    'text': '고양',\n",
       "    'type': 'NNP',\n",
       "    'weight': 4.0},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 11.0,\n",
       "    'position': 1730.0,\n",
       "    'scode': '03',\n",
       "    'text': '지역',\n",
       "    'type': 'NNG',\n",
       "    'weight': 11.6},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 12.0,\n",
       "    'position': 1736.0,\n",
       "    'scode': '00',\n",
       "    'text': '의',\n",
       "    'type': 'JKG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 15.0,\n",
       "    'end': 15.0,\n",
       "    'id': 13.0,\n",
       "    'position': 1740.0,\n",
       "    'scode': '00',\n",
       "    'text': '농업',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 14.0,\n",
       "    'position': 1746.0,\n",
       "    'scode': '00',\n",
       "    'text': '이',\n",
       "    'type': 'JKS',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 17.0,\n",
       "    'end': 19.0,\n",
       "    'id': 15.0,\n",
       "    'position': 1750.0,\n",
       "    'scode': '00',\n",
       "    'text': '활성화되',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 16.0,\n",
       "    'position': 1762.0,\n",
       "    'scode': '00',\n",
       "    'text': '기',\n",
       "    'type': 'ETN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 17.0,\n",
       "    'position': 1765.0,\n",
       "    'scode': '00',\n",
       "    'text': '까지',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 22.0,\n",
       "    'end': 22.0,\n",
       "    'id': 18.0,\n",
       "    'position': 1772.0,\n",
       "    'scode': '00',\n",
       "    'text': '많',\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 23.0,\n",
       "    'end': 23.0,\n",
       "    'id': 19.0,\n",
       "    'position': 1775.0,\n",
       "    'scode': '00',\n",
       "    'text': '은',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 24.0,\n",
       "    'end': 24.0,\n",
       "    'id': 20.0,\n",
       "    'position': 1779.0,\n",
       "    'scode': '01',\n",
       "    'text': '자취',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.2},\n",
       "   {'begin': 25.0,\n",
       "    'end': 25.0,\n",
       "    'id': 21.0,\n",
       "    'position': 1785.0,\n",
       "    'scode': '00',\n",
       "    'text': '를',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 26.0,\n",
       "    'end': 26.0,\n",
       "    'id': 22.0,\n",
       "    'position': 1789.0,\n",
       "    'scode': '00',\n",
       "    'text': '남기',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 27.0,\n",
       "    'end': 27.0,\n",
       "    'id': 23.0,\n",
       "    'position': 1792.0,\n",
       "    'scode': '00',\n",
       "    'text': '었',\n",
       "    'type': 'EP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 28.0,\n",
       "    'end': 28.0,\n",
       "    'id': 24.0,\n",
       "    'position': 1795.0,\n",
       "    'scode': '00',\n",
       "    'text': '다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 29.0,\n",
       "    'end': 29.0,\n",
       "    'id': 25.0,\n",
       "    'position': 1798.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 1.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '농업',\n",
       "    'weight': 0.74298},\n",
       "   {'head': 2.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [0.0],\n",
       "    'text': '분야',\n",
       "    'weight': 0.517246},\n",
       "   {'head': 4.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'VNP_MOD',\n",
       "    'mod': [1.0],\n",
       "    'text': '전문가인',\n",
       "    'weight': 0.68837},\n",
       "   {'head': 4.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '정종현',\n",
       "    'weight': 0.608095},\n",
       "   {'head': 7.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [2.0, 3.0],\n",
       "    'text': '농업기술센터소장도',\n",
       "    'weight': 0.411318},\n",
       "   {'head': 6.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'NP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '고양지역의',\n",
       "    'weight': 0.737632},\n",
       "   {'head': 7.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [5.0],\n",
       "    'text': '농업이',\n",
       "    'weight': 0.580365},\n",
       "   {'head': 10.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [4.0, 6.0],\n",
       "    'text': '활성화되기까지',\n",
       "    'weight': 0.0421968},\n",
       "   {'head': 9.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '많은',\n",
       "    'weight': 0.678651},\n",
       "   {'head': 10.0,\n",
       "    'id': 9.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [8.0],\n",
       "    'text': '자취를',\n",
       "    'weight': 0.708052},\n",
       "   {'head': -1.0,\n",
       "    'id': 10.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [7.0, 9.0],\n",
       "    'text': '남겼다.',\n",
       "    'weight': 0.000450091}],\n",
       "  'id': 11.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '농업',\n",
       "    'position': 1659.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.10922},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '분야',\n",
       "    'position': 1666.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.071304},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '전문',\n",
       "    'position': 1673.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.173507},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '가',\n",
       "    'position': 1679.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.173507},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '이',\n",
       "    'position': 1682.0,\n",
       "    'type': 'VCP',\n",
       "    'weight': 0.0547664},\n",
       "   {'id': 5.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 1682.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0547664},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '정종현',\n",
       "    'position': 1686.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.12416},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '농업',\n",
       "    'position': 1696.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0952179},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '기술',\n",
       "    'position': 1702.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0412843},\n",
       "   {'id': 9.0,\n",
       "    'lemma': '센터',\n",
       "    'position': 1708.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0429968},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '소장',\n",
       "    'position': 1714.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0323335},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '도',\n",
       "    'position': 1720.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.114431},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '고양',\n",
       "    'position': 1724.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0588187},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '지역',\n",
       "    'position': 1730.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0845331},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '의',\n",
       "    'position': 1736.0,\n",
       "    'type': 'JKG',\n",
       "    'weight': 0.0868864},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '농업',\n",
       "    'position': 1740.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.13515},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '이',\n",
       "    'position': 1746.0,\n",
       "    'type': 'JKS',\n",
       "    'weight': 0.0564915},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '활성',\n",
       "    'position': 1750.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0692608},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '화',\n",
       "    'position': 1756.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0692608},\n",
       "   {'id': 19.0,\n",
       "    'lemma': '되',\n",
       "    'position': 1759.0,\n",
       "    'type': 'XSV',\n",
       "    'weight': 0.0692608},\n",
       "   {'id': 20.0,\n",
       "    'lemma': '기',\n",
       "    'position': 1762.0,\n",
       "    'type': 'ETN',\n",
       "    'weight': 0.0674635},\n",
       "   {'id': 21.0,\n",
       "    'lemma': '까지',\n",
       "    'position': 1765.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.0844549},\n",
       "   {'id': 22.0,\n",
       "    'lemma': '많',\n",
       "    'position': 1772.0,\n",
       "    'type': 'VA',\n",
       "    'weight': 0.150679},\n",
       "   {'id': 23.0,\n",
       "    'lemma': '은',\n",
       "    'position': 1775.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0931828},\n",
       "   {'id': 24.0,\n",
       "    'lemma': '자취',\n",
       "    'position': 1779.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.078162},\n",
       "   {'id': 25.0,\n",
       "    'lemma': '를',\n",
       "    'position': 1785.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.112802},\n",
       "   {'id': 26.0,\n",
       "    'lemma': '남기',\n",
       "    'position': 1789.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0571381},\n",
       "   {'id': 27.0,\n",
       "    'lemma': '었',\n",
       "    'position': 1792.0,\n",
       "    'type': 'EP',\n",
       "    'weight': 0.0405717},\n",
       "   {'id': 28.0,\n",
       "    'lemma': '다',\n",
       "    'position': 1795.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0731151},\n",
       "   {'id': 29.0,\n",
       "    'lemma': '.',\n",
       "    'position': 1798.0,\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': ' 농업 분야 전문가인 정종현 농업기술센터소장도 고양지역의 농업이 활성화되기까지 많은 자취를 남겼다.',\n",
       "  'word': [{'begin': 0.0, 'end': 0.0, 'id': 0.0, 'text': '농업', 'type': ''},\n",
       "   {'begin': 1.0, 'end': 1.0, 'id': 1.0, 'text': '분야', 'type': ''},\n",
       "   {'begin': 2.0, 'end': 5.0, 'id': 2.0, 'text': '전문가인', 'type': ''},\n",
       "   {'begin': 6.0, 'end': 6.0, 'id': 3.0, 'text': '정종현', 'type': ''},\n",
       "   {'begin': 7.0, 'end': 11.0, 'id': 4.0, 'text': '농업기술센터소장도', 'type': ''},\n",
       "   {'begin': 12.0, 'end': 14.0, 'id': 5.0, 'text': '고양지역의', 'type': ''},\n",
       "   {'begin': 15.0, 'end': 16.0, 'id': 6.0, 'text': '농업이', 'type': ''},\n",
       "   {'begin': 17.0, 'end': 21.0, 'id': 7.0, 'text': '활성화되기까지', 'type': ''},\n",
       "   {'begin': 22.0, 'end': 23.0, 'id': 8.0, 'text': '많은', 'type': ''},\n",
       "   {'begin': 24.0, 'end': 25.0, 'id': 9.0, 'text': '자취를', 'type': ''},\n",
       "   {'begin': 26.0, 'end': 29.0, 'id': 10.0, 'text': '남겼다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 0.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 1.0,\n",
       "    'id': 0.0,\n",
       "    'text': '2016년',\n",
       "    'type': 'DT_YEAR',\n",
       "    'weight': 0.834758},\n",
       "   {'begin': 4.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 5.0,\n",
       "    'id': 1.0,\n",
       "    'text': '녹조근정훈장',\n",
       "    'type': 'CV_PRIZE',\n",
       "    'weight': 0.573311}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 1801.0,\n",
       "    'scode': '00',\n",
       "    'text': '2016',\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 1805.0,\n",
       "    'scode': '02',\n",
       "    'text': '년',\n",
       "    'type': 'NNB',\n",
       "    'weight': 2.2},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 1808.0,\n",
       "    'scode': '00',\n",
       "    'text': '에',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 1811.0,\n",
       "    'scode': '00',\n",
       "    'text': '는',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 1815.0,\n",
       "    'scode': '00',\n",
       "    'text': '녹조근정',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 5.0,\n",
       "    'position': 1827.0,\n",
       "    'scode': '05',\n",
       "    'text': '훈장',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.05394},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 6.0,\n",
       "    'position': 1834.0,\n",
       "    'scode': '03',\n",
       "    'text': '영예',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.2},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 7.0,\n",
       "    'position': 1840.0,\n",
       "    'scode': '00',\n",
       "    'text': '를',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 8.0,\n",
       "    'position': 1844.0,\n",
       "    'scode': '01',\n",
       "    'text': '받',\n",
       "    'type': 'VV',\n",
       "    'weight': 4.4},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 9.0,\n",
       "    'position': 1847.0,\n",
       "    'scode': '00',\n",
       "    'text': '기',\n",
       "    'type': 'ETN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 10.0,\n",
       "    'position': 1850.0,\n",
       "    'scode': '00',\n",
       "    'text': '도',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 11.0,\n",
       "    'position': 1854.0,\n",
       "    'scode': '01',\n",
       "    'text': '하',\n",
       "    'type': 'VX',\n",
       "    'weight': 3.2},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 12.0,\n",
       "    'position': 1854.0,\n",
       "    'scode': '00',\n",
       "    'text': '었',\n",
       "    'type': 'EP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 13.0,\n",
       "    'position': 1857.0,\n",
       "    'scode': '00',\n",
       "    'text': '다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 14.0,\n",
       "    'position': 1860.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 3.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '2016년에는',\n",
       "    'weight': 0.813216},\n",
       "   {'head': 2.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '녹조근정훈장',\n",
       "    'weight': 0.370594},\n",
       "   {'head': 3.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [1.0],\n",
       "    'text': '영예를',\n",
       "    'weight': 0.630155},\n",
       "   {'head': 4.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [0.0, 2.0],\n",
       "    'text': '받기도',\n",
       "    'weight': 0.513336},\n",
       "   {'head': -1.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [3.0],\n",
       "    'text': '했다.',\n",
       "    'weight': 0.0765187}],\n",
       "  'id': 12.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '2016',\n",
       "    'position': 1801.0,\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '년',\n",
       "    'position': 1805.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.0682491},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '에',\n",
       "    'position': 1808.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0721319},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '는',\n",
       "    'position': 1811.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.133756},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '녹조근정',\n",
       "    'position': 1815.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0175061},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '훈장',\n",
       "    'position': 1827.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0316799},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '영예',\n",
       "    'position': 1834.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.054301},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '를',\n",
       "    'position': 1840.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.123072},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '받',\n",
       "    'position': 1844.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.156233},\n",
       "   {'id': 9.0,\n",
       "    'lemma': '기',\n",
       "    'position': 1847.0,\n",
       "    'type': 'ETN',\n",
       "    'weight': 0.193035},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '도',\n",
       "    'position': 1850.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.119307},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '하',\n",
       "    'position': 1854.0,\n",
       "    'type': 'VX',\n",
       "    'weight': 0.0681144},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '었',\n",
       "    'position': 1854.0,\n",
       "    'type': 'EP',\n",
       "    'weight': 0.0681144},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '다',\n",
       "    'position': 1857.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.104497},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '.',\n",
       "    'position': 1860.0,\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': '  2016년에는 녹조근정훈장 영예를 받기도 했다.',\n",
       "  'word': [{'begin': 0.0,\n",
       "    'end': 3.0,\n",
       "    'id': 0.0,\n",
       "    'text': '2016년에는',\n",
       "    'type': ''},\n",
       "   {'begin': 4.0, 'end': 5.0, 'id': 1.0, 'text': '녹조근정훈장', 'type': ''},\n",
       "   {'begin': 6.0, 'end': 7.0, 'id': 2.0, 'text': '영예를', 'type': ''},\n",
       "   {'begin': 8.0, 'end': 10.0, 'id': 3.0, 'text': '받기도', 'type': ''},\n",
       "   {'begin': 11.0, 'end': 14.0, 'id': 4.0, 'text': '했다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 0.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'text': '신승일',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.281364},\n",
       "   {'begin': 1.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 4.0,\n",
       "    'id': 1.0,\n",
       "    'text': '시민안전주택국장',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.291359}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 1862.0,\n",
       "    'scode': '00',\n",
       "    'text': '신승일',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 1872.0,\n",
       "    'scode': '00',\n",
       "    'text': '시민',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 1878.0,\n",
       "    'scode': '03',\n",
       "    'text': '안전',\n",
       "    'type': 'NNG',\n",
       "    'weight': 5.0},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 1884.0,\n",
       "    'scode': '00',\n",
       "    'text': '주택',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 1890.0,\n",
       "    'scode': '01',\n",
       "    'text': '국장',\n",
       "    'type': 'NNG',\n",
       "    'weight': 7.0},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 5.0,\n",
       "    'position': 1896.0,\n",
       "    'scode': '00',\n",
       "    'text': '도',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 6.0,\n",
       "    'position': 1900.0,\n",
       "    'scode': '05',\n",
       "    'text': '이',\n",
       "    'type': 'NP',\n",
       "    'weight': 10.6},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 7.0,\n",
       "    'position': 1903.0,\n",
       "    'scode': '09',\n",
       "    'text': '들',\n",
       "    'type': 'XSN',\n",
       "    'weight': 7.0},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 8.0,\n",
       "    'position': 1906.0,\n",
       "    'scode': '00',\n",
       "    'text': '과',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 9.0,\n",
       "    'position': 1910.0,\n",
       "    'scode': '00',\n",
       "    'text': '함께',\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 10.0,\n",
       "    'position': 1917.0,\n",
       "    'scode': '04',\n",
       "    'text': '공로',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 11.0,\n",
       "    'position': 1923.0,\n",
       "    'scode': '08',\n",
       "    'text': '연수',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.5},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 12.0,\n",
       "    'position': 1929.0,\n",
       "    'scode': '00',\n",
       "    'text': '에',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 13.0,\n",
       "    'position': 1933.0,\n",
       "    'scode': '01',\n",
       "    'text': '들어가',\n",
       "    'type': 'VV',\n",
       "    'weight': 3.2},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 14.0,\n",
       "    'position': 1939.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 15.0,\n",
       "    'end': 15.0,\n",
       "    'id': 15.0,\n",
       "    'position': 1945.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 1.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '신승일',\n",
       "    'weight': 0.578301},\n",
       "   {'head': 5.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [0.0],\n",
       "    'text': '시민안전주택국장도',\n",
       "    'weight': 0.703215},\n",
       "   {'head': 3.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '이들과',\n",
       "    'weight': 0.451876},\n",
       "   {'head': 5.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'AP',\n",
       "    'mod': [2.0],\n",
       "    'text': '함께',\n",
       "    'weight': 0.736846},\n",
       "   {'head': 5.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '공로연수에',\n",
       "    'weight': 0.710804},\n",
       "   {'head': -1.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [1.0, 3.0, 4.0],\n",
       "    'text': '들어간다.',\n",
       "    'weight': 0.0833014}],\n",
       "  'id': 13.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '신승일',\n",
       "    'position': 1862.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.033786},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '시민',\n",
       "    'position': 1872.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.104202},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '안전',\n",
       "    'position': 1878.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0467729},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '주택',\n",
       "    'position': 1884.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0829355},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '국장',\n",
       "    'position': 1890.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0399463},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '도',\n",
       "    'position': 1896.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.105721},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '이',\n",
       "    'position': 1900.0,\n",
       "    'type': 'NP',\n",
       "    'weight': 0.0994035},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '들',\n",
       "    'position': 1903.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0831824},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '과',\n",
       "    'position': 1906.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.172001},\n",
       "   {'id': 9.0,\n",
       "    'lemma': '함께',\n",
       "    'position': 1910.0,\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.112434},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '공로',\n",
       "    'position': 1917.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0608989},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '연수',\n",
       "    'position': 1923.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0626452},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '에',\n",
       "    'position': 1929.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.102575},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '들어가',\n",
       "    'position': 1933.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.107423},\n",
       "   {'id': 14.0,\n",
       "    'lemma': 'ㄴ다',\n",
       "    'position': 1939.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0500814},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '.',\n",
       "    'position': 1945.0,\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': ' 신승일 시민안전주택국장도 이들과 함께 공로연수에 들어간다.',\n",
       "  'word': [{'begin': 0.0, 'end': 0.0, 'id': 0.0, 'text': '신승일', 'type': ''},\n",
       "   {'begin': 1.0, 'end': 5.0, 'id': 1.0, 'text': '시민안전주택국장도', 'type': ''},\n",
       "   {'begin': 6.0, 'end': 8.0, 'id': 2.0, 'text': '이들과', 'type': ''},\n",
       "   {'begin': 9.0, 'end': 9.0, 'id': 3.0, 'text': '함께', 'type': ''},\n",
       "   {'begin': 10.0, 'end': 12.0, 'id': 4.0, 'text': '공로연수에', 'type': ''},\n",
       "   {'begin': 13.0, 'end': 15.0, 'id': 5.0, 'text': '들어간다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 0.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'text': '신',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.23422},\n",
       "   {'begin': 1.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'text': '국장',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.472096},\n",
       "   {'begin': 3.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 4.0,\n",
       "    'id': 2.0,\n",
       "    'text': '경기북부',\n",
       "    'type': 'LCP_PROVINCE',\n",
       "    'weight': 0.218292},\n",
       "   {'begin': 10.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 10.0,\n",
       "    'id': 3.0,\n",
       "    'text': '고양시',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.247823}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 1948.0,\n",
       "    'scode': '03',\n",
       "    'text': '신',\n",
       "    'type': 'NNP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 1952.0,\n",
       "    'scode': '01',\n",
       "    'text': '국장',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.5},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 1958.0,\n",
       "    'scode': '00',\n",
       "    'text': '은',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 1962.0,\n",
       "    'scode': '02',\n",
       "    'text': '경기',\n",
       "    'type': 'NNP',\n",
       "    'weight': 6.2},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 1968.0,\n",
       "    'scode': '01',\n",
       "    'text': '북부',\n",
       "    'type': 'NNG',\n",
       "    'weight': 6.4},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 5.0,\n",
       "    'position': 1975.0,\n",
       "    'scode': '01',\n",
       "    'text': '중심',\n",
       "    'type': 'NNG',\n",
       "    'weight': 11.8798},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 6.0,\n",
       "    'position': 1982.0,\n",
       "    'scode': '03',\n",
       "    'text': '도시',\n",
       "    'type': 'NNG',\n",
       "    'weight': 9.6},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 7.0,\n",
       "    'position': 1988.0,\n",
       "    'scode': '00',\n",
       "    'text': '가',\n",
       "    'type': 'JKC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 8.0,\n",
       "    'position': 1992.0,\n",
       "    'scode': '01',\n",
       "    'text': '되',\n",
       "    'type': 'VV',\n",
       "    'weight': 6.4},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 9.0,\n",
       "    'position': 1992.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 10.0,\n",
       "    'position': 1996.0,\n",
       "    'scode': '00',\n",
       "    'text': '고양시',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 11.0,\n",
       "    'position': 2005.0,\n",
       "    'scode': '00',\n",
       "    'text': '의',\n",
       "    'type': 'JKG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 12.0,\n",
       "    'position': 2009.0,\n",
       "    'scode': '02',\n",
       "    'text': '미래',\n",
       "    'type': 'NNG',\n",
       "    'weight': 4.0},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 13.0,\n",
       "    'position': 2015.0,\n",
       "    'scode': '02',\n",
       "    'text': '설계',\n",
       "    'type': 'NNG',\n",
       "    'weight': 5.2},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 14.0,\n",
       "    'position': 2021.0,\n",
       "    'scode': '00',\n",
       "    'text': '를',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 15.0,\n",
       "    'end': 16.0,\n",
       "    'id': 15.0,\n",
       "    'position': 2025.0,\n",
       "    'scode': '00',\n",
       "    'text': '담당하',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 17.0,\n",
       "    'end': 17.0,\n",
       "    'id': 16.0,\n",
       "    'position': 2031.0,\n",
       "    'scode': '00',\n",
       "    'text': '어',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 18.0,\n",
       "    'end': 18.0,\n",
       "    'id': 17.0,\n",
       "    'position': 2035.0,\n",
       "    'scode': '01',\n",
       "    'text': '오',\n",
       "    'type': 'VX',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 19.0,\n",
       "    'end': 19.0,\n",
       "    'id': 18.0,\n",
       "    'position': 2035.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 19.0,\n",
       "    'position': 2039.0,\n",
       "    'scode': '00',\n",
       "    'text': '일등',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 20.0,\n",
       "    'position': 2046.0,\n",
       "    'scode': '02',\n",
       "    'text': '공신',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.2},\n",
       "   {'begin': 22.0,\n",
       "    'end': 22.0,\n",
       "    'id': 21.0,\n",
       "    'position': 2053.0,\n",
       "    'scode': '00',\n",
       "    'text': '인물',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 23.0,\n",
       "    'end': 23.0,\n",
       "    'id': 22.0,\n",
       "    'position': 2059.0,\n",
       "    'scode': '01',\n",
       "    'text': '이',\n",
       "    'type': 'VCP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 24.0,\n",
       "    'end': 24.0,\n",
       "    'id': 23.0,\n",
       "    'position': 2062.0,\n",
       "    'scode': '00',\n",
       "    'text': '다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 25.0,\n",
       "    'end': 25.0,\n",
       "    'id': 24.0,\n",
       "    'position': 2065.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 1.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '신',\n",
       "    'weight': 0.627924},\n",
       "   {'head': 12.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [0.0],\n",
       "    'text': '국장은',\n",
       "    'weight': 0.867804},\n",
       "   {'head': 3.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '경기북부',\n",
       "    'weight': 0.0642474},\n",
       "   {'head': 4.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [2.0],\n",
       "    'text': '중심',\n",
       "    'weight': 0.40979},\n",
       "   {'head': 5.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'NP_CMP',\n",
       "    'mod': [3.0],\n",
       "    'text': '도시가',\n",
       "    'weight': 0.661033},\n",
       "   {'head': 7.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [4.0],\n",
       "    'text': '된',\n",
       "    'weight': 0.614366},\n",
       "   {'head': 7.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'NP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '고양시의',\n",
       "    'weight': 0.694219},\n",
       "   {'head': 8.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [5.0, 6.0],\n",
       "    'text': '미래설계를',\n",
       "    'weight': 0.771528},\n",
       "   {'head': 9.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [7.0],\n",
       "    'text': '담당해',\n",
       "    'weight': 0.633885},\n",
       "   {'head': 12.0,\n",
       "    'id': 9.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [8.0],\n",
       "    'text': '온',\n",
       "    'weight': 0.752335},\n",
       "   {'head': 11.0,\n",
       "    'id': 10.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '일등',\n",
       "    'weight': 0.57753},\n",
       "   {'head': 12.0,\n",
       "    'id': 11.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [10.0],\n",
       "    'text': '공신',\n",
       "    'weight': 0.643317},\n",
       "   {'head': -1.0,\n",
       "    'id': 12.0,\n",
       "    'label': 'VNP',\n",
       "    'mod': [1.0, 9.0, 11.0],\n",
       "    'text': '인물이다.',\n",
       "    'weight': 0.000444042}],\n",
       "  'id': 14.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '신',\n",
       "    'position': 1948.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0815232},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '국장',\n",
       "    'position': 1952.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.106204},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '은',\n",
       "    'position': 1958.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.0968925},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '경기',\n",
       "    'position': 1962.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0784235},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '북부',\n",
       "    'position': 1968.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0410873},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '중심',\n",
       "    'position': 1975.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.06304},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '도시',\n",
       "    'position': 1982.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.086578},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '가',\n",
       "    'position': 1988.0,\n",
       "    'type': 'JKC',\n",
       "    'weight': 0.11098},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '되',\n",
       "    'position': 1992.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.112208},\n",
       "   {'id': 9.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 1992.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.112208},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '고양시',\n",
       "    'position': 1996.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0710718},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '의',\n",
       "    'position': 2005.0,\n",
       "    'type': 'JKG',\n",
       "    'weight': 0.0854574},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '미래',\n",
       "    'position': 2009.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0948382},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '설계',\n",
       "    'position': 2015.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0556189},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '를',\n",
       "    'position': 2021.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.109847},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '담당',\n",
       "    'position': 2025.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0459287},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '하',\n",
       "    'position': 2031.0,\n",
       "    'type': 'XSV',\n",
       "    'weight': 0.0459287},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '어',\n",
       "    'position': 2031.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0510215},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '오',\n",
       "    'position': 2035.0,\n",
       "    'type': 'VX',\n",
       "    'weight': 0.0816808},\n",
       "   {'id': 19.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 2035.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0816808},\n",
       "   {'id': 20.0,\n",
       "    'lemma': '일등',\n",
       "    'position': 2039.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0832587},\n",
       "   {'id': 21.0,\n",
       "    'lemma': '공신',\n",
       "    'position': 2046.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0482498},\n",
       "   {'id': 22.0,\n",
       "    'lemma': '인물',\n",
       "    'position': 2053.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0992019},\n",
       "   {'id': 23.0,\n",
       "    'lemma': '이',\n",
       "    'position': 2059.0,\n",
       "    'type': 'VCP',\n",
       "    'weight': 0.0646724},\n",
       "   {'id': 24.0,\n",
       "    'lemma': '다',\n",
       "    'position': 2062.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0770232},\n",
       "   {'id': 25.0,\n",
       "    'lemma': '.',\n",
       "    'position': 2065.0,\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': '  신 국장은 경기북부 중심 도시가 된 고양시의 미래설계를 담당해 온 일등 공신 인물이다.',\n",
       "  'word': [{'begin': 0.0, 'end': 0.0, 'id': 0.0, 'text': '신', 'type': ''},\n",
       "   {'begin': 1.0, 'end': 2.0, 'id': 1.0, 'text': '국장은', 'type': ''},\n",
       "   {'begin': 3.0, 'end': 4.0, 'id': 2.0, 'text': '경기북부', 'type': ''},\n",
       "   {'begin': 5.0, 'end': 5.0, 'id': 3.0, 'text': '중심', 'type': ''},\n",
       "   {'begin': 6.0, 'end': 7.0, 'id': 4.0, 'text': '도시가', 'type': ''},\n",
       "   {'begin': 8.0, 'end': 9.0, 'id': 5.0, 'text': '된', 'type': ''},\n",
       "   {'begin': 10.0, 'end': 11.0, 'id': 6.0, 'text': '고양시의', 'type': ''},\n",
       "   {'begin': 12.0, 'end': 14.0, 'id': 7.0, 'text': '미래설계를', 'type': ''},\n",
       "   {'begin': 15.0, 'end': 17.0, 'id': 8.0, 'text': '담당해', 'type': ''},\n",
       "   {'begin': 18.0, 'end': 19.0, 'id': 9.0, 'text': '온', 'type': ''},\n",
       "   {'begin': 20.0, 'end': 20.0, 'id': 10.0, 'text': '일등', 'type': ''},\n",
       "   {'begin': 21.0, 'end': 21.0, 'id': 11.0, 'text': '공신', 'type': ''},\n",
       "   {'begin': 22.0, 'end': 25.0, 'id': 12.0, 'text': '인물이다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 2.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 2.0,\n",
       "    'id': 0.0,\n",
       "    'text': '고양시',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.347989},\n",
       "   {'begin': 14.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 15.0,\n",
       "    'id': 1.0,\n",
       "    'text': '공직자',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.41833},\n",
       "   {'begin': 33.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 34.0,\n",
       "    'id': 2.0,\n",
       "    'text': '2011년',\n",
       "    'type': 'DT_YEAR',\n",
       "    'weight': 0.841129},\n",
       "   {'begin': 37.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 37.0,\n",
       "    'id': 3.0,\n",
       "    'text': '경희대',\n",
       "    'type': 'OGG_EDUCATION',\n",
       "    'weight': 0.466919},\n",
       "   {'begin': 39.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 40.0,\n",
       "    'id': 4.0,\n",
       "    'text': '경영학',\n",
       "    'type': 'FD_SOCIAL_SCIENCE',\n",
       "    'weight': 0.525991},\n",
       "   {'begin': 45.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 46.0,\n",
       "    'id': 5.0,\n",
       "    'text': '2014년',\n",
       "    'type': 'DT_YEAR',\n",
       "    'weight': 0.803659},\n",
       "   {'begin': 49.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 49.0,\n",
       "    'id': 6.0,\n",
       "    'text': '고려대',\n",
       "    'type': 'OGG_EDUCATION',\n",
       "    'weight': 0.379164},\n",
       "   {'begin': 51.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 53.0,\n",
       "    'id': 7.0,\n",
       "    'text': '건축공학과',\n",
       "    'type': 'FD_SCIENCE',\n",
       "    'weight': 0.368254},\n",
       "   {'begin': 54.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 54.0,\n",
       "    'id': 8.0,\n",
       "    'text': '석사',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.585266}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 2068.0,\n",
       "    'scode': '01',\n",
       "    'text': '그',\n",
       "    'type': 'MM',\n",
       "    'weight': 2.2},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 2071.0,\n",
       "    'scode': '01',\n",
       "    'text': '동안',\n",
       "    'type': 'NNG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 2078.0,\n",
       "    'scode': '00',\n",
       "    'text': '고양시',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 2088.0,\n",
       "    'scode': '01',\n",
       "    'text': '발전',\n",
       "    'type': 'NNG',\n",
       "    'weight': 5.36933},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 2094.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 5.0,\n",
       "    'position': 2098.0,\n",
       "    'scode': '01',\n",
       "    'text': '위하',\n",
       "    'type': 'VV',\n",
       "    'weight': 6.6},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 6.0,\n",
       "    'position': 2101.0,\n",
       "    'scode': '00',\n",
       "    'text': '어서',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 7.0,\n",
       "    'position': 2107.0,\n",
       "    'scode': '00',\n",
       "    'text': '는',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 8.0,\n",
       "    'position': 2111.0,\n",
       "    'scode': '05',\n",
       "    'text': '해당',\n",
       "    'type': 'NNG',\n",
       "    'weight': 4.4},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 9.0,\n",
       "    'position': 2118.0,\n",
       "    'scode': '02',\n",
       "    'text': '업무',\n",
       "    'type': 'NNG',\n",
       "    'weight': 7.6},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 10.0,\n",
       "    'position': 2124.0,\n",
       "    'scode': '00',\n",
       "    'text': '를',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 12.0,\n",
       "    'id': 11.0,\n",
       "    'position': 2128.0,\n",
       "    'scode': '00',\n",
       "    'text': '담당하',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 12.0,\n",
       "    'position': 2137.0,\n",
       "    'scode': '00',\n",
       "    'text': '는',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 14.0,\n",
       "    'end': 15.0,\n",
       "    'id': 13.0,\n",
       "    'position': 2141.0,\n",
       "    'scode': '00',\n",
       "    'text': '공직자',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 14.0,\n",
       "    'position': 2151.0,\n",
       "    'scode': '01',\n",
       "    'text': '역시',\n",
       "    'type': 'MAG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 17.0,\n",
       "    'end': 18.0,\n",
       "    'id': 15.0,\n",
       "    'position': 2158.0,\n",
       "    'scode': '00',\n",
       "    'text': '계속적',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 19.0,\n",
       "    'end': 19.0,\n",
       "    'id': 16.0,\n",
       "    'position': 2167.0,\n",
       "    'scode': '01',\n",
       "    'text': '이',\n",
       "    'type': 'VCP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 17.0,\n",
       "    'position': 2167.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 18.0,\n",
       "    'position': 2171.0,\n",
       "    'scode': '01',\n",
       "    'text': '발전',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.54924},\n",
       "   {'begin': 22.0,\n",
       "    'end': 22.0,\n",
       "    'id': 19.0,\n",
       "    'position': 2177.0,\n",
       "    'scode': '00',\n",
       "    'text': '이',\n",
       "    'type': 'JKS',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 23.0,\n",
       "    'end': 24.0,\n",
       "    'id': 20.0,\n",
       "    'position': 2181.0,\n",
       "    'scode': '00',\n",
       "    'text': '필요하',\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 25.0,\n",
       "    'end': 25.0,\n",
       "    'id': 21.0,\n",
       "    'position': 2190.0,\n",
       "    'scode': '00',\n",
       "    'text': '다고',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 26.0,\n",
       "    'end': 27.0,\n",
       "    'id': 22.0,\n",
       "    'position': 2197.0,\n",
       "    'scode': '00',\n",
       "    'text': '강조하',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 28.0,\n",
       "    'end': 28.0,\n",
       "    'id': 23.0,\n",
       "    'position': 2203.0,\n",
       "    'scode': '00',\n",
       "    'text': '어',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 29.0,\n",
       "    'end': 29.0,\n",
       "    'id': 24.0,\n",
       "    'position': 2207.0,\n",
       "    'scode': '01',\n",
       "    'text': '오',\n",
       "    'type': 'VX',\n",
       "    'weight': 2.0},\n",
       "   {'begin': 30.0,\n",
       "    'end': 30.0,\n",
       "    'id': 25.0,\n",
       "    'position': 2207.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 31.0,\n",
       "    'end': 31.0,\n",
       "    'id': 26.0,\n",
       "    'position': 2211.0,\n",
       "    'scode': '01',\n",
       "    'text': '그',\n",
       "    'type': 'NP',\n",
       "    'weight': 3.7},\n",
       "   {'begin': 32.0,\n",
       "    'end': 32.0,\n",
       "    'id': 27.0,\n",
       "    'position': 2214.0,\n",
       "    'scode': '00',\n",
       "    'text': '는',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 33.0,\n",
       "    'end': 33.0,\n",
       "    'id': 28.0,\n",
       "    'position': 2218.0,\n",
       "    'scode': '00',\n",
       "    'text': '2011',\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 34.0,\n",
       "    'end': 34.0,\n",
       "    'id': 29.0,\n",
       "    'position': 2222.0,\n",
       "    'scode': '02',\n",
       "    'text': '년',\n",
       "    'type': 'NNB',\n",
       "    'weight': 2.5},\n",
       "   {'begin': 35.0,\n",
       "    'end': 35.0,\n",
       "    'id': 30.0,\n",
       "    'position': 2225.0,\n",
       "    'scode': '00',\n",
       "    'text': '에',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 36.0,\n",
       "    'end': 36.0,\n",
       "    'id': 31.0,\n",
       "    'position': 2228.0,\n",
       "    'scode': '00',\n",
       "    'text': '는',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 37.0,\n",
       "    'end': 37.0,\n",
       "    'id': 32.0,\n",
       "    'position': 2232.0,\n",
       "    'scode': '00',\n",
       "    'text': '경희대',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 38.0,\n",
       "    'end': 38.0,\n",
       "    'id': 33.0,\n",
       "    'position': 2241.0,\n",
       "    'scode': '00',\n",
       "    'text': '에서',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 39.0,\n",
       "    'end': 40.0,\n",
       "    'id': 34.0,\n",
       "    'position': 2248.0,\n",
       "    'scode': '00',\n",
       "    'text': '경영학',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 41.0,\n",
       "    'end': 41.0,\n",
       "    'id': 35.0,\n",
       "    'position': 2257.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 42.0,\n",
       "    'end': 43.0,\n",
       "    'id': 36.0,\n",
       "    'position': 2261.0,\n",
       "    'scode': '01',\n",
       "    'text': '전공하',\n",
       "    'type': 'VV',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 44.0,\n",
       "    'end': 44.0,\n",
       "    'id': 37.0,\n",
       "    'position': 2270.0,\n",
       "    'scode': '00',\n",
       "    'text': '고',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 45.0,\n",
       "    'end': 45.0,\n",
       "    'id': 38.0,\n",
       "    'position': 2274.0,\n",
       "    'scode': '00',\n",
       "    'text': '2014',\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 46.0,\n",
       "    'end': 46.0,\n",
       "    'id': 39.0,\n",
       "    'position': 2278.0,\n",
       "    'scode': '02',\n",
       "    'text': '년',\n",
       "    'type': 'NNB',\n",
       "    'weight': 10.1},\n",
       "   {'begin': 47.0,\n",
       "    'end': 47.0,\n",
       "    'id': 40.0,\n",
       "    'position': 2281.0,\n",
       "    'scode': '00',\n",
       "    'text': '에',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 48.0,\n",
       "    'end': 48.0,\n",
       "    'id': 41.0,\n",
       "    'position': 2284.0,\n",
       "    'scode': '00',\n",
       "    'text': '는',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 49.0,\n",
       "    'end': 49.0,\n",
       "    'id': 42.0,\n",
       "    'position': 2288.0,\n",
       "    'scode': '00',\n",
       "    'text': '고려대',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 50.0,\n",
       "    'end': 50.0,\n",
       "    'id': 43.0,\n",
       "    'position': 2297.0,\n",
       "    'scode': '00',\n",
       "    'text': '에서',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 51.0,\n",
       "    'end': 52.0,\n",
       "    'id': 44.0,\n",
       "    'position': 2304.0,\n",
       "    'scode': '00',\n",
       "    'text': '건축공학',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 53.0,\n",
       "    'end': 53.0,\n",
       "    'id': 45.0,\n",
       "    'position': 2316.0,\n",
       "    'scode': '04',\n",
       "    'text': '과',\n",
       "    'type': 'NNG',\n",
       "    'weight': 8.5},\n",
       "   {'begin': 54.0,\n",
       "    'end': 55.0,\n",
       "    'id': 46.0,\n",
       "    'position': 2320.0,\n",
       "    'scode': '00',\n",
       "    'text': '석사과정',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 56.0,\n",
       "    'end': 56.0,\n",
       "    'id': 47.0,\n",
       "    'position': 2332.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 57.0,\n",
       "    'end': 57.0,\n",
       "    'id': 48.0,\n",
       "    'position': 2336.0,\n",
       "    'scode': '02',\n",
       "    'text': '마치',\n",
       "    'type': 'VV',\n",
       "    'weight': 5.2},\n",
       "   {'begin': 58.0,\n",
       "    'end': 58.0,\n",
       "    'id': 49.0,\n",
       "    'position': 2339.0,\n",
       "    'scode': '00',\n",
       "    'text': '었',\n",
       "    'type': 'EP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 59.0,\n",
       "    'end': 59.0,\n",
       "    'id': 50.0,\n",
       "    'position': 2342.0,\n",
       "    'scode': '00',\n",
       "    'text': '다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 60.0,\n",
       "    'end': 60.0,\n",
       "    'id': 51.0,\n",
       "    'position': 2345.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 3.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '그동안',\n",
       "    'weight': 0.106922},\n",
       "   {'head': 2.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '고양시',\n",
       "    'weight': 0.627105},\n",
       "   {'head': 3.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [1.0],\n",
       "    'text': '발전을',\n",
       "    'weight': 0.737102},\n",
       "   {'head': 12.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [0.0, 2.0],\n",
       "    'text': '위해서는',\n",
       "    'weight': 0.137175},\n",
       "   {'head': 5.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '해당',\n",
       "    'weight': 0.562477},\n",
       "   {'head': 6.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [4.0],\n",
       "    'text': '업무를',\n",
       "    'weight': 0.720044},\n",
       "   {'head': 7.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [5.0],\n",
       "    'text': '담당하는',\n",
       "    'weight': 0.501373},\n",
       "   {'head': 12.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [6.0],\n",
       "    'text': '공직자',\n",
       "    'weight': 0.185863},\n",
       "   {'head': 12.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'AP',\n",
       "    'mod': [],\n",
       "    'text': '역시',\n",
       "    'weight': 0.0845747},\n",
       "   {'head': 10.0,\n",
       "    'id': 9.0,\n",
       "    'label': 'VNP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '계속적인',\n",
       "    'weight': 0.640643},\n",
       "   {'head': 11.0,\n",
       "    'id': 10.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [9.0],\n",
       "    'text': '발전이',\n",
       "    'weight': 0.640842},\n",
       "   {'head': 12.0,\n",
       "    'id': 11.0,\n",
       "    'label': 'VP_CMP',\n",
       "    'mod': [10.0],\n",
       "    'text': '필요하다고',\n",
       "    'weight': 0.587666},\n",
       "   {'head': 13.0,\n",
       "    'id': 12.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [3.0, 7.0, 8.0, 11.0],\n",
       "    'text': '강조해',\n",
       "    'weight': 0.767518},\n",
       "   {'head': 14.0,\n",
       "    'id': 13.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [12.0],\n",
       "    'text': '온',\n",
       "    'weight': 0.660278},\n",
       "   {'head': 18.0,\n",
       "    'id': 14.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [13.0],\n",
       "    'text': '그는',\n",
       "    'weight': 0.718271},\n",
       "   {'head': 18.0,\n",
       "    'id': 15.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '2011년에는',\n",
       "    'weight': 0.673021},\n",
       "   {'head': 18.0,\n",
       "    'id': 16.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '경희대에서',\n",
       "    'weight': 0.784805},\n",
       "   {'head': 18.0,\n",
       "    'id': 17.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [],\n",
       "    'text': '경영학을',\n",
       "    'weight': 0.684106},\n",
       "   {'head': 23.0,\n",
       "    'id': 18.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [14.0, 15.0, 16.0, 17.0],\n",
       "    'text': '전공하고',\n",
       "    'weight': 0.804972},\n",
       "   {'head': 23.0,\n",
       "    'id': 19.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '2014년에는',\n",
       "    'weight': 0.609319},\n",
       "   {'head': 23.0,\n",
       "    'id': 20.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '고려대에서',\n",
       "    'weight': 0.777463},\n",
       "   {'head': 22.0,\n",
       "    'id': 21.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '건축공학과',\n",
       "    'weight': 0.610414},\n",
       "   {'head': 23.0,\n",
       "    'id': 22.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [21.0],\n",
       "    'text': '석사과정을',\n",
       "    'weight': 0.671594},\n",
       "   {'head': -1.0,\n",
       "    'id': 23.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [18.0, 19.0, 20.0, 22.0],\n",
       "    'text': '마쳤다.',\n",
       "    'weight': 7.42437e-08}],\n",
       "  'id': 15.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '그',\n",
       "    'position': 2068.0,\n",
       "    'type': 'MM',\n",
       "    'weight': 0.049509},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '동안',\n",
       "    'position': 2071.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.049509},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '고양시',\n",
       "    'position': 2078.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0650413},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '발전',\n",
       "    'position': 2088.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0643419},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '을',\n",
       "    'position': 2094.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0880422},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '위하',\n",
       "    'position': 2098.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0833844},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '어서',\n",
       "    'position': 2101.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0841452},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '는',\n",
       "    'position': 2107.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.115627},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '해당',\n",
       "    'position': 2111.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0765361},\n",
       "   {'id': 9.0,\n",
       "    'lemma': '업무',\n",
       "    'position': 2118.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.146688},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '를',\n",
       "    'position': 2124.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0922402},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '담당',\n",
       "    'position': 2128.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0269004},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '하',\n",
       "    'position': 2134.0,\n",
       "    'type': 'XSV',\n",
       "    'weight': 0.0269004},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '는',\n",
       "    'position': 2137.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.123765},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '공직',\n",
       "    'position': 2141.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.131497},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '자',\n",
       "    'position': 2147.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.131497},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '역시',\n",
       "    'position': 2151.0,\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0769249},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '계속',\n",
       "    'position': 2158.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0719721},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '적',\n",
       "    'position': 2164.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0719721},\n",
       "   {'id': 19.0,\n",
       "    'lemma': '이',\n",
       "    'position': 2167.0,\n",
       "    'type': 'VCP',\n",
       "    'weight': 0.111692},\n",
       "   {'id': 20.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 2167.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.111692},\n",
       "   {'id': 21.0,\n",
       "    'lemma': '발전',\n",
       "    'position': 2171.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0936336},\n",
       "   {'id': 22.0,\n",
       "    'lemma': '이',\n",
       "    'position': 2177.0,\n",
       "    'type': 'JKS',\n",
       "    'weight': 0.0846542},\n",
       "   {'id': 23.0,\n",
       "    'lemma': '필요',\n",
       "    'position': 2181.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0456335},\n",
       "   {'id': 24.0,\n",
       "    'lemma': '하',\n",
       "    'position': 2187.0,\n",
       "    'type': 'XSA',\n",
       "    'weight': 0.0456335},\n",
       "   {'id': 25.0,\n",
       "    'lemma': '다고',\n",
       "    'position': 2190.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0553318},\n",
       "   {'id': 26.0,\n",
       "    'lemma': '강조',\n",
       "    'position': 2197.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0565279},\n",
       "   {'id': 27.0,\n",
       "    'lemma': '하',\n",
       "    'position': 2203.0,\n",
       "    'type': 'XSV',\n",
       "    'weight': 0.0565279},\n",
       "   {'id': 28.0,\n",
       "    'lemma': '어',\n",
       "    'position': 2203.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0612938},\n",
       "   {'id': 29.0,\n",
       "    'lemma': '오',\n",
       "    'position': 2207.0,\n",
       "    'type': 'VX',\n",
       "    'weight': 0.0793067},\n",
       "   {'id': 30.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 2207.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0793067},\n",
       "   {'id': 31.0,\n",
       "    'lemma': '그',\n",
       "    'position': 2211.0,\n",
       "    'type': 'NP',\n",
       "    'weight': 0.104357},\n",
       "   {'id': 32.0,\n",
       "    'lemma': '는',\n",
       "    'position': 2214.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.127566},\n",
       "   {'id': 33.0,\n",
       "    'lemma': '2011',\n",
       "    'position': 2218.0,\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'id': 34.0,\n",
       "    'lemma': '년',\n",
       "    'position': 2222.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.0747491},\n",
       "   {'id': 35.0,\n",
       "    'lemma': '에',\n",
       "    'position': 2225.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0795831},\n",
       "   {'id': 36.0,\n",
       "    'lemma': '는',\n",
       "    'position': 2228.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.127068},\n",
       "   {'id': 37.0,\n",
       "    'lemma': '경희대',\n",
       "    'position': 2232.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0690814},\n",
       "   {'id': 38.0,\n",
       "    'lemma': '에서',\n",
       "    'position': 2241.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0830844},\n",
       "   {'id': 39.0,\n",
       "    'lemma': '경영',\n",
       "    'position': 2248.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.158587},\n",
       "   {'id': 40.0,\n",
       "    'lemma': '학',\n",
       "    'position': 2254.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.158587},\n",
       "   {'id': 41.0,\n",
       "    'lemma': '을',\n",
       "    'position': 2257.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0827272},\n",
       "   {'id': 42.0,\n",
       "    'lemma': '전공',\n",
       "    'position': 2261.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0375048},\n",
       "   {'id': 43.0,\n",
       "    'lemma': '하',\n",
       "    'position': 2267.0,\n",
       "    'type': 'XSV',\n",
       "    'weight': 0.0375048},\n",
       "   {'id': 44.0,\n",
       "    'lemma': '고',\n",
       "    'position': 2270.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0931551},\n",
       "   {'id': 45.0,\n",
       "    'lemma': '2014',\n",
       "    'position': 2274.0,\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'id': 46.0,\n",
       "    'lemma': '년',\n",
       "    'position': 2278.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.080389},\n",
       "   {'id': 47.0,\n",
       "    'lemma': '에',\n",
       "    'position': 2281.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0755452},\n",
       "   {'id': 48.0,\n",
       "    'lemma': '는',\n",
       "    'position': 2284.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.136789},\n",
       "   {'id': 49.0,\n",
       "    'lemma': '고려대',\n",
       "    'position': 2288.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0676482},\n",
       "   {'id': 50.0,\n",
       "    'lemma': '에서',\n",
       "    'position': 2297.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0810954},\n",
       "   {'id': 51.0,\n",
       "    'lemma': '건축',\n",
       "    'position': 2304.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0761965},\n",
       "   {'id': 52.0,\n",
       "    'lemma': '공학',\n",
       "    'position': 2310.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.059906},\n",
       "   {'id': 53.0,\n",
       "    'lemma': '과',\n",
       "    'position': 2316.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.059906},\n",
       "   {'id': 54.0,\n",
       "    'lemma': '석사',\n",
       "    'position': 2320.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0744275},\n",
       "   {'id': 55.0,\n",
       "    'lemma': '과정',\n",
       "    'position': 2326.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0803652},\n",
       "   {'id': 56.0,\n",
       "    'lemma': '을',\n",
       "    'position': 2332.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0915056},\n",
       "   {'id': 57.0,\n",
       "    'lemma': '마치',\n",
       "    'position': 2336.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0667333},\n",
       "   {'id': 58.0,\n",
       "    'lemma': '었',\n",
       "    'position': 2339.0,\n",
       "    'type': 'EP',\n",
       "    'weight': 0.076483},\n",
       "   {'id': 59.0,\n",
       "    'lemma': '다',\n",
       "    'position': 2342.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0752349},\n",
       "   {'id': 60.0,\n",
       "    'lemma': '.',\n",
       "    'position': 2345.0,\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': '  그동안 고양시 발전을 위해서는 해당 업무를 담당하는 공직자 역시 계속적인 발전이 필요하다고 강조해 온 그는 2011년에는 경희대에서 경영학을 전공하고 2014년에는 고려대에서 건축공학과 석사과정을 마쳤다.',\n",
       "  'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '그동안', 'type': ''},\n",
       "   {'begin': 2.0, 'end': 2.0, 'id': 1.0, 'text': '고양시', 'type': ''},\n",
       "   {'begin': 3.0, 'end': 4.0, 'id': 2.0, 'text': '발전을', 'type': ''},\n",
       "   {'begin': 5.0, 'end': 7.0, 'id': 3.0, 'text': '위해서는', 'type': ''},\n",
       "   {'begin': 8.0, 'end': 8.0, 'id': 4.0, 'text': '해당', 'type': ''},\n",
       "   {'begin': 9.0, 'end': 10.0, 'id': 5.0, 'text': '업무를', 'type': ''},\n",
       "   {'begin': 11.0, 'end': 13.0, 'id': 6.0, 'text': '담당하는', 'type': ''},\n",
       "   {'begin': 14.0, 'end': 15.0, 'id': 7.0, 'text': '공직자', 'type': ''},\n",
       "   {'begin': 16.0, 'end': 16.0, 'id': 8.0, 'text': '역시', 'type': ''},\n",
       "   {'begin': 17.0, 'end': 20.0, 'id': 9.0, 'text': '계속적인', 'type': ''},\n",
       "   {'begin': 21.0, 'end': 22.0, 'id': 10.0, 'text': '발전이', 'type': ''},\n",
       "   {'begin': 23.0, 'end': 25.0, 'id': 11.0, 'text': '필요하다고', 'type': ''},\n",
       "   {'begin': 26.0, 'end': 28.0, 'id': 12.0, 'text': '강조해', 'type': ''},\n",
       "   {'begin': 29.0, 'end': 30.0, 'id': 13.0, 'text': '온', 'type': ''},\n",
       "   {'begin': 31.0, 'end': 32.0, 'id': 14.0, 'text': '그는', 'type': ''},\n",
       "   {'begin': 33.0, 'end': 36.0, 'id': 15.0, 'text': '2011년에는', 'type': ''},\n",
       "   {'begin': 37.0, 'end': 38.0, 'id': 16.0, 'text': '경희대에서', 'type': ''},\n",
       "   {'begin': 39.0, 'end': 41.0, 'id': 17.0, 'text': '경영학을', 'type': ''},\n",
       "   {'begin': 42.0, 'end': 44.0, 'id': 18.0, 'text': '전공하고', 'type': ''},\n",
       "   {'begin': 45.0, 'end': 48.0, 'id': 19.0, 'text': '2014년에는', 'type': ''},\n",
       "   {'begin': 49.0, 'end': 50.0, 'id': 20.0, 'text': '고려대에서', 'type': ''},\n",
       "   {'begin': 51.0, 'end': 53.0, 'id': 21.0, 'text': '건축공학과', 'type': ''},\n",
       "   {'begin': 54.0, 'end': 56.0, 'id': 22.0, 'text': '석사과정을', 'type': ''},\n",
       "   {'begin': 57.0, 'end': 60.0, 'id': 23.0, 'text': '마쳤다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 28.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 28.0,\n",
       "    'id': 0.0,\n",
       "    'text': '신',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.239135},\n",
       "   {'begin': 29.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 29.0,\n",
       "    'id': 1.0,\n",
       "    'text': '국장',\n",
       "    'type': 'CV_POSITION',\n",
       "    'weight': 0.43369},\n",
       "   {'begin': 33.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 33.0,\n",
       "    'id': 2.0,\n",
       "    'text': '후배',\n",
       "    'type': 'CV_RELATION',\n",
       "    'weight': 0.325419}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 2348.0,\n",
       "    'scode': '00',\n",
       "    'text': '풍부하',\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 2354.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 2358.0,\n",
       "    'scode': '02',\n",
       "    'text': '학식',\n",
       "    'type': 'NNG',\n",
       "    'weight': 1.56667},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 2364.0,\n",
       "    'scode': '00',\n",
       "    'text': '과',\n",
       "    'type': 'JC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 4.0,\n",
       "    'position': 2368.0,\n",
       "    'scode': '00',\n",
       "    'text': '오랜',\n",
       "    'type': 'MM',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 5.0,\n",
       "    'position': 2375.0,\n",
       "    'scode': '01',\n",
       "    'text': '행정',\n",
       "    'type': 'NNG',\n",
       "    'weight': 5.2},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 6.0,\n",
       "    'position': 2381.0,\n",
       "    'scode': '00',\n",
       "    'text': '경험',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 7.0,\n",
       "    'position': 2387.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 8.0,\n",
       "    'position': 2391.0,\n",
       "    'scode': '00',\n",
       "    'text': '통하',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 9.0,\n",
       "    'position': 2394.0,\n",
       "    'scode': '00',\n",
       "    'text': '어',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 10.0,\n",
       "    'position': 2398.0,\n",
       "    'scode': '00',\n",
       "    'text': '쌓',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 11.0,\n",
       "    'position': 2401.0,\n",
       "    'scode': '00',\n",
       "    'text': '은',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 12.0,\n",
       "    'end': 13.0,\n",
       "    'id': 12.0,\n",
       "    'position': 2405.0,\n",
       "    'scode': '00',\n",
       "    'text': '노하우',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 13.0,\n",
       "    'position': 2414.0,\n",
       "    'scode': '00',\n",
       "    'text': ',',\n",
       "    'type': 'SP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 15.0,\n",
       "    'end': 15.0,\n",
       "    'id': 14.0,\n",
       "    'position': 2416.0,\n",
       "    'scode': '02',\n",
       "    'text': '업무',\n",
       "    'type': 'NNG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 15.0,\n",
       "    'position': 2422.0,\n",
       "    'scode': '00',\n",
       "    'text': '를',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 17.0,\n",
       "    'end': 18.0,\n",
       "    'id': 16.0,\n",
       "    'position': 2426.0,\n",
       "    'scode': '02',\n",
       "    'text': '추진하',\n",
       "    'type': 'VV',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 19.0,\n",
       "    'end': 19.0,\n",
       "    'id': 17.0,\n",
       "    'position': 2435.0,\n",
       "    'scode': '00',\n",
       "    'text': '는',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 18.0,\n",
       "    'position': 2439.0,\n",
       "    'scode': '00',\n",
       "    'text': '뜨겁',\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 19.0,\n",
       "    'position': 2445.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 22.0,\n",
       "    'end': 22.0,\n",
       "    'id': 20.0,\n",
       "    'position': 2449.0,\n",
       "    'scode': '02',\n",
       "    'text': '열정',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.2},\n",
       "   {'begin': 23.0,\n",
       "    'end': 23.0,\n",
       "    'id': 21.0,\n",
       "    'position': 2455.0,\n",
       "    'scode': '00',\n",
       "    'text': ',',\n",
       "    'type': 'SP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 24.0,\n",
       "    'end': 24.0,\n",
       "    'id': 22.0,\n",
       "    'position': 2457.0,\n",
       "    'scode': '00',\n",
       "    'text': '뛰어나',\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 25.0,\n",
       "    'end': 25.0,\n",
       "    'id': 23.0,\n",
       "    'position': 2463.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 26.0,\n",
       "    'end': 26.0,\n",
       "    'id': 24.0,\n",
       "    'position': 2467.0,\n",
       "    'scode': '00',\n",
       "    'text': '리더쉽',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 27.0,\n",
       "    'end': 27.0,\n",
       "    'id': 25.0,\n",
       "    'position': 2476.0,\n",
       "    'scode': '00',\n",
       "    'text': ',',\n",
       "    'type': 'SP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 28.0,\n",
       "    'end': 28.0,\n",
       "    'id': 26.0,\n",
       "    'position': 2478.0,\n",
       "    'scode': '03',\n",
       "    'text': '신',\n",
       "    'type': 'NNP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 29.0,\n",
       "    'end': 29.0,\n",
       "    'id': 27.0,\n",
       "    'position': 2482.0,\n",
       "    'scode': '01',\n",
       "    'text': '국장',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.5},\n",
       "   {'begin': 30.0,\n",
       "    'end': 30.0,\n",
       "    'id': 28.0,\n",
       "    'position': 2488.0,\n",
       "    'scode': '00',\n",
       "    'text': '이',\n",
       "    'type': 'JKS',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 31.0,\n",
       "    'end': 31.0,\n",
       "    'id': 29.0,\n",
       "    'position': 2492.0,\n",
       "    'scode': '02',\n",
       "    'text': '공직',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.0},\n",
       "   {'begin': 32.0,\n",
       "    'end': 32.0,\n",
       "    'id': 30.0,\n",
       "    'position': 2498.0,\n",
       "    'scode': '07',\n",
       "    'text': '사회',\n",
       "    'type': 'NNG',\n",
       "    'weight': 6.7},\n",
       "   {'begin': 33.0,\n",
       "    'end': 33.0,\n",
       "    'id': 31.0,\n",
       "    'position': 2505.0,\n",
       "    'scode': '06',\n",
       "    'text': '후배',\n",
       "    'type': 'NNG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 34.0,\n",
       "    'end': 34.0,\n",
       "    'id': 32.0,\n",
       "    'position': 2511.0,\n",
       "    'scode': '09',\n",
       "    'text': '들',\n",
       "    'type': 'XSN',\n",
       "    'weight': 7.0},\n",
       "   {'begin': 35.0,\n",
       "    'end': 35.0,\n",
       "    'id': 33.0,\n",
       "    'position': 2514.0,\n",
       "    'scode': '00',\n",
       "    'text': '에게',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 36.0,\n",
       "    'end': 36.0,\n",
       "    'id': 34.0,\n",
       "    'position': 2521.0,\n",
       "    'scode': '01',\n",
       "    'text': '받',\n",
       "    'type': 'VV',\n",
       "    'weight': 4.2},\n",
       "   {'begin': 37.0,\n",
       "    'end': 37.0,\n",
       "    'id': 35.0,\n",
       "    'position': 2524.0,\n",
       "    'scode': '00',\n",
       "    'text': '는',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 38.0,\n",
       "    'end': 38.0,\n",
       "    'id': 36.0,\n",
       "    'position': 2528.0,\n",
       "    'scode': '03',\n",
       "    'text': '평가',\n",
       "    'type': 'NNG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 39.0,\n",
       "    'end': 39.0,\n",
       "    'id': 37.0,\n",
       "    'position': 2534.0,\n",
       "    'scode': '01',\n",
       "    'text': '이',\n",
       "    'type': 'VCP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 40.0,\n",
       "    'end': 40.0,\n",
       "    'id': 38.0,\n",
       "    'position': 2534.0,\n",
       "    'scode': '00',\n",
       "    'text': '다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 41.0,\n",
       "    'end': 41.0,\n",
       "    'id': 39.0,\n",
       "    'position': 2537.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 1.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '풍부한',\n",
       "    'weight': 0.577327},\n",
       "   {'head': 3.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP_CNJ',\n",
       "    'mod': [0.0],\n",
       "    'text': '학식과',\n",
       "    'weight': 0.488489},\n",
       "   {'head': 3.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'DP',\n",
       "    'mod': [],\n",
       "    'text': '오랜',\n",
       "    'weight': 0.470382},\n",
       "   {'head': 4.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [1.0, 2.0],\n",
       "    'text': '행정경험을',\n",
       "    'weight': 0.769627},\n",
       "   {'head': 5.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [3.0],\n",
       "    'text': '통해',\n",
       "    'weight': 0.612799},\n",
       "   {'head': 6.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [4.0],\n",
       "    'text': '쌓은',\n",
       "    'weight': 0.451413},\n",
       "   {'head': 14.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'NP_CNJ',\n",
       "    'mod': [5.0],\n",
       "    'text': '노하우,',\n",
       "    'weight': 0.173041},\n",
       "   {'head': 8.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [],\n",
       "    'text': '업무를',\n",
       "    'weight': 0.734133},\n",
       "   {'head': 10.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [7.0],\n",
       "    'text': '추진하는',\n",
       "    'weight': 0.582724},\n",
       "   {'head': 10.0,\n",
       "    'id': 9.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '뜨거운',\n",
       "    'weight': 0.555518},\n",
       "   {'head': 14.0,\n",
       "    'id': 10.0,\n",
       "    'label': 'NP_CNJ',\n",
       "    'mod': [8.0, 9.0],\n",
       "    'text': '열정,',\n",
       "    'weight': 0.228286},\n",
       "   {'head': 12.0,\n",
       "    'id': 11.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '뛰어난',\n",
       "    'weight': 0.582117},\n",
       "   {'head': 14.0,\n",
       "    'id': 12.0,\n",
       "    'label': 'NP_CNJ',\n",
       "    'mod': [11.0],\n",
       "    'text': '리더쉽,',\n",
       "    'weight': 0.0332456},\n",
       "   {'head': 14.0,\n",
       "    'id': 13.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '신',\n",
       "    'weight': 0.701606},\n",
       "   {'head': 17.0,\n",
       "    'id': 14.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [6.0, 10.0, 12.0, 13.0],\n",
       "    'text': '국장이',\n",
       "    'weight': 0.762888},\n",
       "   {'head': 16.0,\n",
       "    'id': 15.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '공직사회',\n",
       "    'weight': 0.520157},\n",
       "   {'head': 17.0,\n",
       "    'id': 16.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [15.0],\n",
       "    'text': '후배들에게',\n",
       "    'weight': 0.697172},\n",
       "   {'head': 18.0,\n",
       "    'id': 17.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [14.0, 16.0],\n",
       "    'text': '받는',\n",
       "    'weight': 0.647006},\n",
       "   {'head': -1.0,\n",
       "    'id': 18.0,\n",
       "    'label': 'VNP',\n",
       "    'mod': [17.0],\n",
       "    'text': '평가다.',\n",
       "    'weight': 5.07428e-07}],\n",
       "  'id': 16.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '풍부하',\n",
       "    'position': 2348.0,\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0595484},\n",
       "   {'id': 1.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 2354.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0335769},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '학식',\n",
       "    'position': 2358.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0794731},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '과',\n",
       "    'position': 2364.0,\n",
       "    'type': 'JC',\n",
       "    'weight': 0.0669113},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '오랜',\n",
       "    'position': 2368.0,\n",
       "    'type': 'MM',\n",
       "    'weight': 0.0528307},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '행정',\n",
       "    'position': 2375.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.106307},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '경험',\n",
       "    'position': 2381.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.118347},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '을',\n",
       "    'position': 2387.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0878383},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '통하',\n",
       "    'position': 2391.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0778748},\n",
       "   {'id': 9.0,\n",
       "    'lemma': '어',\n",
       "    'position': 2394.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0692416},\n",
       "   {'id': 10.0,\n",
       "    'lemma': '쌓',\n",
       "    'position': 2398.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.127916},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '은',\n",
       "    'position': 2401.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0626115},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '노',\n",
       "    'position': 2405.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0527565},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '하우',\n",
       "    'position': 2408.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0527565},\n",
       "   {'id': 14.0, 'lemma': ',', 'position': 2414.0, 'type': 'SP', 'weight': 1.0},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '업무',\n",
       "    'position': 2416.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.119289},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '를',\n",
       "    'position': 2422.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0919228},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '추진',\n",
       "    'position': 2426.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0556149},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '하',\n",
       "    'position': 2432.0,\n",
       "    'type': 'XSV',\n",
       "    'weight': 0.0375256},\n",
       "   {'id': 19.0,\n",
       "    'lemma': '는',\n",
       "    'position': 2435.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.121964},\n",
       "   {'id': 20.0,\n",
       "    'lemma': '뜨겁',\n",
       "    'position': 2439.0,\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0540058},\n",
       "   {'id': 21.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 2445.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0456632},\n",
       "   {'id': 22.0,\n",
       "    'lemma': '열정',\n",
       "    'position': 2449.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0546397},\n",
       "   {'id': 23.0, 'lemma': ',', 'position': 2455.0, 'type': 'SP', 'weight': 1.0},\n",
       "   {'id': 24.0,\n",
       "    'lemma': '뛰어나',\n",
       "    'position': 2457.0,\n",
       "    'type': 'VA',\n",
       "    'weight': 0.068426},\n",
       "   {'id': 25.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 2463.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0774079},\n",
       "   {'id': 26.0,\n",
       "    'lemma': '리더쉽',\n",
       "    'position': 2467.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0394972},\n",
       "   {'id': 27.0, 'lemma': ',', 'position': 2476.0, 'type': 'SP', 'weight': 1.0},\n",
       "   {'id': 28.0,\n",
       "    'lemma': '신',\n",
       "    'position': 2478.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.037657},\n",
       "   {'id': 29.0,\n",
       "    'lemma': '국장',\n",
       "    'position': 2482.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.110679},\n",
       "   {'id': 30.0,\n",
       "    'lemma': '이',\n",
       "    'position': 2488.0,\n",
       "    'type': 'JKS',\n",
       "    'weight': 0.0619183},\n",
       "   {'id': 31.0,\n",
       "    'lemma': '공직',\n",
       "    'position': 2492.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0747808},\n",
       "   {'id': 32.0,\n",
       "    'lemma': '사회',\n",
       "    'position': 2498.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0567425},\n",
       "   {'id': 33.0,\n",
       "    'lemma': '후배',\n",
       "    'position': 2505.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.071888},\n",
       "   {'id': 34.0,\n",
       "    'lemma': '들',\n",
       "    'position': 2511.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0720833},\n",
       "   {'id': 35.0,\n",
       "    'lemma': '에게',\n",
       "    'position': 2514.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0715299},\n",
       "   {'id': 36.0,\n",
       "    'lemma': '받',\n",
       "    'position': 2521.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.113835},\n",
       "   {'id': 37.0,\n",
       "    'lemma': '는',\n",
       "    'position': 2524.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0929622},\n",
       "   {'id': 38.0,\n",
       "    'lemma': '평가',\n",
       "    'position': 2528.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0613124},\n",
       "   {'id': 39.0,\n",
       "    'lemma': '이',\n",
       "    'position': 2534.0,\n",
       "    'type': 'VCP',\n",
       "    'weight': 0.0387355},\n",
       "   {'id': 40.0,\n",
       "    'lemma': '다',\n",
       "    'position': 2534.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0632498},\n",
       "   {'id': 41.0,\n",
       "    'lemma': '.',\n",
       "    'position': 2537.0,\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': '  풍부한 학식과 오랜 행정경험을 통해 쌓은 노하우, 업무를 추진하는 뜨거운 열정, 뛰어난 리더쉽, 신 국장이 공직사회 후배들에게 받는 평가다.',\n",
       "  'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '풍부한', 'type': ''},\n",
       "   {'begin': 2.0, 'end': 3.0, 'id': 1.0, 'text': '학식과', 'type': ''},\n",
       "   {'begin': 4.0, 'end': 4.0, 'id': 2.0, 'text': '오랜', 'type': ''},\n",
       "   {'begin': 5.0, 'end': 7.0, 'id': 3.0, 'text': '행정경험을', 'type': ''},\n",
       "   {'begin': 8.0, 'end': 9.0, 'id': 4.0, 'text': '통해', 'type': ''},\n",
       "   {'begin': 10.0, 'end': 11.0, 'id': 5.0, 'text': '쌓은', 'type': ''},\n",
       "   {'begin': 12.0, 'end': 14.0, 'id': 6.0, 'text': '노하우,', 'type': ''},\n",
       "   {'begin': 15.0, 'end': 16.0, 'id': 7.0, 'text': '업무를', 'type': ''},\n",
       "   {'begin': 17.0, 'end': 19.0, 'id': 8.0, 'text': '추진하는', 'type': ''},\n",
       "   {'begin': 20.0, 'end': 21.0, 'id': 9.0, 'text': '뜨거운', 'type': ''},\n",
       "   {'begin': 22.0, 'end': 23.0, 'id': 10.0, 'text': '열정,', 'type': ''},\n",
       "   {'begin': 24.0, 'end': 25.0, 'id': 11.0, 'text': '뛰어난', 'type': ''},\n",
       "   {'begin': 26.0, 'end': 27.0, 'id': 12.0, 'text': '리더쉽,', 'type': ''},\n",
       "   {'begin': 28.0, 'end': 28.0, 'id': 13.0, 'text': '신', 'type': ''},\n",
       "   {'begin': 29.0, 'end': 30.0, 'id': 14.0, 'text': '국장이', 'type': ''},\n",
       "   {'begin': 31.0, 'end': 32.0, 'id': 15.0, 'text': '공직사회', 'type': ''},\n",
       "   {'begin': 33.0, 'end': 35.0, 'id': 16.0, 'text': '후배들에게', 'type': ''},\n",
       "   {'begin': 36.0, 'end': 37.0, 'id': 17.0, 'text': '받는', 'type': ''},\n",
       "   {'begin': 38.0, 'end': 41.0, 'id': 18.0, 'text': '평가다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 0.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'text': '고양시',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.4491},\n",
       "   {'begin': 4.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 6.0,\n",
       "    'id': 1.0,\n",
       "    'text': '1959년생',\n",
       "    'type': 'QT_AGE',\n",
       "    'weight': 0.283614},\n",
       "   {'begin': 7.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 7.0,\n",
       "    'id': 2.0,\n",
       "    'text': '선배',\n",
       "    'type': 'CV_RELATION',\n",
       "    'weight': 0.563974},\n",
       "   {'begin': 11.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 12.0,\n",
       "    'id': 3.0,\n",
       "    'text': '여섯분',\n",
       "    'type': 'QT_MAN_COUNT',\n",
       "    'weight': 0.236541},\n",
       "   {'begin': 23.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 23.0,\n",
       "    'id': 4.0,\n",
       "    'text': '고양시',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.464346},\n",
       "   {'begin': 28.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 28.0,\n",
       "    'id': 5.0,\n",
       "    'text': '후배',\n",
       "    'type': 'CV_RELATION',\n",
       "    'weight': 0.518573}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 2539.0,\n",
       "    'scode': '00',\n",
       "    'text': '고양시',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 2.0,\n",
       "    'id': 1.0,\n",
       "    'position': 2548.0,\n",
       "    'scode': '00',\n",
       "    'text': '관계자',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 2.0,\n",
       "    'position': 2557.0,\n",
       "    'scode': '00',\n",
       "    'text': '는',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 4.0,\n",
       "    'end': 4.0,\n",
       "    'id': 3.0,\n",
       "    'position': 2561.0,\n",
       "    'scode': '00',\n",
       "    'text': '1959',\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 5.0,\n",
       "    'end': 5.0,\n",
       "    'id': 4.0,\n",
       "    'position': 2565.0,\n",
       "    'scode': '02',\n",
       "    'text': '년',\n",
       "    'type': 'NNB',\n",
       "    'weight': 6.9},\n",
       "   {'begin': 6.0,\n",
       "    'end': 6.0,\n",
       "    'id': 5.0,\n",
       "    'position': 2568.0,\n",
       "    'scode': '08',\n",
       "    'text': '생',\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.5},\n",
       "   {'begin': 7.0,\n",
       "    'end': 7.0,\n",
       "    'id': 6.0,\n",
       "    'position': 2572.0,\n",
       "    'scode': '00',\n",
       "    'text': '선배',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 8.0,\n",
       "    'end': 8.0,\n",
       "    'id': 7.0,\n",
       "    'position': 2578.0,\n",
       "    'scode': '09',\n",
       "    'text': '들',\n",
       "    'type': 'XSN',\n",
       "    'weight': 6.5},\n",
       "   {'begin': 9.0,\n",
       "    'end': 9.0,\n",
       "    'id': 8.0,\n",
       "    'position': 2581.0,\n",
       "    'scode': '01',\n",
       "    'text': '이',\n",
       "    'type': 'VCP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 10.0,\n",
       "    'end': 10.0,\n",
       "    'id': 9.0,\n",
       "    'position': 2581.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 11.0,\n",
       "    'end': 11.0,\n",
       "    'id': 10.0,\n",
       "    'position': 2585.0,\n",
       "    'scode': '00',\n",
       "    'text': '여섯',\n",
       "    'type': 'NR',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 12.0,\n",
       "    'end': 12.0,\n",
       "    'id': 11.0,\n",
       "    'position': 2591.0,\n",
       "    'scode': '01',\n",
       "    'text': '분',\n",
       "    'type': 'NNB',\n",
       "    'weight': 2.70454},\n",
       "   {'begin': 13.0,\n",
       "    'end': 13.0,\n",
       "    'id': 12.0,\n",
       "    'position': 2594.0,\n",
       "    'scode': '00',\n",
       "    'text': '에게',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 14.0,\n",
       "    'end': 14.0,\n",
       "    'id': 13.0,\n",
       "    'position': 2601.0,\n",
       "    'scode': '00',\n",
       "    'text': '많',\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 15.0,\n",
       "    'end': 15.0,\n",
       "    'id': 14.0,\n",
       "    'position': 2604.0,\n",
       "    'scode': '00',\n",
       "    'text': '은',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 16.0,\n",
       "    'end': 16.0,\n",
       "    'id': 15.0,\n",
       "    'position': 2608.0,\n",
       "    'scode': '08',\n",
       "    'text': '감사',\n",
       "    'type': 'NNG',\n",
       "    'weight': 2.18507},\n",
       "   {'begin': 17.0,\n",
       "    'end': 17.0,\n",
       "    'id': 16.0,\n",
       "    'position': 2614.0,\n",
       "    'scode': '00',\n",
       "    'text': '와',\n",
       "    'type': 'JC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 18.0,\n",
       "    'end': 18.0,\n",
       "    'id': 17.0,\n",
       "    'position': 2618.0,\n",
       "    'scode': '00',\n",
       "    'text': '응원',\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 19.0,\n",
       "    'end': 19.0,\n",
       "    'id': 18.0,\n",
       "    'position': 2624.0,\n",
       "    'scode': '00',\n",
       "    'text': '을',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 20.0,\n",
       "    'end': 20.0,\n",
       "    'id': 19.0,\n",
       "    'position': 2628.0,\n",
       "    'scode': '01',\n",
       "    'text': '드리',\n",
       "    'type': 'VV',\n",
       "    'weight': 2.2},\n",
       "   {'begin': 21.0,\n",
       "    'end': 21.0,\n",
       "    'id': 20.0,\n",
       "    'position': 2631.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ다며',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 22.0,\n",
       "    'end': 22.0,\n",
       "    'id': 21.0,\n",
       "    'position': 2641.0,\n",
       "    'scode': '01',\n",
       "    'text': '이제',\n",
       "    'type': 'MAG',\n",
       "    'weight': 5.4},\n",
       "   {'begin': 23.0,\n",
       "    'end': 23.0,\n",
       "    'id': 22.0,\n",
       "    'position': 2648.0,\n",
       "    'scode': '00',\n",
       "    'text': '고양시',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 24.0,\n",
       "    'end': 24.0,\n",
       "    'id': 23.0,\n",
       "    'position': 2657.0,\n",
       "    'scode': '00',\n",
       "    'text': '의',\n",
       "    'type': 'JKG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 25.0,\n",
       "    'end': 25.0,\n",
       "    'id': 24.0,\n",
       "    'position': 2661.0,\n",
       "    'scode': '01',\n",
       "    'text': '다음',\n",
       "    'type': 'NNG',\n",
       "    'weight': 6.4},\n",
       "   {'begin': 26.0,\n",
       "    'end': 26.0,\n",
       "    'id': 25.0,\n",
       "    'position': 2667.0,\n",
       "    'scode': '01',\n",
       "    'text': '일',\n",
       "    'type': 'NNG',\n",
       "    'weight': 5.4},\n",
       "   {'begin': 27.0,\n",
       "    'end': 27.0,\n",
       "    'id': 26.0,\n",
       "    'position': 2670.0,\n",
       "    'scode': '00',\n",
       "    'text': '은',\n",
       "    'type': 'JX',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 28.0,\n",
       "    'end': 28.0,\n",
       "    'id': 27.0,\n",
       "    'position': 2674.0,\n",
       "    'scode': '06',\n",
       "    'text': '후배',\n",
       "    'type': 'NNG',\n",
       "    'weight': 3.0},\n",
       "   {'begin': 29.0,\n",
       "    'end': 29.0,\n",
       "    'id': 28.0,\n",
       "    'position': 2680.0,\n",
       "    'scode': '09',\n",
       "    'text': '들',\n",
       "    'type': 'XSN',\n",
       "    'weight': 7.5},\n",
       "   {'begin': 30.0,\n",
       "    'end': 30.0,\n",
       "    'id': 29.0,\n",
       "    'position': 2683.0,\n",
       "    'scode': '00',\n",
       "    'text': '에게',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 31.0,\n",
       "    'end': 31.0,\n",
       "    'id': 30.0,\n",
       "    'position': 2690.0,\n",
       "    'scode': '00',\n",
       "    'text': '맡기',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 32.0,\n",
       "    'end': 32.0,\n",
       "    'id': 31.0,\n",
       "    'position': 2696.0,\n",
       "    'scode': '00',\n",
       "    'text': '고',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 33.0,\n",
       "    'end': 33.0,\n",
       "    'id': 32.0,\n",
       "    'position': 2700.0,\n",
       "    'scode': '00',\n",
       "    'text': '새롭',\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 34.0,\n",
       "    'end': 34.0,\n",
       "    'id': 33.0,\n",
       "    'position': 2706.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ',\n",
       "    'type': 'ETM',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 35.0,\n",
       "    'end': 35.0,\n",
       "    'id': 34.0,\n",
       "    'position': 2710.0,\n",
       "    'scode': '01',\n",
       "    'text': '인생',\n",
       "    'type': 'NNG',\n",
       "    'weight': 5.2},\n",
       "   {'begin': 36.0,\n",
       "    'end': 36.0,\n",
       "    'id': 35.0,\n",
       "    'position': 2716.0,\n",
       "    'scode': '00',\n",
       "    'text': '에서',\n",
       "    'type': 'JKB',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 37.0,\n",
       "    'end': 37.0,\n",
       "    'id': 36.0,\n",
       "    'position': 2723.0,\n",
       "    'scode': '00',\n",
       "    'text': '또',\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 38.0,\n",
       "    'end': 38.0,\n",
       "    'id': 37.0,\n",
       "    'position': 2727.0,\n",
       "    'scode': '00',\n",
       "    'text': '다른',\n",
       "    'type': 'MM',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 39.0,\n",
       "    'end': 39.0,\n",
       "    'id': 38.0,\n",
       "    'position': 2734.0,\n",
       "    'scode': '01',\n",
       "    'text': '성공',\n",
       "    'type': 'NNG',\n",
       "    'weight': 5.2},\n",
       "   {'begin': 40.0,\n",
       "    'end': 40.0,\n",
       "    'id': 39.0,\n",
       "    'position': 2740.0,\n",
       "    'scode': '00',\n",
       "    'text': '이',\n",
       "    'type': 'JKS',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 41.0,\n",
       "    'end': 41.0,\n",
       "    'id': 40.0,\n",
       "    'position': 2744.0,\n",
       "    'scode': '01',\n",
       "    'text': '있',\n",
       "    'type': 'VA',\n",
       "    'weight': 8.8},\n",
       "   {'begin': 42.0,\n",
       "    'end': 42.0,\n",
       "    'id': 41.0,\n",
       "    'position': 2747.0,\n",
       "    'scode': '00',\n",
       "    'text': '기',\n",
       "    'type': 'ETN',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 43.0,\n",
       "    'end': 43.0,\n",
       "    'id': 42.0,\n",
       "    'position': 2747.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄹ',\n",
       "    'type': 'JKO',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 44.0,\n",
       "    'end': 45.0,\n",
       "    'id': 43.0,\n",
       "    'position': 2751.0,\n",
       "    'scode': '01',\n",
       "    'text': '기원하',\n",
       "    'type': 'VV',\n",
       "    'weight': 4.2},\n",
       "   {'begin': 46.0,\n",
       "    'end': 46.0,\n",
       "    'id': 44.0,\n",
       "    'position': 2757.0,\n",
       "    'scode': '00',\n",
       "    'text': 'ㄴ다고',\n",
       "    'type': 'EC',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 47.0,\n",
       "    'end': 48.0,\n",
       "    'id': 45.0,\n",
       "    'position': 2767.0,\n",
       "    'scode': '00',\n",
       "    'text': '말하',\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 49.0,\n",
       "    'end': 49.0,\n",
       "    'id': 46.0,\n",
       "    'position': 2770.0,\n",
       "    'scode': '00',\n",
       "    'text': '었',\n",
       "    'type': 'EP',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 50.0,\n",
       "    'end': 50.0,\n",
       "    'id': 47.0,\n",
       "    'position': 2773.0,\n",
       "    'scode': '00',\n",
       "    'text': '다',\n",
       "    'type': 'EF',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 51.0,\n",
       "    'end': 51.0,\n",
       "    'id': 48.0,\n",
       "    'position': 2776.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': 7.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [],\n",
       "    'text': '고양시관계자는',\n",
       "    'weight': 0.34617},\n",
       "   {'head': 2.0,\n",
       "    'id': 1.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '1959년생',\n",
       "    'weight': 0.107627},\n",
       "   {'head': 3.0,\n",
       "    'id': 2.0,\n",
       "    'label': 'VNP_MOD',\n",
       "    'mod': [1.0],\n",
       "    'text': '선배들인',\n",
       "    'weight': 0.545596},\n",
       "   {'head': 7.0,\n",
       "    'id': 3.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [2.0],\n",
       "    'text': '여섯분에게',\n",
       "    'weight': 0.622247},\n",
       "   {'head': 6.0,\n",
       "    'id': 4.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '많은',\n",
       "    'weight': 0.563028},\n",
       "   {'head': 6.0,\n",
       "    'id': 5.0,\n",
       "    'label': 'NP_CNJ',\n",
       "    'mod': [],\n",
       "    'text': '감사와',\n",
       "    'weight': 0.69863},\n",
       "   {'head': 7.0,\n",
       "    'id': 6.0,\n",
       "    'label': 'NP_OBJ',\n",
       "    'mod': [4.0, 5.0],\n",
       "    'text': '응원을',\n",
       "    'weight': 0.694341},\n",
       "   {'head': 12.0,\n",
       "    'id': 7.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [0.0, 3.0, 6.0],\n",
       "    'text': '드린다며',\n",
       "    'weight': 0.627472},\n",
       "   {'head': 12.0,\n",
       "    'id': 8.0,\n",
       "    'label': 'AP',\n",
       "    'mod': [],\n",
       "    'text': '이제',\n",
       "    'weight': 0.625879},\n",
       "   {'head': 10.0,\n",
       "    'id': 9.0,\n",
       "    'label': 'NP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '고양시의',\n",
       "    'weight': 0.639676},\n",
       "   {'head': 12.0,\n",
       "    'id': 10.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [9.0],\n",
       "    'text': '다음일은',\n",
       "    'weight': 0.364868},\n",
       "   {'head': 12.0,\n",
       "    'id': 11.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [],\n",
       "    'text': '후배들에게',\n",
       "    'weight': 0.795805},\n",
       "   {'head': 18.0,\n",
       "    'id': 12.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [7.0, 8.0, 10.0, 11.0],\n",
       "    'text': '맡기고',\n",
       "    'weight': 0.769874},\n",
       "   {'head': 14.0,\n",
       "    'id': 13.0,\n",
       "    'label': 'VP_MOD',\n",
       "    'mod': [],\n",
       "    'text': '새로운',\n",
       "    'weight': 0.646145},\n",
       "   {'head': 18.0,\n",
       "    'id': 14.0,\n",
       "    'label': 'NP_AJT',\n",
       "    'mod': [13.0],\n",
       "    'text': '인생에서',\n",
       "    'weight': 0.685025},\n",
       "   {'head': 18.0,\n",
       "    'id': 15.0,\n",
       "    'label': 'AP',\n",
       "    'mod': [],\n",
       "    'text': '또',\n",
       "    'weight': 0.72095},\n",
       "   {'head': 17.0,\n",
       "    'id': 16.0,\n",
       "    'label': 'DP',\n",
       "    'mod': [],\n",
       "    'text': '다른',\n",
       "    'weight': 0.470583},\n",
       "   {'head': 18.0,\n",
       "    'id': 17.0,\n",
       "    'label': 'NP_SBJ',\n",
       "    'mod': [16.0],\n",
       "    'text': '성공이',\n",
       "    'weight': 0.677345},\n",
       "   {'head': 19.0,\n",
       "    'id': 18.0,\n",
       "    'label': 'VP_OBJ',\n",
       "    'mod': [12.0, 14.0, 15.0, 17.0],\n",
       "    'text': '있길',\n",
       "    'weight': 0.538848},\n",
       "   {'head': 20.0,\n",
       "    'id': 19.0,\n",
       "    'label': 'VP_CMP',\n",
       "    'mod': [18.0],\n",
       "    'text': '기원한다고',\n",
       "    'weight': 0.735022},\n",
       "   {'head': -1.0,\n",
       "    'id': 20.0,\n",
       "    'label': 'VP',\n",
       "    'mod': [19.0],\n",
       "    'text': '말했다.',\n",
       "    'weight': 5.35772e-06}],\n",
       "  'id': 17.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '고양시',\n",
       "    'position': 2539.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0536206},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '관계',\n",
       "    'position': 2548.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0813997},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '자',\n",
       "    'position': 2554.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0813997},\n",
       "   {'id': 3.0,\n",
       "    'lemma': '는',\n",
       "    'position': 2557.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.0856465},\n",
       "   {'id': 4.0,\n",
       "    'lemma': '1959',\n",
       "    'position': 2561.0,\n",
       "    'type': 'SN',\n",
       "    'weight': 1.0},\n",
       "   {'id': 5.0,\n",
       "    'lemma': '년',\n",
       "    'position': 2565.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.0562885},\n",
       "   {'id': 6.0,\n",
       "    'lemma': '생',\n",
       "    'position': 2568.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0345796},\n",
       "   {'id': 7.0,\n",
       "    'lemma': '선배',\n",
       "    'position': 2572.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0903209},\n",
       "   {'id': 8.0,\n",
       "    'lemma': '들',\n",
       "    'position': 2578.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0527148},\n",
       "   {'id': 9.0,\n",
       "    'lemma': '이',\n",
       "    'position': 2581.0,\n",
       "    'type': 'VCP',\n",
       "    'weight': 0.0358219},\n",
       "   {'id': 10.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 2581.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0358219},\n",
       "   {'id': 11.0,\n",
       "    'lemma': '여섯',\n",
       "    'position': 2585.0,\n",
       "    'type': 'NR',\n",
       "    'weight': 0.0531325},\n",
       "   {'id': 12.0,\n",
       "    'lemma': '분',\n",
       "    'position': 2591.0,\n",
       "    'type': 'NNB',\n",
       "    'weight': 0.0457801},\n",
       "   {'id': 13.0,\n",
       "    'lemma': '에게',\n",
       "    'position': 2594.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.055368},\n",
       "   {'id': 14.0,\n",
       "    'lemma': '많',\n",
       "    'position': 2601.0,\n",
       "    'type': 'VA',\n",
       "    'weight': 0.171662},\n",
       "   {'id': 15.0,\n",
       "    'lemma': '은',\n",
       "    'position': 2604.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0921806},\n",
       "   {'id': 16.0,\n",
       "    'lemma': '감사',\n",
       "    'position': 2608.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.141198},\n",
       "   {'id': 17.0,\n",
       "    'lemma': '와',\n",
       "    'position': 2614.0,\n",
       "    'type': 'JC',\n",
       "    'weight': 0.0553306},\n",
       "   {'id': 18.0,\n",
       "    'lemma': '응원',\n",
       "    'position': 2618.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0887637},\n",
       "   {'id': 19.0,\n",
       "    'lemma': '을',\n",
       "    'position': 2624.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0974475},\n",
       "   {'id': 20.0,\n",
       "    'lemma': '드리',\n",
       "    'position': 2628.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0506935},\n",
       "   {'id': 21.0,\n",
       "    'lemma': 'ㄴ다며',\n",
       "    'position': 2631.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0452142},\n",
       "   {'id': 22.0,\n",
       "    'lemma': '이제',\n",
       "    'position': 2641.0,\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.0792857},\n",
       "   {'id': 23.0,\n",
       "    'lemma': '고양시',\n",
       "    'position': 2648.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0602277},\n",
       "   {'id': 24.0,\n",
       "    'lemma': '의',\n",
       "    'position': 2657.0,\n",
       "    'type': 'JKG',\n",
       "    'weight': 0.0843952},\n",
       "   {'id': 25.0,\n",
       "    'lemma': '다음',\n",
       "    'position': 2661.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0680206},\n",
       "   {'id': 26.0,\n",
       "    'lemma': '일',\n",
       "    'position': 2667.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.024656},\n",
       "   {'id': 27.0,\n",
       "    'lemma': '은',\n",
       "    'position': 2670.0,\n",
       "    'type': 'JX',\n",
       "    'weight': 0.0773276},\n",
       "   {'id': 28.0,\n",
       "    'lemma': '후배',\n",
       "    'position': 2674.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0751073},\n",
       "   {'id': 29.0,\n",
       "    'lemma': '들',\n",
       "    'position': 2680.0,\n",
       "    'type': 'XSN',\n",
       "    'weight': 0.0750811},\n",
       "   {'id': 30.0,\n",
       "    'lemma': '에게',\n",
       "    'position': 2683.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0750384},\n",
       "   {'id': 31.0,\n",
       "    'lemma': '맡기',\n",
       "    'position': 2690.0,\n",
       "    'type': 'VV',\n",
       "    'weight': 0.0830628},\n",
       "   {'id': 32.0,\n",
       "    'lemma': '고',\n",
       "    'position': 2696.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.0852899},\n",
       "   {'id': 33.0,\n",
       "    'lemma': '새롭',\n",
       "    'position': 2700.0,\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0696052},\n",
       "   {'id': 34.0,\n",
       "    'lemma': 'ㄴ',\n",
       "    'position': 2706.0,\n",
       "    'type': 'ETM',\n",
       "    'weight': 0.0822032},\n",
       "   {'id': 35.0,\n",
       "    'lemma': '인생',\n",
       "    'position': 2710.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.100384},\n",
       "   {'id': 36.0,\n",
       "    'lemma': '에서',\n",
       "    'position': 2716.0,\n",
       "    'type': 'JKB',\n",
       "    'weight': 0.0829839},\n",
       "   {'id': 37.0,\n",
       "    'lemma': '또',\n",
       "    'position': 2723.0,\n",
       "    'type': 'MAG',\n",
       "    'weight': 0.150624},\n",
       "   {'id': 38.0,\n",
       "    'lemma': '다른',\n",
       "    'position': 2727.0,\n",
       "    'type': 'MM',\n",
       "    'weight': 0.084338},\n",
       "   {'id': 39.0,\n",
       "    'lemma': '성공',\n",
       "    'position': 2734.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0869531},\n",
       "   {'id': 40.0,\n",
       "    'lemma': '이',\n",
       "    'position': 2740.0,\n",
       "    'type': 'JKS',\n",
       "    'weight': 0.0963478},\n",
       "   {'id': 41.0,\n",
       "    'lemma': '있',\n",
       "    'position': 2744.0,\n",
       "    'type': 'VA',\n",
       "    'weight': 0.0887464},\n",
       "   {'id': 42.0,\n",
       "    'lemma': '기',\n",
       "    'position': 2747.0,\n",
       "    'type': 'ETN',\n",
       "    'weight': 0.0485912},\n",
       "   {'id': 43.0,\n",
       "    'lemma': 'ㄹ',\n",
       "    'position': 2747.0,\n",
       "    'type': 'JKO',\n",
       "    'weight': 0.0485912},\n",
       "   {'id': 44.0,\n",
       "    'lemma': '기원',\n",
       "    'position': 2751.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0447122},\n",
       "   {'id': 45.0,\n",
       "    'lemma': '하',\n",
       "    'position': 2757.0,\n",
       "    'type': 'XSV',\n",
       "    'weight': 0.0447122},\n",
       "   {'id': 46.0,\n",
       "    'lemma': 'ㄴ다고',\n",
       "    'position': 2757.0,\n",
       "    'type': 'EC',\n",
       "    'weight': 0.060314},\n",
       "   {'id': 47.0,\n",
       "    'lemma': '말',\n",
       "    'position': 2767.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0681178},\n",
       "   {'id': 48.0,\n",
       "    'lemma': '하',\n",
       "    'position': 2770.0,\n",
       "    'type': 'XSV',\n",
       "    'weight': 0.0464244},\n",
       "   {'id': 49.0,\n",
       "    'lemma': '었',\n",
       "    'position': 2770.0,\n",
       "    'type': 'EP',\n",
       "    'weight': 0.0464244},\n",
       "   {'id': 50.0,\n",
       "    'lemma': '다',\n",
       "    'position': 2773.0,\n",
       "    'type': 'EF',\n",
       "    'weight': 0.0914048},\n",
       "   {'id': 51.0,\n",
       "    'lemma': '.',\n",
       "    'position': 2776.0,\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': ' 고양시관계자는 1959년생 선배들인 여섯분에게 많은 감사와 응원을 드린다며 이제 고양시의 다음일은 후배들에게 맡기고 새로운 인생에서 또 다른 성공이 있길 기원한다고 말했다.',\n",
       "  'word': [{'begin': 0.0,\n",
       "    'end': 3.0,\n",
       "    'id': 0.0,\n",
       "    'text': '고양시관계자는',\n",
       "    'type': ''},\n",
       "   {'begin': 4.0, 'end': 6.0, 'id': 1.0, 'text': '1959년생', 'type': ''},\n",
       "   {'begin': 7.0, 'end': 10.0, 'id': 2.0, 'text': '선배들인', 'type': ''},\n",
       "   {'begin': 11.0, 'end': 13.0, 'id': 3.0, 'text': '여섯분에게', 'type': ''},\n",
       "   {'begin': 14.0, 'end': 15.0, 'id': 4.0, 'text': '많은', 'type': ''},\n",
       "   {'begin': 16.0, 'end': 17.0, 'id': 5.0, 'text': '감사와', 'type': ''},\n",
       "   {'begin': 18.0, 'end': 19.0, 'id': 6.0, 'text': '응원을', 'type': ''},\n",
       "   {'begin': 20.0, 'end': 21.0, 'id': 7.0, 'text': '드린다며', 'type': ''},\n",
       "   {'begin': 22.0, 'end': 22.0, 'id': 8.0, 'text': '이제', 'type': ''},\n",
       "   {'begin': 23.0, 'end': 24.0, 'id': 9.0, 'text': '고양시의', 'type': ''},\n",
       "   {'begin': 25.0, 'end': 27.0, 'id': 10.0, 'text': '다음일은', 'type': ''},\n",
       "   {'begin': 28.0, 'end': 30.0, 'id': 11.0, 'text': '후배들에게', 'type': ''},\n",
       "   {'begin': 31.0, 'end': 32.0, 'id': 12.0, 'text': '맡기고', 'type': ''},\n",
       "   {'begin': 33.0, 'end': 34.0, 'id': 13.0, 'text': '새로운', 'type': ''},\n",
       "   {'begin': 35.0, 'end': 36.0, 'id': 14.0, 'text': '인생에서', 'type': ''},\n",
       "   {'begin': 37.0, 'end': 37.0, 'id': 15.0, 'text': '또', 'type': ''},\n",
       "   {'begin': 38.0, 'end': 38.0, 'id': 16.0, 'text': '다른', 'type': ''},\n",
       "   {'begin': 39.0, 'end': 40.0, 'id': 17.0, 'text': '성공이', 'type': ''},\n",
       "   {'begin': 41.0, 'end': 43.0, 'id': 18.0, 'text': '있길', 'type': ''},\n",
       "   {'begin': 44.0, 'end': 46.0, 'id': 19.0, 'text': '기원한다고', 'type': ''},\n",
       "   {'begin': 47.0, 'end': 51.0, 'id': 20.0, 'text': '말했다.', 'type': ''}]},\n",
       " {'NE': [{'begin': 0.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'text': '고양유제원',\n",
       "    'type': 'LCP_CITY',\n",
       "    'weight': 0.138113},\n",
       "   {'begin': 1.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'text': '송주현',\n",
       "    'type': 'PS_NAME',\n",
       "    'weight': 0.449072},\n",
       "   {'begin': 2.0,\n",
       "    'common_noun': 0.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'text': '기자',\n",
       "    'type': 'CV_OCCUPATION',\n",
       "    'weight': 0.473491}],\n",
       "  'NE_Link': [],\n",
       "  'SRL': [],\n",
       "  'WSD': [{'begin': 0.0,\n",
       "    'end': 0.0,\n",
       "    'id': 0.0,\n",
       "    'position': 2778.0,\n",
       "    'scode': '00',\n",
       "    'text': '고양유제원',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 1.0,\n",
       "    'end': 1.0,\n",
       "    'id': 1.0,\n",
       "    'position': 2793.0,\n",
       "    'scode': '00',\n",
       "    'text': '송주현',\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0},\n",
       "   {'begin': 2.0,\n",
       "    'end': 2.0,\n",
       "    'id': 2.0,\n",
       "    'position': 2802.0,\n",
       "    'scode': '05',\n",
       "    'text': '기자',\n",
       "    'type': 'NNG',\n",
       "    'weight': 1.0},\n",
       "   {'begin': 3.0,\n",
       "    'end': 3.0,\n",
       "    'id': 3.0,\n",
       "    'position': 2808.0,\n",
       "    'scode': '00',\n",
       "    'text': '.',\n",
       "    'type': 'SF',\n",
       "    'weight': 1.0}],\n",
       "  'dependency': [{'head': -1.0,\n",
       "    'id': 0.0,\n",
       "    'label': 'NP',\n",
       "    'mod': [],\n",
       "    'text': '고양유제원송주현기자.',\n",
       "    'weight': 0.263873}],\n",
       "  'id': 18.0,\n",
       "  'morp': [{'id': 0.0,\n",
       "    'lemma': '고양유제원',\n",
       "    'position': 2778.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0242117},\n",
       "   {'id': 1.0,\n",
       "    'lemma': '송주현',\n",
       "    'position': 2793.0,\n",
       "    'type': 'NNP',\n",
       "    'weight': 0.0229775},\n",
       "   {'id': 2.0,\n",
       "    'lemma': '기자',\n",
       "    'position': 2802.0,\n",
       "    'type': 'NNG',\n",
       "    'weight': 0.0278239},\n",
       "   {'id': 3.0, 'lemma': '.', 'position': 2808.0, 'type': 'SF', 'weight': 1.0}],\n",
       "  'reserve_str': '',\n",
       "  'text': ' 고양유제원송주현기자. ',\n",
       "  'word': [{'begin': 0.0,\n",
       "    'end': 3.0,\n",
       "    'id': 0.0,\n",
       "    'text': '고양유제원송주현기자.',\n",
       "    'type': ''}]}]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_return_obj['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 967
    },
    "colab_type": "code",
    "id": "OFjKamDsQAhS",
    "outputId": "aa8eaa47-7b00-4580-90fb-52cfa6fefd48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'head': 1.0,\n",
       "  'id': 0.0,\n",
       "  'label': 'NP',\n",
       "  'mod': [],\n",
       "  'text': '송주현',\n",
       "  'weight': 0.618235},\n",
       " {'head': 2.0,\n",
       "  'id': 1.0,\n",
       "  'label': 'NP',\n",
       "  'mod': [0.0],\n",
       "  'text': '기자',\n",
       "  'weight': 0.438543},\n",
       " {'head': 3.0,\n",
       "  'id': 2.0,\n",
       "  'label': 'NP',\n",
       "  'mod': [1.0],\n",
       "  'text': '왼쪽',\n",
       "  'weight': 0.751633},\n",
       " {'head': 8.0,\n",
       "  'id': 3.0,\n",
       "  'label': 'NP',\n",
       "  'mod': [2.0],\n",
       "  'text': '위부터)김운용,',\n",
       "  'weight': 0.170749},\n",
       " {'head': 8.0,\n",
       "  'id': 4.0,\n",
       "  'label': 'NP_CNJ',\n",
       "  'mod': [],\n",
       "  'text': '이현옥,',\n",
       "  'weight': 0.429838},\n",
       " {'head': 8.0,\n",
       "  'id': 5.0,\n",
       "  'label': 'NP_CNJ',\n",
       "  'mod': [],\n",
       "  'text': '이흥민,',\n",
       "  'weight': 0.585637},\n",
       " {'head': 8.0,\n",
       "  'id': 6.0,\n",
       "  'label': 'NP_CNJ',\n",
       "  'mod': [],\n",
       "  'text': '노양호,',\n",
       "  'weight': 0.508906},\n",
       " {'head': 8.0,\n",
       "  'id': 7.0,\n",
       "  'label': 'NP_CNJ',\n",
       "  'mod': [],\n",
       "  'text': '정종현,',\n",
       "  'weight': 0.358688},\n",
       " {'head': -1.0,\n",
       "  'id': 8.0,\n",
       "  'label': 'NP',\n",
       "  'mod': [3.0, 4.0, 5.0, 6.0, 7.0],\n",
       "  'text': '신승일.',\n",
       "  'weight': 0.000866793}]"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = json_return_obj['sentence']\n",
    "sentence[0]['dependency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "yulLEizLLrKP",
    "outputId": "8d8a4df2-4a7f-45e2-9fd7-c204a6416944"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-59dc938b3d2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_return_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#json_return_obj[\"sentence\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "return_result = ''\n",
    "ls_return=[]\n",
    "\n",
    "sentence = json_return_obj['sentence']\n",
    "  for morp in sentence:\n",
    "    for dep in morp['dependency']:\n",
    "      for lmp in dep['label']:\n",
    "        if 'VP' in lmp:\n",
    "          return_result = return_result+str(dep[\"text\"])+\"/\"+str(dep[\"label\"])+\" \"\n",
    "          ls_return_append(str(dep[\"text\"])+\"/\"+str(dep[\"label\"]))\n",
    "        for depend in depend_list:\n",
    "          if depend in lmp:\n",
    "            return_result = return_result+str(dep[\"text\"])+\"/\"+str(dep[\"label\"])+\" \"\n",
    "            ls_return.append(str(dep[\"text\"])+\"/\"+str(dep[\"label\"]))\n",
    "\n",
    "\n",
    "\n",
    "#json_return_obj[\"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "im28yjy0MBRp",
    "outputId": "226f5afd-849b-44cf-b96e-d8b2c2bd6d6c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'NP'"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_return_obj[\"sentence\"][0]['dependency'][0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VGIcjP6gLUJH",
    "outputId": "30ad217e-cfd5-4ecb-e9a1-0278d706dfbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DCT': '',\n",
       " 'category': '',\n",
       " 'category_weight': 0.0,\n",
       " 'doc_id': '',\n",
       " 'entity': [],\n",
       " 'metaInfo': {},\n",
       " 'paragraphInfo': [],\n",
       " 'sentence': [{'NE': [{'begin': 0.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'text': '송주현',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.620646},\n",
       "    {'begin': 1.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'text': '기자',\n",
       "     'type': 'CV_OCCUPATION',\n",
       "     'weight': 0.602677},\n",
       "    {'begin': 2.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'text': '왼쪽',\n",
       "     'type': 'TM_DIRECTION',\n",
       "     'weight': 0.516759},\n",
       "    {'begin': 6.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 6.0,\n",
       "     'id': 3.0,\n",
       "     'text': '김운용',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.774615},\n",
       "    {'begin': 8.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 8.0,\n",
       "     'id': 4.0,\n",
       "     'text': '이현옥',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.587024},\n",
       "    {'begin': 10.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 10.0,\n",
       "     'id': 5.0,\n",
       "     'text': '이흥민',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.48841},\n",
       "    {'begin': 12.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 12.0,\n",
       "     'id': 6.0,\n",
       "     'text': '노양호',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.364307},\n",
       "    {'begin': 14.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 14.0,\n",
       "     'id': 7.0,\n",
       "     'text': '정종현',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.802612},\n",
       "    {'begin': 16.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 16.0,\n",
       "     'id': 8.0,\n",
       "     'text': '신승일',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.448303}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 0.0,\n",
       "     'scode': '00',\n",
       "     'text': '송주현',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 10.0,\n",
       "     'scode': '05',\n",
       "     'text': '기자',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 17.0,\n",
       "     'scode': '00',\n",
       "     'text': '왼쪽',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 24.0,\n",
       "     'scode': '01',\n",
       "     'text': '위',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.03851},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 27.0,\n",
       "     'scode': '00',\n",
       "     'text': '부터',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 5.0,\n",
       "     'position': 33.0,\n",
       "     'scode': '00',\n",
       "     'text': ')',\n",
       "     'type': 'SS',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 6.0,\n",
       "     'position': 34.0,\n",
       "     'scode': '00',\n",
       "     'text': '김운용',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 7.0,\n",
       "     'position': 43.0,\n",
       "     'scode': '00',\n",
       "     'text': ',',\n",
       "     'type': 'SP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 8.0,\n",
       "     'position': 45.0,\n",
       "     'scode': '00',\n",
       "     'text': '이현옥',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 9.0,\n",
       "     'position': 54.0,\n",
       "     'scode': '00',\n",
       "     'text': ',',\n",
       "     'type': 'SP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 10.0,\n",
       "     'position': 56.0,\n",
       "     'scode': '00',\n",
       "     'text': '이흥민',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 11.0,\n",
       "     'position': 65.0,\n",
       "     'scode': '00',\n",
       "     'text': ',',\n",
       "     'type': 'SP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 12.0,\n",
       "     'position': 67.0,\n",
       "     'scode': '00',\n",
       "     'text': '노양호',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 13.0,\n",
       "     'position': 76.0,\n",
       "     'scode': '00',\n",
       "     'text': ',',\n",
       "     'type': 'SP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 14.0,\n",
       "     'position': 78.0,\n",
       "     'scode': '00',\n",
       "     'text': '정종현',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 15.0,\n",
       "     'end': 15.0,\n",
       "     'id': 15.0,\n",
       "     'position': 87.0,\n",
       "     'scode': '00',\n",
       "     'text': ',',\n",
       "     'type': 'SP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 16.0,\n",
       "     'position': 89.0,\n",
       "     'scode': '00',\n",
       "     'text': '신승일',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 17.0,\n",
       "     'end': 17.0,\n",
       "     'id': 17.0,\n",
       "     'position': 98.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 1.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '송주현',\n",
       "     'weight': 0.618235},\n",
       "    {'head': 2.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [0.0],\n",
       "     'text': '기자',\n",
       "     'weight': 0.438543},\n",
       "    {'head': 3.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [1.0],\n",
       "     'text': '왼쪽',\n",
       "     'weight': 0.751633},\n",
       "    {'head': 8.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [2.0],\n",
       "     'text': '위부터)김운용,',\n",
       "     'weight': 0.170749},\n",
       "    {'head': 8.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'NP_CNJ',\n",
       "     'mod': [],\n",
       "     'text': '이현옥,',\n",
       "     'weight': 0.429838},\n",
       "    {'head': 8.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'NP_CNJ',\n",
       "     'mod': [],\n",
       "     'text': '이흥민,',\n",
       "     'weight': 0.585637},\n",
       "    {'head': 8.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'NP_CNJ',\n",
       "     'mod': [],\n",
       "     'text': '노양호,',\n",
       "     'weight': 0.508906},\n",
       "    {'head': 8.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'NP_CNJ',\n",
       "     'mod': [],\n",
       "     'text': '정종현,',\n",
       "     'weight': 0.358688},\n",
       "    {'head': -1.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [3.0, 4.0, 5.0, 6.0, 7.0],\n",
       "     'text': '신승일.',\n",
       "     'weight': 0.000866793}],\n",
       "   'id': 0.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '송주현',\n",
       "     'position': 0.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0718234},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '기자',\n",
       "     'position': 10.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0674813},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '왼쪽',\n",
       "     'position': 17.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.040396},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '위',\n",
       "     'position': 24.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0731358},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '부터',\n",
       "     'position': 27.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.0420098},\n",
       "    {'id': 5.0, 'lemma': ')', 'position': 33.0, 'type': 'SS', 'weight': 1.0},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '김운용',\n",
       "     'position': 34.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0218297},\n",
       "    {'id': 7.0, 'lemma': ',', 'position': 43.0, 'type': 'SP', 'weight': 1.0},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '이현옥',\n",
       "     'position': 45.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0447042},\n",
       "    {'id': 9.0, 'lemma': ',', 'position': 54.0, 'type': 'SP', 'weight': 1.0},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '이흥민',\n",
       "     'position': 56.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0351699},\n",
       "    {'id': 11.0, 'lemma': ',', 'position': 65.0, 'type': 'SP', 'weight': 1.0},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '노양호',\n",
       "     'position': 67.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0393358},\n",
       "    {'id': 13.0, 'lemma': ',', 'position': 76.0, 'type': 'SP', 'weight': 1.0},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '정종현',\n",
       "     'position': 78.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0734248},\n",
       "    {'id': 15.0, 'lemma': ',', 'position': 87.0, 'type': 'SP', 'weight': 1.0},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '신승일',\n",
       "     'position': 89.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0213686},\n",
       "    {'id': 17.0, 'lemma': '.', 'position': 98.0, 'type': 'SF', 'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': '송주현 기자 왼쪽 위부터)김운용, 이현옥, 이흥민, 노양호, 정종현, 신승일.',\n",
       "   'word': [{'begin': 0.0, 'end': 0.0, 'id': 0.0, 'text': '송주현', 'type': ''},\n",
       "    {'begin': 1.0, 'end': 1.0, 'id': 1.0, 'text': '기자', 'type': ''},\n",
       "    {'begin': 2.0, 'end': 2.0, 'id': 2.0, 'text': '왼쪽', 'type': ''},\n",
       "    {'begin': 3.0, 'end': 7.0, 'id': 3.0, 'text': '위부터)김운용,', 'type': ''},\n",
       "    {'begin': 8.0, 'end': 9.0, 'id': 4.0, 'text': '이현옥,', 'type': ''},\n",
       "    {'begin': 10.0, 'end': 11.0, 'id': 5.0, 'text': '이흥민,', 'type': ''},\n",
       "    {'begin': 12.0, 'end': 13.0, 'id': 6.0, 'text': '노양호,', 'type': ''},\n",
       "    {'begin': 14.0, 'end': 15.0, 'id': 7.0, 'text': '정종현,', 'type': ''},\n",
       "    {'begin': 16.0, 'end': 17.0, 'id': 8.0, 'text': '신승일.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 0.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 1.0,\n",
       "     'id': 0.0,\n",
       "     'text': '특례시',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 6.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 7.0,\n",
       "     'id': 1.0,\n",
       "     'text': '105만',\n",
       "     'type': 'QT_MAN_COUNT',\n",
       "     'weight': 0.479627},\n",
       "    {'begin': 8.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 8.0,\n",
       "     'id': 2.0,\n",
       "     'text': '고양시',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.419784},\n",
       "    {'begin': 22.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 23.0,\n",
       "     'id': 3.0,\n",
       "     'text': '6명',\n",
       "     'type': 'QT_MAN_COUNT',\n",
       "     'weight': 0.73004},\n",
       "    {'begin': 25.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 26.0,\n",
       "     'id': 4.0,\n",
       "     'text': '공직자',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.602736},\n",
       "    {'begin': 28.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 29.0,\n",
       "     'id': 5.0,\n",
       "     'text': '서기관',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.500018}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 100.0,\n",
       "     'scode': '00',\n",
       "     'text': '특례',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 106.0,\n",
       "     'scode': '10',\n",
       "     'text': '시',\n",
       "     'type': 'NNB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 110.0,\n",
       "     'scode': '14',\n",
       "     'text': '지정',\n",
       "     'type': 'NNG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 116.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 120.0,\n",
       "     'scode': '00',\n",
       "     'text': '앞두',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 5.0,\n",
       "     'position': 123.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 6.0,\n",
       "     'position': 127.0,\n",
       "     'scode': '00',\n",
       "     'text': '105',\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 7.0,\n",
       "     'position': 130.0,\n",
       "     'scode': '06',\n",
       "     'text': '만',\n",
       "     'type': 'NR',\n",
       "     'weight': 3.5},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 8.0,\n",
       "     'position': 134.0,\n",
       "     'scode': '00',\n",
       "     'text': '고양시',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 9.0,\n",
       "     'position': 143.0,\n",
       "     'scode': '00',\n",
       "     'text': '의',\n",
       "     'type': 'JKG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 10.0,\n",
       "     'position': 147.0,\n",
       "     'scode': '01',\n",
       "     'text': '발전',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.83599},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 11.0,\n",
       "     'position': 153.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 12.0,\n",
       "     'position': 157.0,\n",
       "     'scode': '01',\n",
       "     'text': '위하',\n",
       "     'type': 'VV',\n",
       "     'weight': 6.6},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 13.0,\n",
       "     'position': 160.0,\n",
       "     'scode': '00',\n",
       "     'text': '어',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 14.0,\n",
       "     'position': 164.0,\n",
       "     'scode': '01',\n",
       "     'text': '땀',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.71667},\n",
       "    {'begin': 15.0,\n",
       "     'end': 15.0,\n",
       "     'id': 15.0,\n",
       "     'position': 167.0,\n",
       "     'scode': '00',\n",
       "     'text': '과',\n",
       "     'type': 'JC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 16.0,\n",
       "     'position': 171.0,\n",
       "     'scode': '02',\n",
       "     'text': '열정',\n",
       "     'type': 'NNG',\n",
       "     'weight': 4.4},\n",
       "    {'begin': 17.0,\n",
       "     'end': 17.0,\n",
       "     'id': 17.0,\n",
       "     'position': 177.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 18.0,\n",
       "     'end': 18.0,\n",
       "     'id': 18.0,\n",
       "     'position': 181.0,\n",
       "     'scode': '00',\n",
       "     'text': '쏟',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 19.0,\n",
       "     'end': 19.0,\n",
       "     'id': 19.0,\n",
       "     'position': 184.0,\n",
       "     'scode': '00',\n",
       "     'text': '아',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 20.0,\n",
       "     'position': 187.0,\n",
       "     'scode': '01',\n",
       "     'text': '오',\n",
       "     'type': 'VX',\n",
       "     'weight': 6.0},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 21.0,\n",
       "     'position': 187.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 22.0,\n",
       "     'end': 22.0,\n",
       "     'id': 22.0,\n",
       "     'position': 191.0,\n",
       "     'scode': '00',\n",
       "     'text': '6',\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 23.0,\n",
       "     'end': 23.0,\n",
       "     'id': 23.0,\n",
       "     'position': 192.0,\n",
       "     'scode': '03',\n",
       "     'text': '명',\n",
       "     'type': 'NNB',\n",
       "     'weight': 5.2},\n",
       "    {'begin': 24.0,\n",
       "     'end': 24.0,\n",
       "     'id': 24.0,\n",
       "     'position': 195.0,\n",
       "     'scode': '00',\n",
       "     'text': '의',\n",
       "     'type': 'JKG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 25.0,\n",
       "     'end': 26.0,\n",
       "     'id': 25.0,\n",
       "     'position': 199.0,\n",
       "     'scode': '00',\n",
       "     'text': '공직자',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 27.0,\n",
       "     'end': 27.0,\n",
       "     'id': 26.0,\n",
       "     'position': 208.0,\n",
       "     'scode': '00',\n",
       "     'text': '(',\n",
       "     'type': 'SS',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 28.0,\n",
       "     'end': 29.0,\n",
       "     'id': 27.0,\n",
       "     'position': 209.0,\n",
       "     'scode': '00',\n",
       "     'text': '서기관',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 30.0,\n",
       "     'end': 30.0,\n",
       "     'id': 28.0,\n",
       "     'position': 218.0,\n",
       "     'scode': '00',\n",
       "     'text': ')',\n",
       "     'type': 'SS',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 31.0,\n",
       "     'end': 31.0,\n",
       "     'id': 29.0,\n",
       "     'position': 219.0,\n",
       "     'scode': '09',\n",
       "     'text': '들',\n",
       "     'type': 'XSN',\n",
       "     'weight': 7.0},\n",
       "    {'begin': 32.0,\n",
       "     'end': 32.0,\n",
       "     'id': 30.0,\n",
       "     'position': 222.0,\n",
       "     'scode': '00',\n",
       "     'text': '이',\n",
       "     'type': 'JKS',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 33.0,\n",
       "     'end': 34.0,\n",
       "     'id': 31.0,\n",
       "     'position': 226.0,\n",
       "     'scode': '00',\n",
       "     'text': '아름답',\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 35.0,\n",
       "     'end': 35.0,\n",
       "     'id': 32.0,\n",
       "     'position': 235.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 36.0,\n",
       "     'end': 36.0,\n",
       "     'id': 33.0,\n",
       "     'position': 239.0,\n",
       "     'scode': '02',\n",
       "     'text': '퇴장',\n",
       "     'type': 'NNG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 37.0,\n",
       "     'end': 37.0,\n",
       "     'id': 34.0,\n",
       "     'position': 245.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 38.0,\n",
       "     'end': 38.0,\n",
       "     'id': 35.0,\n",
       "     'position': 249.0,\n",
       "     'scode': '00',\n",
       "     'text': '앞두',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 39.0,\n",
       "     'end': 39.0,\n",
       "     'id': 36.0,\n",
       "     'position': 255.0,\n",
       "     'scode': '00',\n",
       "     'text': '고',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 40.0,\n",
       "     'end': 40.0,\n",
       "     'id': 37.0,\n",
       "     'position': 259.0,\n",
       "     'scode': '01',\n",
       "     'text': '있',\n",
       "     'type': 'VX',\n",
       "     'weight': 3.2},\n",
       "    {'begin': 41.0,\n",
       "     'end': 41.0,\n",
       "     'id': 38.0,\n",
       "     'position': 262.0,\n",
       "     'scode': '00',\n",
       "     'text': '다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 42.0,\n",
       "     'end': 42.0,\n",
       "     'id': 39.0,\n",
       "     'position': 265.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 1.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '특례시',\n",
       "     'weight': 0.238887},\n",
       "    {'head': 2.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [0.0],\n",
       "     'text': '지정을',\n",
       "     'weight': 0.455433},\n",
       "    {'head': 4.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [1.0],\n",
       "     'text': '앞둔',\n",
       "     'weight': 0.326141},\n",
       "    {'head': 4.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '105만',\n",
       "     'weight': 0.512135},\n",
       "    {'head': 5.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'NP_MOD',\n",
       "     'mod': [2.0, 3.0],\n",
       "     'text': '고양시의',\n",
       "     'weight': 0.64694},\n",
       "    {'head': 6.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [4.0],\n",
       "     'text': '발전을',\n",
       "     'weight': 0.682906},\n",
       "    {'head': 9.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [5.0],\n",
       "     'text': '위해',\n",
       "     'weight': 0.625582},\n",
       "    {'head': 8.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'NP_CNJ',\n",
       "     'mod': [],\n",
       "     'text': '땀과',\n",
       "     'weight': 0.742481},\n",
       "    {'head': 9.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [7.0],\n",
       "     'text': '열정을',\n",
       "     'weight': 0.758713},\n",
       "    {'head': 11.0,\n",
       "     'id': 9.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [6.0, 8.0],\n",
       "     'text': '쏟아온',\n",
       "     'weight': 0.702712},\n",
       "    {'head': 11.0,\n",
       "     'id': 10.0,\n",
       "     'label': 'NP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '6명의',\n",
       "     'weight': 0.674267},\n",
       "    {'head': 14.0,\n",
       "     'id': 11.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [9.0, 10.0],\n",
       "     'text': '공직자(서기관)들이',\n",
       "     'weight': 0.726809},\n",
       "    {'head': 13.0,\n",
       "     'id': 12.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '아름다운',\n",
       "     'weight': 0.689657},\n",
       "    {'head': 14.0,\n",
       "     'id': 13.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [12.0],\n",
       "     'text': '퇴장을',\n",
       "     'weight': 0.683548},\n",
       "    {'head': 15.0,\n",
       "     'id': 14.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [11.0, 13.0],\n",
       "     'text': '앞두고',\n",
       "     'weight': 0.687865},\n",
       "    {'head': -1.0,\n",
       "     'id': 15.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [14.0],\n",
       "     'text': '있다.',\n",
       "     'weight': 0.00025235}],\n",
       "   'id': 1.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '특례',\n",
       "     'position': 100.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0940307},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '시',\n",
       "     'position': 106.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.0185931},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '지정',\n",
       "     'position': 110.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0952375},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '을',\n",
       "     'position': 116.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0929647},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '앞두',\n",
       "     'position': 120.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0739523},\n",
       "    {'id': 5.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 123.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0446133},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '105',\n",
       "     'position': 127.0,\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '만',\n",
       "     'position': 130.0,\n",
       "     'type': 'NR',\n",
       "     'weight': 0.0390491},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '고양시',\n",
       "     'position': 134.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0573831},\n",
       "    {'id': 9.0,\n",
       "     'lemma': '의',\n",
       "     'position': 143.0,\n",
       "     'type': 'JKG',\n",
       "     'weight': 0.0806884},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '발전',\n",
       "     'position': 147.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0873932},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '을',\n",
       "     'position': 153.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0953326},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '위하',\n",
       "     'position': 157.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.114276},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '어',\n",
       "     'position': 160.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0954842},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '땀',\n",
       "     'position': 164.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0578831},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '과',\n",
       "     'position': 167.0,\n",
       "     'type': 'JC',\n",
       "     'weight': 0.06294},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '열정',\n",
       "     'position': 171.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0715766},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '을',\n",
       "     'position': 177.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0892933},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '쏟',\n",
       "     'position': 181.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.101958},\n",
       "    {'id': 19.0,\n",
       "     'lemma': '아',\n",
       "     'position': 184.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0528974},\n",
       "    {'id': 20.0,\n",
       "     'lemma': '오',\n",
       "     'position': 187.0,\n",
       "     'type': 'VX',\n",
       "     'weight': 0.0262734},\n",
       "    {'id': 21.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 187.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0262734},\n",
       "    {'id': 22.0, 'lemma': '6', 'position': 191.0, 'type': 'SN', 'weight': 1.0},\n",
       "    {'id': 23.0,\n",
       "     'lemma': '명',\n",
       "     'position': 192.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.0733494},\n",
       "    {'id': 24.0,\n",
       "     'lemma': '의',\n",
       "     'position': 195.0,\n",
       "     'type': 'JKG',\n",
       "     'weight': 0.108658},\n",
       "    {'id': 25.0,\n",
       "     'lemma': '공직',\n",
       "     'position': 199.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.12325},\n",
       "    {'id': 26.0,\n",
       "     'lemma': '자',\n",
       "     'position': 205.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.12325},\n",
       "    {'id': 27.0, 'lemma': '(', 'position': 208.0, 'type': 'SS', 'weight': 1.0},\n",
       "    {'id': 28.0,\n",
       "     'lemma': '서기',\n",
       "     'position': 209.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0804729},\n",
       "    {'id': 29.0,\n",
       "     'lemma': '관',\n",
       "     'position': 215.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0804729},\n",
       "    {'id': 30.0, 'lemma': ')', 'position': 218.0, 'type': 'SS', 'weight': 1.0},\n",
       "    {'id': 31.0,\n",
       "     'lemma': '들',\n",
       "     'position': 219.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0962877},\n",
       "    {'id': 32.0,\n",
       "     'lemma': '이',\n",
       "     'position': 222.0,\n",
       "     'type': 'JKS',\n",
       "     'weight': 0.0558637},\n",
       "    {'id': 33.0,\n",
       "     'lemma': '아름',\n",
       "     'position': 226.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0653759},\n",
       "    {'id': 34.0,\n",
       "     'lemma': '답',\n",
       "     'position': 232.0,\n",
       "     'type': 'XSA',\n",
       "     'weight': 0.0653759},\n",
       "    {'id': 35.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 235.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0563553},\n",
       "    {'id': 36.0,\n",
       "     'lemma': '퇴장',\n",
       "     'position': 239.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.150974},\n",
       "    {'id': 37.0,\n",
       "     'lemma': '을',\n",
       "     'position': 245.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.10161},\n",
       "    {'id': 38.0,\n",
       "     'lemma': '앞두',\n",
       "     'position': 249.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0777981},\n",
       "    {'id': 39.0,\n",
       "     'lemma': '고',\n",
       "     'position': 255.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.141023},\n",
       "    {'id': 40.0,\n",
       "     'lemma': '있',\n",
       "     'position': 259.0,\n",
       "     'type': 'VX',\n",
       "     'weight': 0.104292},\n",
       "    {'id': 41.0,\n",
       "     'lemma': '다',\n",
       "     'position': 262.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0991963},\n",
       "    {'id': 42.0,\n",
       "     'lemma': '.',\n",
       "     'position': 265.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': ' 특례시 지정을 앞둔 105만 고양시의 발전을 위해 땀과 열정을 쏟아온 6명의 공직자(서기관)들이 아름다운 퇴장을 앞두고 있다.',\n",
       "   'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '특례시', 'type': ''},\n",
       "    {'begin': 2.0, 'end': 3.0, 'id': 1.0, 'text': '지정을', 'type': ''},\n",
       "    {'begin': 4.0, 'end': 5.0, 'id': 2.0, 'text': '앞둔', 'type': ''},\n",
       "    {'begin': 6.0, 'end': 7.0, 'id': 3.0, 'text': '105만', 'type': ''},\n",
       "    {'begin': 8.0, 'end': 9.0, 'id': 4.0, 'text': '고양시의', 'type': ''},\n",
       "    {'begin': 10.0, 'end': 11.0, 'id': 5.0, 'text': '발전을', 'type': ''},\n",
       "    {'begin': 12.0, 'end': 13.0, 'id': 6.0, 'text': '위해', 'type': ''},\n",
       "    {'begin': 14.0, 'end': 15.0, 'id': 7.0, 'text': '땀과', 'type': ''},\n",
       "    {'begin': 16.0, 'end': 17.0, 'id': 8.0, 'text': '열정을', 'type': ''},\n",
       "    {'begin': 18.0, 'end': 21.0, 'id': 9.0, 'text': '쏟아온', 'type': ''},\n",
       "    {'begin': 22.0, 'end': 24.0, 'id': 10.0, 'text': '6명의', 'type': ''},\n",
       "    {'begin': 25.0, 'end': 32.0, 'id': 11.0, 'text': '공직자(서기관)들이', 'type': ''},\n",
       "    {'begin': 33.0, 'end': 35.0, 'id': 12.0, 'text': '아름다운', 'type': ''},\n",
       "    {'begin': 36.0, 'end': 37.0, 'id': 13.0, 'text': '퇴장을', 'type': ''},\n",
       "    {'begin': 38.0, 'end': 39.0, 'id': 14.0, 'text': '앞두고', 'type': ''},\n",
       "    {'begin': 40.0, 'end': 42.0, 'id': 15.0, 'text': '있다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 0.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 1.0,\n",
       "     'id': 0.0,\n",
       "     'text': '경기북부',\n",
       "     'type': 'LCP_PROVINCE',\n",
       "     'weight': 0.167595},\n",
       "    {'begin': 7.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 7.0,\n",
       "     'id': 1.0,\n",
       "     'text': '고양시',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.333063},\n",
       "    {'begin': 21.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 21.0,\n",
       "     'id': 2.0,\n",
       "     'text': '후배',\n",
       "     'type': 'CV_RELATION',\n",
       "     'weight': 0.538012},\n",
       "    {'begin': 29.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 30.0,\n",
       "     'id': 3.0,\n",
       "     'text': '2막',\n",
       "     'type': 'QT_COUNT',\n",
       "     'weight': 0.402024}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 267.0,\n",
       "     'scode': '02',\n",
       "     'text': '경기',\n",
       "     'type': 'NNP',\n",
       "     'weight': 7.7},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 273.0,\n",
       "     'scode': '01',\n",
       "     'text': '북부',\n",
       "     'type': 'NNG',\n",
       "     'weight': 9.7},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 279.0,\n",
       "     'scode': '00',\n",
       "     'text': '의',\n",
       "     'type': 'JKG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 283.0,\n",
       "     'scode': '01',\n",
       "     'text': '중심',\n",
       "     'type': 'NNG',\n",
       "     'weight': 10.6798},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 289.0,\n",
       "     'scode': '03',\n",
       "     'text': '도시',\n",
       "     'type': 'NNG',\n",
       "     'weight': 9.4},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 5.0,\n",
       "     'position': 295.0,\n",
       "     'scode': '01',\n",
       "     'text': '이',\n",
       "     'type': 'VCP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 6.0,\n",
       "     'position': 295.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 7.0,\n",
       "     'position': 299.0,\n",
       "     'scode': '00',\n",
       "     'text': '고양시',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 8.0,\n",
       "     'position': 308.0,\n",
       "     'scode': '00',\n",
       "     'text': '가',\n",
       "     'type': 'JKC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 9.0,\n",
       "     'position': 312.0,\n",
       "     'scode': '01',\n",
       "     'text': '되',\n",
       "     'type': 'VV',\n",
       "     'weight': 7.6},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 10.0,\n",
       "     'position': 315.0,\n",
       "     'scode': '00',\n",
       "     'text': '기',\n",
       "     'type': 'ETN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 11.0,\n",
       "     'position': 318.0,\n",
       "     'scode': '00',\n",
       "     'text': '까지',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 12.0,\n",
       "     'position': 325.0,\n",
       "     'scode': '00',\n",
       "     'text': '쉼',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 13.0,\n",
       "     'position': 328.0,\n",
       "     'scode': '00',\n",
       "     'text': '없이',\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 14.0,\n",
       "     'position': 335.0,\n",
       "     'scode': '00',\n",
       "     'text': '달려오',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 15.0,\n",
       "     'end': 15.0,\n",
       "     'id': 15.0,\n",
       "     'position': 341.0,\n",
       "     'scode': '00',\n",
       "     'text': '았',\n",
       "     'type': 'EP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 16.0,\n",
       "     'position': 344.0,\n",
       "     'scode': '00',\n",
       "     'text': '던',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 17.0,\n",
       "     'end': 17.0,\n",
       "     'id': 17.0,\n",
       "     'position': 348.0,\n",
       "     'scode': '05',\n",
       "     'text': '이',\n",
       "     'type': 'NP',\n",
       "     'weight': 5.2},\n",
       "    {'begin': 18.0,\n",
       "     'end': 18.0,\n",
       "     'id': 18.0,\n",
       "     'position': 351.0,\n",
       "     'scode': '09',\n",
       "     'text': '들',\n",
       "     'type': 'XSN',\n",
       "     'weight': 4.0},\n",
       "    {'begin': 19.0,\n",
       "     'end': 19.0,\n",
       "     'id': 19.0,\n",
       "     'position': 354.0,\n",
       "     'scode': '00',\n",
       "     'text': '은',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 20.0,\n",
       "     'position': 358.0,\n",
       "     'scode': '01',\n",
       "     'text': '이제',\n",
       "     'type': 'MAG',\n",
       "     'weight': 5.4},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 21.0,\n",
       "     'position': 365.0,\n",
       "     'scode': '06',\n",
       "     'text': '후배',\n",
       "     'type': 'NNG',\n",
       "     'weight': 4.2},\n",
       "    {'begin': 22.0,\n",
       "     'end': 22.0,\n",
       "     'id': 22.0,\n",
       "     'position': 371.0,\n",
       "     'scode': '09',\n",
       "     'text': '들',\n",
       "     'type': 'XSN',\n",
       "     'weight': 5.0},\n",
       "    {'begin': 23.0,\n",
       "     'end': 23.0,\n",
       "     'id': 23.0,\n",
       "     'position': 374.0,\n",
       "     'scode': '00',\n",
       "     'text': '에게',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 24.0,\n",
       "     'end': 24.0,\n",
       "     'id': 24.0,\n",
       "     'position': 381.0,\n",
       "     'scode': '01',\n",
       "     'text': '자리',\n",
       "     'type': 'NNG',\n",
       "     'weight': 7.54444},\n",
       "    {'begin': 25.0,\n",
       "     'end': 25.0,\n",
       "     'id': 25.0,\n",
       "     'position': 387.0,\n",
       "     'scode': '00',\n",
       "     'text': '를',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 26.0,\n",
       "     'end': 26.0,\n",
       "     'id': 26.0,\n",
       "     'position': 391.0,\n",
       "     'scode': '00',\n",
       "     'text': '물려주',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 27.0,\n",
       "     'end': 27.0,\n",
       "     'id': 27.0,\n",
       "     'position': 400.0,\n",
       "     'scode': '00',\n",
       "     'text': '고',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 28.0,\n",
       "     'end': 28.0,\n",
       "     'id': 28.0,\n",
       "     'position': 404.0,\n",
       "     'scode': '01',\n",
       "     'text': '인생',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 29.0,\n",
       "     'end': 29.0,\n",
       "     'id': 29.0,\n",
       "     'position': 411.0,\n",
       "     'scode': '00',\n",
       "     'text': '2',\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 30.0,\n",
       "     'end': 30.0,\n",
       "     'id': 30.0,\n",
       "     'position': 412.0,\n",
       "     'scode': '05',\n",
       "     'text': '막',\n",
       "     'type': 'NNB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 31.0,\n",
       "     'end': 31.0,\n",
       "     'id': 31.0,\n",
       "     'position': 415.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 32.0,\n",
       "     'end': 32.0,\n",
       "     'id': 32.0,\n",
       "     'position': 419.0,\n",
       "     'scode': '00',\n",
       "     'text': '준비',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 33.0,\n",
       "     'end': 33.0,\n",
       "     'id': 33.0,\n",
       "     'position': 426.0,\n",
       "     'scode': '04',\n",
       "     'text': '중',\n",
       "     'type': 'NNB',\n",
       "     'weight': 2.2},\n",
       "    {'begin': 34.0,\n",
       "     'end': 34.0,\n",
       "     'id': 34.0,\n",
       "     'position': 429.0,\n",
       "     'scode': '01',\n",
       "     'text': '이',\n",
       "     'type': 'VCP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 35.0,\n",
       "     'end': 35.0,\n",
       "     'id': 35.0,\n",
       "     'position': 432.0,\n",
       "     'scode': '00',\n",
       "     'text': '다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 36.0,\n",
       "     'end': 36.0,\n",
       "     'id': 36.0,\n",
       "     'position': 435.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 1.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '경기북부의',\n",
       "     'weight': 0.255136},\n",
       "    {'head': 2.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'VNP_MOD',\n",
       "     'mod': [0.0],\n",
       "     'text': '중심도시인',\n",
       "     'weight': 0.435945},\n",
       "    {'head': 3.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'NP_CMP',\n",
       "     'mod': [1.0],\n",
       "     'text': '고양시가',\n",
       "     'weight': 0.477354},\n",
       "    {'head': 10.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [2.0],\n",
       "     'text': '되기까지',\n",
       "     'weight': 0.085665},\n",
       "    {'head': 5.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'AP',\n",
       "     'mod': [],\n",
       "     'text': '쉼없이',\n",
       "     'weight': 0.24795},\n",
       "    {'head': 6.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [4.0],\n",
       "     'text': '달려왔던',\n",
       "     'weight': 0.642505},\n",
       "    {'head': 10.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [5.0],\n",
       "     'text': '이들은',\n",
       "     'weight': 0.582525},\n",
       "    {'head': 10.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'AP',\n",
       "     'mod': [],\n",
       "     'text': '이제',\n",
       "     'weight': 0.702037},\n",
       "    {'head': 10.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '후배들에게',\n",
       "     'weight': 0.688299},\n",
       "    {'head': 10.0,\n",
       "     'id': 9.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [],\n",
       "     'text': '자리를',\n",
       "     'weight': 0.586633},\n",
       "    {'head': 14.0,\n",
       "     'id': 10.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [3.0, 6.0, 7.0, 8.0, 9.0],\n",
       "     'text': '물려주고',\n",
       "     'weight': 0.853554},\n",
       "    {'head': 12.0,\n",
       "     'id': 11.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '인생',\n",
       "     'weight': 0.552956},\n",
       "    {'head': 14.0,\n",
       "     'id': 12.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [11.0],\n",
       "     'text': '2막을',\n",
       "     'weight': 0.786685},\n",
       "    {'head': 14.0,\n",
       "     'id': 13.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '준비',\n",
       "     'weight': 0.478475},\n",
       "    {'head': -1.0,\n",
       "     'id': 14.0,\n",
       "     'label': 'VNP',\n",
       "     'mod': [10.0, 12.0, 13.0],\n",
       "     'text': '중이다.',\n",
       "     'weight': 1.71678e-05}],\n",
       "   'id': 2.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '경기',\n",
       "     'position': 267.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0735863},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '북부',\n",
       "     'position': 273.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0486974},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '의',\n",
       "     'position': 279.0,\n",
       "     'type': 'JKG',\n",
       "     'weight': 0.155895},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '중심',\n",
       "     'position': 283.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0756438},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '도시',\n",
       "     'position': 289.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0393359},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '이',\n",
       "     'position': 295.0,\n",
       "     'type': 'VCP',\n",
       "     'weight': 0.0651511},\n",
       "    {'id': 6.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 295.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0651511},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '고양시',\n",
       "     'position': 299.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0692494},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '가',\n",
       "     'position': 308.0,\n",
       "     'type': 'JKC',\n",
       "     'weight': 0.121098},\n",
       "    {'id': 9.0,\n",
       "     'lemma': '되',\n",
       "     'position': 312.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.105734},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '기',\n",
       "     'position': 315.0,\n",
       "     'type': 'ETN',\n",
       "     'weight': 0.0789256},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '까지',\n",
       "     'position': 318.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.07388},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '쉼',\n",
       "     'position': 325.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0343709},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '없이',\n",
       "     'position': 328.0,\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0502394},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '달려오',\n",
       "     'position': 335.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0599902},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '았',\n",
       "     'position': 341.0,\n",
       "     'type': 'EP',\n",
       "     'weight': 0.043681},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '던',\n",
       "     'position': 344.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.10417},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '이',\n",
       "     'position': 348.0,\n",
       "     'type': 'NP',\n",
       "     'weight': 0.096199},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '들',\n",
       "     'position': 351.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0765447},\n",
       "    {'id': 19.0,\n",
       "     'lemma': '은',\n",
       "     'position': 354.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.118022},\n",
       "    {'id': 20.0,\n",
       "     'lemma': '이제',\n",
       "     'position': 358.0,\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0946292},\n",
       "    {'id': 21.0,\n",
       "     'lemma': '후배',\n",
       "     'position': 365.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0646672},\n",
       "    {'id': 22.0,\n",
       "     'lemma': '들',\n",
       "     'position': 371.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0727001},\n",
       "    {'id': 23.0,\n",
       "     'lemma': '에게',\n",
       "     'position': 374.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0756487},\n",
       "    {'id': 24.0,\n",
       "     'lemma': '자리',\n",
       "     'position': 381.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.116745},\n",
       "    {'id': 25.0,\n",
       "     'lemma': '를',\n",
       "     'position': 387.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.138704},\n",
       "    {'id': 26.0,\n",
       "     'lemma': '물려주',\n",
       "     'position': 391.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0625751},\n",
       "    {'id': 27.0,\n",
       "     'lemma': '고',\n",
       "     'position': 400.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0747157},\n",
       "    {'id': 28.0,\n",
       "     'lemma': '인생',\n",
       "     'position': 404.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0857949},\n",
       "    {'id': 29.0, 'lemma': '2', 'position': 411.0, 'type': 'SN', 'weight': 1.0},\n",
       "    {'id': 30.0,\n",
       "     'lemma': '막',\n",
       "     'position': 412.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.0385147},\n",
       "    {'id': 31.0,\n",
       "     'lemma': '을',\n",
       "     'position': 415.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0758765},\n",
       "    {'id': 32.0,\n",
       "     'lemma': '준비',\n",
       "     'position': 419.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0843675},\n",
       "    {'id': 33.0,\n",
       "     'lemma': '중',\n",
       "     'position': 426.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.110531},\n",
       "    {'id': 34.0,\n",
       "     'lemma': '이',\n",
       "     'position': 429.0,\n",
       "     'type': 'VCP',\n",
       "     'weight': 0.0740337},\n",
       "    {'id': 35.0,\n",
       "     'lemma': '다',\n",
       "     'position': 432.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0782521},\n",
       "    {'id': 36.0,\n",
       "     'lemma': '.',\n",
       "     'position': 435.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': ' 경기북부의 중심도시인 고양시가 되기까지 쉼없이 달려왔던 이들은 이제 후배들에게 자리를 물려주고 인생 2막을 준비 중이다.',\n",
       "   'word': [{'begin': 0.0, 'end': 2.0, 'id': 0.0, 'text': '경기북부의', 'type': ''},\n",
       "    {'begin': 3.0, 'end': 6.0, 'id': 1.0, 'text': '중심도시인', 'type': ''},\n",
       "    {'begin': 7.0, 'end': 8.0, 'id': 2.0, 'text': '고양시가', 'type': ''},\n",
       "    {'begin': 9.0, 'end': 11.0, 'id': 3.0, 'text': '되기까지', 'type': ''},\n",
       "    {'begin': 12.0, 'end': 13.0, 'id': 4.0, 'text': '쉼없이', 'type': ''},\n",
       "    {'begin': 14.0, 'end': 16.0, 'id': 5.0, 'text': '달려왔던', 'type': ''},\n",
       "    {'begin': 17.0, 'end': 19.0, 'id': 6.0, 'text': '이들은', 'type': ''},\n",
       "    {'begin': 20.0, 'end': 20.0, 'id': 7.0, 'text': '이제', 'type': ''},\n",
       "    {'begin': 21.0, 'end': 23.0, 'id': 8.0, 'text': '후배들에게', 'type': ''},\n",
       "    {'begin': 24.0, 'end': 25.0, 'id': 9.0, 'text': '자리를', 'type': ''},\n",
       "    {'begin': 26.0, 'end': 27.0, 'id': 10.0, 'text': '물려주고', 'type': ''},\n",
       "    {'begin': 28.0, 'end': 28.0, 'id': 11.0, 'text': '인생', 'type': ''},\n",
       "    {'begin': 29.0, 'end': 31.0, 'id': 12.0, 'text': '2막을', 'type': ''},\n",
       "    {'begin': 32.0, 'end': 32.0, 'id': 13.0, 'text': '준비', 'type': ''},\n",
       "    {'begin': 33.0, 'end': 36.0, 'id': 14.0, 'text': '중이다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 0.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'text': '김운용',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.64914},\n",
       "    {'begin': 1.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'text': '고양시',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.473747},\n",
       "    {'begin': 2.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 5.0,\n",
       "     'id': 2.0,\n",
       "     'text': '푸른도시사업소장',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.113445},\n",
       "    {'begin': 7.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 8.0,\n",
       "     'id': 3.0,\n",
       "     'text': '1983년',\n",
       "     'type': 'DT_YEAR',\n",
       "     'weight': 0.819285},\n",
       "    {'begin': 14.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 14.0,\n",
       "     'id': 4.0,\n",
       "     'text': '고양시',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.408767}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 437.0,\n",
       "     'scode': '00',\n",
       "     'text': '김운용',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 447.0,\n",
       "     'scode': '00',\n",
       "     'text': '고양시',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 457.0,\n",
       "     'scode': '00',\n",
       "     'text': '푸른',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 463.0,\n",
       "     'scode': '03',\n",
       "     'text': '도시',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 469.0,\n",
       "     'scode': '04',\n",
       "     'text': '사업',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 5.0,\n",
       "     'position': 475.0,\n",
       "     'scode': '08',\n",
       "     'text': '소장',\n",
       "     'type': 'NNG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 6.0,\n",
       "     'position': 481.0,\n",
       "     'scode': '00',\n",
       "     'text': '은',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 7.0,\n",
       "     'position': 485.0,\n",
       "     'scode': '00',\n",
       "     'text': '1983',\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 8.0,\n",
       "     'position': 489.0,\n",
       "     'scode': '02',\n",
       "     'text': '년',\n",
       "     'type': 'NNB',\n",
       "     'weight': 11.3},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 9.0,\n",
       "     'position': 493.0,\n",
       "     'scode': '02',\n",
       "     'text': '공직',\n",
       "     'type': 'NNG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 10.0,\n",
       "     'position': 499.0,\n",
       "     'scode': '00',\n",
       "     'text': '에',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 12.0,\n",
       "     'id': 11.0,\n",
       "     'position': 503.0,\n",
       "     'scode': '01',\n",
       "     'text': '입문하',\n",
       "     'type': 'VV',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 12.0,\n",
       "     'position': 509.0,\n",
       "     'scode': '00',\n",
       "     'text': '어',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 13.0,\n",
       "     'position': 513.0,\n",
       "     'scode': '00',\n",
       "     'text': '고양시',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 15.0,\n",
       "     'end': 15.0,\n",
       "     'id': 14.0,\n",
       "     'position': 522.0,\n",
       "     'scode': '00',\n",
       "     'text': '가',\n",
       "     'type': 'JKS',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 15.0,\n",
       "     'position': 526.0,\n",
       "     'scode': '01',\n",
       "     'text': '자연',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.2},\n",
       "    {'begin': 17.0,\n",
       "     'end': 17.0,\n",
       "     'id': 16.0,\n",
       "     'position': 532.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 18.0,\n",
       "     'end': 18.0,\n",
       "     'id': 17.0,\n",
       "     'position': 536.0,\n",
       "     'scode': '01',\n",
       "     'text': '품',\n",
       "     'type': 'VV',\n",
       "     'weight': 4.2},\n",
       "    {'begin': 19.0,\n",
       "     'end': 19.0,\n",
       "     'id': 18.0,\n",
       "     'position': 539.0,\n",
       "     'scode': '00',\n",
       "     'text': '은',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 19.0,\n",
       "     'position': 543.0,\n",
       "     'scode': '03',\n",
       "     'text': '도시',\n",
       "     'type': 'NNG',\n",
       "     'weight': 5.9},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 20.0,\n",
       "     'position': 549.0,\n",
       "     'scode': '00',\n",
       "     'text': '가',\n",
       "     'type': 'JKC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 22.0,\n",
       "     'end': 22.0,\n",
       "     'id': 21.0,\n",
       "     'position': 553.0,\n",
       "     'scode': '01',\n",
       "     'text': '되',\n",
       "     'type': 'VV',\n",
       "     'weight': 7.6},\n",
       "    {'begin': 23.0,\n",
       "     'end': 23.0,\n",
       "     'id': 22.0,\n",
       "     'position': 553.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄹ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 24.0,\n",
       "     'end': 24.0,\n",
       "     'id': 23.0,\n",
       "     'position': 557.0,\n",
       "     'scode': '02',\n",
       "     'text': '수',\n",
       "     'type': 'NNB',\n",
       "     'weight': 7.59923},\n",
       "    {'begin': 25.0,\n",
       "     'end': 25.0,\n",
       "     'id': 24.0,\n",
       "     'position': 561.0,\n",
       "     'scode': '01',\n",
       "     'text': '있',\n",
       "     'type': 'VA',\n",
       "     'weight': 7.6},\n",
       "    {'begin': 26.0,\n",
       "     'end': 26.0,\n",
       "     'id': 25.0,\n",
       "     'position': 564.0,\n",
       "     'scode': '00',\n",
       "     'text': '도록',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 27.0,\n",
       "     'end': 27.0,\n",
       "     'id': 26.0,\n",
       "     'position': 571.0,\n",
       "     'scode': '00',\n",
       "     'text': '많',\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 28.0,\n",
       "     'end': 28.0,\n",
       "     'id': 27.0,\n",
       "     'position': 574.0,\n",
       "     'scode': '00',\n",
       "     'text': '은',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 29.0,\n",
       "     'end': 29.0,\n",
       "     'id': 28.0,\n",
       "     'position': 578.0,\n",
       "     'scode': '03',\n",
       "     'text': '연구',\n",
       "     'type': 'NNG',\n",
       "     'weight': 8.1},\n",
       "    {'begin': 30.0,\n",
       "     'end': 30.0,\n",
       "     'id': 29.0,\n",
       "     'position': 584.0,\n",
       "     'scode': '00',\n",
       "     'text': '와',\n",
       "     'type': 'JC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 31.0,\n",
       "     'end': 31.0,\n",
       "     'id': 30.0,\n",
       "     'position': 588.0,\n",
       "     'scode': '01',\n",
       "     'text': '노력',\n",
       "     'type': 'NNG',\n",
       "     'weight': 5.4},\n",
       "    {'begin': 32.0,\n",
       "     'end': 32.0,\n",
       "     'id': 31.0,\n",
       "     'position': 594.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 33.0,\n",
       "     'end': 33.0,\n",
       "     'id': 32.0,\n",
       "     'position': 598.0,\n",
       "     'scode': '00',\n",
       "     'text': '기울이',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 34.0,\n",
       "     'end': 34.0,\n",
       "     'id': 33.0,\n",
       "     'position': 604.0,\n",
       "     'scode': '00',\n",
       "     'text': '어',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 35.0,\n",
       "     'end': 35.0,\n",
       "     'id': 34.0,\n",
       "     'position': 607.0,\n",
       "     'scode': '01',\n",
       "     'text': '오',\n",
       "     'type': 'VX',\n",
       "     'weight': 5.2},\n",
       "    {'begin': 36.0,\n",
       "     'end': 36.0,\n",
       "     'id': 35.0,\n",
       "     'position': 607.0,\n",
       "     'scode': '00',\n",
       "     'text': '았',\n",
       "     'type': 'EP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 37.0,\n",
       "     'end': 37.0,\n",
       "     'id': 36.0,\n",
       "     'position': 610.0,\n",
       "     'scode': '00',\n",
       "     'text': '다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 38.0,\n",
       "     'end': 38.0,\n",
       "     'id': 37.0,\n",
       "     'position': 613.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 1.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '김운용',\n",
       "     'weight': 0.189354},\n",
       "    {'head': 2.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [0.0],\n",
       "     'text': '고양시',\n",
       "     'weight': 0.450608},\n",
       "    {'head': 10.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [1.0],\n",
       "     'text': '푸른도시사업소장은',\n",
       "     'weight': 0.242854},\n",
       "    {'head': 5.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '1983년',\n",
       "     'weight': 0.476616},\n",
       "    {'head': 5.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '공직에',\n",
       "     'weight': 0.60747},\n",
       "    {'head': 10.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [3.0, 4.0],\n",
       "     'text': '입문해',\n",
       "     'weight': 0.831563},\n",
       "    {'head': 10.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [],\n",
       "     'text': '고양시가',\n",
       "     'weight': 0.837649},\n",
       "    {'head': 8.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [],\n",
       "     'text': '자연을',\n",
       "     'weight': 0.756616},\n",
       "    {'head': 9.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [7.0],\n",
       "     'text': '품은',\n",
       "     'weight': 0.591793},\n",
       "    {'head': 10.0,\n",
       "     'id': 9.0,\n",
       "     'label': 'NP_CMP',\n",
       "     'mod': [8.0],\n",
       "     'text': '도시가',\n",
       "     'weight': 0.553355},\n",
       "    {'head': 11.0,\n",
       "     'id': 10.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [2.0, 5.0, 6.0, 9.0],\n",
       "     'text': '될',\n",
       "     'weight': 0.722573},\n",
       "    {'head': 12.0,\n",
       "     'id': 11.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [10.0],\n",
       "     'text': '수',\n",
       "     'weight': 0.582944},\n",
       "    {'head': 16.0,\n",
       "     'id': 12.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [11.0],\n",
       "     'text': '있도록',\n",
       "     'weight': 0.54814},\n",
       "    {'head': 15.0,\n",
       "     'id': 13.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '많은',\n",
       "     'weight': 0.656456},\n",
       "    {'head': 15.0,\n",
       "     'id': 14.0,\n",
       "     'label': 'NP_CNJ',\n",
       "     'mod': [],\n",
       "     'text': '연구와',\n",
       "     'weight': 0.727066},\n",
       "    {'head': 16.0,\n",
       "     'id': 15.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [13.0, 14.0],\n",
       "     'text': '노력을',\n",
       "     'weight': 0.687592},\n",
       "    {'head': -1.0,\n",
       "     'id': 16.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [12.0, 15.0],\n",
       "     'text': '기울여왔다.',\n",
       "     'weight': 5.64663e-05}],\n",
       "   'id': 3.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '김운용',\n",
       "     'position': 437.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0748456},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '고양시',\n",
       "     'position': 447.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0527326},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '푸른',\n",
       "     'position': 457.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0312592},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '도시',\n",
       "     'position': 463.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0278652},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '사업',\n",
       "     'position': 469.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0805918},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '소장',\n",
       "     'position': 475.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0448367},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '은',\n",
       "     'position': 481.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.0970794},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '1983',\n",
       "     'position': 485.0,\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '년',\n",
       "     'position': 489.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.065533},\n",
       "    {'id': 9.0,\n",
       "     'lemma': '공직',\n",
       "     'position': 493.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0861151},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '에',\n",
       "     'position': 499.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0898719},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '입문',\n",
       "     'position': 503.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0992509},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '하',\n",
       "     'position': 509.0,\n",
       "     'type': 'XSV',\n",
       "     'weight': 0.0402947},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '어',\n",
       "     'position': 509.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0402947},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '고양시',\n",
       "     'position': 513.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0539177},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '가',\n",
       "     'position': 522.0,\n",
       "     'type': 'JKS',\n",
       "     'weight': 0.0965236},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '자연',\n",
       "     'position': 526.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.087804},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '을',\n",
       "     'position': 532.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0885779},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '품',\n",
       "     'position': 536.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.106293},\n",
       "    {'id': 19.0,\n",
       "     'lemma': '은',\n",
       "     'position': 539.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0620383},\n",
       "    {'id': 20.0,\n",
       "     'lemma': '도시',\n",
       "     'position': 543.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0983781},\n",
       "    {'id': 21.0,\n",
       "     'lemma': '가',\n",
       "     'position': 549.0,\n",
       "     'type': 'JKC',\n",
       "     'weight': 0.102474},\n",
       "    {'id': 22.0,\n",
       "     'lemma': '되',\n",
       "     'position': 553.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.126803},\n",
       "    {'id': 23.0,\n",
       "     'lemma': 'ㄹ',\n",
       "     'position': 553.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.126803},\n",
       "    {'id': 24.0,\n",
       "     'lemma': '수',\n",
       "     'position': 557.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.190736},\n",
       "    {'id': 25.0,\n",
       "     'lemma': '있',\n",
       "     'position': 561.0,\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0969874},\n",
       "    {'id': 26.0,\n",
       "     'lemma': '도록',\n",
       "     'position': 564.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0989595},\n",
       "    {'id': 27.0,\n",
       "     'lemma': '많',\n",
       "     'position': 571.0,\n",
       "     'type': 'VA',\n",
       "     'weight': 0.164127},\n",
       "    {'id': 28.0,\n",
       "     'lemma': '은',\n",
       "     'position': 574.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0971838},\n",
       "    {'id': 29.0,\n",
       "     'lemma': '연구',\n",
       "     'position': 578.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.140999},\n",
       "    {'id': 30.0,\n",
       "     'lemma': '와',\n",
       "     'position': 584.0,\n",
       "     'type': 'JC',\n",
       "     'weight': 0.057918},\n",
       "    {'id': 31.0,\n",
       "     'lemma': '노력',\n",
       "     'position': 588.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0697194},\n",
       "    {'id': 32.0,\n",
       "     'lemma': '을',\n",
       "     'position': 594.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0844299},\n",
       "    {'id': 33.0,\n",
       "     'lemma': '기울이',\n",
       "     'position': 598.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0474764},\n",
       "    {'id': 34.0,\n",
       "     'lemma': '어',\n",
       "     'position': 604.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0245038},\n",
       "    {'id': 35.0,\n",
       "     'lemma': '오',\n",
       "     'position': 607.0,\n",
       "     'type': 'VX',\n",
       "     'weight': 0.0245038},\n",
       "    {'id': 36.0,\n",
       "     'lemma': '았',\n",
       "     'position': 607.0,\n",
       "     'type': 'EP',\n",
       "     'weight': 0.0245038},\n",
       "    {'id': 37.0,\n",
       "     'lemma': '다',\n",
       "     'position': 610.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0808567},\n",
       "    {'id': 38.0,\n",
       "     'lemma': '.',\n",
       "     'position': 613.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': ' 김운용 고양시 푸른도시사업소장은 1983년 공직에 입문해 고양시가 자연을 품은 도시가 될 수 있도록 많은 연구와 노력을 기울여왔다.',\n",
       "   'word': [{'begin': 0.0, 'end': 0.0, 'id': 0.0, 'text': '김운용', 'type': ''},\n",
       "    {'begin': 1.0, 'end': 1.0, 'id': 1.0, 'text': '고양시', 'type': ''},\n",
       "    {'begin': 2.0, 'end': 6.0, 'id': 2.0, 'text': '푸른도시사업소장은', 'type': ''},\n",
       "    {'begin': 7.0, 'end': 8.0, 'id': 3.0, 'text': '1983년', 'type': ''},\n",
       "    {'begin': 9.0, 'end': 10.0, 'id': 4.0, 'text': '공직에', 'type': ''},\n",
       "    {'begin': 11.0, 'end': 13.0, 'id': 5.0, 'text': '입문해', 'type': ''},\n",
       "    {'begin': 14.0, 'end': 15.0, 'id': 6.0, 'text': '고양시가', 'type': ''},\n",
       "    {'begin': 16.0, 'end': 17.0, 'id': 7.0, 'text': '자연을', 'type': ''},\n",
       "    {'begin': 18.0, 'end': 19.0, 'id': 8.0, 'text': '품은', 'type': ''},\n",
       "    {'begin': 20.0, 'end': 21.0, 'id': 9.0, 'text': '도시가', 'type': ''},\n",
       "    {'begin': 22.0, 'end': 23.0, 'id': 10.0, 'text': '될', 'type': ''},\n",
       "    {'begin': 24.0, 'end': 24.0, 'id': 11.0, 'text': '수', 'type': ''},\n",
       "    {'begin': 25.0, 'end': 26.0, 'id': 12.0, 'text': '있도록', 'type': ''},\n",
       "    {'begin': 27.0, 'end': 28.0, 'id': 13.0, 'text': '많은', 'type': ''},\n",
       "    {'begin': 29.0, 'end': 30.0, 'id': 14.0, 'text': '연구와', 'type': ''},\n",
       "    {'begin': 31.0, 'end': 32.0, 'id': 15.0, 'text': '노력을', 'type': ''},\n",
       "    {'begin': 33.0, 'end': 38.0, 'id': 16.0, 'text': '기울여왔다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 0.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 3.0,\n",
       "     'id': 0.0,\n",
       "     'text': '지난 28일',\n",
       "     'type': 'DT_DAY',\n",
       "     'weight': 0.893865},\n",
       "    {'begin': 19.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 20.0,\n",
       "     'id': 1.0,\n",
       "     'text': '산림청장표창',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.196843},\n",
       "    {'begin': 25.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 26.0,\n",
       "     'id': 2.0,\n",
       "     'text': '국무총리',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.565509},\n",
       "    {'begin': 28.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 29.0,\n",
       "     'id': 3.0,\n",
       "     'text': '국방부',\n",
       "     'type': 'OGG_POLITICS',\n",
       "     'weight': 0.625059},\n",
       "    {'begin': 30.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 30.0,\n",
       "     'id': 4.0,\n",
       "     'text': '장관',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.418697},\n",
       "    {'begin': 32.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 33.0,\n",
       "     'id': 5.0,\n",
       "     'text': '도지사',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.710788},\n",
       "    {'begin': 34.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 34.0,\n",
       "     'id': 6.0,\n",
       "     'text': '표창',\n",
       "     'type': 'CV_PRIZE',\n",
       "     'weight': 0.190505}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 616.0,\n",
       "     'scode': '00',\n",
       "     'text': '지나',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 619.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 623.0,\n",
       "     'scode': '00',\n",
       "     'text': '28',\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 625.0,\n",
       "     'scode': '07',\n",
       "     'text': '일',\n",
       "     'type': 'NNB',\n",
       "     'weight': 3.2},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 629.0,\n",
       "     'scode': '01',\n",
       "     'text': '명예',\n",
       "     'type': 'NNG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 5.0,\n",
       "     'end': 6.0,\n",
       "     'id': 5.0,\n",
       "     'position': 635.0,\n",
       "     'scode': '00',\n",
       "     'text': '퇴직하',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 6.0,\n",
       "     'position': 641.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 7.0,\n",
       "     'position': 645.0,\n",
       "     'scode': '01',\n",
       "     'text': '그',\n",
       "     'type': 'NP',\n",
       "     'weight': 5.4},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 8.0,\n",
       "     'position': 648.0,\n",
       "     'scode': '00',\n",
       "     'text': '는',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 9.0,\n",
       "     'position': 652.0,\n",
       "     'scode': '00',\n",
       "     'text': '산림',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 10.0,\n",
       "     'position': 658.0,\n",
       "     'scode': '01',\n",
       "     'text': '보호',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.2},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 11.0,\n",
       "     'position': 664.0,\n",
       "     'scode': '02',\n",
       "     'text': '유공',\n",
       "     'type': 'NNG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 12.0,\n",
       "     'position': 670.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 14.0,\n",
       "     'end': 15.0,\n",
       "     'id': 13.0,\n",
       "     'position': 674.0,\n",
       "     'scode': '00',\n",
       "     'text': '인정받',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 14.0,\n",
       "     'position': 683.0,\n",
       "     'scode': '00',\n",
       "     'text': '아',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 17.0,\n",
       "     'end': 17.0,\n",
       "     'id': 15.0,\n",
       "     'position': 687.0,\n",
       "     'scode': '01',\n",
       "     'text': '받',\n",
       "     'type': 'VV',\n",
       "     'weight': 5.2},\n",
       "    {'begin': 18.0,\n",
       "     'end': 18.0,\n",
       "     'id': 16.0,\n",
       "     'position': 690.0,\n",
       "     'scode': '00',\n",
       "     'text': '은',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 19.0,\n",
       "     'end': 19.0,\n",
       "     'id': 17.0,\n",
       "     'position': 694.0,\n",
       "     'scode': '00',\n",
       "     'text': '산림청장',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 18.0,\n",
       "     'position': 706.0,\n",
       "     'scode': '01',\n",
       "     'text': '표창',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.2},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 19.0,\n",
       "     'position': 712.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 22.0,\n",
       "     'end': 22.0,\n",
       "     'id': 20.0,\n",
       "     'position': 716.0,\n",
       "     'scode': '00',\n",
       "     'text': '비롯하',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 23.0,\n",
       "     'end': 23.0,\n",
       "     'id': 21.0,\n",
       "     'position': 722.0,\n",
       "     'scode': '00',\n",
       "     'text': '어',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 24.0,\n",
       "     'end': 24.0,\n",
       "     'id': 22.0,\n",
       "     'position': 725.0,\n",
       "     'scode': '00',\n",
       "     'text': ',',\n",
       "     'type': 'SP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 25.0,\n",
       "     'end': 26.0,\n",
       "     'id': 23.0,\n",
       "     'position': 727.0,\n",
       "     'scode': '00',\n",
       "     'text': '국무총리',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 27.0,\n",
       "     'end': 27.0,\n",
       "     'id': 24.0,\n",
       "     'position': 739.0,\n",
       "     'scode': '00',\n",
       "     'text': '와',\n",
       "     'type': 'JC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 28.0,\n",
       "     'end': 29.0,\n",
       "     'id': 25.0,\n",
       "     'position': 743.0,\n",
       "     'scode': '00',\n",
       "     'text': '국방부',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 30.0,\n",
       "     'end': 30.0,\n",
       "     'id': 26.0,\n",
       "     'position': 752.0,\n",
       "     'scode': '02',\n",
       "     'text': '장관',\n",
       "     'type': 'NNG',\n",
       "     'weight': 15.8},\n",
       "    {'begin': 31.0,\n",
       "     'end': 31.0,\n",
       "     'id': 27.0,\n",
       "     'position': 758.0,\n",
       "     'scode': '00',\n",
       "     'text': ',',\n",
       "     'type': 'SP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 32.0,\n",
       "     'end': 33.0,\n",
       "     'id': 28.0,\n",
       "     'position': 760.0,\n",
       "     'scode': '00',\n",
       "     'text': '도지사',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 34.0,\n",
       "     'end': 34.0,\n",
       "     'id': 29.0,\n",
       "     'position': 770.0,\n",
       "     'scode': '01',\n",
       "     'text': '표창',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 35.0,\n",
       "     'end': 35.0,\n",
       "     'id': 30.0,\n",
       "     'position': 776.0,\n",
       "     'scode': '09',\n",
       "     'text': '들',\n",
       "     'type': 'XSN',\n",
       "     'weight': 7.0},\n",
       "    {'begin': 36.0,\n",
       "     'end': 36.0,\n",
       "     'id': 31.0,\n",
       "     'position': 779.0,\n",
       "     'scode': '00',\n",
       "     'text': '이',\n",
       "     'type': 'JKS',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 37.0,\n",
       "     'end': 37.0,\n",
       "     'id': 32.0,\n",
       "     'position': 783.0,\n",
       "     'scode': '00',\n",
       "     'text': '묵묵히',\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 38.0,\n",
       "     'end': 38.0,\n",
       "     'id': 33.0,\n",
       "     'position': 793.0,\n",
       "     'scode': '02',\n",
       "     'text': '업무',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.2},\n",
       "    {'begin': 39.0,\n",
       "     'end': 39.0,\n",
       "     'id': 34.0,\n",
       "     'position': 799.0,\n",
       "     'scode': '00',\n",
       "     'text': '에',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 40.0,\n",
       "     'end': 41.0,\n",
       "     'id': 35.0,\n",
       "     'position': 803.0,\n",
       "     'scode': '02',\n",
       "     'text': '충실하',\n",
       "     'type': 'VA',\n",
       "     'weight': 1.86667},\n",
       "    {'begin': 42.0,\n",
       "     'end': 42.0,\n",
       "     'id': 36.0,\n",
       "     'position': 809.0,\n",
       "     'scode': '00',\n",
       "     'text': '어',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 43.0,\n",
       "     'end': 43.0,\n",
       "     'id': 37.0,\n",
       "     'position': 813.0,\n",
       "     'scode': '01',\n",
       "     'text': '오',\n",
       "     'type': 'VX',\n",
       "     'weight': 5.2},\n",
       "    {'begin': 44.0,\n",
       "     'end': 44.0,\n",
       "     'id': 38.0,\n",
       "     'position': 813.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 45.0,\n",
       "     'end': 45.0,\n",
       "     'id': 39.0,\n",
       "     'position': 817.0,\n",
       "     'scode': '01',\n",
       "     'text': '그',\n",
       "     'type': 'NP',\n",
       "     'weight': 7.6},\n",
       "    {'begin': 46.0,\n",
       "     'end': 46.0,\n",
       "     'id': 40.0,\n",
       "     'position': 820.0,\n",
       "     'scode': '00',\n",
       "     'text': '의',\n",
       "     'type': 'JKG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 47.0,\n",
       "     'end': 47.0,\n",
       "     'id': 41.0,\n",
       "     'position': 824.0,\n",
       "     'scode': '02',\n",
       "     'text': '공직',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 48.0,\n",
       "     'end': 48.0,\n",
       "     'id': 42.0,\n",
       "     'position': 830.0,\n",
       "     'scode': '00',\n",
       "     'text': '생활',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 49.0,\n",
       "     'end': 49.0,\n",
       "     'id': 43.0,\n",
       "     'position': 836.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 50.0,\n",
       "     'end': 50.0,\n",
       "     'id': 44.0,\n",
       "     'position': 840.0,\n",
       "     'scode': '01',\n",
       "     'text': '보이',\n",
       "     'type': 'VV',\n",
       "     'weight': 1.59107},\n",
       "    {'begin': 51.0,\n",
       "     'end': 51.0,\n",
       "     'id': 45.0,\n",
       "     'position': 843.0,\n",
       "     'scode': '00',\n",
       "     'text': '어',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 52.0,\n",
       "     'end': 52.0,\n",
       "     'id': 46.0,\n",
       "     'position': 846.0,\n",
       "     'scode': '01',\n",
       "     'text': '주',\n",
       "     'type': 'VX',\n",
       "     'weight': 7.6},\n",
       "    {'begin': 53.0,\n",
       "     'end': 53.0,\n",
       "     'id': 47.0,\n",
       "     'position': 846.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 54.0,\n",
       "     'end': 54.0,\n",
       "     'id': 48.0,\n",
       "     'position': 852.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 1.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '지난',\n",
       "     'weight': 0.547704},\n",
       "    {'head': 2.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [0.0],\n",
       "     'text': '28일',\n",
       "     'weight': 0.683389},\n",
       "    {'head': 3.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [1.0],\n",
       "     'text': '명예퇴직한',\n",
       "     'weight': 0.654602},\n",
       "    {'head': 8.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [2.0],\n",
       "     'text': '그는',\n",
       "     'weight': 0.498012},\n",
       "    {'head': 5.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [],\n",
       "     'text': '산림보호유공을',\n",
       "     'weight': 0.454183},\n",
       "    {'head': 6.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [4.0],\n",
       "     'text': '인정받아',\n",
       "     'weight': 0.224991},\n",
       "    {'head': 7.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [5.0],\n",
       "     'text': '받은',\n",
       "     'weight': 0.677448},\n",
       "    {'head': 8.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [6.0],\n",
       "     'text': '산림청장표창을',\n",
       "     'weight': 0.706745},\n",
       "    {'head': 19.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [3.0, 7.0],\n",
       "     'text': '비롯해,',\n",
       "     'weight': 0.737569},\n",
       "    {'head': 11.0,\n",
       "     'id': 9.0,\n",
       "     'label': 'NP_CNJ',\n",
       "     'mod': [],\n",
       "     'text': '국무총리와',\n",
       "     'weight': 0.751998},\n",
       "    {'head': 11.0,\n",
       "     'id': 10.0,\n",
       "     'label': 'NP_CNJ',\n",
       "     'mod': [],\n",
       "     'text': '국방부장관,',\n",
       "     'weight': 0.105319},\n",
       "    {'head': 12.0,\n",
       "     'id': 11.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [10.0, 9.0],\n",
       "     'text': '도지사',\n",
       "     'weight': 0.58355},\n",
       "    {'head': 15.0,\n",
       "     'id': 12.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [11.0],\n",
       "     'text': '표창들이',\n",
       "     'weight': 0.347706},\n",
       "    {'head': 15.0,\n",
       "     'id': 13.0,\n",
       "     'label': 'AP',\n",
       "     'mod': [],\n",
       "     'text': '묵묵히',\n",
       "     'weight': 0.636801},\n",
       "    {'head': 15.0,\n",
       "     'id': 14.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '업무에',\n",
       "     'weight': 0.59592},\n",
       "    {'head': 16.0,\n",
       "     'id': 15.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [12.0, 13.0, 14.0],\n",
       "     'text': '충실해',\n",
       "     'weight': 0.791105},\n",
       "    {'head': 18.0,\n",
       "     'id': 16.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [15.0],\n",
       "     'text': '온',\n",
       "     'weight': 0.558214},\n",
       "    {'head': 18.0,\n",
       "     'id': 17.0,\n",
       "     'label': 'NP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '그의',\n",
       "     'weight': 0.633813},\n",
       "    {'head': 19.0,\n",
       "     'id': 18.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [16.0, 17.0],\n",
       "     'text': '공직생활을',\n",
       "     'weight': 0.62751},\n",
       "    {'head': -1.0,\n",
       "     'id': 19.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [8.0, 18.0],\n",
       "     'text': '보여준다.',\n",
       "     'weight': 3.7114e-06}],\n",
       "   'id': 4.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '지나',\n",
       "     'position': 616.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0769696},\n",
       "    {'id': 1.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 619.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0581092},\n",
       "    {'id': 2.0, 'lemma': '28', 'position': 623.0, 'type': 'SN', 'weight': 1.0},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '일',\n",
       "     'position': 625.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.0461482},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '명예',\n",
       "     'position': 629.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0345652},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '퇴직',\n",
       "     'position': 635.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0345652},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '하',\n",
       "     'position': 641.0,\n",
       "     'type': 'XSV',\n",
       "     'weight': 0.0246647},\n",
       "    {'id': 7.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 641.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0246647},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '그',\n",
       "     'position': 645.0,\n",
       "     'type': 'NP',\n",
       "     'weight': 0.115441},\n",
       "    {'id': 9.0,\n",
       "     'lemma': '는',\n",
       "     'position': 648.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.103728},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '산림',\n",
       "     'position': 652.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0848682},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '보호',\n",
       "     'position': 658.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.032685},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '유공',\n",
       "     'position': 664.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0182877},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '을',\n",
       "     'position': 670.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0832244},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '인정',\n",
       "     'position': 674.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.074037},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '받',\n",
       "     'position': 680.0,\n",
       "     'type': 'XSV',\n",
       "     'weight': 0.0247723},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '아',\n",
       "     'position': 683.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.056703},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '받',\n",
       "     'position': 687.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.114572},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '은',\n",
       "     'position': 690.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.11425},\n",
       "    {'id': 19.0,\n",
       "     'lemma': '산림청장',\n",
       "     'position': 694.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0588786},\n",
       "    {'id': 20.0,\n",
       "     'lemma': '표창',\n",
       "     'position': 706.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0347575},\n",
       "    {'id': 21.0,\n",
       "     'lemma': '을',\n",
       "     'position': 712.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0976257},\n",
       "    {'id': 22.0,\n",
       "     'lemma': '비롯하',\n",
       "     'position': 716.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0368364},\n",
       "    {'id': 23.0,\n",
       "     'lemma': '어',\n",
       "     'position': 722.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0251946},\n",
       "    {'id': 24.0, 'lemma': ',', 'position': 725.0, 'type': 'SP', 'weight': 1.0},\n",
       "    {'id': 25.0,\n",
       "     'lemma': '국무',\n",
       "     'position': 727.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.105662},\n",
       "    {'id': 26.0,\n",
       "     'lemma': '총리',\n",
       "     'position': 733.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.105662},\n",
       "    {'id': 27.0,\n",
       "     'lemma': '와',\n",
       "     'position': 739.0,\n",
       "     'type': 'JC',\n",
       "     'weight': 0.0627067},\n",
       "    {'id': 28.0,\n",
       "     'lemma': '국방',\n",
       "     'position': 743.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.140389},\n",
       "    {'id': 29.0,\n",
       "     'lemma': '부',\n",
       "     'position': 749.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.140389},\n",
       "    {'id': 30.0,\n",
       "     'lemma': '장관',\n",
       "     'position': 752.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0628887},\n",
       "    {'id': 31.0, 'lemma': ',', 'position': 758.0, 'type': 'SP', 'weight': 1.0},\n",
       "    {'id': 32.0,\n",
       "     'lemma': '도',\n",
       "     'position': 760.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0955113},\n",
       "    {'id': 33.0,\n",
       "     'lemma': '지사',\n",
       "     'position': 763.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0955113},\n",
       "    {'id': 34.0,\n",
       "     'lemma': '표창',\n",
       "     'position': 770.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0532685},\n",
       "    {'id': 35.0,\n",
       "     'lemma': '들',\n",
       "     'position': 776.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0700378},\n",
       "    {'id': 36.0,\n",
       "     'lemma': '이',\n",
       "     'position': 779.0,\n",
       "     'type': 'JKS',\n",
       "     'weight': 0.063019},\n",
       "    {'id': 37.0,\n",
       "     'lemma': '묵묵히',\n",
       "     'position': 783.0,\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0492452},\n",
       "    {'id': 38.0,\n",
       "     'lemma': '업무',\n",
       "     'position': 793.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0986893},\n",
       "    {'id': 39.0,\n",
       "     'lemma': '에',\n",
       "     'position': 799.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0909971},\n",
       "    {'id': 40.0,\n",
       "     'lemma': '충실',\n",
       "     'position': 803.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0429959},\n",
       "    {'id': 41.0,\n",
       "     'lemma': '하',\n",
       "     'position': 809.0,\n",
       "     'type': 'XSA',\n",
       "     'weight': 0.0429959},\n",
       "    {'id': 42.0,\n",
       "     'lemma': '어',\n",
       "     'position': 809.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0382715},\n",
       "    {'id': 43.0,\n",
       "     'lemma': '오',\n",
       "     'position': 813.0,\n",
       "     'type': 'VX',\n",
       "     'weight': 0.0739748},\n",
       "    {'id': 44.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 813.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0739748},\n",
       "    {'id': 45.0,\n",
       "     'lemma': '그',\n",
       "     'position': 817.0,\n",
       "     'type': 'NP',\n",
       "     'weight': 0.0896799},\n",
       "    {'id': 46.0,\n",
       "     'lemma': '의',\n",
       "     'position': 820.0,\n",
       "     'type': 'JKG',\n",
       "     'weight': 0.118274},\n",
       "    {'id': 47.0,\n",
       "     'lemma': '공직',\n",
       "     'position': 824.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0889909},\n",
       "    {'id': 48.0,\n",
       "     'lemma': '생활',\n",
       "     'position': 830.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0490292},\n",
       "    {'id': 49.0,\n",
       "     'lemma': '을',\n",
       "     'position': 836.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0868579},\n",
       "    {'id': 50.0,\n",
       "     'lemma': '보이',\n",
       "     'position': 840.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0778142},\n",
       "    {'id': 51.0,\n",
       "     'lemma': '어',\n",
       "     'position': 843.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0313283},\n",
       "    {'id': 52.0,\n",
       "     'lemma': '주',\n",
       "     'position': 846.0,\n",
       "     'type': 'VX',\n",
       "     'weight': 0.0313283},\n",
       "    {'id': 53.0,\n",
       "     'lemma': 'ㄴ다',\n",
       "     'position': 846.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0485559},\n",
       "    {'id': 54.0,\n",
       "     'lemma': '.',\n",
       "     'position': 852.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': '  지난 28일 명예퇴직한 그는 산림보호유공을 인정받아 받은 산림청장표창을 비롯해, 국무총리와 국방부장관, 도지사 표창들이 묵묵히 업무에 충실해 온 그의 공직생활을 보여준다.',\n",
       "   'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '지난', 'type': ''},\n",
       "    {'begin': 2.0, 'end': 3.0, 'id': 1.0, 'text': '28일', 'type': ''},\n",
       "    {'begin': 4.0, 'end': 7.0, 'id': 2.0, 'text': '명예퇴직한', 'type': ''},\n",
       "    {'begin': 8.0, 'end': 9.0, 'id': 3.0, 'text': '그는', 'type': ''},\n",
       "    {'begin': 10.0, 'end': 13.0, 'id': 4.0, 'text': '산림보호유공을', 'type': ''},\n",
       "    {'begin': 14.0, 'end': 16.0, 'id': 5.0, 'text': '인정받아', 'type': ''},\n",
       "    {'begin': 17.0, 'end': 18.0, 'id': 6.0, 'text': '받은', 'type': ''},\n",
       "    {'begin': 19.0, 'end': 21.0, 'id': 7.0, 'text': '산림청장표창을', 'type': ''},\n",
       "    {'begin': 22.0, 'end': 24.0, 'id': 8.0, 'text': '비롯해,', 'type': ''},\n",
       "    {'begin': 25.0, 'end': 27.0, 'id': 9.0, 'text': '국무총리와', 'type': ''},\n",
       "    {'begin': 28.0, 'end': 31.0, 'id': 10.0, 'text': '국방부장관,', 'type': ''},\n",
       "    {'begin': 32.0, 'end': 33.0, 'id': 11.0, 'text': '도지사', 'type': ''},\n",
       "    {'begin': 34.0, 'end': 36.0, 'id': 12.0, 'text': '표창들이', 'type': ''},\n",
       "    {'begin': 37.0, 'end': 37.0, 'id': 13.0, 'text': '묵묵히', 'type': ''},\n",
       "    {'begin': 38.0, 'end': 39.0, 'id': 14.0, 'text': '업무에', 'type': ''},\n",
       "    {'begin': 40.0, 'end': 42.0, 'id': 15.0, 'text': '충실해', 'type': ''},\n",
       "    {'begin': 43.0, 'end': 44.0, 'id': 16.0, 'text': '온', 'type': ''},\n",
       "    {'begin': 45.0, 'end': 46.0, 'id': 17.0, 'text': '그의', 'type': ''},\n",
       "    {'begin': 47.0, 'end': 49.0, 'id': 18.0, 'text': '공직생활을', 'type': ''},\n",
       "    {'begin': 50.0, 'end': 54.0, 'id': 19.0, 'text': '보여준다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 0.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 3.0,\n",
       "     'id': 0.0,\n",
       "     'text': '40년 세월동안',\n",
       "     'type': 'DT_DURATION',\n",
       "     'weight': 0.511448},\n",
       "    {'begin': 4.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 4.0,\n",
       "     'id': 1.0,\n",
       "     'text': '고양시',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.482232},\n",
       "    {'begin': 10.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 10.0,\n",
       "     'id': 2.0,\n",
       "     'text': '이현옥',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.532402},\n",
       "    {'begin': 11.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 13.0,\n",
       "     'id': 3.0,\n",
       "     'text': '교육문화국장',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.685573}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 854.0,\n",
       "     'scode': '00',\n",
       "     'text': '40',\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 856.0,\n",
       "     'scode': '02',\n",
       "     'text': '년',\n",
       "     'type': 'NNB',\n",
       "     'weight': 4.4},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 860.0,\n",
       "     'scode': '02',\n",
       "     'text': '세월',\n",
       "     'type': 'NNG',\n",
       "     'weight': 4.2},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 866.0,\n",
       "     'scode': '01',\n",
       "     'text': '동안',\n",
       "     'type': 'NNG',\n",
       "     'weight': 4.2},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 873.0,\n",
       "     'scode': '00',\n",
       "     'text': '고양시',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 5.0,\n",
       "     'position': 882.0,\n",
       "     'scode': '00',\n",
       "     'text': '를',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 6.0,\n",
       "     'position': 886.0,\n",
       "     'scode': '01',\n",
       "     'text': '지키',\n",
       "     'type': 'VV',\n",
       "     'weight': 8.8},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 7.0,\n",
       "     'position': 889.0,\n",
       "     'scode': '00',\n",
       "     'text': '어',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 8.0,\n",
       "     'position': 892.0,\n",
       "     'scode': '01',\n",
       "     'text': '오',\n",
       "     'type': 'VX',\n",
       "     'weight': 11.8},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 9.0,\n",
       "     'position': 892.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 10.0,\n",
       "     'position': 896.0,\n",
       "     'scode': '00',\n",
       "     'text': '이현옥',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 11.0,\n",
       "     'position': 906.0,\n",
       "     'scode': '00',\n",
       "     'text': '교육',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 12.0,\n",
       "     'position': 912.0,\n",
       "     'scode': '01',\n",
       "     'text': '문화',\n",
       "     'type': 'NNG',\n",
       "     'weight': 7.2},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 13.0,\n",
       "     'position': 918.0,\n",
       "     'scode': '01',\n",
       "     'text': '국장',\n",
       "     'type': 'NNG',\n",
       "     'weight': 5.0},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 14.0,\n",
       "     'position': 924.0,\n",
       "     'scode': '00',\n",
       "     'text': '도',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 15.0,\n",
       "     'end': 15.0,\n",
       "     'id': 15.0,\n",
       "     'position': 928.0,\n",
       "     'scode': '02',\n",
       "     'text': '공직',\n",
       "     'type': 'NNG',\n",
       "     'weight': 4.0},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 16.0,\n",
       "     'position': 934.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 17.0,\n",
       "     'end': 18.0,\n",
       "     'id': 17.0,\n",
       "     'position': 938.0,\n",
       "     'scode': '00',\n",
       "     'text': '마무리하',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 19.0,\n",
       "     'end': 19.0,\n",
       "     'id': 18.0,\n",
       "     'position': 950.0,\n",
       "     'scode': '00',\n",
       "     'text': '기',\n",
       "     'type': 'ETN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 19.0,\n",
       "     'position': 954.0,\n",
       "     'scode': '01',\n",
       "     'text': '위하',\n",
       "     'type': 'VV',\n",
       "     'weight': 8.6},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 20.0,\n",
       "     'position': 957.0,\n",
       "     'scode': '00',\n",
       "     'text': '어',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 22.0,\n",
       "     'end': 22.0,\n",
       "     'id': 21.0,\n",
       "     'position': 961.0,\n",
       "     'scode': '04',\n",
       "     'text': '공로',\n",
       "     'type': 'NNG',\n",
       "     'weight': 4.10909},\n",
       "    {'begin': 23.0,\n",
       "     'end': 23.0,\n",
       "     'id': 22.0,\n",
       "     'position': 967.0,\n",
       "     'scode': '08',\n",
       "     'text': '연수',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.5},\n",
       "    {'begin': 24.0,\n",
       "     'end': 24.0,\n",
       "     'id': 23.0,\n",
       "     'position': 973.0,\n",
       "     'scode': '00',\n",
       "     'text': '에',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 25.0,\n",
       "     'end': 25.0,\n",
       "     'id': 24.0,\n",
       "     'position': 977.0,\n",
       "     'scode': '01',\n",
       "     'text': '들어가',\n",
       "     'type': 'VV',\n",
       "     'weight': 3.2},\n",
       "    {'begin': 26.0,\n",
       "     'end': 26.0,\n",
       "     'id': 25.0,\n",
       "     'position': 983.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 27.0,\n",
       "     'end': 27.0,\n",
       "     'id': 26.0,\n",
       "     'position': 989.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 1.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '40년',\n",
       "     'weight': 0.59692},\n",
       "    {'head': 3.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [0.0],\n",
       "     'text': '세월동안',\n",
       "     'weight': 0.476202},\n",
       "    {'head': 3.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [],\n",
       "     'text': '고양시를',\n",
       "     'weight': 0.762293},\n",
       "    {'head': 5.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [1.0, 2.0],\n",
       "     'text': '지켜온',\n",
       "     'weight': 0.807895},\n",
       "    {'head': 5.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '이현옥',\n",
       "     'weight': 0.567486},\n",
       "    {'head': 7.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [3.0, 4.0],\n",
       "     'text': '교육문화국장도',\n",
       "     'weight': 0.263154},\n",
       "    {'head': 7.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [],\n",
       "     'text': '공직을',\n",
       "     'weight': 0.62883},\n",
       "    {'head': 8.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'VP_OBJ',\n",
       "     'mod': [5.0, 6.0],\n",
       "     'text': '마무리하기',\n",
       "     'weight': 0.567291},\n",
       "    {'head': 10.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [7.0],\n",
       "     'text': '위해',\n",
       "     'weight': 0.711053},\n",
       "    {'head': 10.0,\n",
       "     'id': 9.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '공로연수에',\n",
       "     'weight': 0.699732},\n",
       "    {'head': -1.0,\n",
       "     'id': 10.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [8.0, 9.0],\n",
       "     'text': '들어간다.',\n",
       "     'weight': 0.00397418}],\n",
       "   'id': 5.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '40',\n",
       "     'position': 854.0,\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '년',\n",
       "     'position': 856.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.0620024},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '세월',\n",
       "     'position': 860.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0653524},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '동안',\n",
       "     'position': 866.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0530216},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '고양시',\n",
       "     'position': 873.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0555228},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '를',\n",
       "     'position': 882.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.116286},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '지키',\n",
       "     'position': 886.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0585379},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '어',\n",
       "     'position': 889.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0297251},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '오',\n",
       "     'position': 892.0,\n",
       "     'type': 'VX',\n",
       "     'weight': 0.0297251},\n",
       "    {'id': 9.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 892.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0297251},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '이현옥',\n",
       "     'position': 896.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0653221},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '교육',\n",
       "     'position': 906.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.105517},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '문화',\n",
       "     'position': 912.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.100961},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '국장',\n",
       "     'position': 918.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0314261},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '도',\n",
       "     'position': 924.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.0995007},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '공직',\n",
       "     'position': 928.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0827499},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '을',\n",
       "     'position': 934.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0894116},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '마무리',\n",
       "     'position': 938.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0325706},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '하',\n",
       "     'position': 947.0,\n",
       "     'type': 'XSV',\n",
       "     'weight': 0.0325706},\n",
       "    {'id': 19.0,\n",
       "     'lemma': '기',\n",
       "     'position': 950.0,\n",
       "     'type': 'ETN',\n",
       "     'weight': 0.237182},\n",
       "    {'id': 20.0,\n",
       "     'lemma': '위하',\n",
       "     'position': 954.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.111879},\n",
       "    {'id': 21.0,\n",
       "     'lemma': '어',\n",
       "     'position': 957.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0749282},\n",
       "    {'id': 22.0,\n",
       "     'lemma': '공로',\n",
       "     'position': 961.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0710124},\n",
       "    {'id': 23.0,\n",
       "     'lemma': '연수',\n",
       "     'position': 967.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.070642},\n",
       "    {'id': 24.0,\n",
       "     'lemma': '에',\n",
       "     'position': 973.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.104803},\n",
       "    {'id': 25.0,\n",
       "     'lemma': '들어가',\n",
       "     'position': 977.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.107452},\n",
       "    {'id': 26.0,\n",
       "     'lemma': 'ㄴ다',\n",
       "     'position': 983.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0500818},\n",
       "    {'id': 27.0,\n",
       "     'lemma': '.',\n",
       "     'position': 989.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': ' 40년 세월동안 고양시를 지켜온 이현옥 교육문화국장도 공직을 마무리하기 위해 공로연수에 들어간다.',\n",
       "   'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '40년', 'type': ''},\n",
       "    {'begin': 2.0, 'end': 3.0, 'id': 1.0, 'text': '세월동안', 'type': ''},\n",
       "    {'begin': 4.0, 'end': 5.0, 'id': 2.0, 'text': '고양시를', 'type': ''},\n",
       "    {'begin': 6.0, 'end': 9.0, 'id': 3.0, 'text': '지켜온', 'type': ''},\n",
       "    {'begin': 10.0, 'end': 10.0, 'id': 4.0, 'text': '이현옥', 'type': ''},\n",
       "    {'begin': 11.0, 'end': 14.0, 'id': 5.0, 'text': '교육문화국장도', 'type': ''},\n",
       "    {'begin': 15.0, 'end': 16.0, 'id': 6.0, 'text': '공직을', 'type': ''},\n",
       "    {'begin': 17.0, 'end': 19.0, 'id': 7.0, 'text': '마무리하기', 'type': ''},\n",
       "    {'begin': 20.0, 'end': 21.0, 'id': 8.0, 'text': '위해', 'type': ''},\n",
       "    {'begin': 22.0, 'end': 24.0, 'id': 9.0, 'text': '공로연수에', 'type': ''},\n",
       "    {'begin': 25.0, 'end': 27.0, 'id': 10.0, 'text': '들어간다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 10.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 10.0,\n",
       "     'id': 0.0,\n",
       "     'text': '후배',\n",
       "     'type': 'CV_RELATION',\n",
       "     'weight': 0.584798}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 992.0,\n",
       "     'scode': '00',\n",
       "     'text': '부드럽',\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 1001.0,\n",
       "     'scode': '00',\n",
       "     'text': '고',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 2.0,\n",
       "     'end': 3.0,\n",
       "     'id': 2.0,\n",
       "     'position': 1005.0,\n",
       "     'scode': '00',\n",
       "     'text': '섬세하',\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 3.0,\n",
       "     'position': 1011.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 4.0,\n",
       "     'position': 1015.0,\n",
       "     'scode': '01',\n",
       "     'text': '그',\n",
       "     'type': 'NP',\n",
       "     'weight': 9.8},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 5.0,\n",
       "     'position': 1018.0,\n",
       "     'scode': '00',\n",
       "     'text': '의',\n",
       "     'type': 'JKG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 6.0,\n",
       "     'position': 1022.0,\n",
       "     'scode': '02',\n",
       "     'text': '업무',\n",
       "     'type': 'NNG',\n",
       "     'weight': 4.2},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 7.0,\n",
       "     'position': 1028.0,\n",
       "     'scode': '00',\n",
       "     'text': '스타일',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 8.0,\n",
       "     'position': 1037.0,\n",
       "     'scode': '00',\n",
       "     'text': '은',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 9.0,\n",
       "     'position': 1041.0,\n",
       "     'scode': '06',\n",
       "     'text': '후배',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.2},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 10.0,\n",
       "     'position': 1047.0,\n",
       "     'scode': '09',\n",
       "     'text': '들',\n",
       "     'type': 'XSN',\n",
       "     'weight': 6.0},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 11.0,\n",
       "     'position': 1050.0,\n",
       "     'scode': '00',\n",
       "     'text': '에게',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 12.0,\n",
       "     'position': 1056.0,\n",
       "     'scode': '00',\n",
       "     'text': '도',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 13.0,\n",
       "     'position': 1060.0,\n",
       "     'scode': '00',\n",
       "     'text': '많',\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 15.0,\n",
       "     'end': 15.0,\n",
       "     'id': 14.0,\n",
       "     'position': 1063.0,\n",
       "     'scode': '00',\n",
       "     'text': '은',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 15.0,\n",
       "     'position': 1067.0,\n",
       "     'scode': '02',\n",
       "     'text': '신뢰',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.2},\n",
       "    {'begin': 17.0,\n",
       "     'end': 17.0,\n",
       "     'id': 16.0,\n",
       "     'position': 1073.0,\n",
       "     'scode': '00',\n",
       "     'text': '와',\n",
       "     'type': 'JC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 18.0,\n",
       "     'end': 18.0,\n",
       "     'id': 17.0,\n",
       "     'position': 1077.0,\n",
       "     'scode': '02',\n",
       "     'text': '박수',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.83929},\n",
       "    {'begin': 19.0,\n",
       "     'end': 19.0,\n",
       "     'id': 18.0,\n",
       "     'position': 1083.0,\n",
       "     'scode': '00',\n",
       "     'text': '를',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 19.0,\n",
       "     'position': 1087.0,\n",
       "     'scode': '01',\n",
       "     'text': '받',\n",
       "     'type': 'VV',\n",
       "     'weight': 4.4},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 20.0,\n",
       "     'position': 1090.0,\n",
       "     'scode': '00',\n",
       "     'text': '아',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 22.0,\n",
       "     'end': 22.0,\n",
       "     'id': 21.0,\n",
       "     'position': 1093.0,\n",
       "     'scode': '01',\n",
       "     'text': '오',\n",
       "     'type': 'VX',\n",
       "     'weight': 5.2},\n",
       "    {'begin': 23.0,\n",
       "     'end': 23.0,\n",
       "     'id': 22.0,\n",
       "     'position': 1093.0,\n",
       "     'scode': '00',\n",
       "     'text': '았',\n",
       "     'type': 'EP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 24.0,\n",
       "     'end': 24.0,\n",
       "     'id': 23.0,\n",
       "     'position': 1096.0,\n",
       "     'scode': '00',\n",
       "     'text': '다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 25.0,\n",
       "     'end': 25.0,\n",
       "     'id': 24.0,\n",
       "     'position': 1099.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 1.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [],\n",
       "     'text': '부드럽고',\n",
       "     'weight': 0.723763},\n",
       "    {'head': 3.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [0.0],\n",
       "     'text': '섬세한',\n",
       "     'weight': 0.651086},\n",
       "    {'head': 3.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'NP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '그의',\n",
       "     'weight': 0.610304},\n",
       "    {'head': 8.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [1.0, 2.0],\n",
       "     'text': '업무스타일은',\n",
       "     'weight': 0.779938},\n",
       "    {'head': 8.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '후배들에게도',\n",
       "     'weight': 0.584133},\n",
       "    {'head': 7.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '많은',\n",
       "     'weight': 0.561973},\n",
       "    {'head': 7.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'NP_CNJ',\n",
       "     'mod': [],\n",
       "     'text': '신뢰와',\n",
       "     'weight': 0.720678},\n",
       "    {'head': 8.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [5.0, 6.0],\n",
       "     'text': '박수를',\n",
       "     'weight': 0.645041},\n",
       "    {'head': -1.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [3.0, 4.0, 7.0],\n",
       "     'text': '받아왔다.',\n",
       "     'weight': 0.0237885}],\n",
       "   'id': 6.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '부드럽',\n",
       "     'position': 992.0,\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0462247},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '고',\n",
       "     'position': 1001.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0590407},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '섬세',\n",
       "     'position': 1005.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0554714},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '하',\n",
       "     'position': 1011.0,\n",
       "     'type': 'XSA',\n",
       "     'weight': 0.0554714},\n",
       "    {'id': 4.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 1011.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0283526},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '그',\n",
       "     'position': 1015.0,\n",
       "     'type': 'NP',\n",
       "     'weight': 0.0997758},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '의',\n",
       "     'position': 1018.0,\n",
       "     'type': 'JKG',\n",
       "     'weight': 0.123432},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '업무',\n",
       "     'position': 1022.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.107745},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '스타일',\n",
       "     'position': 1028.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0869361},\n",
       "    {'id': 9.0,\n",
       "     'lemma': '은',\n",
       "     'position': 1037.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.0880177},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '후배',\n",
       "     'position': 1041.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0770732},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '들',\n",
       "     'position': 1047.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0784122},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '에게',\n",
       "     'position': 1050.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0583923},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '도',\n",
       "     'position': 1056.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.178251},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '많',\n",
       "     'position': 1060.0,\n",
       "     'type': 'VA',\n",
       "     'weight': 0.193986},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '은',\n",
       "     'position': 1063.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0942571},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '신뢰',\n",
       "     'position': 1067.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0793142},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '와',\n",
       "     'position': 1073.0,\n",
       "     'type': 'JC',\n",
       "     'weight': 0.0589239},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '박수',\n",
       "     'position': 1077.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.066423},\n",
       "    {'id': 19.0,\n",
       "     'lemma': '를',\n",
       "     'position': 1083.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.125048},\n",
       "    {'id': 20.0,\n",
       "     'lemma': '받',\n",
       "     'position': 1087.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.113869},\n",
       "    {'id': 21.0,\n",
       "     'lemma': '아',\n",
       "     'position': 1090.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0600462},\n",
       "    {'id': 22.0,\n",
       "     'lemma': '오',\n",
       "     'position': 1093.0,\n",
       "     'type': 'VX',\n",
       "     'weight': 0.0396257},\n",
       "    {'id': 23.0,\n",
       "     'lemma': '았',\n",
       "     'position': 1093.0,\n",
       "     'type': 'EP',\n",
       "     'weight': 0.0396257},\n",
       "    {'id': 24.0,\n",
       "     'lemma': '다',\n",
       "     'position': 1096.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0911348},\n",
       "    {'id': 25.0,\n",
       "     'lemma': '.',\n",
       "     'position': 1099.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': '  부드럽고 섬세한 그의 업무스타일은 후배들에게도 많은 신뢰와 박수를 받아왔다.',\n",
       "   'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '부드럽고', 'type': ''},\n",
       "    {'begin': 2.0, 'end': 4.0, 'id': 1.0, 'text': '섬세한', 'type': ''},\n",
       "    {'begin': 5.0, 'end': 6.0, 'id': 2.0, 'text': '그의', 'type': ''},\n",
       "    {'begin': 7.0, 'end': 9.0, 'id': 3.0, 'text': '업무스타일은', 'type': ''},\n",
       "    {'begin': 10.0, 'end': 13.0, 'id': 4.0, 'text': '후배들에게도', 'type': ''},\n",
       "    {'begin': 14.0, 'end': 15.0, 'id': 5.0, 'text': '많은', 'type': ''},\n",
       "    {'begin': 16.0, 'end': 17.0, 'id': 6.0, 'text': '신뢰와', 'type': ''},\n",
       "    {'begin': 18.0, 'end': 19.0, 'id': 7.0, 'text': '박수를', 'type': ''},\n",
       "    {'begin': 20.0, 'end': 25.0, 'id': 8.0, 'text': '받아왔다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 0.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 1.0,\n",
       "     'id': 0.0,\n",
       "     'text': '정부부처',\n",
       "     'type': 'OGG_POLITICS',\n",
       "     'weight': 0.298825},\n",
       "    {'begin': 6.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 7.0,\n",
       "     'id': 1.0,\n",
       "     'text': '13회',\n",
       "     'type': 'QT_COUNT',\n",
       "     'weight': 0.595865},\n",
       "    {'begin': 11.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 11.0,\n",
       "     'id': 2.0,\n",
       "     'text': '이흥민',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.413754},\n",
       "    {'begin': 12.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 14.0,\n",
       "     'id': 3.0,\n",
       "     'text': '민생경제국장',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.262842},\n",
       "    {'begin': 16.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 16.0,\n",
       "     'id': 4.0,\n",
       "     'text': '고양시',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.265124}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 1101.0,\n",
       "     'scode': '08',\n",
       "     'text': '정부',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 1107.0,\n",
       "     'scode': '04',\n",
       "     'text': '부처',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.0},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 1114.0,\n",
       "     'scode': '05',\n",
       "     'text': '등',\n",
       "     'type': 'NNB',\n",
       "     'weight': 5.4},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 1117.0,\n",
       "     'scode': '00',\n",
       "     'text': '으로부터',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 1130.0,\n",
       "     'scode': '01',\n",
       "     'text': '표창',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.2},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 5.0,\n",
       "     'position': 1136.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 6.0,\n",
       "     'position': 1140.0,\n",
       "     'scode': '00',\n",
       "     'text': '13',\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 7.0,\n",
       "     'position': 1142.0,\n",
       "     'scode': '08',\n",
       "     'text': '회',\n",
       "     'type': 'NNB',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 8.0,\n",
       "     'position': 1145.0,\n",
       "     'scode': '00',\n",
       "     'text': '나',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 9.0,\n",
       "     'position': 1149.0,\n",
       "     'scode': '01',\n",
       "     'text': '받',\n",
       "     'type': 'VV',\n",
       "     'weight': 4.4},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 10.0,\n",
       "     'position': 1152.0,\n",
       "     'scode': '00',\n",
       "     'text': '은',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 11.0,\n",
       "     'position': 1156.0,\n",
       "     'scode': '00',\n",
       "     'text': '이흥민',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 12.0,\n",
       "     'position': 1166.0,\n",
       "     'scode': '00',\n",
       "     'text': '민생',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 13.0,\n",
       "     'position': 1172.0,\n",
       "     'scode': '04',\n",
       "     'text': '경제',\n",
       "     'type': 'NNG',\n",
       "     'weight': 5.2},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 14.0,\n",
       "     'position': 1178.0,\n",
       "     'scode': '01',\n",
       "     'text': '국장',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.0},\n",
       "    {'begin': 15.0,\n",
       "     'end': 15.0,\n",
       "     'id': 15.0,\n",
       "     'position': 1185.0,\n",
       "     'scode': '01',\n",
       "     'text': '역시',\n",
       "     'type': 'MAG',\n",
       "     'weight': 3.0},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 16.0,\n",
       "     'position': 1192.0,\n",
       "     'scode': '00',\n",
       "     'text': '고양시',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 17.0,\n",
       "     'end': 17.0,\n",
       "     'id': 17.0,\n",
       "     'position': 1201.0,\n",
       "     'scode': '00',\n",
       "     'text': '에게',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 18.0,\n",
       "     'end': 18.0,\n",
       "     'id': 18.0,\n",
       "     'position': 1207.0,\n",
       "     'scode': '00',\n",
       "     'text': '는',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 19.0,\n",
       "     'end': 19.0,\n",
       "     'id': 19.0,\n",
       "     'position': 1211.0,\n",
       "     'scode': '00',\n",
       "     'text': '아깝',\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 20.0,\n",
       "     'position': 1217.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 21.0,\n",
       "     'position': 1221.0,\n",
       "     'scode': '02',\n",
       "     'text': '인재',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.2},\n",
       "    {'begin': 22.0,\n",
       "     'end': 22.0,\n",
       "     'id': 22.0,\n",
       "     'position': 1227.0,\n",
       "     'scode': '01',\n",
       "     'text': '이',\n",
       "     'type': 'VCP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 23.0,\n",
       "     'end': 23.0,\n",
       "     'id': 23.0,\n",
       "     'position': 1227.0,\n",
       "     'scode': '00',\n",
       "     'text': '다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 24.0,\n",
       "     'end': 24.0,\n",
       "     'id': 24.0,\n",
       "     'position': 1230.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 1.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '정부부처',\n",
       "     'weight': 0.575132},\n",
       "    {'head': 4.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [0.0],\n",
       "     'text': '등으로부터',\n",
       "     'weight': 0.536978},\n",
       "    {'head': 4.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [],\n",
       "     'text': '표창을',\n",
       "     'weight': 0.712637},\n",
       "    {'head': 4.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [],\n",
       "     'text': '13회나',\n",
       "     'weight': 0.497727},\n",
       "    {'head': 6.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [1.0, 2.0, 3.0],\n",
       "     'text': '받은',\n",
       "     'weight': 0.752247},\n",
       "    {'head': 6.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '이흥민',\n",
       "     'weight': 0.624862},\n",
       "    {'head': 9.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [4.0, 5.0],\n",
       "     'text': '민생경제국장',\n",
       "     'weight': 0.356399},\n",
       "    {'head': 9.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'AP',\n",
       "     'mod': [],\n",
       "     'text': '역시',\n",
       "     'weight': 0.780702},\n",
       "    {'head': 9.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '고양시에게는',\n",
       "     'weight': 0.670933},\n",
       "    {'head': 10.0,\n",
       "     'id': 9.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [6.0, 7.0, 8.0],\n",
       "     'text': '아까운',\n",
       "     'weight': 0.684296},\n",
       "    {'head': -1.0,\n",
       "     'id': 10.0,\n",
       "     'label': 'VNP',\n",
       "     'mod': [9.0],\n",
       "     'text': '인재다.',\n",
       "     'weight': 0.00512573}],\n",
       "   'id': 7.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '정부',\n",
       "     'position': 1101.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0786011},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '부처',\n",
       "     'position': 1107.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0610427},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '등',\n",
       "     'position': 1114.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.153512},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '으로부터',\n",
       "     'position': 1117.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0663022},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '표창',\n",
       "     'position': 1130.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.074908},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '을',\n",
       "     'position': 1136.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0830249},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '13',\n",
       "     'position': 1140.0,\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '회',\n",
       "     'position': 1142.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.0417621},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '나',\n",
       "     'position': 1145.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.026281},\n",
       "    {'id': 9.0,\n",
       "     'lemma': '받',\n",
       "     'position': 1149.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.141768},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '은',\n",
       "     'position': 1152.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.116126},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '이흥민',\n",
       "     'position': 1156.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0525572},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '민생',\n",
       "     'position': 1166.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0574642},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '경제',\n",
       "     'position': 1172.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0488646},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '국장',\n",
       "     'position': 1178.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0433426},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '역시',\n",
       "     'position': 1185.0,\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0790521},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '고양시',\n",
       "     'position': 1192.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0728245},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '에게',\n",
       "     'position': 1201.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.057028},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '는',\n",
       "     'position': 1207.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.142711},\n",
       "    {'id': 19.0,\n",
       "     'lemma': '아깝',\n",
       "     'position': 1211.0,\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0473776},\n",
       "    {'id': 20.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 1217.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0570711},\n",
       "    {'id': 21.0,\n",
       "     'lemma': '인재',\n",
       "     'position': 1221.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0680801},\n",
       "    {'id': 22.0,\n",
       "     'lemma': '이',\n",
       "     'position': 1227.0,\n",
       "     'type': 'VCP',\n",
       "     'weight': 0.0578411},\n",
       "    {'id': 23.0,\n",
       "     'lemma': '다',\n",
       "     'position': 1227.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0616223},\n",
       "    {'id': 24.0,\n",
       "     'lemma': '.',\n",
       "     'position': 1230.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': ' 정부부처 등으로부터 표창을 13회나 받은 이흥민 민생경제국장 역시 고양시에게는 아까운 인재다.',\n",
       "   'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '정부부처', 'type': ''},\n",
       "    {'begin': 2.0, 'end': 3.0, 'id': 1.0, 'text': '등으로부터', 'type': ''},\n",
       "    {'begin': 4.0, 'end': 5.0, 'id': 2.0, 'text': '표창을', 'type': ''},\n",
       "    {'begin': 6.0, 'end': 8.0, 'id': 3.0, 'text': '13회나', 'type': ''},\n",
       "    {'begin': 9.0, 'end': 10.0, 'id': 4.0, 'text': '받은', 'type': ''},\n",
       "    {'begin': 11.0, 'end': 11.0, 'id': 5.0, 'text': '이흥민', 'type': ''},\n",
       "    {'begin': 12.0, 'end': 14.0, 'id': 6.0, 'text': '민생경제국장', 'type': ''},\n",
       "    {'begin': 15.0, 'end': 15.0, 'id': 7.0, 'text': '역시', 'type': ''},\n",
       "    {'begin': 16.0, 'end': 18.0, 'id': 8.0, 'text': '고양시에게는', 'type': ''},\n",
       "    {'begin': 19.0, 'end': 20.0, 'id': 9.0, 'text': '아까운', 'type': ''},\n",
       "    {'begin': 21.0, 'end': 24.0, 'id': 10.0, 'text': '인재다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 2.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 2.0,\n",
       "     'id': 0.0,\n",
       "     'text': '고양',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.435763},\n",
       "    {'begin': 4.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 4.0,\n",
       "     'id': 1.0,\n",
       "     'text': '주민',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.461411},\n",
       "    {'begin': 19.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 19.0,\n",
       "     'id': 2.0,\n",
       "     'text': '주민',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.461171},\n",
       "    {'begin': 25.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 25.0,\n",
       "     'id': 3.0,\n",
       "     'text': '고양시',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.451072}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 1233.0,\n",
       "     'scode': '01',\n",
       "     'text': '그',\n",
       "     'type': 'NP',\n",
       "     'weight': 4.4},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 1236.0,\n",
       "     'scode': '00',\n",
       "     'text': '는',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 1240.0,\n",
       "     'scode': '06',\n",
       "     'text': '고양',\n",
       "     'type': 'NNP',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 1246.0,\n",
       "     'scode': '03',\n",
       "     'text': '지역',\n",
       "     'type': 'NNG',\n",
       "     'weight': 4.2},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 1253.0,\n",
       "     'scode': '00',\n",
       "     'text': '주민',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 5.0,\n",
       "     'position': 1259.0,\n",
       "     'scode': '09',\n",
       "     'text': '들',\n",
       "     'type': 'XSN',\n",
       "     'weight': 6.0},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 6.0,\n",
       "     'position': 1262.0,\n",
       "     'scode': '00',\n",
       "     'text': '이',\n",
       "     'type': 'JKS',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 7.0,\n",
       "     'end': 8.0,\n",
       "     'id': 7.0,\n",
       "     'position': 1266.0,\n",
       "     'scode': '00',\n",
       "     'text': '원활하',\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 8.0,\n",
       "     'position': 1272.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 9.0,\n",
       "     'position': 1276.0,\n",
       "     'scode': '00',\n",
       "     'text': '생활',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 10.0,\n",
       "     'position': 1282.0,\n",
       "     'scode': '02',\n",
       "     'text': '지원',\n",
       "     'type': 'NNG',\n",
       "     'weight': 6.2},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 11.0,\n",
       "     'position': 1288.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 12.0,\n",
       "     'position': 1292.0,\n",
       "     'scode': '01',\n",
       "     'text': '받',\n",
       "     'type': 'VV',\n",
       "     'weight': 7.59036},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 13.0,\n",
       "     'position': 1295.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 15.0,\n",
       "     'end': 15.0,\n",
       "     'id': 14.0,\n",
       "     'position': 1299.0,\n",
       "     'scode': '02',\n",
       "     'text': '수',\n",
       "     'type': 'NNB',\n",
       "     'weight': 10.9992},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 15.0,\n",
       "     'position': 1303.0,\n",
       "     'scode': '01',\n",
       "     'text': '있',\n",
       "     'type': 'VA',\n",
       "     'weight': 6.6},\n",
       "    {'begin': 17.0,\n",
       "     'end': 17.0,\n",
       "     'id': 16.0,\n",
       "     'position': 1306.0,\n",
       "     'scode': '00',\n",
       "     'text': '도록',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 18.0,\n",
       "     'end': 18.0,\n",
       "     'id': 17.0,\n",
       "     'position': 1313.0,\n",
       "     'scode': '00',\n",
       "     'text': '늘',\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 19.0,\n",
       "     'end': 19.0,\n",
       "     'id': 18.0,\n",
       "     'position': 1317.0,\n",
       "     'scode': '00',\n",
       "     'text': '주민',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 19.0,\n",
       "     'position': 1323.0,\n",
       "     'scode': '09',\n",
       "     'text': '들',\n",
       "     'type': 'XSN',\n",
       "     'weight': 5.0},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 20.0,\n",
       "     'position': 1326.0,\n",
       "     'scode': '00',\n",
       "     'text': '과',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 22.0,\n",
       "     'end': 23.0,\n",
       "     'id': 21.0,\n",
       "     'position': 1330.0,\n",
       "     'scode': '00',\n",
       "     'text': '함께하',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 24.0,\n",
       "     'end': 24.0,\n",
       "     'id': 22.0,\n",
       "     'position': 1339.0,\n",
       "     'scode': '00',\n",
       "     'text': '며',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 25.0,\n",
       "     'end': 25.0,\n",
       "     'id': 23.0,\n",
       "     'position': 1343.0,\n",
       "     'scode': '00',\n",
       "     'text': '고양시',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 26.0,\n",
       "     'end': 26.0,\n",
       "     'id': 24.0,\n",
       "     'position': 1353.0,\n",
       "     'scode': '01',\n",
       "     'text': '행정',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 27.0,\n",
       "     'end': 27.0,\n",
       "     'id': 25.0,\n",
       "     'position': 1359.0,\n",
       "     'scode': '00',\n",
       "     'text': '에',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 28.0,\n",
       "     'end': 28.0,\n",
       "     'id': 26.0,\n",
       "     'position': 1363.0,\n",
       "     'scode': '03',\n",
       "     'text': '현장',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.0},\n",
       "    {'begin': 29.0,\n",
       "     'end': 29.0,\n",
       "     'id': 27.0,\n",
       "     'position': 1369.0,\n",
       "     'scode': '00',\n",
       "     'text': '의',\n",
       "     'type': 'JKG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 30.0,\n",
       "     'end': 31.0,\n",
       "     'id': 28.0,\n",
       "     'position': 1373.0,\n",
       "     'scode': '00',\n",
       "     'text': '목소리',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 32.0,\n",
       "     'end': 32.0,\n",
       "     'id': 29.0,\n",
       "     'position': 1382.0,\n",
       "     'scode': '00',\n",
       "     'text': '를',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 33.0,\n",
       "     'end': 33.0,\n",
       "     'id': 30.0,\n",
       "     'position': 1386.0,\n",
       "     'scode': '00',\n",
       "     'text': '담아오',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 34.0,\n",
       "     'end': 34.0,\n",
       "     'id': 31.0,\n",
       "     'position': 1392.0,\n",
       "     'scode': '00',\n",
       "     'text': '았',\n",
       "     'type': 'EP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 35.0,\n",
       "     'end': 35.0,\n",
       "     'id': 32.0,\n",
       "     'position': 1395.0,\n",
       "     'scode': '00',\n",
       "     'text': '다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 36.0,\n",
       "     'end': 36.0,\n",
       "     'id': 33.0,\n",
       "     'position': 1398.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 7.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [],\n",
       "     'text': '그는',\n",
       "     'weight': 0.212},\n",
       "    {'head': 2.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '고양지역',\n",
       "     'weight': 0.41661},\n",
       "    {'head': 5.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [1.0],\n",
       "     'text': '주민들이',\n",
       "     'weight': 0.565949},\n",
       "    {'head': 4.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '원활한',\n",
       "     'weight': 0.696276},\n",
       "    {'head': 5.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [3.0],\n",
       "     'text': '생활지원을',\n",
       "     'weight': 0.60839},\n",
       "    {'head': 6.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [2.0, 4.0],\n",
       "     'text': '받을',\n",
       "     'weight': 0.722259},\n",
       "    {'head': 7.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [5.0],\n",
       "     'text': '수',\n",
       "     'weight': 0.668727},\n",
       "    {'head': 10.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [0.0, 6.0],\n",
       "     'text': '있도록',\n",
       "     'weight': 0.698144},\n",
       "    {'head': 10.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'AP',\n",
       "     'mod': [],\n",
       "     'text': '늘',\n",
       "     'weight': 0.69933},\n",
       "    {'head': 10.0,\n",
       "     'id': 9.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '주민들과',\n",
       "     'weight': 0.715647},\n",
       "    {'head': 15.0,\n",
       "     'id': 10.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [7.0, 8.0, 9.0],\n",
       "     'text': '함께하며',\n",
       "     'weight': 0.564753},\n",
       "    {'head': 12.0,\n",
       "     'id': 11.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '고양시',\n",
       "     'weight': 0.579028},\n",
       "    {'head': 15.0,\n",
       "     'id': 12.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [11.0],\n",
       "     'text': '행정에',\n",
       "     'weight': 0.743706},\n",
       "    {'head': 14.0,\n",
       "     'id': 13.0,\n",
       "     'label': 'NP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '현장의',\n",
       "     'weight': 0.535362},\n",
       "    {'head': 15.0,\n",
       "     'id': 14.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [13.0],\n",
       "     'text': '목소리를',\n",
       "     'weight': 0.687593},\n",
       "    {'head': -1.0,\n",
       "     'id': 15.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [10.0, 12.0, 14.0],\n",
       "     'text': '담아왔다.',\n",
       "     'weight': 0.000232658}],\n",
       "   'id': 8.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '그',\n",
       "     'position': 1233.0,\n",
       "     'type': 'NP',\n",
       "     'weight': 0.109226},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '는',\n",
       "     'position': 1236.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.1124},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '고양',\n",
       "     'position': 1240.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0771626},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '지역',\n",
       "     'position': 1246.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0616679},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '주민',\n",
       "     'position': 1253.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.110431},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '들',\n",
       "     'position': 1259.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0857102},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '이',\n",
       "     'position': 1262.0,\n",
       "     'type': 'JKS',\n",
       "     'weight': 0.0708404},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '원활',\n",
       "     'position': 1266.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0463476},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '하',\n",
       "     'position': 1272.0,\n",
       "     'type': 'XSA',\n",
       "     'weight': 0.0463476},\n",
       "    {'id': 9.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 1272.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0473384},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '생활',\n",
       "     'position': 1276.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0928478},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '지원',\n",
       "     'position': 1282.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0845234},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '을',\n",
       "     'position': 1288.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.101296},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '받',\n",
       "     'position': 1292.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.146405},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '을',\n",
       "     'position': 1295.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.149223},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '수',\n",
       "     'position': 1299.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.244943},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '있',\n",
       "     'position': 1303.0,\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0992615},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '도록',\n",
       "     'position': 1306.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.10274},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '늘',\n",
       "     'position': 1313.0,\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0774975},\n",
       "    {'id': 19.0,\n",
       "     'lemma': '주민',\n",
       "     'position': 1317.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0929645},\n",
       "    {'id': 20.0,\n",
       "     'lemma': '들',\n",
       "     'position': 1323.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0771089},\n",
       "    {'id': 21.0,\n",
       "     'lemma': '과',\n",
       "     'position': 1326.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0677364},\n",
       "    {'id': 22.0,\n",
       "     'lemma': '함께',\n",
       "     'position': 1330.0,\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0921061},\n",
       "    {'id': 23.0,\n",
       "     'lemma': '하',\n",
       "     'position': 1336.0,\n",
       "     'type': 'XSV',\n",
       "     'weight': 0.0453254},\n",
       "    {'id': 24.0,\n",
       "     'lemma': '며',\n",
       "     'position': 1339.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.12918},\n",
       "    {'id': 25.0,\n",
       "     'lemma': '고양시',\n",
       "     'position': 1343.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0688935},\n",
       "    {'id': 26.0,\n",
       "     'lemma': '행정',\n",
       "     'position': 1353.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.106702},\n",
       "    {'id': 27.0,\n",
       "     'lemma': '에',\n",
       "     'position': 1359.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.077173},\n",
       "    {'id': 28.0,\n",
       "     'lemma': '현장',\n",
       "     'position': 1363.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.114015},\n",
       "    {'id': 29.0,\n",
       "     'lemma': '의',\n",
       "     'position': 1369.0,\n",
       "     'type': 'JKG',\n",
       "     'weight': 0.0990535},\n",
       "    {'id': 30.0,\n",
       "     'lemma': '목',\n",
       "     'position': 1373.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.256853},\n",
       "    {'id': 31.0,\n",
       "     'lemma': '소리',\n",
       "     'position': 1376.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.256853},\n",
       "    {'id': 32.0,\n",
       "     'lemma': '를',\n",
       "     'position': 1382.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.142369},\n",
       "    {'id': 33.0,\n",
       "     'lemma': '담아오',\n",
       "     'position': 1386.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0433565},\n",
       "    {'id': 34.0,\n",
       "     'lemma': '았',\n",
       "     'position': 1392.0,\n",
       "     'type': 'EP',\n",
       "     'weight': 0.0265464},\n",
       "    {'id': 35.0,\n",
       "     'lemma': '다',\n",
       "     'position': 1395.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0881576},\n",
       "    {'id': 36.0,\n",
       "     'lemma': '.',\n",
       "     'position': 1398.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': '  그는 고양지역 주민들이 원활한 생활지원을 받을 수 있도록 늘 주민들과 함께하며 고양시 행정에 현장의 목소리를 담아왔다.',\n",
       "   'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '그는', 'type': ''},\n",
       "    {'begin': 2.0, 'end': 3.0, 'id': 1.0, 'text': '고양지역', 'type': ''},\n",
       "    {'begin': 4.0, 'end': 6.0, 'id': 2.0, 'text': '주민들이', 'type': ''},\n",
       "    {'begin': 7.0, 'end': 9.0, 'id': 3.0, 'text': '원활한', 'type': ''},\n",
       "    {'begin': 10.0, 'end': 12.0, 'id': 4.0, 'text': '생활지원을', 'type': ''},\n",
       "    {'begin': 13.0, 'end': 14.0, 'id': 5.0, 'text': '받을', 'type': ''},\n",
       "    {'begin': 15.0, 'end': 15.0, 'id': 6.0, 'text': '수', 'type': ''},\n",
       "    {'begin': 16.0, 'end': 17.0, 'id': 7.0, 'text': '있도록', 'type': ''},\n",
       "    {'begin': 18.0, 'end': 18.0, 'id': 8.0, 'text': '늘', 'type': ''},\n",
       "    {'begin': 19.0, 'end': 21.0, 'id': 9.0, 'text': '주민들과', 'type': ''},\n",
       "    {'begin': 22.0, 'end': 24.0, 'id': 10.0, 'text': '함께하며', 'type': ''},\n",
       "    {'begin': 25.0, 'end': 25.0, 'id': 11.0, 'text': '고양시', 'type': ''},\n",
       "    {'begin': 26.0, 'end': 27.0, 'id': 12.0, 'text': '행정에', 'type': ''},\n",
       "    {'begin': 28.0, 'end': 29.0, 'id': 13.0, 'text': '현장의', 'type': ''},\n",
       "    {'begin': 30.0, 'end': 32.0, 'id': 14.0, 'text': '목소리를', 'type': ''},\n",
       "    {'begin': 33.0, 'end': 36.0, 'id': 15.0, 'text': '담아왔다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 0.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'text': '노양호',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.333467},\n",
       "    {'begin': 1.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 3.0,\n",
       "     'id': 1.0,\n",
       "     'text': '여성가족국장',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.378504},\n",
       "    {'begin': 5.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 5.0,\n",
       "     'id': 2.0,\n",
       "     'text': '고양',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.481313},\n",
       "    {'begin': 11.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 12.0,\n",
       "     'id': 3.0,\n",
       "     'text': '40년',\n",
       "     'type': 'DT_DURATION',\n",
       "     'weight': 0.557002}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 1400.0,\n",
       "     'scode': '00',\n",
       "     'text': '노양호',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 1410.0,\n",
       "     'scode': '01',\n",
       "     'text': '여성',\n",
       "     'type': 'NNG',\n",
       "     'weight': 6.0},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 1416.0,\n",
       "     'scode': '01',\n",
       "     'text': '가족',\n",
       "     'type': 'NNG',\n",
       "     'weight': 6.4},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 1422.0,\n",
       "     'scode': '01',\n",
       "     'text': '국장',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.0},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 1428.0,\n",
       "     'scode': '00',\n",
       "     'text': '도',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 5.0,\n",
       "     'position': 1432.0,\n",
       "     'scode': '06',\n",
       "     'text': '고양',\n",
       "     'type': 'NNP',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 6.0,\n",
       "     'position': 1438.0,\n",
       "     'scode': '03',\n",
       "     'text': '지역',\n",
       "     'type': 'NNG',\n",
       "     'weight': 10.6},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 7.0,\n",
       "     'position': 1445.0,\n",
       "     'scode': '01',\n",
       "     'text': '발전',\n",
       "     'type': 'NNG',\n",
       "     'weight': 7.56933},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 8.0,\n",
       "     'position': 1451.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 9.0,\n",
       "     'position': 1455.0,\n",
       "     'scode': '01',\n",
       "     'text': '위하',\n",
       "     'type': 'VV',\n",
       "     'weight': 5.4},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 10.0,\n",
       "     'position': 1458.0,\n",
       "     'scode': '00',\n",
       "     'text': '어',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 11.0,\n",
       "     'position': 1462.0,\n",
       "     'scode': '00',\n",
       "     'text': '40',\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 12.0,\n",
       "     'position': 1464.0,\n",
       "     'scode': '02',\n",
       "     'text': '년',\n",
       "     'type': 'NNB',\n",
       "     'weight': 10.9979},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 13.0,\n",
       "     'position': 1468.0,\n",
       "     'scode': '01',\n",
       "     'text': '넘',\n",
       "     'type': 'VV',\n",
       "     'weight': 3.2},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 14.0,\n",
       "     'position': 1471.0,\n",
       "     'scode': '00',\n",
       "     'text': '게',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 15.0,\n",
       "     'end': 15.0,\n",
       "     'id': 15.0,\n",
       "     'position': 1475.0,\n",
       "     'scode': '02',\n",
       "     'text': '예산',\n",
       "     'type': 'NNG',\n",
       "     'weight': 4.2},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 16.0,\n",
       "     'position': 1481.0,\n",
       "     'scode': '01',\n",
       "     'text': '법무',\n",
       "     'type': 'NNG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 17.0,\n",
       "     'end': 17.0,\n",
       "     'id': 17.0,\n",
       "     'position': 1487.0,\n",
       "     'scode': '14',\n",
       "     'text': '과',\n",
       "     'type': 'XSN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 18.0,\n",
       "     'end': 18.0,\n",
       "     'id': 18.0,\n",
       "     'position': 1491.0,\n",
       "     'scode': '05',\n",
       "     'text': '등',\n",
       "     'type': 'NNB',\n",
       "     'weight': 8.4},\n",
       "    {'begin': 19.0,\n",
       "     'end': 19.0,\n",
       "     'id': 19.0,\n",
       "     'position': 1495.0,\n",
       "     'scode': '01',\n",
       "     'text': '주요',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 20.0,\n",
       "     'position': 1501.0,\n",
       "     'scode': '12',\n",
       "     'text': '부서',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.0},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 21.0,\n",
       "     'position': 1507.0,\n",
       "     'scode': '00',\n",
       "     'text': '에서',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 22.0,\n",
       "     'end': 23.0,\n",
       "     'id': 22.0,\n",
       "     'position': 1514.0,\n",
       "     'scode': '00',\n",
       "     'text': '활약하',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 24.0,\n",
       "     'end': 24.0,\n",
       "     'id': 23.0,\n",
       "     'position': 1520.0,\n",
       "     'scode': '00',\n",
       "     'text': '어',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 25.0,\n",
       "     'end': 25.0,\n",
       "     'id': 24.0,\n",
       "     'position': 1524.0,\n",
       "     'scode': '01',\n",
       "     'text': '오',\n",
       "     'type': 'VX',\n",
       "     'weight': 4.2},\n",
       "    {'begin': 26.0,\n",
       "     'end': 26.0,\n",
       "     'id': 25.0,\n",
       "     'position': 1524.0,\n",
       "     'scode': '00',\n",
       "     'text': '았',\n",
       "     'type': 'EP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 27.0,\n",
       "     'end': 27.0,\n",
       "     'id': 26.0,\n",
       "     'position': 1527.0,\n",
       "     'scode': '00',\n",
       "     'text': '다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 28.0,\n",
       "     'end': 28.0,\n",
       "     'id': 27.0,\n",
       "     'position': 1530.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 1.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '노양호',\n",
       "     'weight': 0.472935},\n",
       "    {'head': 4.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [0.0],\n",
       "     'text': '여성가족국장도',\n",
       "     'weight': 0.296624},\n",
       "    {'head': 3.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '고양지역',\n",
       "     'weight': 0.665069},\n",
       "    {'head': 4.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [2.0],\n",
       "     'text': '발전을',\n",
       "     'weight': 0.710175},\n",
       "    {'head': 6.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [1.0, 3.0],\n",
       "     'text': '위해',\n",
       "     'weight': 0.713761},\n",
       "    {'head': 6.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [],\n",
       "     'text': '40년',\n",
       "     'weight': 0.180268},\n",
       "    {'head': 10.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [4.0, 5.0],\n",
       "     'text': '넘게',\n",
       "     'weight': 0.25906},\n",
       "    {'head': 8.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '예산법무과',\n",
       "     'weight': 0.732728},\n",
       "    {'head': 9.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [7.0],\n",
       "     'text': '등',\n",
       "     'weight': 0.0252941},\n",
       "    {'head': 10.0,\n",
       "     'id': 9.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [8.0],\n",
       "     'text': '주요부서에서',\n",
       "     'weight': 0.738762},\n",
       "    {'head': 11.0,\n",
       "     'id': 10.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [6.0, 9.0],\n",
       "     'text': '활약해',\n",
       "     'weight': 0.73942},\n",
       "    {'head': -1.0,\n",
       "     'id': 11.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [10.0],\n",
       "     'text': '왔다.',\n",
       "     'weight': 1.86152e-05}],\n",
       "   'id': 9.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '노양호',\n",
       "     'position': 1400.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0601613},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '여성',\n",
       "     'position': 1410.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0976816},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '가족',\n",
       "     'position': 1416.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0594258},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '국장',\n",
       "     'position': 1422.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0415428},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '도',\n",
       "     'position': 1428.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.113391},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '고양',\n",
       "     'position': 1432.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0600651},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '지역',\n",
       "     'position': 1438.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0726147},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '발전',\n",
       "     'position': 1445.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0805563},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '을',\n",
       "     'position': 1451.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0944437},\n",
       "    {'id': 9.0,\n",
       "     'lemma': '위하',\n",
       "     'position': 1455.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0945465},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '어',\n",
       "     'position': 1458.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0679444},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '40',\n",
       "     'position': 1462.0,\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '년',\n",
       "     'position': 1464.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.0652439},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '넘',\n",
       "     'position': 1468.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0538848},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '게',\n",
       "     'position': 1471.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0637545},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '예산',\n",
       "     'position': 1475.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.123562},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '법무',\n",
       "     'position': 1481.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0257218},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '과',\n",
       "     'position': 1487.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0257218},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '등',\n",
       "     'position': 1491.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.132083},\n",
       "    {'id': 19.0,\n",
       "     'lemma': '주요',\n",
       "     'position': 1495.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0642861},\n",
       "    {'id': 20.0,\n",
       "     'lemma': '부서',\n",
       "     'position': 1501.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0562746},\n",
       "    {'id': 21.0,\n",
       "     'lemma': '에서',\n",
       "     'position': 1507.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0824276},\n",
       "    {'id': 22.0,\n",
       "     'lemma': '활약',\n",
       "     'position': 1514.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0375543},\n",
       "    {'id': 23.0,\n",
       "     'lemma': '하',\n",
       "     'position': 1520.0,\n",
       "     'type': 'XSV',\n",
       "     'weight': 0.0375543},\n",
       "    {'id': 24.0,\n",
       "     'lemma': '어',\n",
       "     'position': 1520.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0460888},\n",
       "    {'id': 25.0,\n",
       "     'lemma': '오',\n",
       "     'position': 1524.0,\n",
       "     'type': 'VX',\n",
       "     'weight': 0.083447},\n",
       "    {'id': 26.0,\n",
       "     'lemma': '았',\n",
       "     'position': 1524.0,\n",
       "     'type': 'EP',\n",
       "     'weight': 0.083447},\n",
       "    {'id': 27.0,\n",
       "     'lemma': '다',\n",
       "     'position': 1527.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0906551},\n",
       "    {'id': 28.0,\n",
       "     'lemma': '.',\n",
       "     'position': 1530.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': ' 노양호 여성가족국장도 고양지역 발전을 위해 40년 넘게 예산법무과 등 주요부서에서 활약해 왔다.',\n",
       "   'word': [{'begin': 0.0, 'end': 0.0, 'id': 0.0, 'text': '노양호', 'type': ''},\n",
       "    {'begin': 1.0, 'end': 4.0, 'id': 1.0, 'text': '여성가족국장도', 'type': ''},\n",
       "    {'begin': 5.0, 'end': 6.0, 'id': 2.0, 'text': '고양지역', 'type': ''},\n",
       "    {'begin': 7.0, 'end': 8.0, 'id': 3.0, 'text': '발전을', 'type': ''},\n",
       "    {'begin': 9.0, 'end': 10.0, 'id': 4.0, 'text': '위해', 'type': ''},\n",
       "    {'begin': 11.0, 'end': 12.0, 'id': 5.0, 'text': '40년', 'type': ''},\n",
       "    {'begin': 13.0, 'end': 14.0, 'id': 6.0, 'text': '넘게', 'type': ''},\n",
       "    {'begin': 15.0, 'end': 17.0, 'id': 7.0, 'text': '예산법무과', 'type': ''},\n",
       "    {'begin': 18.0, 'end': 18.0, 'id': 8.0, 'text': '등', 'type': ''},\n",
       "    {'begin': 19.0, 'end': 21.0, 'id': 9.0, 'text': '주요부서에서', 'type': ''},\n",
       "    {'begin': 22.0, 'end': 24.0, 'id': 10.0, 'text': '활약해', 'type': ''},\n",
       "    {'begin': 25.0, 'end': 28.0, 'id': 11.0, 'text': '왔다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 1.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 3.0,\n",
       "     'id': 0.0,\n",
       "     'text': '교육지원과장',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.508763},\n",
       "    {'begin': 7.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 7.0,\n",
       "     'id': 1.0,\n",
       "     'text': '고양',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.496913},\n",
       "    {'begin': 9.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 9.0,\n",
       "     'id': 2.0,\n",
       "     'text': '학생',\n",
       "     'type': 'CV_OCCUPATION',\n",
       "     'weight': 0.650918}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 1533.0,\n",
       "     'scode': '00',\n",
       "     'text': '특히',\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 1540.0,\n",
       "     'scode': '00',\n",
       "     'text': '교육',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 1546.0,\n",
       "     'scode': '02',\n",
       "     'text': '지원',\n",
       "     'type': 'NNG',\n",
       "     'weight': 6.0},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 1552.0,\n",
       "     'scode': '07',\n",
       "     'text': '과장',\n",
       "     'type': 'NNG',\n",
       "     'weight': 5.23077},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 1559.0,\n",
       "     'scode': '01',\n",
       "     'text': '시절',\n",
       "     'type': 'NNG',\n",
       "     'weight': 6.2},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 5.0,\n",
       "     'position': 1565.0,\n",
       "     'scode': '00',\n",
       "     'text': '에',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 6.0,\n",
       "     'position': 1568.0,\n",
       "     'scode': '00',\n",
       "     'text': '는',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 7.0,\n",
       "     'position': 1572.0,\n",
       "     'scode': '06',\n",
       "     'text': '고양',\n",
       "     'type': 'NNP',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 8.0,\n",
       "     'position': 1578.0,\n",
       "     'scode': '03',\n",
       "     'text': '지역',\n",
       "     'type': 'NNG',\n",
       "     'weight': 13.8},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 9.0,\n",
       "     'position': 1585.0,\n",
       "     'scode': '00',\n",
       "     'text': '학생',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 10.0,\n",
       "     'position': 1591.0,\n",
       "     'scode': '09',\n",
       "     'text': '들',\n",
       "     'type': 'XSN',\n",
       "     'weight': 7.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 11.0,\n",
       "     'position': 1594.0,\n",
       "     'scode': '00',\n",
       "     'text': '의',\n",
       "     'type': 'JKG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 12.0,\n",
       "     'position': 1598.0,\n",
       "     'scode': '00',\n",
       "     'text': '교육',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 13.0,\n",
       "     'position': 1604.0,\n",
       "     'scode': '02',\n",
       "     'text': '환경',\n",
       "     'type': 'NNG',\n",
       "     'weight': 10.8},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 14.0,\n",
       "     'position': 1611.0,\n",
       "     'scode': '01',\n",
       "     'text': '개선',\n",
       "     'type': 'NNG',\n",
       "     'weight': 9.8},\n",
       "    {'begin': 15.0,\n",
       "     'end': 15.0,\n",
       "     'id': 15.0,\n",
       "     'position': 1617.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 16.0,\n",
       "     'position': 1621.0,\n",
       "     'scode': '01',\n",
       "     'text': '위하',\n",
       "     'type': 'VV',\n",
       "     'weight': 11.0},\n",
       "    {'begin': 17.0,\n",
       "     'end': 17.0,\n",
       "     'id': 17.0,\n",
       "     'position': 1624.0,\n",
       "     'scode': '00',\n",
       "     'text': '어',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 18.0,\n",
       "     'end': 18.0,\n",
       "     'id': 18.0,\n",
       "     'position': 1628.0,\n",
       "     'scode': '01',\n",
       "     'text': '노력',\n",
       "     'type': 'NNG',\n",
       "     'weight': 7.6},\n",
       "    {'begin': 19.0,\n",
       "     'end': 19.0,\n",
       "     'id': 19.0,\n",
       "     'position': 1634.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 20.0,\n",
       "     'position': 1638.0,\n",
       "     'scode': '00',\n",
       "     'text': '아끼',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 21.0,\n",
       "     'position': 1644.0,\n",
       "     'scode': '00',\n",
       "     'text': '지',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 22.0,\n",
       "     'end': 22.0,\n",
       "     'id': 22.0,\n",
       "     'position': 1648.0,\n",
       "     'scode': '00',\n",
       "     'text': '않',\n",
       "     'type': 'VX',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 23.0,\n",
       "     'end': 23.0,\n",
       "     'id': 23.0,\n",
       "     'position': 1651.0,\n",
       "     'scode': '00',\n",
       "     'text': '았',\n",
       "     'type': 'EP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 24.0,\n",
       "     'end': 24.0,\n",
       "     'id': 24.0,\n",
       "     'position': 1654.0,\n",
       "     'scode': '00',\n",
       "     'text': '다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 25.0,\n",
       "     'end': 25.0,\n",
       "     'id': 25.0,\n",
       "     'position': 1657.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 7.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'AP',\n",
       "     'mod': [],\n",
       "     'text': '특히',\n",
       "     'weight': 0.628373},\n",
       "    {'head': 2.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '교육지원과장',\n",
       "     'weight': 0.592826},\n",
       "    {'head': 7.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [1.0],\n",
       "     'text': '시절에는',\n",
       "     'weight': 0.53014},\n",
       "    {'head': 4.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '고양지역',\n",
       "     'weight': 0.448153},\n",
       "    {'head': 6.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'NP_MOD',\n",
       "     'mod': [3.0],\n",
       "     'text': '학생들의',\n",
       "     'weight': 0.656003},\n",
       "    {'head': 6.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '교육환경',\n",
       "     'weight': 0.586248},\n",
       "    {'head': 7.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [4.0, 5.0],\n",
       "     'text': '개선을',\n",
       "     'weight': 0.652301},\n",
       "    {'head': 9.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [0.0, 2.0, 6.0],\n",
       "     'text': '위해',\n",
       "     'weight': 0.760105},\n",
       "    {'head': 9.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [],\n",
       "     'text': '노력을',\n",
       "     'weight': 0.655741},\n",
       "    {'head': 10.0,\n",
       "     'id': 9.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [7.0, 8.0],\n",
       "     'text': '아끼지',\n",
       "     'weight': 0.670569},\n",
       "    {'head': -1.0,\n",
       "     'id': 10.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [9.0],\n",
       "     'text': '않았다.',\n",
       "     'weight': 0.00581716}],\n",
       "   'id': 10.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '특히',\n",
       "     'position': 1533.0,\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0875818},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '교육',\n",
       "     'position': 1540.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0855396},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '지원',\n",
       "     'position': 1546.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0898435},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '과장',\n",
       "     'position': 1552.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0356463},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '시절',\n",
       "     'position': 1559.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0940224},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '에',\n",
       "     'position': 1565.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0720916},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '는',\n",
       "     'position': 1568.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.134751},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '고양',\n",
       "     'position': 1572.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0642053},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '지역',\n",
       "     'position': 1578.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0648163},\n",
       "    {'id': 9.0,\n",
       "     'lemma': '학생',\n",
       "     'position': 1585.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.107385},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '들',\n",
       "     'position': 1591.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0838698},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '의',\n",
       "     'position': 1594.0,\n",
       "     'type': 'JKG',\n",
       "     'weight': 0.0934142},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '교육',\n",
       "     'position': 1598.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0871301},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '환경',\n",
       "     'position': 1604.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0440539},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '개선',\n",
       "     'position': 1611.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.108937},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '을',\n",
       "     'position': 1617.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.093356},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '위하',\n",
       "     'position': 1621.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.101799},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '어',\n",
       "     'position': 1624.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.083466},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '노력',\n",
       "     'position': 1628.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0857289},\n",
       "    {'id': 19.0,\n",
       "     'lemma': '을',\n",
       "     'position': 1634.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0891093},\n",
       "    {'id': 20.0,\n",
       "     'lemma': '아끼',\n",
       "     'position': 1638.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0425844},\n",
       "    {'id': 21.0,\n",
       "     'lemma': '지',\n",
       "     'position': 1644.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.1324},\n",
       "    {'id': 22.0,\n",
       "     'lemma': '않',\n",
       "     'position': 1648.0,\n",
       "     'type': 'VX',\n",
       "     'weight': 0.117938},\n",
       "    {'id': 23.0,\n",
       "     'lemma': '았',\n",
       "     'position': 1651.0,\n",
       "     'type': 'EP',\n",
       "     'weight': 0.0689724},\n",
       "    {'id': 24.0,\n",
       "     'lemma': '다',\n",
       "     'position': 1654.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0735122},\n",
       "    {'id': 25.0,\n",
       "     'lemma': '.',\n",
       "     'position': 1657.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': '  특히 교육지원과장 시절에는 고양지역 학생들의 교육환경 개선을 위해 노력을 아끼지 않았다.',\n",
       "   'word': [{'begin': 0.0, 'end': 0.0, 'id': 0.0, 'text': '특히', 'type': ''},\n",
       "    {'begin': 1.0, 'end': 3.0, 'id': 1.0, 'text': '교육지원과장', 'type': ''},\n",
       "    {'begin': 4.0, 'end': 6.0, 'id': 2.0, 'text': '시절에는', 'type': ''},\n",
       "    {'begin': 7.0, 'end': 8.0, 'id': 3.0, 'text': '고양지역', 'type': ''},\n",
       "    {'begin': 9.0, 'end': 11.0, 'id': 4.0, 'text': '학생들의', 'type': ''},\n",
       "    {'begin': 12.0, 'end': 13.0, 'id': 5.0, 'text': '교육환경', 'type': ''},\n",
       "    {'begin': 14.0, 'end': 15.0, 'id': 6.0, 'text': '개선을', 'type': ''},\n",
       "    {'begin': 16.0, 'end': 17.0, 'id': 7.0, 'text': '위해', 'type': ''},\n",
       "    {'begin': 18.0, 'end': 19.0, 'id': 8.0, 'text': '노력을', 'type': ''},\n",
       "    {'begin': 20.0, 'end': 21.0, 'id': 9.0, 'text': '아끼지', 'type': ''},\n",
       "    {'begin': 22.0, 'end': 25.0, 'id': 10.0, 'text': '않았다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 2.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 3.0,\n",
       "     'id': 0.0,\n",
       "     'text': '전문가',\n",
       "     'type': 'CV_OCCUPATION',\n",
       "     'weight': 0.69013},\n",
       "    {'begin': 6.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 6.0,\n",
       "     'id': 1.0,\n",
       "     'text': '정종현',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.7836},\n",
       "    {'begin': 7.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 9.0,\n",
       "     'id': 2.0,\n",
       "     'text': '농업기술센터',\n",
       "     'type': 'OGG_POLITICS',\n",
       "     'weight': 0.931462},\n",
       "    {'begin': 12.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 12.0,\n",
       "     'id': 3.0,\n",
       "     'text': '고양',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.504681}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 1659.0,\n",
       "     'scode': '00',\n",
       "     'text': '농업',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 1666.0,\n",
       "     'scode': '00',\n",
       "     'text': '분야',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 2.0,\n",
       "     'end': 3.0,\n",
       "     'id': 2.0,\n",
       "     'position': 1673.0,\n",
       "     'scode': '00',\n",
       "     'text': '전문가',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 3.0,\n",
       "     'position': 1682.0,\n",
       "     'scode': '01',\n",
       "     'text': '이',\n",
       "     'type': 'VCP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 4.0,\n",
       "     'position': 1682.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 5.0,\n",
       "     'position': 1686.0,\n",
       "     'scode': '00',\n",
       "     'text': '정종현',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 7.0,\n",
       "     'end': 8.0,\n",
       "     'id': 6.0,\n",
       "     'position': 1696.0,\n",
       "     'scode': '00',\n",
       "     'text': '농업기술',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 7.0,\n",
       "     'position': 1708.0,\n",
       "     'scode': '02',\n",
       "     'text': '센터',\n",
       "     'type': 'NNG',\n",
       "     'weight': 8.0},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 8.0,\n",
       "     'position': 1714.0,\n",
       "     'scode': '08',\n",
       "     'text': '소장',\n",
       "     'type': 'NNG',\n",
       "     'weight': 4.33333},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 9.0,\n",
       "     'position': 1720.0,\n",
       "     'scode': '00',\n",
       "     'text': '도',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 10.0,\n",
       "     'position': 1724.0,\n",
       "     'scode': '06',\n",
       "     'text': '고양',\n",
       "     'type': 'NNP',\n",
       "     'weight': 4.0},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 11.0,\n",
       "     'position': 1730.0,\n",
       "     'scode': '03',\n",
       "     'text': '지역',\n",
       "     'type': 'NNG',\n",
       "     'weight': 11.6},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 12.0,\n",
       "     'position': 1736.0,\n",
       "     'scode': '00',\n",
       "     'text': '의',\n",
       "     'type': 'JKG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 15.0,\n",
       "     'end': 15.0,\n",
       "     'id': 13.0,\n",
       "     'position': 1740.0,\n",
       "     'scode': '00',\n",
       "     'text': '농업',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 14.0,\n",
       "     'position': 1746.0,\n",
       "     'scode': '00',\n",
       "     'text': '이',\n",
       "     'type': 'JKS',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 17.0,\n",
       "     'end': 19.0,\n",
       "     'id': 15.0,\n",
       "     'position': 1750.0,\n",
       "     'scode': '00',\n",
       "     'text': '활성화되',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 16.0,\n",
       "     'position': 1762.0,\n",
       "     'scode': '00',\n",
       "     'text': '기',\n",
       "     'type': 'ETN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 17.0,\n",
       "     'position': 1765.0,\n",
       "     'scode': '00',\n",
       "     'text': '까지',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 22.0,\n",
       "     'end': 22.0,\n",
       "     'id': 18.0,\n",
       "     'position': 1772.0,\n",
       "     'scode': '00',\n",
       "     'text': '많',\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 23.0,\n",
       "     'end': 23.0,\n",
       "     'id': 19.0,\n",
       "     'position': 1775.0,\n",
       "     'scode': '00',\n",
       "     'text': '은',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 24.0,\n",
       "     'end': 24.0,\n",
       "     'id': 20.0,\n",
       "     'position': 1779.0,\n",
       "     'scode': '01',\n",
       "     'text': '자취',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.2},\n",
       "    {'begin': 25.0,\n",
       "     'end': 25.0,\n",
       "     'id': 21.0,\n",
       "     'position': 1785.0,\n",
       "     'scode': '00',\n",
       "     'text': '를',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 26.0,\n",
       "     'end': 26.0,\n",
       "     'id': 22.0,\n",
       "     'position': 1789.0,\n",
       "     'scode': '00',\n",
       "     'text': '남기',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 27.0,\n",
       "     'end': 27.0,\n",
       "     'id': 23.0,\n",
       "     'position': 1792.0,\n",
       "     'scode': '00',\n",
       "     'text': '었',\n",
       "     'type': 'EP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 28.0,\n",
       "     'end': 28.0,\n",
       "     'id': 24.0,\n",
       "     'position': 1795.0,\n",
       "     'scode': '00',\n",
       "     'text': '다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 29.0,\n",
       "     'end': 29.0,\n",
       "     'id': 25.0,\n",
       "     'position': 1798.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 1.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '농업',\n",
       "     'weight': 0.74298},\n",
       "    {'head': 2.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [0.0],\n",
       "     'text': '분야',\n",
       "     'weight': 0.517246},\n",
       "    {'head': 4.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'VNP_MOD',\n",
       "     'mod': [1.0],\n",
       "     'text': '전문가인',\n",
       "     'weight': 0.68837},\n",
       "    {'head': 4.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '정종현',\n",
       "     'weight': 0.608095},\n",
       "    {'head': 7.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [2.0, 3.0],\n",
       "     'text': '농업기술센터소장도',\n",
       "     'weight': 0.411318},\n",
       "    {'head': 6.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'NP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '고양지역의',\n",
       "     'weight': 0.737632},\n",
       "    {'head': 7.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [5.0],\n",
       "     'text': '농업이',\n",
       "     'weight': 0.580365},\n",
       "    {'head': 10.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [4.0, 6.0],\n",
       "     'text': '활성화되기까지',\n",
       "     'weight': 0.0421968},\n",
       "    {'head': 9.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '많은',\n",
       "     'weight': 0.678651},\n",
       "    {'head': 10.0,\n",
       "     'id': 9.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [8.0],\n",
       "     'text': '자취를',\n",
       "     'weight': 0.708052},\n",
       "    {'head': -1.0,\n",
       "     'id': 10.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [7.0, 9.0],\n",
       "     'text': '남겼다.',\n",
       "     'weight': 0.000450091}],\n",
       "   'id': 11.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '농업',\n",
       "     'position': 1659.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.10922},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '분야',\n",
       "     'position': 1666.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.071304},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '전문',\n",
       "     'position': 1673.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.173507},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '가',\n",
       "     'position': 1679.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.173507},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '이',\n",
       "     'position': 1682.0,\n",
       "     'type': 'VCP',\n",
       "     'weight': 0.0547664},\n",
       "    {'id': 5.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 1682.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0547664},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '정종현',\n",
       "     'position': 1686.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.12416},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '농업',\n",
       "     'position': 1696.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0952179},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '기술',\n",
       "     'position': 1702.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0412843},\n",
       "    {'id': 9.0,\n",
       "     'lemma': '센터',\n",
       "     'position': 1708.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0429968},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '소장',\n",
       "     'position': 1714.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0323335},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '도',\n",
       "     'position': 1720.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.114431},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '고양',\n",
       "     'position': 1724.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0588187},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '지역',\n",
       "     'position': 1730.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0845331},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '의',\n",
       "     'position': 1736.0,\n",
       "     'type': 'JKG',\n",
       "     'weight': 0.0868864},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '농업',\n",
       "     'position': 1740.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.13515},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '이',\n",
       "     'position': 1746.0,\n",
       "     'type': 'JKS',\n",
       "     'weight': 0.0564915},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '활성',\n",
       "     'position': 1750.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0692608},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '화',\n",
       "     'position': 1756.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0692608},\n",
       "    {'id': 19.0,\n",
       "     'lemma': '되',\n",
       "     'position': 1759.0,\n",
       "     'type': 'XSV',\n",
       "     'weight': 0.0692608},\n",
       "    {'id': 20.0,\n",
       "     'lemma': '기',\n",
       "     'position': 1762.0,\n",
       "     'type': 'ETN',\n",
       "     'weight': 0.0674635},\n",
       "    {'id': 21.0,\n",
       "     'lemma': '까지',\n",
       "     'position': 1765.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.0844549},\n",
       "    {'id': 22.0,\n",
       "     'lemma': '많',\n",
       "     'position': 1772.0,\n",
       "     'type': 'VA',\n",
       "     'weight': 0.150679},\n",
       "    {'id': 23.0,\n",
       "     'lemma': '은',\n",
       "     'position': 1775.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0931828},\n",
       "    {'id': 24.0,\n",
       "     'lemma': '자취',\n",
       "     'position': 1779.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.078162},\n",
       "    {'id': 25.0,\n",
       "     'lemma': '를',\n",
       "     'position': 1785.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.112802},\n",
       "    {'id': 26.0,\n",
       "     'lemma': '남기',\n",
       "     'position': 1789.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0571381},\n",
       "    {'id': 27.0,\n",
       "     'lemma': '었',\n",
       "     'position': 1792.0,\n",
       "     'type': 'EP',\n",
       "     'weight': 0.0405717},\n",
       "    {'id': 28.0,\n",
       "     'lemma': '다',\n",
       "     'position': 1795.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0731151},\n",
       "    {'id': 29.0,\n",
       "     'lemma': '.',\n",
       "     'position': 1798.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': ' 농업 분야 전문가인 정종현 농업기술센터소장도 고양지역의 농업이 활성화되기까지 많은 자취를 남겼다.',\n",
       "   'word': [{'begin': 0.0, 'end': 0.0, 'id': 0.0, 'text': '농업', 'type': ''},\n",
       "    {'begin': 1.0, 'end': 1.0, 'id': 1.0, 'text': '분야', 'type': ''},\n",
       "    {'begin': 2.0, 'end': 5.0, 'id': 2.0, 'text': '전문가인', 'type': ''},\n",
       "    {'begin': 6.0, 'end': 6.0, 'id': 3.0, 'text': '정종현', 'type': ''},\n",
       "    {'begin': 7.0, 'end': 11.0, 'id': 4.0, 'text': '농업기술센터소장도', 'type': ''},\n",
       "    {'begin': 12.0, 'end': 14.0, 'id': 5.0, 'text': '고양지역의', 'type': ''},\n",
       "    {'begin': 15.0, 'end': 16.0, 'id': 6.0, 'text': '농업이', 'type': ''},\n",
       "    {'begin': 17.0, 'end': 21.0, 'id': 7.0, 'text': '활성화되기까지', 'type': ''},\n",
       "    {'begin': 22.0, 'end': 23.0, 'id': 8.0, 'text': '많은', 'type': ''},\n",
       "    {'begin': 24.0, 'end': 25.0, 'id': 9.0, 'text': '자취를', 'type': ''},\n",
       "    {'begin': 26.0, 'end': 29.0, 'id': 10.0, 'text': '남겼다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 0.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 1.0,\n",
       "     'id': 0.0,\n",
       "     'text': '2016년',\n",
       "     'type': 'DT_YEAR',\n",
       "     'weight': 0.834758},\n",
       "    {'begin': 4.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 5.0,\n",
       "     'id': 1.0,\n",
       "     'text': '녹조근정훈장',\n",
       "     'type': 'CV_PRIZE',\n",
       "     'weight': 0.573311}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 1801.0,\n",
       "     'scode': '00',\n",
       "     'text': '2016',\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 1805.0,\n",
       "     'scode': '02',\n",
       "     'text': '년',\n",
       "     'type': 'NNB',\n",
       "     'weight': 2.2},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 1808.0,\n",
       "     'scode': '00',\n",
       "     'text': '에',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 1811.0,\n",
       "     'scode': '00',\n",
       "     'text': '는',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 1815.0,\n",
       "     'scode': '00',\n",
       "     'text': '녹조근정',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 5.0,\n",
       "     'position': 1827.0,\n",
       "     'scode': '05',\n",
       "     'text': '훈장',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.05394},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 6.0,\n",
       "     'position': 1834.0,\n",
       "     'scode': '03',\n",
       "     'text': '영예',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.2},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 7.0,\n",
       "     'position': 1840.0,\n",
       "     'scode': '00',\n",
       "     'text': '를',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 8.0,\n",
       "     'position': 1844.0,\n",
       "     'scode': '01',\n",
       "     'text': '받',\n",
       "     'type': 'VV',\n",
       "     'weight': 4.4},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 9.0,\n",
       "     'position': 1847.0,\n",
       "     'scode': '00',\n",
       "     'text': '기',\n",
       "     'type': 'ETN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 10.0,\n",
       "     'position': 1850.0,\n",
       "     'scode': '00',\n",
       "     'text': '도',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 11.0,\n",
       "     'position': 1854.0,\n",
       "     'scode': '01',\n",
       "     'text': '하',\n",
       "     'type': 'VX',\n",
       "     'weight': 3.2},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 12.0,\n",
       "     'position': 1854.0,\n",
       "     'scode': '00',\n",
       "     'text': '었',\n",
       "     'type': 'EP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 13.0,\n",
       "     'position': 1857.0,\n",
       "     'scode': '00',\n",
       "     'text': '다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 14.0,\n",
       "     'position': 1860.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 3.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '2016년에는',\n",
       "     'weight': 0.813216},\n",
       "    {'head': 2.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '녹조근정훈장',\n",
       "     'weight': 0.370594},\n",
       "    {'head': 3.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [1.0],\n",
       "     'text': '영예를',\n",
       "     'weight': 0.630155},\n",
       "    {'head': 4.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [0.0, 2.0],\n",
       "     'text': '받기도',\n",
       "     'weight': 0.513336},\n",
       "    {'head': -1.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [3.0],\n",
       "     'text': '했다.',\n",
       "     'weight': 0.0765187}],\n",
       "   'id': 12.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '2016',\n",
       "     'position': 1801.0,\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '년',\n",
       "     'position': 1805.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.0682491},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '에',\n",
       "     'position': 1808.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0721319},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '는',\n",
       "     'position': 1811.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.133756},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '녹조근정',\n",
       "     'position': 1815.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0175061},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '훈장',\n",
       "     'position': 1827.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0316799},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '영예',\n",
       "     'position': 1834.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.054301},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '를',\n",
       "     'position': 1840.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.123072},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '받',\n",
       "     'position': 1844.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.156233},\n",
       "    {'id': 9.0,\n",
       "     'lemma': '기',\n",
       "     'position': 1847.0,\n",
       "     'type': 'ETN',\n",
       "     'weight': 0.193035},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '도',\n",
       "     'position': 1850.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.119307},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '하',\n",
       "     'position': 1854.0,\n",
       "     'type': 'VX',\n",
       "     'weight': 0.0681144},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '었',\n",
       "     'position': 1854.0,\n",
       "     'type': 'EP',\n",
       "     'weight': 0.0681144},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '다',\n",
       "     'position': 1857.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.104497},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '.',\n",
       "     'position': 1860.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': '  2016년에는 녹조근정훈장 영예를 받기도 했다.',\n",
       "   'word': [{'begin': 0.0,\n",
       "     'end': 3.0,\n",
       "     'id': 0.0,\n",
       "     'text': '2016년에는',\n",
       "     'type': ''},\n",
       "    {'begin': 4.0, 'end': 5.0, 'id': 1.0, 'text': '녹조근정훈장', 'type': ''},\n",
       "    {'begin': 6.0, 'end': 7.0, 'id': 2.0, 'text': '영예를', 'type': ''},\n",
       "    {'begin': 8.0, 'end': 10.0, 'id': 3.0, 'text': '받기도', 'type': ''},\n",
       "    {'begin': 11.0, 'end': 14.0, 'id': 4.0, 'text': '했다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 0.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'text': '신승일',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.281364},\n",
       "    {'begin': 1.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 4.0,\n",
       "     'id': 1.0,\n",
       "     'text': '시민안전주택국장',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.291359}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 1862.0,\n",
       "     'scode': '00',\n",
       "     'text': '신승일',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 1872.0,\n",
       "     'scode': '00',\n",
       "     'text': '시민',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 1878.0,\n",
       "     'scode': '03',\n",
       "     'text': '안전',\n",
       "     'type': 'NNG',\n",
       "     'weight': 5.0},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 1884.0,\n",
       "     'scode': '00',\n",
       "     'text': '주택',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 1890.0,\n",
       "     'scode': '01',\n",
       "     'text': '국장',\n",
       "     'type': 'NNG',\n",
       "     'weight': 7.0},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 5.0,\n",
       "     'position': 1896.0,\n",
       "     'scode': '00',\n",
       "     'text': '도',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 6.0,\n",
       "     'position': 1900.0,\n",
       "     'scode': '05',\n",
       "     'text': '이',\n",
       "     'type': 'NP',\n",
       "     'weight': 10.6},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 7.0,\n",
       "     'position': 1903.0,\n",
       "     'scode': '09',\n",
       "     'text': '들',\n",
       "     'type': 'XSN',\n",
       "     'weight': 7.0},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 8.0,\n",
       "     'position': 1906.0,\n",
       "     'scode': '00',\n",
       "     'text': '과',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 9.0,\n",
       "     'position': 1910.0,\n",
       "     'scode': '00',\n",
       "     'text': '함께',\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 10.0,\n",
       "     'position': 1917.0,\n",
       "     'scode': '04',\n",
       "     'text': '공로',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 11.0,\n",
       "     'position': 1923.0,\n",
       "     'scode': '08',\n",
       "     'text': '연수',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.5},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 12.0,\n",
       "     'position': 1929.0,\n",
       "     'scode': '00',\n",
       "     'text': '에',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 13.0,\n",
       "     'position': 1933.0,\n",
       "     'scode': '01',\n",
       "     'text': '들어가',\n",
       "     'type': 'VV',\n",
       "     'weight': 3.2},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 14.0,\n",
       "     'position': 1939.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 15.0,\n",
       "     'end': 15.0,\n",
       "     'id': 15.0,\n",
       "     'position': 1945.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 1.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '신승일',\n",
       "     'weight': 0.578301},\n",
       "    {'head': 5.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [0.0],\n",
       "     'text': '시민안전주택국장도',\n",
       "     'weight': 0.703215},\n",
       "    {'head': 3.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '이들과',\n",
       "     'weight': 0.451876},\n",
       "    {'head': 5.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'AP',\n",
       "     'mod': [2.0],\n",
       "     'text': '함께',\n",
       "     'weight': 0.736846},\n",
       "    {'head': 5.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '공로연수에',\n",
       "     'weight': 0.710804},\n",
       "    {'head': -1.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [1.0, 3.0, 4.0],\n",
       "     'text': '들어간다.',\n",
       "     'weight': 0.0833014}],\n",
       "   'id': 13.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '신승일',\n",
       "     'position': 1862.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.033786},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '시민',\n",
       "     'position': 1872.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.104202},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '안전',\n",
       "     'position': 1878.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0467729},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '주택',\n",
       "     'position': 1884.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0829355},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '국장',\n",
       "     'position': 1890.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0399463},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '도',\n",
       "     'position': 1896.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.105721},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '이',\n",
       "     'position': 1900.0,\n",
       "     'type': 'NP',\n",
       "     'weight': 0.0994035},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '들',\n",
       "     'position': 1903.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0831824},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '과',\n",
       "     'position': 1906.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.172001},\n",
       "    {'id': 9.0,\n",
       "     'lemma': '함께',\n",
       "     'position': 1910.0,\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.112434},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '공로',\n",
       "     'position': 1917.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0608989},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '연수',\n",
       "     'position': 1923.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0626452},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '에',\n",
       "     'position': 1929.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.102575},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '들어가',\n",
       "     'position': 1933.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.107423},\n",
       "    {'id': 14.0,\n",
       "     'lemma': 'ㄴ다',\n",
       "     'position': 1939.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0500814},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '.',\n",
       "     'position': 1945.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': ' 신승일 시민안전주택국장도 이들과 함께 공로연수에 들어간다.',\n",
       "   'word': [{'begin': 0.0, 'end': 0.0, 'id': 0.0, 'text': '신승일', 'type': ''},\n",
       "    {'begin': 1.0, 'end': 5.0, 'id': 1.0, 'text': '시민안전주택국장도', 'type': ''},\n",
       "    {'begin': 6.0, 'end': 8.0, 'id': 2.0, 'text': '이들과', 'type': ''},\n",
       "    {'begin': 9.0, 'end': 9.0, 'id': 3.0, 'text': '함께', 'type': ''},\n",
       "    {'begin': 10.0, 'end': 12.0, 'id': 4.0, 'text': '공로연수에', 'type': ''},\n",
       "    {'begin': 13.0, 'end': 15.0, 'id': 5.0, 'text': '들어간다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 0.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'text': '신',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.23422},\n",
       "    {'begin': 1.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'text': '국장',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.472096},\n",
       "    {'begin': 3.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 4.0,\n",
       "     'id': 2.0,\n",
       "     'text': '경기북부',\n",
       "     'type': 'LCP_PROVINCE',\n",
       "     'weight': 0.218292},\n",
       "    {'begin': 10.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 10.0,\n",
       "     'id': 3.0,\n",
       "     'text': '고양시',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.247823}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 1948.0,\n",
       "     'scode': '03',\n",
       "     'text': '신',\n",
       "     'type': 'NNP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 1952.0,\n",
       "     'scode': '01',\n",
       "     'text': '국장',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.5},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 1958.0,\n",
       "     'scode': '00',\n",
       "     'text': '은',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 1962.0,\n",
       "     'scode': '02',\n",
       "     'text': '경기',\n",
       "     'type': 'NNP',\n",
       "     'weight': 6.2},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 1968.0,\n",
       "     'scode': '01',\n",
       "     'text': '북부',\n",
       "     'type': 'NNG',\n",
       "     'weight': 6.4},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 5.0,\n",
       "     'position': 1975.0,\n",
       "     'scode': '01',\n",
       "     'text': '중심',\n",
       "     'type': 'NNG',\n",
       "     'weight': 11.8798},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 6.0,\n",
       "     'position': 1982.0,\n",
       "     'scode': '03',\n",
       "     'text': '도시',\n",
       "     'type': 'NNG',\n",
       "     'weight': 9.6},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 7.0,\n",
       "     'position': 1988.0,\n",
       "     'scode': '00',\n",
       "     'text': '가',\n",
       "     'type': 'JKC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 8.0,\n",
       "     'position': 1992.0,\n",
       "     'scode': '01',\n",
       "     'text': '되',\n",
       "     'type': 'VV',\n",
       "     'weight': 6.4},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 9.0,\n",
       "     'position': 1992.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 10.0,\n",
       "     'position': 1996.0,\n",
       "     'scode': '00',\n",
       "     'text': '고양시',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 11.0,\n",
       "     'position': 2005.0,\n",
       "     'scode': '00',\n",
       "     'text': '의',\n",
       "     'type': 'JKG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 12.0,\n",
       "     'position': 2009.0,\n",
       "     'scode': '02',\n",
       "     'text': '미래',\n",
       "     'type': 'NNG',\n",
       "     'weight': 4.0},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 13.0,\n",
       "     'position': 2015.0,\n",
       "     'scode': '02',\n",
       "     'text': '설계',\n",
       "     'type': 'NNG',\n",
       "     'weight': 5.2},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 14.0,\n",
       "     'position': 2021.0,\n",
       "     'scode': '00',\n",
       "     'text': '를',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 15.0,\n",
       "     'end': 16.0,\n",
       "     'id': 15.0,\n",
       "     'position': 2025.0,\n",
       "     'scode': '00',\n",
       "     'text': '담당하',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 17.0,\n",
       "     'end': 17.0,\n",
       "     'id': 16.0,\n",
       "     'position': 2031.0,\n",
       "     'scode': '00',\n",
       "     'text': '어',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 18.0,\n",
       "     'end': 18.0,\n",
       "     'id': 17.0,\n",
       "     'position': 2035.0,\n",
       "     'scode': '01',\n",
       "     'text': '오',\n",
       "     'type': 'VX',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 19.0,\n",
       "     'end': 19.0,\n",
       "     'id': 18.0,\n",
       "     'position': 2035.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 19.0,\n",
       "     'position': 2039.0,\n",
       "     'scode': '00',\n",
       "     'text': '일등',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 20.0,\n",
       "     'position': 2046.0,\n",
       "     'scode': '02',\n",
       "     'text': '공신',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.2},\n",
       "    {'begin': 22.0,\n",
       "     'end': 22.0,\n",
       "     'id': 21.0,\n",
       "     'position': 2053.0,\n",
       "     'scode': '00',\n",
       "     'text': '인물',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 23.0,\n",
       "     'end': 23.0,\n",
       "     'id': 22.0,\n",
       "     'position': 2059.0,\n",
       "     'scode': '01',\n",
       "     'text': '이',\n",
       "     'type': 'VCP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 24.0,\n",
       "     'end': 24.0,\n",
       "     'id': 23.0,\n",
       "     'position': 2062.0,\n",
       "     'scode': '00',\n",
       "     'text': '다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 25.0,\n",
       "     'end': 25.0,\n",
       "     'id': 24.0,\n",
       "     'position': 2065.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 1.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '신',\n",
       "     'weight': 0.627924},\n",
       "    {'head': 12.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [0.0],\n",
       "     'text': '국장은',\n",
       "     'weight': 0.867804},\n",
       "    {'head': 3.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '경기북부',\n",
       "     'weight': 0.0642474},\n",
       "    {'head': 4.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [2.0],\n",
       "     'text': '중심',\n",
       "     'weight': 0.40979},\n",
       "    {'head': 5.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'NP_CMP',\n",
       "     'mod': [3.0],\n",
       "     'text': '도시가',\n",
       "     'weight': 0.661033},\n",
       "    {'head': 7.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [4.0],\n",
       "     'text': '된',\n",
       "     'weight': 0.614366},\n",
       "    {'head': 7.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'NP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '고양시의',\n",
       "     'weight': 0.694219},\n",
       "    {'head': 8.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [5.0, 6.0],\n",
       "     'text': '미래설계를',\n",
       "     'weight': 0.771528},\n",
       "    {'head': 9.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [7.0],\n",
       "     'text': '담당해',\n",
       "     'weight': 0.633885},\n",
       "    {'head': 12.0,\n",
       "     'id': 9.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [8.0],\n",
       "     'text': '온',\n",
       "     'weight': 0.752335},\n",
       "    {'head': 11.0,\n",
       "     'id': 10.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '일등',\n",
       "     'weight': 0.57753},\n",
       "    {'head': 12.0,\n",
       "     'id': 11.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [10.0],\n",
       "     'text': '공신',\n",
       "     'weight': 0.643317},\n",
       "    {'head': -1.0,\n",
       "     'id': 12.0,\n",
       "     'label': 'VNP',\n",
       "     'mod': [1.0, 9.0, 11.0],\n",
       "     'text': '인물이다.',\n",
       "     'weight': 0.000444042}],\n",
       "   'id': 14.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '신',\n",
       "     'position': 1948.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0815232},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '국장',\n",
       "     'position': 1952.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.106204},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '은',\n",
       "     'position': 1958.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.0968925},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '경기',\n",
       "     'position': 1962.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0784235},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '북부',\n",
       "     'position': 1968.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0410873},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '중심',\n",
       "     'position': 1975.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.06304},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '도시',\n",
       "     'position': 1982.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.086578},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '가',\n",
       "     'position': 1988.0,\n",
       "     'type': 'JKC',\n",
       "     'weight': 0.11098},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '되',\n",
       "     'position': 1992.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.112208},\n",
       "    {'id': 9.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 1992.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.112208},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '고양시',\n",
       "     'position': 1996.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0710718},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '의',\n",
       "     'position': 2005.0,\n",
       "     'type': 'JKG',\n",
       "     'weight': 0.0854574},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '미래',\n",
       "     'position': 2009.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0948382},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '설계',\n",
       "     'position': 2015.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0556189},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '를',\n",
       "     'position': 2021.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.109847},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '담당',\n",
       "     'position': 2025.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0459287},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '하',\n",
       "     'position': 2031.0,\n",
       "     'type': 'XSV',\n",
       "     'weight': 0.0459287},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '어',\n",
       "     'position': 2031.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0510215},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '오',\n",
       "     'position': 2035.0,\n",
       "     'type': 'VX',\n",
       "     'weight': 0.0816808},\n",
       "    {'id': 19.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 2035.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0816808},\n",
       "    {'id': 20.0,\n",
       "     'lemma': '일등',\n",
       "     'position': 2039.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0832587},\n",
       "    {'id': 21.0,\n",
       "     'lemma': '공신',\n",
       "     'position': 2046.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0482498},\n",
       "    {'id': 22.0,\n",
       "     'lemma': '인물',\n",
       "     'position': 2053.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0992019},\n",
       "    {'id': 23.0,\n",
       "     'lemma': '이',\n",
       "     'position': 2059.0,\n",
       "     'type': 'VCP',\n",
       "     'weight': 0.0646724},\n",
       "    {'id': 24.0,\n",
       "     'lemma': '다',\n",
       "     'position': 2062.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0770232},\n",
       "    {'id': 25.0,\n",
       "     'lemma': '.',\n",
       "     'position': 2065.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': '  신 국장은 경기북부 중심 도시가 된 고양시의 미래설계를 담당해 온 일등 공신 인물이다.',\n",
       "   'word': [{'begin': 0.0, 'end': 0.0, 'id': 0.0, 'text': '신', 'type': ''},\n",
       "    {'begin': 1.0, 'end': 2.0, 'id': 1.0, 'text': '국장은', 'type': ''},\n",
       "    {'begin': 3.0, 'end': 4.0, 'id': 2.0, 'text': '경기북부', 'type': ''},\n",
       "    {'begin': 5.0, 'end': 5.0, 'id': 3.0, 'text': '중심', 'type': ''},\n",
       "    {'begin': 6.0, 'end': 7.0, 'id': 4.0, 'text': '도시가', 'type': ''},\n",
       "    {'begin': 8.0, 'end': 9.0, 'id': 5.0, 'text': '된', 'type': ''},\n",
       "    {'begin': 10.0, 'end': 11.0, 'id': 6.0, 'text': '고양시의', 'type': ''},\n",
       "    {'begin': 12.0, 'end': 14.0, 'id': 7.0, 'text': '미래설계를', 'type': ''},\n",
       "    {'begin': 15.0, 'end': 17.0, 'id': 8.0, 'text': '담당해', 'type': ''},\n",
       "    {'begin': 18.0, 'end': 19.0, 'id': 9.0, 'text': '온', 'type': ''},\n",
       "    {'begin': 20.0, 'end': 20.0, 'id': 10.0, 'text': '일등', 'type': ''},\n",
       "    {'begin': 21.0, 'end': 21.0, 'id': 11.0, 'text': '공신', 'type': ''},\n",
       "    {'begin': 22.0, 'end': 25.0, 'id': 12.0, 'text': '인물이다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 2.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 2.0,\n",
       "     'id': 0.0,\n",
       "     'text': '고양시',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.347989},\n",
       "    {'begin': 14.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 15.0,\n",
       "     'id': 1.0,\n",
       "     'text': '공직자',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.41833},\n",
       "    {'begin': 33.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 34.0,\n",
       "     'id': 2.0,\n",
       "     'text': '2011년',\n",
       "     'type': 'DT_YEAR',\n",
       "     'weight': 0.841129},\n",
       "    {'begin': 37.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 37.0,\n",
       "     'id': 3.0,\n",
       "     'text': '경희대',\n",
       "     'type': 'OGG_EDUCATION',\n",
       "     'weight': 0.466919},\n",
       "    {'begin': 39.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 40.0,\n",
       "     'id': 4.0,\n",
       "     'text': '경영학',\n",
       "     'type': 'FD_SOCIAL_SCIENCE',\n",
       "     'weight': 0.525991},\n",
       "    {'begin': 45.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 46.0,\n",
       "     'id': 5.0,\n",
       "     'text': '2014년',\n",
       "     'type': 'DT_YEAR',\n",
       "     'weight': 0.803659},\n",
       "    {'begin': 49.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 49.0,\n",
       "     'id': 6.0,\n",
       "     'text': '고려대',\n",
       "     'type': 'OGG_EDUCATION',\n",
       "     'weight': 0.379164},\n",
       "    {'begin': 51.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 53.0,\n",
       "     'id': 7.0,\n",
       "     'text': '건축공학과',\n",
       "     'type': 'FD_SCIENCE',\n",
       "     'weight': 0.368254},\n",
       "    {'begin': 54.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 54.0,\n",
       "     'id': 8.0,\n",
       "     'text': '석사',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.585266}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 2068.0,\n",
       "     'scode': '01',\n",
       "     'text': '그',\n",
       "     'type': 'MM',\n",
       "     'weight': 2.2},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 2071.0,\n",
       "     'scode': '01',\n",
       "     'text': '동안',\n",
       "     'type': 'NNG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 2078.0,\n",
       "     'scode': '00',\n",
       "     'text': '고양시',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 2088.0,\n",
       "     'scode': '01',\n",
       "     'text': '발전',\n",
       "     'type': 'NNG',\n",
       "     'weight': 5.36933},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 2094.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 5.0,\n",
       "     'position': 2098.0,\n",
       "     'scode': '01',\n",
       "     'text': '위하',\n",
       "     'type': 'VV',\n",
       "     'weight': 6.6},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 6.0,\n",
       "     'position': 2101.0,\n",
       "     'scode': '00',\n",
       "     'text': '어서',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 7.0,\n",
       "     'position': 2107.0,\n",
       "     'scode': '00',\n",
       "     'text': '는',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 8.0,\n",
       "     'position': 2111.0,\n",
       "     'scode': '05',\n",
       "     'text': '해당',\n",
       "     'type': 'NNG',\n",
       "     'weight': 4.4},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 9.0,\n",
       "     'position': 2118.0,\n",
       "     'scode': '02',\n",
       "     'text': '업무',\n",
       "     'type': 'NNG',\n",
       "     'weight': 7.6},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 10.0,\n",
       "     'position': 2124.0,\n",
       "     'scode': '00',\n",
       "     'text': '를',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 12.0,\n",
       "     'id': 11.0,\n",
       "     'position': 2128.0,\n",
       "     'scode': '00',\n",
       "     'text': '담당하',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 12.0,\n",
       "     'position': 2137.0,\n",
       "     'scode': '00',\n",
       "     'text': '는',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 14.0,\n",
       "     'end': 15.0,\n",
       "     'id': 13.0,\n",
       "     'position': 2141.0,\n",
       "     'scode': '00',\n",
       "     'text': '공직자',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 14.0,\n",
       "     'position': 2151.0,\n",
       "     'scode': '01',\n",
       "     'text': '역시',\n",
       "     'type': 'MAG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 17.0,\n",
       "     'end': 18.0,\n",
       "     'id': 15.0,\n",
       "     'position': 2158.0,\n",
       "     'scode': '00',\n",
       "     'text': '계속적',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 19.0,\n",
       "     'end': 19.0,\n",
       "     'id': 16.0,\n",
       "     'position': 2167.0,\n",
       "     'scode': '01',\n",
       "     'text': '이',\n",
       "     'type': 'VCP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 17.0,\n",
       "     'position': 2167.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 18.0,\n",
       "     'position': 2171.0,\n",
       "     'scode': '01',\n",
       "     'text': '발전',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.54924},\n",
       "    {'begin': 22.0,\n",
       "     'end': 22.0,\n",
       "     'id': 19.0,\n",
       "     'position': 2177.0,\n",
       "     'scode': '00',\n",
       "     'text': '이',\n",
       "     'type': 'JKS',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 23.0,\n",
       "     'end': 24.0,\n",
       "     'id': 20.0,\n",
       "     'position': 2181.0,\n",
       "     'scode': '00',\n",
       "     'text': '필요하',\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 25.0,\n",
       "     'end': 25.0,\n",
       "     'id': 21.0,\n",
       "     'position': 2190.0,\n",
       "     'scode': '00',\n",
       "     'text': '다고',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 26.0,\n",
       "     'end': 27.0,\n",
       "     'id': 22.0,\n",
       "     'position': 2197.0,\n",
       "     'scode': '00',\n",
       "     'text': '강조하',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 28.0,\n",
       "     'end': 28.0,\n",
       "     'id': 23.0,\n",
       "     'position': 2203.0,\n",
       "     'scode': '00',\n",
       "     'text': '어',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 29.0,\n",
       "     'end': 29.0,\n",
       "     'id': 24.0,\n",
       "     'position': 2207.0,\n",
       "     'scode': '01',\n",
       "     'text': '오',\n",
       "     'type': 'VX',\n",
       "     'weight': 2.0},\n",
       "    {'begin': 30.0,\n",
       "     'end': 30.0,\n",
       "     'id': 25.0,\n",
       "     'position': 2207.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 31.0,\n",
       "     'end': 31.0,\n",
       "     'id': 26.0,\n",
       "     'position': 2211.0,\n",
       "     'scode': '01',\n",
       "     'text': '그',\n",
       "     'type': 'NP',\n",
       "     'weight': 3.7},\n",
       "    {'begin': 32.0,\n",
       "     'end': 32.0,\n",
       "     'id': 27.0,\n",
       "     'position': 2214.0,\n",
       "     'scode': '00',\n",
       "     'text': '는',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 33.0,\n",
       "     'end': 33.0,\n",
       "     'id': 28.0,\n",
       "     'position': 2218.0,\n",
       "     'scode': '00',\n",
       "     'text': '2011',\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 34.0,\n",
       "     'end': 34.0,\n",
       "     'id': 29.0,\n",
       "     'position': 2222.0,\n",
       "     'scode': '02',\n",
       "     'text': '년',\n",
       "     'type': 'NNB',\n",
       "     'weight': 2.5},\n",
       "    {'begin': 35.0,\n",
       "     'end': 35.0,\n",
       "     'id': 30.0,\n",
       "     'position': 2225.0,\n",
       "     'scode': '00',\n",
       "     'text': '에',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 36.0,\n",
       "     'end': 36.0,\n",
       "     'id': 31.0,\n",
       "     'position': 2228.0,\n",
       "     'scode': '00',\n",
       "     'text': '는',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 37.0,\n",
       "     'end': 37.0,\n",
       "     'id': 32.0,\n",
       "     'position': 2232.0,\n",
       "     'scode': '00',\n",
       "     'text': '경희대',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 38.0,\n",
       "     'end': 38.0,\n",
       "     'id': 33.0,\n",
       "     'position': 2241.0,\n",
       "     'scode': '00',\n",
       "     'text': '에서',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 39.0,\n",
       "     'end': 40.0,\n",
       "     'id': 34.0,\n",
       "     'position': 2248.0,\n",
       "     'scode': '00',\n",
       "     'text': '경영학',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 41.0,\n",
       "     'end': 41.0,\n",
       "     'id': 35.0,\n",
       "     'position': 2257.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 42.0,\n",
       "     'end': 43.0,\n",
       "     'id': 36.0,\n",
       "     'position': 2261.0,\n",
       "     'scode': '01',\n",
       "     'text': '전공하',\n",
       "     'type': 'VV',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 44.0,\n",
       "     'end': 44.0,\n",
       "     'id': 37.0,\n",
       "     'position': 2270.0,\n",
       "     'scode': '00',\n",
       "     'text': '고',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 45.0,\n",
       "     'end': 45.0,\n",
       "     'id': 38.0,\n",
       "     'position': 2274.0,\n",
       "     'scode': '00',\n",
       "     'text': '2014',\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 46.0,\n",
       "     'end': 46.0,\n",
       "     'id': 39.0,\n",
       "     'position': 2278.0,\n",
       "     'scode': '02',\n",
       "     'text': '년',\n",
       "     'type': 'NNB',\n",
       "     'weight': 10.1},\n",
       "    {'begin': 47.0,\n",
       "     'end': 47.0,\n",
       "     'id': 40.0,\n",
       "     'position': 2281.0,\n",
       "     'scode': '00',\n",
       "     'text': '에',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 48.0,\n",
       "     'end': 48.0,\n",
       "     'id': 41.0,\n",
       "     'position': 2284.0,\n",
       "     'scode': '00',\n",
       "     'text': '는',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 49.0,\n",
       "     'end': 49.0,\n",
       "     'id': 42.0,\n",
       "     'position': 2288.0,\n",
       "     'scode': '00',\n",
       "     'text': '고려대',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 50.0,\n",
       "     'end': 50.0,\n",
       "     'id': 43.0,\n",
       "     'position': 2297.0,\n",
       "     'scode': '00',\n",
       "     'text': '에서',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 51.0,\n",
       "     'end': 52.0,\n",
       "     'id': 44.0,\n",
       "     'position': 2304.0,\n",
       "     'scode': '00',\n",
       "     'text': '건축공학',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 53.0,\n",
       "     'end': 53.0,\n",
       "     'id': 45.0,\n",
       "     'position': 2316.0,\n",
       "     'scode': '04',\n",
       "     'text': '과',\n",
       "     'type': 'NNG',\n",
       "     'weight': 8.5},\n",
       "    {'begin': 54.0,\n",
       "     'end': 55.0,\n",
       "     'id': 46.0,\n",
       "     'position': 2320.0,\n",
       "     'scode': '00',\n",
       "     'text': '석사과정',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 56.0,\n",
       "     'end': 56.0,\n",
       "     'id': 47.0,\n",
       "     'position': 2332.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 57.0,\n",
       "     'end': 57.0,\n",
       "     'id': 48.0,\n",
       "     'position': 2336.0,\n",
       "     'scode': '02',\n",
       "     'text': '마치',\n",
       "     'type': 'VV',\n",
       "     'weight': 5.2},\n",
       "    {'begin': 58.0,\n",
       "     'end': 58.0,\n",
       "     'id': 49.0,\n",
       "     'position': 2339.0,\n",
       "     'scode': '00',\n",
       "     'text': '었',\n",
       "     'type': 'EP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 59.0,\n",
       "     'end': 59.0,\n",
       "     'id': 50.0,\n",
       "     'position': 2342.0,\n",
       "     'scode': '00',\n",
       "     'text': '다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 60.0,\n",
       "     'end': 60.0,\n",
       "     'id': 51.0,\n",
       "     'position': 2345.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 3.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '그동안',\n",
       "     'weight': 0.106922},\n",
       "    {'head': 2.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '고양시',\n",
       "     'weight': 0.627105},\n",
       "    {'head': 3.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [1.0],\n",
       "     'text': '발전을',\n",
       "     'weight': 0.737102},\n",
       "    {'head': 12.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [0.0, 2.0],\n",
       "     'text': '위해서는',\n",
       "     'weight': 0.137175},\n",
       "    {'head': 5.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '해당',\n",
       "     'weight': 0.562477},\n",
       "    {'head': 6.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [4.0],\n",
       "     'text': '업무를',\n",
       "     'weight': 0.720044},\n",
       "    {'head': 7.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [5.0],\n",
       "     'text': '담당하는',\n",
       "     'weight': 0.501373},\n",
       "    {'head': 12.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [6.0],\n",
       "     'text': '공직자',\n",
       "     'weight': 0.185863},\n",
       "    {'head': 12.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'AP',\n",
       "     'mod': [],\n",
       "     'text': '역시',\n",
       "     'weight': 0.0845747},\n",
       "    {'head': 10.0,\n",
       "     'id': 9.0,\n",
       "     'label': 'VNP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '계속적인',\n",
       "     'weight': 0.640643},\n",
       "    {'head': 11.0,\n",
       "     'id': 10.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [9.0],\n",
       "     'text': '발전이',\n",
       "     'weight': 0.640842},\n",
       "    {'head': 12.0,\n",
       "     'id': 11.0,\n",
       "     'label': 'VP_CMP',\n",
       "     'mod': [10.0],\n",
       "     'text': '필요하다고',\n",
       "     'weight': 0.587666},\n",
       "    {'head': 13.0,\n",
       "     'id': 12.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [3.0, 7.0, 8.0, 11.0],\n",
       "     'text': '강조해',\n",
       "     'weight': 0.767518},\n",
       "    {'head': 14.0,\n",
       "     'id': 13.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [12.0],\n",
       "     'text': '온',\n",
       "     'weight': 0.660278},\n",
       "    {'head': 18.0,\n",
       "     'id': 14.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [13.0],\n",
       "     'text': '그는',\n",
       "     'weight': 0.718271},\n",
       "    {'head': 18.0,\n",
       "     'id': 15.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '2011년에는',\n",
       "     'weight': 0.673021},\n",
       "    {'head': 18.0,\n",
       "     'id': 16.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '경희대에서',\n",
       "     'weight': 0.784805},\n",
       "    {'head': 18.0,\n",
       "     'id': 17.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [],\n",
       "     'text': '경영학을',\n",
       "     'weight': 0.684106},\n",
       "    {'head': 23.0,\n",
       "     'id': 18.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [14.0, 15.0, 16.0, 17.0],\n",
       "     'text': '전공하고',\n",
       "     'weight': 0.804972},\n",
       "    {'head': 23.0,\n",
       "     'id': 19.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '2014년에는',\n",
       "     'weight': 0.609319},\n",
       "    {'head': 23.0,\n",
       "     'id': 20.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '고려대에서',\n",
       "     'weight': 0.777463},\n",
       "    {'head': 22.0,\n",
       "     'id': 21.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '건축공학과',\n",
       "     'weight': 0.610414},\n",
       "    {'head': 23.0,\n",
       "     'id': 22.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [21.0],\n",
       "     'text': '석사과정을',\n",
       "     'weight': 0.671594},\n",
       "    {'head': -1.0,\n",
       "     'id': 23.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [18.0, 19.0, 20.0, 22.0],\n",
       "     'text': '마쳤다.',\n",
       "     'weight': 7.42437e-08}],\n",
       "   'id': 15.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '그',\n",
       "     'position': 2068.0,\n",
       "     'type': 'MM',\n",
       "     'weight': 0.049509},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '동안',\n",
       "     'position': 2071.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.049509},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '고양시',\n",
       "     'position': 2078.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0650413},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '발전',\n",
       "     'position': 2088.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0643419},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '을',\n",
       "     'position': 2094.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0880422},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '위하',\n",
       "     'position': 2098.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0833844},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '어서',\n",
       "     'position': 2101.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0841452},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '는',\n",
       "     'position': 2107.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.115627},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '해당',\n",
       "     'position': 2111.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0765361},\n",
       "    {'id': 9.0,\n",
       "     'lemma': '업무',\n",
       "     'position': 2118.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.146688},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '를',\n",
       "     'position': 2124.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0922402},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '담당',\n",
       "     'position': 2128.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0269004},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '하',\n",
       "     'position': 2134.0,\n",
       "     'type': 'XSV',\n",
       "     'weight': 0.0269004},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '는',\n",
       "     'position': 2137.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.123765},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '공직',\n",
       "     'position': 2141.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.131497},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '자',\n",
       "     'position': 2147.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.131497},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '역시',\n",
       "     'position': 2151.0,\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0769249},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '계속',\n",
       "     'position': 2158.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0719721},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '적',\n",
       "     'position': 2164.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0719721},\n",
       "    {'id': 19.0,\n",
       "     'lemma': '이',\n",
       "     'position': 2167.0,\n",
       "     'type': 'VCP',\n",
       "     'weight': 0.111692},\n",
       "    {'id': 20.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 2167.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.111692},\n",
       "    {'id': 21.0,\n",
       "     'lemma': '발전',\n",
       "     'position': 2171.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0936336},\n",
       "    {'id': 22.0,\n",
       "     'lemma': '이',\n",
       "     'position': 2177.0,\n",
       "     'type': 'JKS',\n",
       "     'weight': 0.0846542},\n",
       "    {'id': 23.0,\n",
       "     'lemma': '필요',\n",
       "     'position': 2181.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0456335},\n",
       "    {'id': 24.0,\n",
       "     'lemma': '하',\n",
       "     'position': 2187.0,\n",
       "     'type': 'XSA',\n",
       "     'weight': 0.0456335},\n",
       "    {'id': 25.0,\n",
       "     'lemma': '다고',\n",
       "     'position': 2190.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0553318},\n",
       "    {'id': 26.0,\n",
       "     'lemma': '강조',\n",
       "     'position': 2197.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0565279},\n",
       "    {'id': 27.0,\n",
       "     'lemma': '하',\n",
       "     'position': 2203.0,\n",
       "     'type': 'XSV',\n",
       "     'weight': 0.0565279},\n",
       "    {'id': 28.0,\n",
       "     'lemma': '어',\n",
       "     'position': 2203.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0612938},\n",
       "    {'id': 29.0,\n",
       "     'lemma': '오',\n",
       "     'position': 2207.0,\n",
       "     'type': 'VX',\n",
       "     'weight': 0.0793067},\n",
       "    {'id': 30.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 2207.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0793067},\n",
       "    {'id': 31.0,\n",
       "     'lemma': '그',\n",
       "     'position': 2211.0,\n",
       "     'type': 'NP',\n",
       "     'weight': 0.104357},\n",
       "    {'id': 32.0,\n",
       "     'lemma': '는',\n",
       "     'position': 2214.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.127566},\n",
       "    {'id': 33.0,\n",
       "     'lemma': '2011',\n",
       "     'position': 2218.0,\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'id': 34.0,\n",
       "     'lemma': '년',\n",
       "     'position': 2222.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.0747491},\n",
       "    {'id': 35.0,\n",
       "     'lemma': '에',\n",
       "     'position': 2225.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0795831},\n",
       "    {'id': 36.0,\n",
       "     'lemma': '는',\n",
       "     'position': 2228.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.127068},\n",
       "    {'id': 37.0,\n",
       "     'lemma': '경희대',\n",
       "     'position': 2232.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0690814},\n",
       "    {'id': 38.0,\n",
       "     'lemma': '에서',\n",
       "     'position': 2241.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0830844},\n",
       "    {'id': 39.0,\n",
       "     'lemma': '경영',\n",
       "     'position': 2248.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.158587},\n",
       "    {'id': 40.0,\n",
       "     'lemma': '학',\n",
       "     'position': 2254.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.158587},\n",
       "    {'id': 41.0,\n",
       "     'lemma': '을',\n",
       "     'position': 2257.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0827272},\n",
       "    {'id': 42.0,\n",
       "     'lemma': '전공',\n",
       "     'position': 2261.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0375048},\n",
       "    {'id': 43.0,\n",
       "     'lemma': '하',\n",
       "     'position': 2267.0,\n",
       "     'type': 'XSV',\n",
       "     'weight': 0.0375048},\n",
       "    {'id': 44.0,\n",
       "     'lemma': '고',\n",
       "     'position': 2270.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0931551},\n",
       "    {'id': 45.0,\n",
       "     'lemma': '2014',\n",
       "     'position': 2274.0,\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'id': 46.0,\n",
       "     'lemma': '년',\n",
       "     'position': 2278.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.080389},\n",
       "    {'id': 47.0,\n",
       "     'lemma': '에',\n",
       "     'position': 2281.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0755452},\n",
       "    {'id': 48.0,\n",
       "     'lemma': '는',\n",
       "     'position': 2284.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.136789},\n",
       "    {'id': 49.0,\n",
       "     'lemma': '고려대',\n",
       "     'position': 2288.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0676482},\n",
       "    {'id': 50.0,\n",
       "     'lemma': '에서',\n",
       "     'position': 2297.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0810954},\n",
       "    {'id': 51.0,\n",
       "     'lemma': '건축',\n",
       "     'position': 2304.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0761965},\n",
       "    {'id': 52.0,\n",
       "     'lemma': '공학',\n",
       "     'position': 2310.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.059906},\n",
       "    {'id': 53.0,\n",
       "     'lemma': '과',\n",
       "     'position': 2316.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.059906},\n",
       "    {'id': 54.0,\n",
       "     'lemma': '석사',\n",
       "     'position': 2320.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0744275},\n",
       "    {'id': 55.0,\n",
       "     'lemma': '과정',\n",
       "     'position': 2326.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0803652},\n",
       "    {'id': 56.0,\n",
       "     'lemma': '을',\n",
       "     'position': 2332.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0915056},\n",
       "    {'id': 57.0,\n",
       "     'lemma': '마치',\n",
       "     'position': 2336.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0667333},\n",
       "    {'id': 58.0,\n",
       "     'lemma': '었',\n",
       "     'position': 2339.0,\n",
       "     'type': 'EP',\n",
       "     'weight': 0.076483},\n",
       "    {'id': 59.0,\n",
       "     'lemma': '다',\n",
       "     'position': 2342.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0752349},\n",
       "    {'id': 60.0,\n",
       "     'lemma': '.',\n",
       "     'position': 2345.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': '  그동안 고양시 발전을 위해서는 해당 업무를 담당하는 공직자 역시 계속적인 발전이 필요하다고 강조해 온 그는 2011년에는 경희대에서 경영학을 전공하고 2014년에는 고려대에서 건축공학과 석사과정을 마쳤다.',\n",
       "   'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '그동안', 'type': ''},\n",
       "    {'begin': 2.0, 'end': 2.0, 'id': 1.0, 'text': '고양시', 'type': ''},\n",
       "    {'begin': 3.0, 'end': 4.0, 'id': 2.0, 'text': '발전을', 'type': ''},\n",
       "    {'begin': 5.0, 'end': 7.0, 'id': 3.0, 'text': '위해서는', 'type': ''},\n",
       "    {'begin': 8.0, 'end': 8.0, 'id': 4.0, 'text': '해당', 'type': ''},\n",
       "    {'begin': 9.0, 'end': 10.0, 'id': 5.0, 'text': '업무를', 'type': ''},\n",
       "    {'begin': 11.0, 'end': 13.0, 'id': 6.0, 'text': '담당하는', 'type': ''},\n",
       "    {'begin': 14.0, 'end': 15.0, 'id': 7.0, 'text': '공직자', 'type': ''},\n",
       "    {'begin': 16.0, 'end': 16.0, 'id': 8.0, 'text': '역시', 'type': ''},\n",
       "    {'begin': 17.0, 'end': 20.0, 'id': 9.0, 'text': '계속적인', 'type': ''},\n",
       "    {'begin': 21.0, 'end': 22.0, 'id': 10.0, 'text': '발전이', 'type': ''},\n",
       "    {'begin': 23.0, 'end': 25.0, 'id': 11.0, 'text': '필요하다고', 'type': ''},\n",
       "    {'begin': 26.0, 'end': 28.0, 'id': 12.0, 'text': '강조해', 'type': ''},\n",
       "    {'begin': 29.0, 'end': 30.0, 'id': 13.0, 'text': '온', 'type': ''},\n",
       "    {'begin': 31.0, 'end': 32.0, 'id': 14.0, 'text': '그는', 'type': ''},\n",
       "    {'begin': 33.0, 'end': 36.0, 'id': 15.0, 'text': '2011년에는', 'type': ''},\n",
       "    {'begin': 37.0, 'end': 38.0, 'id': 16.0, 'text': '경희대에서', 'type': ''},\n",
       "    {'begin': 39.0, 'end': 41.0, 'id': 17.0, 'text': '경영학을', 'type': ''},\n",
       "    {'begin': 42.0, 'end': 44.0, 'id': 18.0, 'text': '전공하고', 'type': ''},\n",
       "    {'begin': 45.0, 'end': 48.0, 'id': 19.0, 'text': '2014년에는', 'type': ''},\n",
       "    {'begin': 49.0, 'end': 50.0, 'id': 20.0, 'text': '고려대에서', 'type': ''},\n",
       "    {'begin': 51.0, 'end': 53.0, 'id': 21.0, 'text': '건축공학과', 'type': ''},\n",
       "    {'begin': 54.0, 'end': 56.0, 'id': 22.0, 'text': '석사과정을', 'type': ''},\n",
       "    {'begin': 57.0, 'end': 60.0, 'id': 23.0, 'text': '마쳤다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 28.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 28.0,\n",
       "     'id': 0.0,\n",
       "     'text': '신',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.239135},\n",
       "    {'begin': 29.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 29.0,\n",
       "     'id': 1.0,\n",
       "     'text': '국장',\n",
       "     'type': 'CV_POSITION',\n",
       "     'weight': 0.43369},\n",
       "    {'begin': 33.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 33.0,\n",
       "     'id': 2.0,\n",
       "     'text': '후배',\n",
       "     'type': 'CV_RELATION',\n",
       "     'weight': 0.325419}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 2348.0,\n",
       "     'scode': '00',\n",
       "     'text': '풍부하',\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 2354.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 2358.0,\n",
       "     'scode': '02',\n",
       "     'text': '학식',\n",
       "     'type': 'NNG',\n",
       "     'weight': 1.56667},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 2364.0,\n",
       "     'scode': '00',\n",
       "     'text': '과',\n",
       "     'type': 'JC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 4.0,\n",
       "     'position': 2368.0,\n",
       "     'scode': '00',\n",
       "     'text': '오랜',\n",
       "     'type': 'MM',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 5.0,\n",
       "     'position': 2375.0,\n",
       "     'scode': '01',\n",
       "     'text': '행정',\n",
       "     'type': 'NNG',\n",
       "     'weight': 5.2},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 6.0,\n",
       "     'position': 2381.0,\n",
       "     'scode': '00',\n",
       "     'text': '경험',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 7.0,\n",
       "     'position': 2387.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 8.0,\n",
       "     'position': 2391.0,\n",
       "     'scode': '00',\n",
       "     'text': '통하',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 9.0,\n",
       "     'position': 2394.0,\n",
       "     'scode': '00',\n",
       "     'text': '어',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 10.0,\n",
       "     'position': 2398.0,\n",
       "     'scode': '00',\n",
       "     'text': '쌓',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 11.0,\n",
       "     'position': 2401.0,\n",
       "     'scode': '00',\n",
       "     'text': '은',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 12.0,\n",
       "     'end': 13.0,\n",
       "     'id': 12.0,\n",
       "     'position': 2405.0,\n",
       "     'scode': '00',\n",
       "     'text': '노하우',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 13.0,\n",
       "     'position': 2414.0,\n",
       "     'scode': '00',\n",
       "     'text': ',',\n",
       "     'type': 'SP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 15.0,\n",
       "     'end': 15.0,\n",
       "     'id': 14.0,\n",
       "     'position': 2416.0,\n",
       "     'scode': '02',\n",
       "     'text': '업무',\n",
       "     'type': 'NNG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 15.0,\n",
       "     'position': 2422.0,\n",
       "     'scode': '00',\n",
       "     'text': '를',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 17.0,\n",
       "     'end': 18.0,\n",
       "     'id': 16.0,\n",
       "     'position': 2426.0,\n",
       "     'scode': '02',\n",
       "     'text': '추진하',\n",
       "     'type': 'VV',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 19.0,\n",
       "     'end': 19.0,\n",
       "     'id': 17.0,\n",
       "     'position': 2435.0,\n",
       "     'scode': '00',\n",
       "     'text': '는',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 18.0,\n",
       "     'position': 2439.0,\n",
       "     'scode': '00',\n",
       "     'text': '뜨겁',\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 19.0,\n",
       "     'position': 2445.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 22.0,\n",
       "     'end': 22.0,\n",
       "     'id': 20.0,\n",
       "     'position': 2449.0,\n",
       "     'scode': '02',\n",
       "     'text': '열정',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.2},\n",
       "    {'begin': 23.0,\n",
       "     'end': 23.0,\n",
       "     'id': 21.0,\n",
       "     'position': 2455.0,\n",
       "     'scode': '00',\n",
       "     'text': ',',\n",
       "     'type': 'SP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 24.0,\n",
       "     'end': 24.0,\n",
       "     'id': 22.0,\n",
       "     'position': 2457.0,\n",
       "     'scode': '00',\n",
       "     'text': '뛰어나',\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 25.0,\n",
       "     'end': 25.0,\n",
       "     'id': 23.0,\n",
       "     'position': 2463.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 26.0,\n",
       "     'end': 26.0,\n",
       "     'id': 24.0,\n",
       "     'position': 2467.0,\n",
       "     'scode': '00',\n",
       "     'text': '리더쉽',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 27.0,\n",
       "     'end': 27.0,\n",
       "     'id': 25.0,\n",
       "     'position': 2476.0,\n",
       "     'scode': '00',\n",
       "     'text': ',',\n",
       "     'type': 'SP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 28.0,\n",
       "     'end': 28.0,\n",
       "     'id': 26.0,\n",
       "     'position': 2478.0,\n",
       "     'scode': '03',\n",
       "     'text': '신',\n",
       "     'type': 'NNP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 29.0,\n",
       "     'end': 29.0,\n",
       "     'id': 27.0,\n",
       "     'position': 2482.0,\n",
       "     'scode': '01',\n",
       "     'text': '국장',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.5},\n",
       "    {'begin': 30.0,\n",
       "     'end': 30.0,\n",
       "     'id': 28.0,\n",
       "     'position': 2488.0,\n",
       "     'scode': '00',\n",
       "     'text': '이',\n",
       "     'type': 'JKS',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 31.0,\n",
       "     'end': 31.0,\n",
       "     'id': 29.0,\n",
       "     'position': 2492.0,\n",
       "     'scode': '02',\n",
       "     'text': '공직',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.0},\n",
       "    {'begin': 32.0,\n",
       "     'end': 32.0,\n",
       "     'id': 30.0,\n",
       "     'position': 2498.0,\n",
       "     'scode': '07',\n",
       "     'text': '사회',\n",
       "     'type': 'NNG',\n",
       "     'weight': 6.7},\n",
       "    {'begin': 33.0,\n",
       "     'end': 33.0,\n",
       "     'id': 31.0,\n",
       "     'position': 2505.0,\n",
       "     'scode': '06',\n",
       "     'text': '후배',\n",
       "     'type': 'NNG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 34.0,\n",
       "     'end': 34.0,\n",
       "     'id': 32.0,\n",
       "     'position': 2511.0,\n",
       "     'scode': '09',\n",
       "     'text': '들',\n",
       "     'type': 'XSN',\n",
       "     'weight': 7.0},\n",
       "    {'begin': 35.0,\n",
       "     'end': 35.0,\n",
       "     'id': 33.0,\n",
       "     'position': 2514.0,\n",
       "     'scode': '00',\n",
       "     'text': '에게',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 36.0,\n",
       "     'end': 36.0,\n",
       "     'id': 34.0,\n",
       "     'position': 2521.0,\n",
       "     'scode': '01',\n",
       "     'text': '받',\n",
       "     'type': 'VV',\n",
       "     'weight': 4.2},\n",
       "    {'begin': 37.0,\n",
       "     'end': 37.0,\n",
       "     'id': 35.0,\n",
       "     'position': 2524.0,\n",
       "     'scode': '00',\n",
       "     'text': '는',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 38.0,\n",
       "     'end': 38.0,\n",
       "     'id': 36.0,\n",
       "     'position': 2528.0,\n",
       "     'scode': '03',\n",
       "     'text': '평가',\n",
       "     'type': 'NNG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 39.0,\n",
       "     'end': 39.0,\n",
       "     'id': 37.0,\n",
       "     'position': 2534.0,\n",
       "     'scode': '01',\n",
       "     'text': '이',\n",
       "     'type': 'VCP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 40.0,\n",
       "     'end': 40.0,\n",
       "     'id': 38.0,\n",
       "     'position': 2534.0,\n",
       "     'scode': '00',\n",
       "     'text': '다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 41.0,\n",
       "     'end': 41.0,\n",
       "     'id': 39.0,\n",
       "     'position': 2537.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 1.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '풍부한',\n",
       "     'weight': 0.577327},\n",
       "    {'head': 3.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP_CNJ',\n",
       "     'mod': [0.0],\n",
       "     'text': '학식과',\n",
       "     'weight': 0.488489},\n",
       "    {'head': 3.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'DP',\n",
       "     'mod': [],\n",
       "     'text': '오랜',\n",
       "     'weight': 0.470382},\n",
       "    {'head': 4.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [1.0, 2.0],\n",
       "     'text': '행정경험을',\n",
       "     'weight': 0.769627},\n",
       "    {'head': 5.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [3.0],\n",
       "     'text': '통해',\n",
       "     'weight': 0.612799},\n",
       "    {'head': 6.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [4.0],\n",
       "     'text': '쌓은',\n",
       "     'weight': 0.451413},\n",
       "    {'head': 14.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'NP_CNJ',\n",
       "     'mod': [5.0],\n",
       "     'text': '노하우,',\n",
       "     'weight': 0.173041},\n",
       "    {'head': 8.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [],\n",
       "     'text': '업무를',\n",
       "     'weight': 0.734133},\n",
       "    {'head': 10.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [7.0],\n",
       "     'text': '추진하는',\n",
       "     'weight': 0.582724},\n",
       "    {'head': 10.0,\n",
       "     'id': 9.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '뜨거운',\n",
       "     'weight': 0.555518},\n",
       "    {'head': 14.0,\n",
       "     'id': 10.0,\n",
       "     'label': 'NP_CNJ',\n",
       "     'mod': [8.0, 9.0],\n",
       "     'text': '열정,',\n",
       "     'weight': 0.228286},\n",
       "    {'head': 12.0,\n",
       "     'id': 11.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '뛰어난',\n",
       "     'weight': 0.582117},\n",
       "    {'head': 14.0,\n",
       "     'id': 12.0,\n",
       "     'label': 'NP_CNJ',\n",
       "     'mod': [11.0],\n",
       "     'text': '리더쉽,',\n",
       "     'weight': 0.0332456},\n",
       "    {'head': 14.0,\n",
       "     'id': 13.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '신',\n",
       "     'weight': 0.701606},\n",
       "    {'head': 17.0,\n",
       "     'id': 14.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [6.0, 10.0, 12.0, 13.0],\n",
       "     'text': '국장이',\n",
       "     'weight': 0.762888},\n",
       "    {'head': 16.0,\n",
       "     'id': 15.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '공직사회',\n",
       "     'weight': 0.520157},\n",
       "    {'head': 17.0,\n",
       "     'id': 16.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [15.0],\n",
       "     'text': '후배들에게',\n",
       "     'weight': 0.697172},\n",
       "    {'head': 18.0,\n",
       "     'id': 17.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [14.0, 16.0],\n",
       "     'text': '받는',\n",
       "     'weight': 0.647006},\n",
       "    {'head': -1.0,\n",
       "     'id': 18.0,\n",
       "     'label': 'VNP',\n",
       "     'mod': [17.0],\n",
       "     'text': '평가다.',\n",
       "     'weight': 5.07428e-07}],\n",
       "   'id': 16.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '풍부하',\n",
       "     'position': 2348.0,\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0595484},\n",
       "    {'id': 1.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 2354.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0335769},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '학식',\n",
       "     'position': 2358.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0794731},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '과',\n",
       "     'position': 2364.0,\n",
       "     'type': 'JC',\n",
       "     'weight': 0.0669113},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '오랜',\n",
       "     'position': 2368.0,\n",
       "     'type': 'MM',\n",
       "     'weight': 0.0528307},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '행정',\n",
       "     'position': 2375.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.106307},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '경험',\n",
       "     'position': 2381.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.118347},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '을',\n",
       "     'position': 2387.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0878383},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '통하',\n",
       "     'position': 2391.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0778748},\n",
       "    {'id': 9.0,\n",
       "     'lemma': '어',\n",
       "     'position': 2394.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0692416},\n",
       "    {'id': 10.0,\n",
       "     'lemma': '쌓',\n",
       "     'position': 2398.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.127916},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '은',\n",
       "     'position': 2401.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0626115},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '노',\n",
       "     'position': 2405.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0527565},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '하우',\n",
       "     'position': 2408.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0527565},\n",
       "    {'id': 14.0,\n",
       "     'lemma': ',',\n",
       "     'position': 2414.0,\n",
       "     'type': 'SP',\n",
       "     'weight': 1.0},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '업무',\n",
       "     'position': 2416.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.119289},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '를',\n",
       "     'position': 2422.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0919228},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '추진',\n",
       "     'position': 2426.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0556149},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '하',\n",
       "     'position': 2432.0,\n",
       "     'type': 'XSV',\n",
       "     'weight': 0.0375256},\n",
       "    {'id': 19.0,\n",
       "     'lemma': '는',\n",
       "     'position': 2435.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.121964},\n",
       "    {'id': 20.0,\n",
       "     'lemma': '뜨겁',\n",
       "     'position': 2439.0,\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0540058},\n",
       "    {'id': 21.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 2445.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0456632},\n",
       "    {'id': 22.0,\n",
       "     'lemma': '열정',\n",
       "     'position': 2449.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0546397},\n",
       "    {'id': 23.0,\n",
       "     'lemma': ',',\n",
       "     'position': 2455.0,\n",
       "     'type': 'SP',\n",
       "     'weight': 1.0},\n",
       "    {'id': 24.0,\n",
       "     'lemma': '뛰어나',\n",
       "     'position': 2457.0,\n",
       "     'type': 'VA',\n",
       "     'weight': 0.068426},\n",
       "    {'id': 25.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 2463.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0774079},\n",
       "    {'id': 26.0,\n",
       "     'lemma': '리더쉽',\n",
       "     'position': 2467.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0394972},\n",
       "    {'id': 27.0,\n",
       "     'lemma': ',',\n",
       "     'position': 2476.0,\n",
       "     'type': 'SP',\n",
       "     'weight': 1.0},\n",
       "    {'id': 28.0,\n",
       "     'lemma': '신',\n",
       "     'position': 2478.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.037657},\n",
       "    {'id': 29.0,\n",
       "     'lemma': '국장',\n",
       "     'position': 2482.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.110679},\n",
       "    {'id': 30.0,\n",
       "     'lemma': '이',\n",
       "     'position': 2488.0,\n",
       "     'type': 'JKS',\n",
       "     'weight': 0.0619183},\n",
       "    {'id': 31.0,\n",
       "     'lemma': '공직',\n",
       "     'position': 2492.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0747808},\n",
       "    {'id': 32.0,\n",
       "     'lemma': '사회',\n",
       "     'position': 2498.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0567425},\n",
       "    {'id': 33.0,\n",
       "     'lemma': '후배',\n",
       "     'position': 2505.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.071888},\n",
       "    {'id': 34.0,\n",
       "     'lemma': '들',\n",
       "     'position': 2511.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0720833},\n",
       "    {'id': 35.0,\n",
       "     'lemma': '에게',\n",
       "     'position': 2514.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0715299},\n",
       "    {'id': 36.0,\n",
       "     'lemma': '받',\n",
       "     'position': 2521.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.113835},\n",
       "    {'id': 37.0,\n",
       "     'lemma': '는',\n",
       "     'position': 2524.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0929622},\n",
       "    {'id': 38.0,\n",
       "     'lemma': '평가',\n",
       "     'position': 2528.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0613124},\n",
       "    {'id': 39.0,\n",
       "     'lemma': '이',\n",
       "     'position': 2534.0,\n",
       "     'type': 'VCP',\n",
       "     'weight': 0.0387355},\n",
       "    {'id': 40.0,\n",
       "     'lemma': '다',\n",
       "     'position': 2534.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0632498},\n",
       "    {'id': 41.0,\n",
       "     'lemma': '.',\n",
       "     'position': 2537.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': '  풍부한 학식과 오랜 행정경험을 통해 쌓은 노하우, 업무를 추진하는 뜨거운 열정, 뛰어난 리더쉽, 신 국장이 공직사회 후배들에게 받는 평가다.',\n",
       "   'word': [{'begin': 0.0, 'end': 1.0, 'id': 0.0, 'text': '풍부한', 'type': ''},\n",
       "    {'begin': 2.0, 'end': 3.0, 'id': 1.0, 'text': '학식과', 'type': ''},\n",
       "    {'begin': 4.0, 'end': 4.0, 'id': 2.0, 'text': '오랜', 'type': ''},\n",
       "    {'begin': 5.0, 'end': 7.0, 'id': 3.0, 'text': '행정경험을', 'type': ''},\n",
       "    {'begin': 8.0, 'end': 9.0, 'id': 4.0, 'text': '통해', 'type': ''},\n",
       "    {'begin': 10.0, 'end': 11.0, 'id': 5.0, 'text': '쌓은', 'type': ''},\n",
       "    {'begin': 12.0, 'end': 14.0, 'id': 6.0, 'text': '노하우,', 'type': ''},\n",
       "    {'begin': 15.0, 'end': 16.0, 'id': 7.0, 'text': '업무를', 'type': ''},\n",
       "    {'begin': 17.0, 'end': 19.0, 'id': 8.0, 'text': '추진하는', 'type': ''},\n",
       "    {'begin': 20.0, 'end': 21.0, 'id': 9.0, 'text': '뜨거운', 'type': ''},\n",
       "    {'begin': 22.0, 'end': 23.0, 'id': 10.0, 'text': '열정,', 'type': ''},\n",
       "    {'begin': 24.0, 'end': 25.0, 'id': 11.0, 'text': '뛰어난', 'type': ''},\n",
       "    {'begin': 26.0, 'end': 27.0, 'id': 12.0, 'text': '리더쉽,', 'type': ''},\n",
       "    {'begin': 28.0, 'end': 28.0, 'id': 13.0, 'text': '신', 'type': ''},\n",
       "    {'begin': 29.0, 'end': 30.0, 'id': 14.0, 'text': '국장이', 'type': ''},\n",
       "    {'begin': 31.0, 'end': 32.0, 'id': 15.0, 'text': '공직사회', 'type': ''},\n",
       "    {'begin': 33.0, 'end': 35.0, 'id': 16.0, 'text': '후배들에게', 'type': ''},\n",
       "    {'begin': 36.0, 'end': 37.0, 'id': 17.0, 'text': '받는', 'type': ''},\n",
       "    {'begin': 38.0, 'end': 41.0, 'id': 18.0, 'text': '평가다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 0.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'text': '고양시',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.4491},\n",
       "    {'begin': 4.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 6.0,\n",
       "     'id': 1.0,\n",
       "     'text': '1959년생',\n",
       "     'type': 'QT_AGE',\n",
       "     'weight': 0.283614},\n",
       "    {'begin': 7.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 7.0,\n",
       "     'id': 2.0,\n",
       "     'text': '선배',\n",
       "     'type': 'CV_RELATION',\n",
       "     'weight': 0.563974},\n",
       "    {'begin': 11.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 12.0,\n",
       "     'id': 3.0,\n",
       "     'text': '여섯분',\n",
       "     'type': 'QT_MAN_COUNT',\n",
       "     'weight': 0.236541},\n",
       "    {'begin': 23.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 23.0,\n",
       "     'id': 4.0,\n",
       "     'text': '고양시',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.464346},\n",
       "    {'begin': 28.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 28.0,\n",
       "     'id': 5.0,\n",
       "     'text': '후배',\n",
       "     'type': 'CV_RELATION',\n",
       "     'weight': 0.518573}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 2539.0,\n",
       "     'scode': '00',\n",
       "     'text': '고양시',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 2.0,\n",
       "     'id': 1.0,\n",
       "     'position': 2548.0,\n",
       "     'scode': '00',\n",
       "     'text': '관계자',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 2.0,\n",
       "     'position': 2557.0,\n",
       "     'scode': '00',\n",
       "     'text': '는',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 4.0,\n",
       "     'end': 4.0,\n",
       "     'id': 3.0,\n",
       "     'position': 2561.0,\n",
       "     'scode': '00',\n",
       "     'text': '1959',\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 5.0,\n",
       "     'end': 5.0,\n",
       "     'id': 4.0,\n",
       "     'position': 2565.0,\n",
       "     'scode': '02',\n",
       "     'text': '년',\n",
       "     'type': 'NNB',\n",
       "     'weight': 6.9},\n",
       "    {'begin': 6.0,\n",
       "     'end': 6.0,\n",
       "     'id': 5.0,\n",
       "     'position': 2568.0,\n",
       "     'scode': '08',\n",
       "     'text': '생',\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.5},\n",
       "    {'begin': 7.0,\n",
       "     'end': 7.0,\n",
       "     'id': 6.0,\n",
       "     'position': 2572.0,\n",
       "     'scode': '00',\n",
       "     'text': '선배',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 8.0,\n",
       "     'end': 8.0,\n",
       "     'id': 7.0,\n",
       "     'position': 2578.0,\n",
       "     'scode': '09',\n",
       "     'text': '들',\n",
       "     'type': 'XSN',\n",
       "     'weight': 6.5},\n",
       "    {'begin': 9.0,\n",
       "     'end': 9.0,\n",
       "     'id': 8.0,\n",
       "     'position': 2581.0,\n",
       "     'scode': '01',\n",
       "     'text': '이',\n",
       "     'type': 'VCP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 10.0,\n",
       "     'end': 10.0,\n",
       "     'id': 9.0,\n",
       "     'position': 2581.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 11.0,\n",
       "     'end': 11.0,\n",
       "     'id': 10.0,\n",
       "     'position': 2585.0,\n",
       "     'scode': '00',\n",
       "     'text': '여섯',\n",
       "     'type': 'NR',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 12.0,\n",
       "     'end': 12.0,\n",
       "     'id': 11.0,\n",
       "     'position': 2591.0,\n",
       "     'scode': '01',\n",
       "     'text': '분',\n",
       "     'type': 'NNB',\n",
       "     'weight': 2.70454},\n",
       "    {'begin': 13.0,\n",
       "     'end': 13.0,\n",
       "     'id': 12.0,\n",
       "     'position': 2594.0,\n",
       "     'scode': '00',\n",
       "     'text': '에게',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 14.0,\n",
       "     'end': 14.0,\n",
       "     'id': 13.0,\n",
       "     'position': 2601.0,\n",
       "     'scode': '00',\n",
       "     'text': '많',\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 15.0,\n",
       "     'end': 15.0,\n",
       "     'id': 14.0,\n",
       "     'position': 2604.0,\n",
       "     'scode': '00',\n",
       "     'text': '은',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 16.0,\n",
       "     'end': 16.0,\n",
       "     'id': 15.0,\n",
       "     'position': 2608.0,\n",
       "     'scode': '08',\n",
       "     'text': '감사',\n",
       "     'type': 'NNG',\n",
       "     'weight': 2.18507},\n",
       "    {'begin': 17.0,\n",
       "     'end': 17.0,\n",
       "     'id': 16.0,\n",
       "     'position': 2614.0,\n",
       "     'scode': '00',\n",
       "     'text': '와',\n",
       "     'type': 'JC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 18.0,\n",
       "     'end': 18.0,\n",
       "     'id': 17.0,\n",
       "     'position': 2618.0,\n",
       "     'scode': '00',\n",
       "     'text': '응원',\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 19.0,\n",
       "     'end': 19.0,\n",
       "     'id': 18.0,\n",
       "     'position': 2624.0,\n",
       "     'scode': '00',\n",
       "     'text': '을',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 20.0,\n",
       "     'end': 20.0,\n",
       "     'id': 19.0,\n",
       "     'position': 2628.0,\n",
       "     'scode': '01',\n",
       "     'text': '드리',\n",
       "     'type': 'VV',\n",
       "     'weight': 2.2},\n",
       "    {'begin': 21.0,\n",
       "     'end': 21.0,\n",
       "     'id': 20.0,\n",
       "     'position': 2631.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ다며',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 22.0,\n",
       "     'end': 22.0,\n",
       "     'id': 21.0,\n",
       "     'position': 2641.0,\n",
       "     'scode': '01',\n",
       "     'text': '이제',\n",
       "     'type': 'MAG',\n",
       "     'weight': 5.4},\n",
       "    {'begin': 23.0,\n",
       "     'end': 23.0,\n",
       "     'id': 22.0,\n",
       "     'position': 2648.0,\n",
       "     'scode': '00',\n",
       "     'text': '고양시',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 24.0,\n",
       "     'end': 24.0,\n",
       "     'id': 23.0,\n",
       "     'position': 2657.0,\n",
       "     'scode': '00',\n",
       "     'text': '의',\n",
       "     'type': 'JKG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 25.0,\n",
       "     'end': 25.0,\n",
       "     'id': 24.0,\n",
       "     'position': 2661.0,\n",
       "     'scode': '01',\n",
       "     'text': '다음',\n",
       "     'type': 'NNG',\n",
       "     'weight': 6.4},\n",
       "    {'begin': 26.0,\n",
       "     'end': 26.0,\n",
       "     'id': 25.0,\n",
       "     'position': 2667.0,\n",
       "     'scode': '01',\n",
       "     'text': '일',\n",
       "     'type': 'NNG',\n",
       "     'weight': 5.4},\n",
       "    {'begin': 27.0,\n",
       "     'end': 27.0,\n",
       "     'id': 26.0,\n",
       "     'position': 2670.0,\n",
       "     'scode': '00',\n",
       "     'text': '은',\n",
       "     'type': 'JX',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 28.0,\n",
       "     'end': 28.0,\n",
       "     'id': 27.0,\n",
       "     'position': 2674.0,\n",
       "     'scode': '06',\n",
       "     'text': '후배',\n",
       "     'type': 'NNG',\n",
       "     'weight': 3.0},\n",
       "    {'begin': 29.0,\n",
       "     'end': 29.0,\n",
       "     'id': 28.0,\n",
       "     'position': 2680.0,\n",
       "     'scode': '09',\n",
       "     'text': '들',\n",
       "     'type': 'XSN',\n",
       "     'weight': 7.5},\n",
       "    {'begin': 30.0,\n",
       "     'end': 30.0,\n",
       "     'id': 29.0,\n",
       "     'position': 2683.0,\n",
       "     'scode': '00',\n",
       "     'text': '에게',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 31.0,\n",
       "     'end': 31.0,\n",
       "     'id': 30.0,\n",
       "     'position': 2690.0,\n",
       "     'scode': '00',\n",
       "     'text': '맡기',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 32.0,\n",
       "     'end': 32.0,\n",
       "     'id': 31.0,\n",
       "     'position': 2696.0,\n",
       "     'scode': '00',\n",
       "     'text': '고',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 33.0,\n",
       "     'end': 33.0,\n",
       "     'id': 32.0,\n",
       "     'position': 2700.0,\n",
       "     'scode': '00',\n",
       "     'text': '새롭',\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 34.0,\n",
       "     'end': 34.0,\n",
       "     'id': 33.0,\n",
       "     'position': 2706.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ',\n",
       "     'type': 'ETM',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 35.0,\n",
       "     'end': 35.0,\n",
       "     'id': 34.0,\n",
       "     'position': 2710.0,\n",
       "     'scode': '01',\n",
       "     'text': '인생',\n",
       "     'type': 'NNG',\n",
       "     'weight': 5.2},\n",
       "    {'begin': 36.0,\n",
       "     'end': 36.0,\n",
       "     'id': 35.0,\n",
       "     'position': 2716.0,\n",
       "     'scode': '00',\n",
       "     'text': '에서',\n",
       "     'type': 'JKB',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 37.0,\n",
       "     'end': 37.0,\n",
       "     'id': 36.0,\n",
       "     'position': 2723.0,\n",
       "     'scode': '00',\n",
       "     'text': '또',\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 38.0,\n",
       "     'end': 38.0,\n",
       "     'id': 37.0,\n",
       "     'position': 2727.0,\n",
       "     'scode': '00',\n",
       "     'text': '다른',\n",
       "     'type': 'MM',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 39.0,\n",
       "     'end': 39.0,\n",
       "     'id': 38.0,\n",
       "     'position': 2734.0,\n",
       "     'scode': '01',\n",
       "     'text': '성공',\n",
       "     'type': 'NNG',\n",
       "     'weight': 5.2},\n",
       "    {'begin': 40.0,\n",
       "     'end': 40.0,\n",
       "     'id': 39.0,\n",
       "     'position': 2740.0,\n",
       "     'scode': '00',\n",
       "     'text': '이',\n",
       "     'type': 'JKS',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 41.0,\n",
       "     'end': 41.0,\n",
       "     'id': 40.0,\n",
       "     'position': 2744.0,\n",
       "     'scode': '01',\n",
       "     'text': '있',\n",
       "     'type': 'VA',\n",
       "     'weight': 8.8},\n",
       "    {'begin': 42.0,\n",
       "     'end': 42.0,\n",
       "     'id': 41.0,\n",
       "     'position': 2747.0,\n",
       "     'scode': '00',\n",
       "     'text': '기',\n",
       "     'type': 'ETN',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 43.0,\n",
       "     'end': 43.0,\n",
       "     'id': 42.0,\n",
       "     'position': 2747.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄹ',\n",
       "     'type': 'JKO',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 44.0,\n",
       "     'end': 45.0,\n",
       "     'id': 43.0,\n",
       "     'position': 2751.0,\n",
       "     'scode': '01',\n",
       "     'text': '기원하',\n",
       "     'type': 'VV',\n",
       "     'weight': 4.2},\n",
       "    {'begin': 46.0,\n",
       "     'end': 46.0,\n",
       "     'id': 44.0,\n",
       "     'position': 2757.0,\n",
       "     'scode': '00',\n",
       "     'text': 'ㄴ다고',\n",
       "     'type': 'EC',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 47.0,\n",
       "     'end': 48.0,\n",
       "     'id': 45.0,\n",
       "     'position': 2767.0,\n",
       "     'scode': '00',\n",
       "     'text': '말하',\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 49.0,\n",
       "     'end': 49.0,\n",
       "     'id': 46.0,\n",
       "     'position': 2770.0,\n",
       "     'scode': '00',\n",
       "     'text': '었',\n",
       "     'type': 'EP',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 50.0,\n",
       "     'end': 50.0,\n",
       "     'id': 47.0,\n",
       "     'position': 2773.0,\n",
       "     'scode': '00',\n",
       "     'text': '다',\n",
       "     'type': 'EF',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 51.0,\n",
       "     'end': 51.0,\n",
       "     'id': 48.0,\n",
       "     'position': 2776.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': 7.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [],\n",
       "     'text': '고양시관계자는',\n",
       "     'weight': 0.34617},\n",
       "    {'head': 2.0,\n",
       "     'id': 1.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '1959년생',\n",
       "     'weight': 0.107627},\n",
       "    {'head': 3.0,\n",
       "     'id': 2.0,\n",
       "     'label': 'VNP_MOD',\n",
       "     'mod': [1.0],\n",
       "     'text': '선배들인',\n",
       "     'weight': 0.545596},\n",
       "    {'head': 7.0,\n",
       "     'id': 3.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [2.0],\n",
       "     'text': '여섯분에게',\n",
       "     'weight': 0.622247},\n",
       "    {'head': 6.0,\n",
       "     'id': 4.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '많은',\n",
       "     'weight': 0.563028},\n",
       "    {'head': 6.0,\n",
       "     'id': 5.0,\n",
       "     'label': 'NP_CNJ',\n",
       "     'mod': [],\n",
       "     'text': '감사와',\n",
       "     'weight': 0.69863},\n",
       "    {'head': 7.0,\n",
       "     'id': 6.0,\n",
       "     'label': 'NP_OBJ',\n",
       "     'mod': [4.0, 5.0],\n",
       "     'text': '응원을',\n",
       "     'weight': 0.694341},\n",
       "    {'head': 12.0,\n",
       "     'id': 7.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [0.0, 3.0, 6.0],\n",
       "     'text': '드린다며',\n",
       "     'weight': 0.627472},\n",
       "    {'head': 12.0,\n",
       "     'id': 8.0,\n",
       "     'label': 'AP',\n",
       "     'mod': [],\n",
       "     'text': '이제',\n",
       "     'weight': 0.625879},\n",
       "    {'head': 10.0,\n",
       "     'id': 9.0,\n",
       "     'label': 'NP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '고양시의',\n",
       "     'weight': 0.639676},\n",
       "    {'head': 12.0,\n",
       "     'id': 10.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [9.0],\n",
       "     'text': '다음일은',\n",
       "     'weight': 0.364868},\n",
       "    {'head': 12.0,\n",
       "     'id': 11.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [],\n",
       "     'text': '후배들에게',\n",
       "     'weight': 0.795805},\n",
       "    {'head': 18.0,\n",
       "     'id': 12.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [7.0, 8.0, 10.0, 11.0],\n",
       "     'text': '맡기고',\n",
       "     'weight': 0.769874},\n",
       "    {'head': 14.0,\n",
       "     'id': 13.0,\n",
       "     'label': 'VP_MOD',\n",
       "     'mod': [],\n",
       "     'text': '새로운',\n",
       "     'weight': 0.646145},\n",
       "    {'head': 18.0,\n",
       "     'id': 14.0,\n",
       "     'label': 'NP_AJT',\n",
       "     'mod': [13.0],\n",
       "     'text': '인생에서',\n",
       "     'weight': 0.685025},\n",
       "    {'head': 18.0,\n",
       "     'id': 15.0,\n",
       "     'label': 'AP',\n",
       "     'mod': [],\n",
       "     'text': '또',\n",
       "     'weight': 0.72095},\n",
       "    {'head': 17.0,\n",
       "     'id': 16.0,\n",
       "     'label': 'DP',\n",
       "     'mod': [],\n",
       "     'text': '다른',\n",
       "     'weight': 0.470583},\n",
       "    {'head': 18.0,\n",
       "     'id': 17.0,\n",
       "     'label': 'NP_SBJ',\n",
       "     'mod': [16.0],\n",
       "     'text': '성공이',\n",
       "     'weight': 0.677345},\n",
       "    {'head': 19.0,\n",
       "     'id': 18.0,\n",
       "     'label': 'VP_OBJ',\n",
       "     'mod': [12.0, 14.0, 15.0, 17.0],\n",
       "     'text': '있길',\n",
       "     'weight': 0.538848},\n",
       "    {'head': 20.0,\n",
       "     'id': 19.0,\n",
       "     'label': 'VP_CMP',\n",
       "     'mod': [18.0],\n",
       "     'text': '기원한다고',\n",
       "     'weight': 0.735022},\n",
       "    {'head': -1.0,\n",
       "     'id': 20.0,\n",
       "     'label': 'VP',\n",
       "     'mod': [19.0],\n",
       "     'text': '말했다.',\n",
       "     'weight': 5.35772e-06}],\n",
       "   'id': 17.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '고양시',\n",
       "     'position': 2539.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0536206},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '관계',\n",
       "     'position': 2548.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0813997},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '자',\n",
       "     'position': 2554.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0813997},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '는',\n",
       "     'position': 2557.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.0856465},\n",
       "    {'id': 4.0,\n",
       "     'lemma': '1959',\n",
       "     'position': 2561.0,\n",
       "     'type': 'SN',\n",
       "     'weight': 1.0},\n",
       "    {'id': 5.0,\n",
       "     'lemma': '년',\n",
       "     'position': 2565.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.0562885},\n",
       "    {'id': 6.0,\n",
       "     'lemma': '생',\n",
       "     'position': 2568.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0345796},\n",
       "    {'id': 7.0,\n",
       "     'lemma': '선배',\n",
       "     'position': 2572.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0903209},\n",
       "    {'id': 8.0,\n",
       "     'lemma': '들',\n",
       "     'position': 2578.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0527148},\n",
       "    {'id': 9.0,\n",
       "     'lemma': '이',\n",
       "     'position': 2581.0,\n",
       "     'type': 'VCP',\n",
       "     'weight': 0.0358219},\n",
       "    {'id': 10.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 2581.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0358219},\n",
       "    {'id': 11.0,\n",
       "     'lemma': '여섯',\n",
       "     'position': 2585.0,\n",
       "     'type': 'NR',\n",
       "     'weight': 0.0531325},\n",
       "    {'id': 12.0,\n",
       "     'lemma': '분',\n",
       "     'position': 2591.0,\n",
       "     'type': 'NNB',\n",
       "     'weight': 0.0457801},\n",
       "    {'id': 13.0,\n",
       "     'lemma': '에게',\n",
       "     'position': 2594.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.055368},\n",
       "    {'id': 14.0,\n",
       "     'lemma': '많',\n",
       "     'position': 2601.0,\n",
       "     'type': 'VA',\n",
       "     'weight': 0.171662},\n",
       "    {'id': 15.0,\n",
       "     'lemma': '은',\n",
       "     'position': 2604.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0921806},\n",
       "    {'id': 16.0,\n",
       "     'lemma': '감사',\n",
       "     'position': 2608.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.141198},\n",
       "    {'id': 17.0,\n",
       "     'lemma': '와',\n",
       "     'position': 2614.0,\n",
       "     'type': 'JC',\n",
       "     'weight': 0.0553306},\n",
       "    {'id': 18.0,\n",
       "     'lemma': '응원',\n",
       "     'position': 2618.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0887637},\n",
       "    {'id': 19.0,\n",
       "     'lemma': '을',\n",
       "     'position': 2624.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0974475},\n",
       "    {'id': 20.0,\n",
       "     'lemma': '드리',\n",
       "     'position': 2628.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0506935},\n",
       "    {'id': 21.0,\n",
       "     'lemma': 'ㄴ다며',\n",
       "     'position': 2631.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0452142},\n",
       "    {'id': 22.0,\n",
       "     'lemma': '이제',\n",
       "     'position': 2641.0,\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.0792857},\n",
       "    {'id': 23.0,\n",
       "     'lemma': '고양시',\n",
       "     'position': 2648.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0602277},\n",
       "    {'id': 24.0,\n",
       "     'lemma': '의',\n",
       "     'position': 2657.0,\n",
       "     'type': 'JKG',\n",
       "     'weight': 0.0843952},\n",
       "    {'id': 25.0,\n",
       "     'lemma': '다음',\n",
       "     'position': 2661.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0680206},\n",
       "    {'id': 26.0,\n",
       "     'lemma': '일',\n",
       "     'position': 2667.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.024656},\n",
       "    {'id': 27.0,\n",
       "     'lemma': '은',\n",
       "     'position': 2670.0,\n",
       "     'type': 'JX',\n",
       "     'weight': 0.0773276},\n",
       "    {'id': 28.0,\n",
       "     'lemma': '후배',\n",
       "     'position': 2674.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0751073},\n",
       "    {'id': 29.0,\n",
       "     'lemma': '들',\n",
       "     'position': 2680.0,\n",
       "     'type': 'XSN',\n",
       "     'weight': 0.0750811},\n",
       "    {'id': 30.0,\n",
       "     'lemma': '에게',\n",
       "     'position': 2683.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0750384},\n",
       "    {'id': 31.0,\n",
       "     'lemma': '맡기',\n",
       "     'position': 2690.0,\n",
       "     'type': 'VV',\n",
       "     'weight': 0.0830628},\n",
       "    {'id': 32.0,\n",
       "     'lemma': '고',\n",
       "     'position': 2696.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.0852899},\n",
       "    {'id': 33.0,\n",
       "     'lemma': '새롭',\n",
       "     'position': 2700.0,\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0696052},\n",
       "    {'id': 34.0,\n",
       "     'lemma': 'ㄴ',\n",
       "     'position': 2706.0,\n",
       "     'type': 'ETM',\n",
       "     'weight': 0.0822032},\n",
       "    {'id': 35.0,\n",
       "     'lemma': '인생',\n",
       "     'position': 2710.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.100384},\n",
       "    {'id': 36.0,\n",
       "     'lemma': '에서',\n",
       "     'position': 2716.0,\n",
       "     'type': 'JKB',\n",
       "     'weight': 0.0829839},\n",
       "    {'id': 37.0,\n",
       "     'lemma': '또',\n",
       "     'position': 2723.0,\n",
       "     'type': 'MAG',\n",
       "     'weight': 0.150624},\n",
       "    {'id': 38.0,\n",
       "     'lemma': '다른',\n",
       "     'position': 2727.0,\n",
       "     'type': 'MM',\n",
       "     'weight': 0.084338},\n",
       "    {'id': 39.0,\n",
       "     'lemma': '성공',\n",
       "     'position': 2734.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0869531},\n",
       "    {'id': 40.0,\n",
       "     'lemma': '이',\n",
       "     'position': 2740.0,\n",
       "     'type': 'JKS',\n",
       "     'weight': 0.0963478},\n",
       "    {'id': 41.0,\n",
       "     'lemma': '있',\n",
       "     'position': 2744.0,\n",
       "     'type': 'VA',\n",
       "     'weight': 0.0887464},\n",
       "    {'id': 42.0,\n",
       "     'lemma': '기',\n",
       "     'position': 2747.0,\n",
       "     'type': 'ETN',\n",
       "     'weight': 0.0485912},\n",
       "    {'id': 43.0,\n",
       "     'lemma': 'ㄹ',\n",
       "     'position': 2747.0,\n",
       "     'type': 'JKO',\n",
       "     'weight': 0.0485912},\n",
       "    {'id': 44.0,\n",
       "     'lemma': '기원',\n",
       "     'position': 2751.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0447122},\n",
       "    {'id': 45.0,\n",
       "     'lemma': '하',\n",
       "     'position': 2757.0,\n",
       "     'type': 'XSV',\n",
       "     'weight': 0.0447122},\n",
       "    {'id': 46.0,\n",
       "     'lemma': 'ㄴ다고',\n",
       "     'position': 2757.0,\n",
       "     'type': 'EC',\n",
       "     'weight': 0.060314},\n",
       "    {'id': 47.0,\n",
       "     'lemma': '말',\n",
       "     'position': 2767.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0681178},\n",
       "    {'id': 48.0,\n",
       "     'lemma': '하',\n",
       "     'position': 2770.0,\n",
       "     'type': 'XSV',\n",
       "     'weight': 0.0464244},\n",
       "    {'id': 49.0,\n",
       "     'lemma': '었',\n",
       "     'position': 2770.0,\n",
       "     'type': 'EP',\n",
       "     'weight': 0.0464244},\n",
       "    {'id': 50.0,\n",
       "     'lemma': '다',\n",
       "     'position': 2773.0,\n",
       "     'type': 'EF',\n",
       "     'weight': 0.0914048},\n",
       "    {'id': 51.0,\n",
       "     'lemma': '.',\n",
       "     'position': 2776.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': ' 고양시관계자는 1959년생 선배들인 여섯분에게 많은 감사와 응원을 드린다며 이제 고양시의 다음일은 후배들에게 맡기고 새로운 인생에서 또 다른 성공이 있길 기원한다고 말했다.',\n",
       "   'word': [{'begin': 0.0,\n",
       "     'end': 3.0,\n",
       "     'id': 0.0,\n",
       "     'text': '고양시관계자는',\n",
       "     'type': ''},\n",
       "    {'begin': 4.0, 'end': 6.0, 'id': 1.0, 'text': '1959년생', 'type': ''},\n",
       "    {'begin': 7.0, 'end': 10.0, 'id': 2.0, 'text': '선배들인', 'type': ''},\n",
       "    {'begin': 11.0, 'end': 13.0, 'id': 3.0, 'text': '여섯분에게', 'type': ''},\n",
       "    {'begin': 14.0, 'end': 15.0, 'id': 4.0, 'text': '많은', 'type': ''},\n",
       "    {'begin': 16.0, 'end': 17.0, 'id': 5.0, 'text': '감사와', 'type': ''},\n",
       "    {'begin': 18.0, 'end': 19.0, 'id': 6.0, 'text': '응원을', 'type': ''},\n",
       "    {'begin': 20.0, 'end': 21.0, 'id': 7.0, 'text': '드린다며', 'type': ''},\n",
       "    {'begin': 22.0, 'end': 22.0, 'id': 8.0, 'text': '이제', 'type': ''},\n",
       "    {'begin': 23.0, 'end': 24.0, 'id': 9.0, 'text': '고양시의', 'type': ''},\n",
       "    {'begin': 25.0, 'end': 27.0, 'id': 10.0, 'text': '다음일은', 'type': ''},\n",
       "    {'begin': 28.0, 'end': 30.0, 'id': 11.0, 'text': '후배들에게', 'type': ''},\n",
       "    {'begin': 31.0, 'end': 32.0, 'id': 12.0, 'text': '맡기고', 'type': ''},\n",
       "    {'begin': 33.0, 'end': 34.0, 'id': 13.0, 'text': '새로운', 'type': ''},\n",
       "    {'begin': 35.0, 'end': 36.0, 'id': 14.0, 'text': '인생에서', 'type': ''},\n",
       "    {'begin': 37.0, 'end': 37.0, 'id': 15.0, 'text': '또', 'type': ''},\n",
       "    {'begin': 38.0, 'end': 38.0, 'id': 16.0, 'text': '다른', 'type': ''},\n",
       "    {'begin': 39.0, 'end': 40.0, 'id': 17.0, 'text': '성공이', 'type': ''},\n",
       "    {'begin': 41.0, 'end': 43.0, 'id': 18.0, 'text': '있길', 'type': ''},\n",
       "    {'begin': 44.0, 'end': 46.0, 'id': 19.0, 'text': '기원한다고', 'type': ''},\n",
       "    {'begin': 47.0, 'end': 51.0, 'id': 20.0, 'text': '말했다.', 'type': ''}]},\n",
       "  {'NE': [{'begin': 0.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'text': '고양유제원',\n",
       "     'type': 'LCP_CITY',\n",
       "     'weight': 0.138113},\n",
       "    {'begin': 1.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'text': '송주현',\n",
       "     'type': 'PS_NAME',\n",
       "     'weight': 0.449072},\n",
       "    {'begin': 2.0,\n",
       "     'common_noun': 0.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'text': '기자',\n",
       "     'type': 'CV_OCCUPATION',\n",
       "     'weight': 0.473491}],\n",
       "   'NE_Link': [],\n",
       "   'SRL': [],\n",
       "   'WSD': [{'begin': 0.0,\n",
       "     'end': 0.0,\n",
       "     'id': 0.0,\n",
       "     'position': 2778.0,\n",
       "     'scode': '00',\n",
       "     'text': '고양유제원',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 1.0,\n",
       "     'end': 1.0,\n",
       "     'id': 1.0,\n",
       "     'position': 2793.0,\n",
       "     'scode': '00',\n",
       "     'text': '송주현',\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0},\n",
       "    {'begin': 2.0,\n",
       "     'end': 2.0,\n",
       "     'id': 2.0,\n",
       "     'position': 2802.0,\n",
       "     'scode': '05',\n",
       "     'text': '기자',\n",
       "     'type': 'NNG',\n",
       "     'weight': 1.0},\n",
       "    {'begin': 3.0,\n",
       "     'end': 3.0,\n",
       "     'id': 3.0,\n",
       "     'position': 2808.0,\n",
       "     'scode': '00',\n",
       "     'text': '.',\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'dependency': [{'head': -1.0,\n",
       "     'id': 0.0,\n",
       "     'label': 'NP',\n",
       "     'mod': [],\n",
       "     'text': '고양유제원송주현기자.',\n",
       "     'weight': 0.263873}],\n",
       "   'id': 18.0,\n",
       "   'morp': [{'id': 0.0,\n",
       "     'lemma': '고양유제원',\n",
       "     'position': 2778.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0242117},\n",
       "    {'id': 1.0,\n",
       "     'lemma': '송주현',\n",
       "     'position': 2793.0,\n",
       "     'type': 'NNP',\n",
       "     'weight': 0.0229775},\n",
       "    {'id': 2.0,\n",
       "     'lemma': '기자',\n",
       "     'position': 2802.0,\n",
       "     'type': 'NNG',\n",
       "     'weight': 0.0278239},\n",
       "    {'id': 3.0,\n",
       "     'lemma': '.',\n",
       "     'position': 2808.0,\n",
       "     'type': 'SF',\n",
       "     'weight': 1.0}],\n",
       "   'reserve_str': '',\n",
       "   'text': ' 고양유제원송주현기자. ',\n",
       "   'word': [{'begin': 0.0,\n",
       "     'end': 3.0,\n",
       "     'id': 0.0,\n",
       "     'text': '고양유제원송주현기자.',\n",
       "     'type': ''}]}],\n",
       " 'title': {'NE': '', 'text': ''}}"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_return_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gm7hgaDoKfUT",
    "outputId": "7ed9a0ec-8914-40b3-b470-36fe7c8a93b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_lang2(api_key, df['content1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2EeOISVHAF9"
   },
   "outputs": [],
   "source": [
    "depend_list = ['SBJ', 'OBJ', 'VP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8weltloXHAKz"
   },
   "outputs": [],
   "source": [
    "ls = []\n",
    "\n",
    "lt = ['SBJ', 'OBJ', 'SSS', 'VIP']\n",
    "\n",
    "for element in lt:\n",
    "  if element == 'SBJ':\n",
    "    ls.append(element)\n",
    "    pass\n",
    "  \n",
    "  elif element == 'OBJ':\n",
    "    ls.append(element)\n",
    "    pass\n",
    "\n",
    "  elif element == 'VP':\n",
    "    ls.append(element)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r0QXO3cHHADQ",
    "outputId": "8aefdfeb-acbe-421f-8734-b38c251609d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SBJ', 'OBJ']"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCArvmDLIrMv"
   },
   "outputs": [],
   "source": [
    "lsls = []\n",
    "for element in lt:\n",
    "  if element in depend_list:\n",
    "    lsls.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "khv_vjlaI2pE",
    "outputId": "67e57ec1-6347-4e7d-d009-ffa7f59e1da8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SBJ', 'OBJ']"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ziH78D3uJDZl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tokenizing_zeropadding",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05cbb615c88d4c1db69d618835b76a01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc9c88d7d40f4fbeb04caeba39ba0bde",
      "placeholder": "​",
      "style": "IPY_MODEL_70cf344a34a94f239ae84259054a94d0",
      "value": " 371k/371k [00:00&lt;00:00, 417kB/s]"
     }
    },
    "06caa90078164dcdb1975cf359534caa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07bcb4a3d2b24237b3ac23e3fcc8d8ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0834455e82164704ae7bf7213bb34738": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0e6142df085342eba8fb131a6781b286": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e76951c143df4ece837dcb8751ea6030",
      "max": 371391,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0834455e82164704ae7bf7213bb34738",
      "value": 371391
     }
    },
    "10611e4df18f4fa7b71239e2673cf6c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06caa90078164dcdb1975cf359534caa",
      "placeholder": "​",
      "style": "IPY_MODEL_07bcb4a3d2b24237b3ac23e3fcc8d8ac",
      "value": " 426/426 [00:00&lt;00:00, 538B/s]"
     }
    },
    "1738a6c11b0a47d69dade4d9b932643e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "244f5d58c1ad4d2d858acaa35253182c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "24ff8eae473d4b748a3fbf851e88bf44": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2936c6a120cd408886668a0cfa5bc104": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24ff8eae473d4b748a3fbf851e88bf44",
      "max": 426,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5c181b3b6a34448e8fcb20d10d90f4b4",
      "value": 426
     }
    },
    "37fdd6b591274c78a53b00bf7e2523e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1738a6c11b0a47d69dade4d9b932643e",
      "placeholder": "​",
      "style": "IPY_MODEL_431b8d54fbf94c7f98b775a4c6a8a1d0",
      "value": " 77.8k/77.8k [00:24&lt;00:00, 3.21kB/s]"
     }
    },
    "431b8d54fbf94c7f98b775a4c6a8a1d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43b176cc11784880889e17c2c6568721": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b3220312556d4530afd92a94d04ab038",
       "IPY_MODEL_37fdd6b591274c78a53b00bf7e2523e1"
      ],
      "layout": "IPY_MODEL_cea3abb6dd4948ce887de40ada21fc1d"
     }
    },
    "5209d984217747dea7f10d4159470ae8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53aaf732d70b411f8339f69d9931b72c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2936c6a120cd408886668a0cfa5bc104",
       "IPY_MODEL_10611e4df18f4fa7b71239e2673cf6c6"
      ],
      "layout": "IPY_MODEL_bb86a7c4a255439396f12e6c508575f4"
     }
    },
    "55dae1efed9d481c9ad209fcff827b2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "56c271355ec84deea236bedf2d260f15": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c181b3b6a34448e8fcb20d10d90f4b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "70a43b0bf75d42e7a826d51ef008839d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f97788f302d54ee9a1f5bfa4821cb25d",
       "IPY_MODEL_9c0ed2056f624347ba44eab8c9f1625a"
      ],
      "layout": "IPY_MODEL_8f0e56f9f7db45ae83636b1c24fed99a"
     }
    },
    "70cf344a34a94f239ae84259054a94d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e0967c2f08b4377a6aedc6672575ede": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8f0e56f9f7db45ae83636b1c24fed99a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c0ed2056f624347ba44eab8c9f1625a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b30d3815a92447428f765fb2dd73ee70",
      "placeholder": "​",
      "style": "IPY_MODEL_55dae1efed9d481c9ad209fcff827b2c",
      "value": " 369M/369M [00:05&lt;00:00, 72.0MB/s]"
     }
    },
    "b30d3815a92447428f765fb2dd73ee70": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3220312556d4530afd92a94d04ab038": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56c271355ec84deea236bedf2d260f15",
      "max": 77779,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_244f5d58c1ad4d2d858acaa35253182c",
      "value": 77779
     }
    },
    "bb86a7c4a255439396f12e6c508575f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc9c88d7d40f4fbeb04caeba39ba0bde": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cea3abb6dd4948ce887de40ada21fc1d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4e63a59106a41fa9220a6bc87879467": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e76951c143df4ece837dcb8751ea6030": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec57e59e25d248e7970d95131ae46b3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0e6142df085342eba8fb131a6781b286",
       "IPY_MODEL_05cbb615c88d4c1db69d618835b76a01"
      ],
      "layout": "IPY_MODEL_5209d984217747dea7f10d4159470ae8"
     }
    },
    "f97788f302d54ee9a1f5bfa4821cb25d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4e63a59106a41fa9220a6bc87879467",
      "max": 368792146,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e0967c2f08b4377a6aedc6672575ede",
      "value": 368792146
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
