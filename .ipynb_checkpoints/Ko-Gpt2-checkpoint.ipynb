{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpFBzQnFcOWH"
   },
   "source": [
    "### Ko-Gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jgPcbE1cS2t"
   },
   "outputs": [],
   "source": [
    "!pip install gluonnlp\n",
    "!pip install transformers\n",
    "!pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "8vCpC2Muywzm",
    "outputId": "8dd4bd4a-87dc-4480-fe31-675090a25f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rE3iYxsVGvfm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import gluonnlp as nlp\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from transformers import *\n",
    "from kogpt2.pytorch_kogpt2 import get_pytorch_kogpt2_model\n",
    "from kogpt2.utils import get_tokenizer\n",
    "from gluonnlp.data import SentencepieceTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wRcw-I9urxp"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_AFmzbJwr-53"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buItlI-XtFsL"
   },
   "outputs": [],
   "source": [
    "import numpy as np; np.random.seed(1234)\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('/content/gdrive/My Drive/labeled_0825_924.xlsx')\n",
    "data = data[['a_num','content','inform']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHnuAmd5tJz1"
   },
   "outputs": [],
   "source": [
    "\n",
    "ntrain = 800\n",
    "\n",
    "trn, tst = data[:ntrain], data[ntrain:]\n",
    "\n",
    "header = 'a_num depend quality'.split()\n",
    "trn.to_csv('ratings_train.txt', sep='\\t', index=False, header=header)\n",
    "tst.to_csv('ratings_test.txt', sep='\\t', index=False, header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQjHElLmKGeS"
   },
   "outputs": [],
   "source": [
    "dataset_train = nlp.data.TSVDataset(\"ratings_train.txt\", field_indices=[1,2], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(\"ratings_test.txt\", field_indices=[1,2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "DDyuasyEKLI2",
    "outputId": "ce65e2fb-7a62-4ae9-bc9a-109c6e119518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "tok_path = get_tokenizer()\n",
    "model_gpt, vocab, config = get_pytorch_kogpt2_model()\n",
    "tok = nlp.data.BERTSPTokenizer(tok_path, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQwnDdCFLLXz"
   },
   "outputs": [],
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, gpt2,\n",
    "                 max_len, pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            gpt2, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgezpjybNR4n"
   },
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 512\n",
    "batch_size = 8\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYztFESeNSRe"
   },
   "outputs": [],
   "source": [
    "data_train = GPT2Dataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = GPT2Dataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbKNVjLWZj8S"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bW58WyjUqFfM"
   },
   "outputs": [],
   "source": [
    "# attention mask 삭제\n",
    "class GPT2Classifier(nn.Module):\n",
    "    def __init__(self, gpt2, hidden_size = 768, num_classes = 2, dr_rate = None, params = None):\n",
    "        super(GPT2Classifier, self).__init__()\n",
    "        self.gpt2 = gpt2 # pre_trained model\n",
    "        self.dr_rate = dr_rate\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p = dr_rate)\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "\n",
    "        _, hidden_output = self.gpt2(input_ids=token_ids, token_type_ids=segment_ids.long())\n",
    "        pooled_output = hidden_output[:,-1]\n",
    "        # pooler_output = pooler_out[0][:,-1] ## transformers 모듈을 사용할 경우\n",
    "\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooled_output)\n",
    "\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85lnX2qpGna8"
   },
   "outputs": [],
   "source": [
    "model = GPT2Classifier(model_gpt, dr_rate = 0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
